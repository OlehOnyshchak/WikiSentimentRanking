{
  "pages": [
    {
      "title": "Uniformly hyperfinite algebra",
      "url": "https://en.wikipedia.org/wiki/Uniformly_hyperfinite_algebra",
      "text": "In [[mathematics]], particularly in the theory of [[C*-algebras]], a '''uniformly hyperfinite''', or '''UHF''', algebra is a C*-algebra that can be written as the closure, in the [[Operator norm|norm topology]], of an increasing union of finite-dimensional full [[matrix ring|matrix algebras]].\n\n== Definition ==\n\nA UHF C*-algebra is the [[direct limit]] of an inductive system {''A<sub>n</sub>'', ''&phi;<sub>n</sub>''} where each ''A<sub>n</sub>'' is a finite-dimensional full matrix algebra and each ''&phi;<sub>n</sub>'' : ''A<sub>n</sub>'' &rarr; ''A''<sub>''n''+1</sub> is a unital embedding. Suppressing the connecting maps, one can write\n\n:<math>A = \\overline {\\cup_n A_n}.</math>\n\n== Classification ==\n\nIf\n\n:<math>A_n \\simeq M_{k_n} (\\mathbb C),</math>\n\nthen ''rk''<sub>''n''</sub> = ''k''<sub>''n'' + 1</sub> for some integer ''r'' and\n\n:<math>\\phi_n (a) = a \\otimes I_r,</math>\n\nwhere ''I<sub>r</sub>'' is the identity in the ''r'' &times; ''r'' matrices. The sequence ...''k<sub>n</sub>''|''k''<sub>''n'' + 1</sub>|''k''<sub>''n'' + 2</sub>... determines a formal product\n\n:<math>\\delta(A) = \\prod_p p^{t_p}</math>\n\nwhere each ''p'' is prime and ''t<sub>p</sub>'' = sup {''m'' &nbsp; | &nbsp; ''p<sup>m</sup>'' divides ''k<sub>n</sub> '' for some ''n''}, possibly zero or infinite. The formal product ''&delta;''(''A'') is said to be the [[supernatural number]] corresponding to ''A''.<ref name=Rordam00>{{cite book|last=Rørdam|first=M.|last2=Larsen|first2=F.|last3=Laustsen|first3=N.J.|title=An Introduction to K-Theory for C*-Algebras|year=2000|publisher=Cambridge University Press|location=Cambridge|isbn=0521789443}}</ref> [[James Glimm|Glimm]] showed that the supernatural number is a complete invariant of UHF C*-algebras.<ref name=glimm60>{{cite journal|last=Glimm|first=James G.|title=On a certain class of operator algebras|journal=Transactions of the American Mathematical Society|date=1 February 1960|volume=95|issue=2|pages=318–340|doi=10.1090/S0002-9947-1960-0112057-5|url=http://www.ams.org/journals/tran/1960-095-02/S0002-9947-1960-0112057-5/S0002-9947-1960-0112057-5.pdf|accessdate=2 March 2013}}</ref>  In particular, there are uncountably many isomorphism classes of UHF C*-algebras.\n\nIf ''&delta;''(''A'') is finite, then ''A'' is the full matrix algebra ''M''<sub>''&delta;''(''A'')</sub>. A UHF algebra is said to be of '''infinite type''' if each ''t<sub>p</sub>'' in ''&delta;''(''A'') is 0 or ∞.\n\nIn the language of [[K-theory]], each [[supernatural number]]\n\n:<math>\\delta(A) = \\prod_p p^{t_p}</math>\n\nspecifies an additive subgroup of '''Q''' that is the rational numbers of the type ''n''/''m'' where ''m'' formally divides ''&delta;''(''A''). This group is the [[Operator K-theory|''K''<sub>0</sub> group]] of ''A''. <ref name=Rordam00 />\n\n== CAR algebra ==\n\nOne example of a UHF C*-algebra is the [[CAR algebra]]. It is defined as follows: let ''H'' be a separable complex Hilbert space ''H'' with orthonormal basis ''f<sub>n</sub>'' and ''L''(''H'') the bounded operators on ''H'', consider a linear map\n\n:<math>\\alpha : H \\rightarrow L(H)</math>\n\nwith the property that\n\n:<math>\n\\{ \\alpha(f_n), \\alpha(f_m) \\} = 0 \\quad  \\mbox{and} \\quad \\alpha(f_n)^*\\alpha(f_m) + \\alpha(f_m)\\alpha(f_n)^* = \n\\langle f_m, f_n \\rangle I.\n</math>\n\nThe CAR algebra is the C*-algebra generated by\n\n:<math>\\{ \\alpha(f_n) \\}\\;.</math>\n\nThe embedding\n\n:<math>C^*(\\alpha(f_1), \\cdots, \\alpha(f_n)) \\hookrightarrow  C^*(\\alpha(f_1), \\cdots, \\alpha(f_{n+1}))</math>\n\ncan be identified with the multiplicity 2 embedding\n\n:<math>M_{2^n} \\hookrightarrow M_{2^{n+1}}.</math>\n\nTherefore, the CAR algebra has supernatural number 2<sup>∞</sup>.<ref name=\"Davidson97\">{{cite book|last=Davidson|first=Kenneth|authorlink=Kenneth Davidson (mathematician)|title=C*-Algebras by Example|year=1997|publisher=Fields Institute|isbn=0-8218-0599-1|pages=166, 218–219, 234}}</ref> This identification also yields that its ''K''<sub>0</sub> group is the [[dyadic rational]]s.\n\n== References ==\n<references />\n\n[[Category:C*-algebras]]"
    },
    {
      "title": "Unital map",
      "url": "https://en.wikipedia.org/wiki/Unital_map",
      "text": "{{Short description|Mapping preserving identity}}{{unreferenced|date=October 2010}}\nIn [[abstract algebra]], a '''unital map''' on a [[C*-algebra]] is a map <math>\\phi</math> which preserves the identity element:  \n\n:<math>\\phi ( I ) = I. </math>\n\nThis condition appears often in the context of [[completely positive map]]s, especially when they represent [[quantum operation]]s.  \n\nIf <math>\\phi</math> is completely positive, it can always be represented as \n\n:<math>\\phi ( \\rho ) = \\sum_i E_i \\rho E_i^\\dagger. </math>\n\n(The <math>E_i</math> are the [[Kraus operator]]s associated with <math>\\phi</math>).  In this case, the unital condition can be expressed as\n\n:<math>\\sum_i E_i E_i ^\\dagger= I. </math>\n\n[[Category:C*-algebras]]\n\n\n{{Mathanalysis-stub}}"
    },
    {
      "title": "Universal C*-algebra",
      "url": "https://en.wikipedia.org/wiki/Universal_C%2A-algebra",
      "text": "In [[mathematics]], a '''universal C*-algebra''' is a [[C*-algebra]] described in terms of generators and relations. In contrast to [[ring (mathematics)|rings]] or [[algebra over a field|algebras]], where one can consider [[quotient ring|quotients]] by [[free ring]]s to construct universal objects, C*-algebras must be realizable as algebras of bounded operators on a Hilbert space by the [[Gelfand-Naimark-Segal construction]] and the relations must prescribe a uniform bound on the norm of each generator. This means that depending on the generators and relations, a universal C*-algebra may not exist. In particular, free C*-algebras do not exist.\n\n== C*-Algebra Relations ==\n\nThere are several problems with defining relations for C*-algebras. One is, as previously mentioned, due to the non-existence of free C*-algebras, not every relation defines a C*-algebra. Another problem is that one would often want to include order relations, formulas involving [[continuous functional calculus]], and spectral data as relations. For that reason, we use a relatively roundabout way of defining C*-algebra relations. The basic motivation behind the following definitions is that we will define relations as the [[category (mathematics)|category]] of their representations.\n\nGiven a set ''X'', the ''null C*-relation'' on ''X'' is the category <math>\\mathcal{F}_{X}</math> with objects consisting of pairs (''j'', ''A''), where ''A'' is a C*-algebra and ''j'' is a function from ''X'' to ''A'' and with morphisms from (''j'', ''A'') to (''k'', ''B'') consisting of *-homomorphisms φ from ''A'' to ''B'' satisfying φ ∘ ''j'' = ''k''. A ''C*-relation'' on ''X'' is a [[full subcategory]] of <math>\\mathcal{F}_{X}</math> satisfying:\n# the unique function ''X'' to {0} is an object;\n# given an injective *-homomorphism φ from ''A'' to ''B'' and a function ''f'' from ''X'' to ''A'', if φ ∘ ''f'' is an object, then ''f'' is an object;\n# given a *-homomorphism φ from ''A'' to ''B'' and a function ''f'' from ''X'' to ''A'', if ''f'' is an object, then φ ∘ ''f'' is an object;\n# if ''f''<sub>''i''</sub> is an object for ''i''=1,2,...,n, then <math>\\prod_{i=1}^{n} f_i: X\\to \\prod_{i=1}^{n} A_i</math> is also an object. Furthermore, if ''f''<sub>''i''</sub> is an object for ''i'' in an nonempty index set ''I'' implies the product <math>\\prod_{i\\in I} f_i : X \\to \\prod A_i</math> is also an object, then the C*-relation is ''compact''.\n\nGiven a C*-relation ''R'' on a set ''X''. then a function ι from ''X'' to a C*-algebra ''U'' is called a ''universal representation'' for ''R'' if\n# given a C*-algebra ''A'' and a *-homomorphism φ from ''U'' to ''A'', φ ∘ ι is an object of ''R'';\n# given a C*-algebra ''A'' and an object (''f'', ''A'') in ''R'', there exists a unique *-homomorphism φ from ''U'' to ''A'' such that ''f'' = φ ∘ ι. Notice that ι and ''U'' are unique up to isomorphism and ''U'' is called the ''universal C*-algebra for R''.\n\nA C*-relation ''R'' has a universal representation if and only if ''R'' is compact.\n\nGiven a *-polynomial ''p'' on a set ''X'', we can define a full subcategory of <math>\\mathcal{F}_{X}</math> with objects (''j'', ''A'') such that ''p'' ∘ ''j'' = 0. For convenience, we can call ''p'' a relation, and we can recover the classical concept of relations. Unfortunately, not every *-polynomial will define a compact C*-relation.\n<ref name=\"Loring10\">{{cite journal|last1=Loring|first1=Terry A.|title=C*-Algebra Relations|journal=Mathematica Scandinavica|date=1 September 2010|volume=107|issue=1|pages=43–72|url=http://www.mscand.dk/article/view/15142/13137|accessdate=27 March 2017|issn=1903-1807}}</ref>\n\n== Alternative Approach ==\n\nAlternatively, one can use a more concrete characterization of universal C*-algebras that more closely resembles the construction in abstract algebra. Unfortunately, this restricts the types of relations that are possible. Given a set ''G'', a ''relation'' on ''G'' is a set ''R'' consisting of pairs (''p'', η) where ''p'' is a *-polynomial on ''X'' and η is a non-negative real number. A ''representation'' of (''G'', ''R'') on a Hilbert space ''H'' is a function ρ from ''X'' to the algebra of bounded operators on ''H'' such that <math>\\lVert p\\circ \\rho(X) \\rVert \\leq \\eta</math> for all (''p'', η) in ''R''. The pair (''G'', ''R'') is called ''admissible'' if a representation exists and the direct sum of representations is also a representation. Then\n:<math>\\lVert z \\rVert_{u} = \\sup\\{ \\lVert \\rho(z)\\rVert \\colon \\rho \\text{ is a representation of } (G,R)\\}</math>\nis finite and defines a [[seminorm]] satisfying the C*-norm condition on the [[free algebra]] on ''X''. The completion of the quotient of the free algebra by the ideal <math>\\{ z \\colon \\lVert z \\rVert_{u} = 0\\}</math> is called the ''universal C*-algebra'' of (''G'',''R'').\n<ref name=\"Blackadar85\">{{cite journal|last1=Blackadar|first1=Bruce|title=Shape theory for $C^*$-algebras.|journal=Mathematica Scandinavica|date=1 December 1985|volume=56|issue=0|pages=249–275|url=http://www.mscand.dk/article/view/12100/10116|accessdate=27 March 2017|issn=1903-1807}}</ref>\n\n== Examples ==\n* The [[noncommutative torus]] can be defined as a universal C*-algebra generated by two unitaries with a certain commutation relation.\n* The [[Cuntz algebra]]s, [[graph C*-algebras]] and [[k-graph C*-algebras]] are universal C*-algebras generated by certain partial isometries.\n* The universal C*-algebra generated by a unitary element ''u'' has presentation <''u'' | ''u*u'' = ''uu*'' = 1>. By continuous functional calculus, this C*-algebra is the algebra of continuous functions on the unit circle in the complex plane. Any C*-algebra generated by a unitary element is isomorphic to a quotient of this universal C*-algebra.<ref name=\"Blackadar85\" />\n\n==References==\n{{Reflist}}\n\n*{{citation |first=T.|last=Loring |title=Lifting Solutions to Perturbing Problems in C*-Algebras  |volume=8 |series=[[Fields Institute Monographs]] | year=1997 |publisher=[[American Mathematical Society]] |isbn=0-8218-0602-5}}\n\n{{DEFAULTSORT:Universal C Algebra}}\n[[Category:C*-algebras]]"
    },
    {
      "title": "Universal representation (C*-algebra)",
      "url": "https://en.wikipedia.org/wiki/Universal_representation_%28C%2A-algebra%29",
      "text": "{{unreferenced|date=June 2015}}\n\nIn the theory of [[C*-algebra]]s, the '''universal representation''' of a C*-algebra is a faithful representation which is the direct sum of the [[Gelfand–Naimark–Segal construction#The GNS construction|GNS representations]] corresponding to the states of the C*-algebra. The various properties of the universal representation are used to obtain information about the ideals and quotients of the C*-algebra. The close relationship between an arbitrary representation of a C*-algebra and its universal representation can be exploited to obtain several criteria for determining whether a linear functional on the algebra is [[ultraweak topology|ultraweakly]] continuous. The method of using the properties of the universal representation as a tool to prove results about the C*-algebra and its representations is commonly referred to as ''universal representation techniques'' in the literature.\n\n==Formal definition and properties==\n:'''Definition.''' Let ''A'' be a C*-algebra with [[State (functional analysis)|state space]] ''S''. The representation\n::<math>\\Phi :=  \\sum_{\\rho \\in S} \\oplus \\; \\pi_\\rho</math>\n:on the Hilbert space <math>H_{\\Phi}</math> is known as the '''universal representation''' of ''A''.\n\nAs the universal representation is faithful, ''A'' is *-isomorphic to the C*-subalgebra Φ(''A'') of ''B(H<sub>Φ</sub>)''.\n\n===States of Φ(''A'')===\nWith τ a state of ''A'', let π<sub>τ</sub> denote the corresponding [[Gelfand–Naimark–Segal construction#The GNS construction|GNS representation]] on the Hilbert space ''H''<sub>τ</sub>. Using the notation defined [[State (functional analysis)#Vector states|here]], τ is ω<sub>''x''</sub> ∘ π<sub>τ</sub> for a suitable unit vector ''x''(=''x''<sub>τ</sub>) in ''H''<sub>τ</sub>. Thus τ is ω<sub>''y''</sub> ∘ Φ, where ''y'' is the unit vector ∑<sub>ρ∈''S''</sub> ⊕''y''<sub>ρ</sub> in ''H''<sub>Φ</sub>, defined by ''y''<sub>τ</sub>=x, ''y''<sub>ρ</sub>=0(ρ≠τ). Since the mapping τ → τ ∘ Φ<sup>−1</sup> takes the state space of ''A'' onto the state space of Φ(''A''), it follows that each state of Φ(''A'') is a [[State (functional analysis)#Vector states|vector state]].\n\n===Bounded functionals of Φ(''A'')===\nLet Φ(''A'')<sup>&minus;</sup> denote the weak-operator closure of Φ(''A'') in ''B(H<sub>Φ</sub>)''. Each bounded linear functional ρ on Φ(''A'') is weak-operator continuous and extends uniquely preserving norm, to a weak-operator continuous linear functional {{overline|ρ}} on the von Neumann algebra Φ(''A'')<sup>&minus;</sup>. If ρ is hermitian, or positive, the same is true of {{overline|ρ}}. The mapping ρ → {{overline|ρ}} is an isometric isomorphism from the dual space Φ(''A'')<sup>*</sup> onto the predual of  Φ(''A'')<sup>&minus;</sup>. As the set of linear functionals determining the weak topologies coincide,  the weak-operator topology on Φ(''A'')<sup>&minus;</sup> coincides with the ultraweak topology. Thus the weak-operator and ultraweak topologies on Φ(''A'') both coincide with the weak topology of Φ(''A'') obtained from its norm-dual as a Banach space.\n\n===Ideals of Φ(''A'')===\nIf ''K'' is a convex subset of Φ(''A''), the ultraweak closure of ''K'' (denoted by ''K''<sup>&minus;</sup>)coincides with the strong-operator, weak-operator closures of ''K'' in ''B(H<sub>Φ</sub>)''. The norm closure of ''K'' is Φ(''A'') ∩ ''K''<sup>&minus;</sup>. One can give a description of norm-closed left ideals in Φ(''A'') from the structure theory of ideals for von Neumann algebras, which is relatively much more simple. If ''K'' is a norm-closed left ideal in Φ(''A''), there is a projection ''E'' in Φ(''A'')<sup>&minus;</sup> such that \n: <math>K = \\Phi(A) \\cap \\Phi(A)^{-}E, K^{-} = \\Phi(A)^{-}E</math>\nIf ''K'' is a norm-closed two-sided ideal in Φ(''A''), ''E'' lies in the center of Φ(''A'')<sup>&minus;</sup>.\n\n===Representations of ''A''===\nIf π is a representation of ''A'', there is a projection ''P'' in the center of Φ(''A'')<sup>&minus;</sup> and a *-isomorphism α from the von Neumann algebra Φ(''A'')<sup>&minus;</sup>''P'' onto π(''A'')<sup>&minus;</sup> such that π(''a'') = α(Φ(''a'')''P'') for each ''a'' in ''A''. This can be conveniently captured in the [[commutative diagram]] below :\n\n:[[File:Univ rep diag.png|400px]]\nHere ψ is the map that sends ''a'' to ''aP'', α<sub>0</sub> denotes the restriction of α to Φ(''A'')''P'', ι denotes the inclusion map.\n\nAs α is ultraweakly bicontinuous, the same is true of α<sub>0</sub>. Moreover, ψ is ultraweakly continuous, and is a *-isomorphism if π is a faithful representation.\n\n===Ultraweakly continuous, and singular components===\nLet ''A'' be a C*-algebra acting on a Hilbert space ''H''. For ρ in ''A''<sup>*</sup> and ''S'' in Φ(''A'')<sup>&minus;</sup>, let ''S''ρ in ''A''<sup>*</sup> be defined by ''S''ρ(''a'') = {{overline|ρ∘Φ<sup>−1</sup>}}(Φ(''a'')S) for all ''a'' in ''A''. If ''P'' is the projection in the above commutative diagram when π:''A'' → ''B(H)'' is the inclusion mapping, then ρ in ''A''<sup>*</sup> is ultraweakly continuous if and only if ρ = ''P''ρ. A functional ρ in ''A''<sup>*</sup> is said to be '''singular''' if ''P''ρ = 0.\nEach ρ in ''A''<sup>*</sup> can be uniquely expressed in the form ρ=ρ<sub>u</sub>+ρ<sub>s</sub>, with ρ<sub>u</sub> ultraweakly continuous and ρ<sub>s</sub> singular. Moreover, ||ρ||=||ρ<sub>u</sub>||+||ρ<sub>s</sub>|| and if ρ is positive, or hermitian, the same is true of ρ<sub>u</sub>, ρ<sub>s</sub>.\n\n==Applications==\n\n===Christensen–Haagerup principle===\nLet ''f'' and ''g'' be continuous, real-valued functions on '''C'''<sup>4m</sup> and '''C'''<sup>4n</sup>, respectively, σ<sub>1</sub>, σ<sub>2</sub>, ..., σ<sub>m</sub> be ultraweakly continuous, linear functionals on a von Neumann algebra ''R'' acting on the Hilbert space ''H'', and ρ<sub>1</sub>, ρ<sub>2</sub>, ..., ρ<sub>n</sub> be bounded linear functionals on ''R'' such that, for each ''a'' in ''R'',\n:<math>f(\\sigma_1(a), \\sigma_1(a^*), \\sigma_1(aa^*), \\sigma_1(a^*a), \\cdots, \\sigma_m(a), \\sigma_m(a^*), \\sigma_m(aa^*), \\sigma_m(a^*a))</math>\n:<math> \\le g(\\rho_1(a), \\rho_1(a^*), \\rho_1(aa^*), \\rho_1(a^*a), \\cdots, \\rho_n(a), \\rho_n(a^*), \\rho_n(aa^*), \\rho_n(a^*a)).</math>\nThen the above inequality holds if each ρ<sub>j</sub> is replaced by its ultraweakly continuous component (ρ<sub>j</sub>)<sub>u</sub>.\n\n==See also==\n\n{{Empty section|date=June 2015}}\n\n==References==\n*[[Kadison, Richard]], ''Fundamentals of the Theory of Operator Algebras, Vol. I : Elementary Theory'', American Mathematical Society. {{ISBN|978-0821808191}}.\n*[[Kadison, Richard]], ''Fundamentals of the Theory of Operator Algebras, Vol. II : Advanced Theory'', American Mathematical Society. {{ISBN|978-0821808207}}.\n*{{citation\n | last = Kadison | first = Richard V. | authorlink = Richard Kadison\n | issue = 1\n | journal = Journal of Operator Theory\n | mr = 1277964\n | pages = 57–67\n | title = On an inequality of Haagerup–Pisier\n | url = http://www.theta.ro/jot/archive/1993-029-001/1993-029-001-004.html\n | volume = 29\n | year = 1993}}.\n\n{{DEFAULTSORT:Universal representation (C-algebra)}}\n[[Category:Operator algebras]]\n[[Category:C*-algebras]]"
    },
    {
      "title": "Wold's decomposition",
      "url": "https://en.wikipedia.org/wiki/Wold%27s_decomposition",
      "text": "{{otheruses4|the general mathematical result|the application to time series analysis|Wold's theorem}}\nIn [[mathematics]], particularly in [[operator theory]], '''Wold decomposition''' or '''Wold–von Neumann decomposition''', named after [[Herman Wold]] and [[John von Neumann]], is a classification theorem for [[isometry|isometric linear operator]]s on a given [[Hilbert space]]. It states that every isometry is a direct sum of copies of the [[unilateral shift]] and a [[unitary operator]].\n\nIn [[time series analysis]], the theorem implies that any [[Stationary process|stationary]] discrete-time [[stochastic process]] can be decomposed into a pair of uncorrelated processes, one deterministic, and the other being a [[moving average process]].\n\n== Details ==\n\nLet ''H'' be a Hilbert space, ''L''(''H'') be the bounded operators on ''H'', and ''V'' ∈ ''L''(''H'') be an isometry. The '''Wold decomposition''' states that every isometry ''V'' takes the form\n\n:<math>V = (\\oplus_{\\alpha \\in A} S) \\oplus U</math>\n\nfor some index set ''A'', where ''S'' is the [[unilateral shift]] on a Hilbert space ''H<sub>α</sub>'', and ''U'' is a unitary operator (possible vacuous). The family {''H<sub>α</sub>''} consists of isomorphic Hilbert spaces. \n\nA proof can be sketched as follows. Successive applications of ''V'' give a descending sequences of copies of ''H'' isomorphically embedded in itself:\n\n:<math>H = H \\supset V(H) \\supset V^2 (H) \\supset \\cdots = H_0 \\supset H_1 \\supset H_2 \\supset \\cdots, </math>\n\nwhere ''V''(''H'') denotes the range of ''V''. The above defined ''H''<sub>''i''</sub>&nbsp;=&nbsp;''V''<sup>''i''</sup>(''H''). If one defines\n\n:<math>M_i = H_i \\ominus H_{i+1} = V^i (H \\ominus V(H)) \\quad \\text{for} \\quad i \\geq 0 \\;,</math>\n\nthen\n\n:<math>H = (\\oplus_{i \\geq 0} M_i) \\oplus (\\cap_{i \\geq 0} H_i) = K_1 \\oplus K_2.</math>\n\nIt is clear that ''K''<sub>1</sub> and ''K''<sub>2</sub> are invariant subspaces of ''V''. \n\nSo ''V''(''K''<sub>2</sub>) = ''K''<sub>2</sub>. In other words, ''V'' restricted to ''K''<sub>2</sub> is a surjective isometry, i.e., a unitary operator ''U''.\n\nFurthermore, each ''M<sub>i</sub>'' is isomorphic to another, with ''V'' being an isomorphism between ''M<sub>i</sub>'' and ''M''<sub>''i''+1</sub>: ''V'' \"shifts\" ''M<sub>i</sub>'' to ''M''<sub>''i''+1</sub>. Suppose the dimension of each ''M<sub>i</sub>'' is some cardinal number ''α''. We see  that ''K''<sub>1</sub> can be written as a direct sum Hilbert spaces\n\n:<math>K_1 = \\oplus H_{\\alpha}</math>\n\nwhere each ''H<sub>α</sub>'' is an invariant subspaces of ''V'' and ''V'' restricted to each ''H<sub>α</sub>'' is the unilateral shift ''S''. Therefore\n\n:<math>V = V \\vert_{K_1} \\oplus V\\vert_{K_2} = (\\oplus_{\\alpha \\in A} S) \\oplus U,</math>\n\nwhich is a Wold decomposition of ''V''.\n\n=== Remarks ===\n\nIt is immediate from the Wold decomposition that the [[spectrum (functional analysis)|spectrum]] of any proper, i.e. non-unitary, isometry is the unit disk in the complex plane.\n\nAn isometry ''V'' is said to be '''pure''' if, in the notation of the above proof, ∩<sub>''i''≥0</sub> ''H''<sub>''i''</sub> = {0}. The '''multiplicity''' of a pure isometry ''V'' is the dimension of the kernel of ''V*'', i.e. the cardinality of the index set ''A'' in the Wold decomposition of ''V''. In other words, a pure isometry of multiplicity ''N'' takes the form\n\n:<math>V = \\oplus_{1 \\le \\alpha \\le N} S .</math>\n\nIn this terminology, the Wold decomposition expresses an isometry as a direct sum of a pure isometry and a unitary operator.\n\nA subspace ''M'' is called a [[wandering set|wandering subspace]] of ''V'' if ''V''<sup>''n''</sup>(''M'') ⊥ ''V''<sup>''m''</sup>(''M'') for all ''n'' ≠ ''m''. In particular, each ''M''<sub>''i''</sub> defined above is a wandering subspace of&nbsp;''V''.\n\n== A sequence of isometries ==\n{{Expand section|date=June 2008}}\nThe decomposition above can be generalized slightly to a sequence of isometries, indexed by the integers.\n\n== The C*-algebra generated by an isometry ==\n\nConsider an isometry ''V'' ∈ ''L''(''H''). Denote by ''C*''(''V'') the [[C*-algebra]] generated by ''V'', i.e. ''C*''(''V'') is the norm closure of polynomials in ''V'' and ''V*''. The Wold decomposition can be applied to characterize ''C*''(''V'').\n\nLet ''C''('''T''') be the continuous functions on the unit circle '''T'''. We recall that the C*-algebra ''C*''(''S'') generated by the unilateral shift ''S'' takes the following form\n\n:''C*''(''S'') = {''T''<sub>''f''</sub> + ''K'' | ''T''<sub>''f''</sub> is a [[Toeplitz operator]] with continuous symbol ''f'' &isin; ''C''('''T''') and ''K'' is a [[compact operator on Hilbert space|compact operator]]}.\n\nIn this identification, ''S'' = ''T''<sub>''z''</sub> where ''z'' is the identity function in ''C''('''T'''). The algebra ''C*''(''S'') is called the [[Toeplitz algebra]]. \n\n'''Theorem (Coburn)''' ''C*''(''V'') is isomorphic to the Toeplitz algebra and ''V'' is the isomorphic image of ''T<sub>z</sub>''.\n\nThe proof hinges on the connections with ''C''('''T'''), in the description of the Toeplitz algebra and that the spectrum of an unitary operator is contained in the circle '''T'''. \n\nThe following properties of the Toeplitz algebra will be needed:\n\n#<math>T_f + T_g = T_{f+g}.\\,</math>\n#<math> T_f ^* = T_{{\\bar f}} .</math>\n#The semicommutator <math>T_fT_g - T_{fg} \\,</math> is compact.\n\nThe Wold decomposition says that ''V'' is the direct sum of copies of ''T''<sub>''z''</sub> and then some unitary ''U'':\n\n:<math>V = (\\oplus_{\\alpha \\in A} T_z) \\oplus U.</math>\n\nSo we invoke the [[continuous functional calculus]] ''f'' → ''f''(''U''), and define\n\n:<math>\n\\Phi : C^*(S) \\rightarrow C^*(V) \\quad \\text{by} \\quad \\Phi(T_f + K) = \\oplus_{\\alpha \\in A} (T_f + K) \\oplus f(U).\n</math>\n\nOne can now verify Φ is an isomorphism that maps the unilateral shift to ''V'': \n\nBy property 1 above, Φ is linear. The map Φ is injective because ''T<sub>f</sub>'' is not compact for any non-zero ''f'' ∈ ''C''('''T''') and thus ''T<sub>f</sub>'' + ''K'' = 0 implies ''f'' = 0. Since the range of Φ is a C*-algebra, Φ is surjective by the minimality of ''C*''(''V''). Property 2 and the continuous functional calculus ensure that Φ preserves the *-operation. Finally, the semicommutator property shows that Φ is multiplicative. Therefore the theorem holds.\n\n== References ==\n* {{cite journal |first=L. |last=Coburn |title=The C*-algebra of an isometry |journal=[[Bulletin of the American Mathematical Society|Bull. Amer. Math. Soc.]] |volume=73 |issue=5 |year=1967 |pages=722–726 |doi=10.1090/S0002-9904-1967-11845-7 }}\n* {{cite book |first=T. |last=Constantinescu |title=Schur Parameters, Factorization and Dilation Problems |publisher=Birkhäuser |series=Operator Theory, Advances and Applications |volume=82 |year=1996 |isbn=3-7643-5285-X |url=https://books.google.com/books?id=aEwoy7k8ufcC }}\n* {{cite book |first=R. G. |last=Douglas |title=Banach Algebra Techniques in Operator Theory |publisher=Academic Press |year=1972 |isbn=0-12-221350-5 |url=https://books.google.com/books?id=_xvDk-mOiHIC }}\n* {{cite book |first=Marvin |last=Rosenblum |first2=James |last2=Rovnyak |title=Hardy Classes and Operator Theory |publisher=Oxford University Press |year=1985 |isbn=0-19-503591-7 |url=https://books.google.com/books?id=PchPAQAAIAAJ }}\n\n[[Category:Operator theory]]\n[[Category:Invariant subspaces]]\n[[Category:C*-algebras]]\n[[Category:Theorems in functional analysis]]\n\n[[de:Shiftoperator#Wold-Zerlegung]]"
    },
    {
      "title": "Finite von Neumann algebra",
      "url": "https://en.wikipedia.org/wiki/Finite_von_Neumann_algebra",
      "text": "In [[mathematics]], a '''finite von Neumann algebra''' is a [[von Neumann algebra]] in which every [[isometry]] is a [[unitary operator|unitary]]. In other words, for an operator ''V'' in a finite von Neumann algebra if <math>V^*V = I</math>, then <math>VV^* = I</math>. In terms of the [[von Neumann algebra#Comparison theory of projections|comparison theory of projections]], the identity operator is not (Murray-von Neumann) equivalent to any proper subprojection in the von Neumann algebra.\n\n==Properties==\nLet <math>\\mathcal{M}</math> denote a finite von Neumann algebra with [[Center (algebra)|center]] <math>\\mathcal{Z}</math>. One of the fundamental characterizing properties of finite von Neumann algebras is the existence of a center-valued trace. This is a [[von Neumann algebra#The predual|normal]] positive bounded map <math>\\tau : \\mathcal{M} \\to \\mathcal{Z}</math> with the properties:\n* <math>\\tau(AB) = \\tau(BA), A, B \\in \\mathcal{M}</math>,\n* if <math>A \\ge 0</math> and <math>\\tau(A) = 0</math> then <math>A = 0</math>,\n* <math>\\tau(C) = C</math> for <math>C \\in \\mathcal{Z}</math>,\n* <math>\\tau(CA) = C\\tau(A)</math> for <math>A \\in \\mathcal{M}</math> and <math>C \\in \\mathcal{Z}</math>.\n\n==Examples==\n\n===Finite-dimensional von Neumann algebras===\nThe finite-dimensional von Neumann algebras can be characterized using [[Joseph Wedderburn|Wedderburn]]'s theory of [[semisimple algebra]]s.\nLet '''C'''<sup>''n'' &times; ''n''</sup> be the ''n'' &times; ''n'' matrices with complex entries. A '''von Neumann algebra''' '''M''' is a self adjoint subalgebra in '''C'''<sup>''n'' &times; ''n''</sup> such that '''M''' contains the identity operator ''I'' in '''C'''<sup>''n'' &times; ''n''</sup>.\n\nEvery such '''M''' as defined above is a [[semisimple algebra]], i.e. it contains no nilpotent ideals. Suppose ''M'' ≠ 0 lies in a nilpotent ideal of '''M'''. Since ''M*'' ∈ '''M''' by assumption, we have ''M*M'', a positive semidefinite matrix, lies in that nilpotent ideal. This implies (''M*M'')<sup>''k''</sup> =  0 for some ''k''. So ''M*M'' = 0, i.e. ''M'' = 0.\n\nThe [[center (algebra)|center]] of a von Neumann algebra '''M''' will be denoted by ''Z''('''M'''). Since '''M''' is self-adjoint, ''Z''('''M''') is itself a (commutative) von Neumann algebra. A von Neumann algebra '''N''' is called a '''factor''' if ''Z''('''N''') is one-dimensional, that is, ''Z''('''N''') consists of multiples of the identity ''I''.\n\n'''Theorem''' Every finite-dimensional von Neumann algebra '''M''' is a direct sum of ''m'' factors, where ''m'' is the dimension of ''Z''('''M'''). \n\n'''Proof:''' By Wedderburn's theory of semisimple algebras, ''Z''('''M''') contains a finite orthogonal set of idempotents (projections) {''P<sub>i</sub>''} such that ''P<sub>i</sub>P<sub>j</sub>'' = 0 for ''i'' ≠ ''j'', Σ ''P<sub>i</sub>'' = ''I'', and\n\n:<math>\nZ(\\mathbf M) = \\bigoplus _i  Z(\\mathbf M) P_i </math>\n\nwhere each ''Z''('''M''''')P<sub>i</sub>'' is a commutative simple algebra. Every complex simple algebras is isomorphic to  \nthe full matrix algebra '''C'''<sup>''k'' &times; ''k''</sup> for some ''k''. But ''Z''('''M''''')P<sub>i</sub>'' is commutative, therefore one-dimensional.\n\nThe projections ''P<sub>i</sub>'' \"diagonalizes\" '''M''' in a natural way. For ''M'' ∈ '''M''', ''M'' can be uniquely decomposed into ''M'' = Σ ''MP<sub>i</sub>''. Therefore,\n\n:<math>{\\mathbf M} = \\bigoplus_i  {\\mathbf M} P_i .</math>\n\nOne can see that ''Z''('''M'''''P<sub>i</sub>'') = ''Z''('''M''''')P<sub>i</sub>''. So ''Z''('''M'''''P<sub>i</sub>'') is one-dimensional and each '''M'''''P<sub>i</sub>'' is a factor. This proves the claim.\n\nFor general von Neumann algebras, the direct sum is replaced by the [[direct integral]]. The above is a special case of the [[direct integral#Central decomposition|central decomposition of von Neumann algebras]].\n\n===Abelian von Neumann algebras===\n\n===Type <math>II_1</math> factors===\n\n\n\n==References==\n*{{cite book |title=Fundamentals of the Theory of Operator Algebras, Vol. II : Advanced Theory\n|first1=R. V.|last1=Kadison|first2=J. R.|last2=Ringrose\n|publisher=AMS|year=1997|isbn=978-0821808207|pages=676.}}\n\n*{{cite book |title=Finite von Neumann Algebras and Masas\n|first1=A. M.|last1=Sinclair|first2=R. R.|last2=Smith\n|publisher=Cambridge University Press|year=2008|isbn=978-0521719193|pages=410.}}\n\n{{DEFAULTSORT:Finite von Neumann Algebra}}\n[[Category:Linear algebra]]\n[[Category:Von Neumann algebras|*]]"
    },
    {
      "title": "Von Neumann algebra",
      "url": "https://en.wikipedia.org/wiki/Von_Neumann_algebra",
      "text": "<!--Do not add the lowercase template to this article.  \"Von\" in \"von Neumann\" is properly capitalized when it begins a sentence or an article title.-->\nIn [[mathematics]], a '''von Neumann algebra''' or '''W*-algebra''' is a [[*-algebra]] of [[Bounded linear operator|bounded operators]] on a [[Hilbert space]] that is [[Closed set|closed]] in the [[weak operator topology]] and contains the [[identity operator]]. It is a special type of [[C*-algebra]].\n\nVon Neumann algebras were originally introduced by [[John von Neumann]], motivated by his study of [[operator theory|single operator]]s, [[group representations]], [[ergodic theory]] and [[quantum mechanics]]. His [[von Neumann double commutant theorem|double commutant theorem]] shows that the [[Mathematical analysis|analytic]] definition is equivalent to a purely [[abstract algebra|algebraic]] definition as an algebra of symmetries.\n\nTwo basic examples of von Neumann algebras are as follows:\n*The ring <math>L^\\infty(\\mathbb R)</math> of [[essentially bounded]] [[measurable function]]s on the real line is a commutative von Neumann algebra, whose elements act as [[multiplication operator]]s by pointwise multiplication on the [[Hilbert space]] <math>L^2(\\mathbb R)</math> of [[square-integrable function]]s.\n*The algebra <math>\\mathcal B(\\mathcal H)</math> of all [[bounded operator]]s on a Hilbert space <math>\\mathcal H</math> is a von Neumann algebra, non-commutative if the Hilbert space has dimension at least <math>2</math>.\n\nVon Neumann algebras were first studied by {{harvtxt|von Neumann|1930}} in 1929; he and [[Francis Joseph Murray|Francis Murray]] developed the basic theory, under the original name of '''rings of operators''', in a series of papers written in the 1930s and 1940s ({{harvard citations|nb=yes|first=F.J.|last= Murray|first2= J. |last2=von Neumann |year=1936|year2=1937|year3=1943}}; {{harvard citations|nb=yes|first= J. |last=von Neumann |year1=1938|year2=1940|year3=1943|year4=1949}}), reprinted in the collected works of {{harvtxt|von Neumann|1961}}.\n\nIntroductory accounts of von Neumann algebras are given in the online notes of {{harvtxt|Jones|2003}} and {{harvtxt|Wassermann|1991}} and the books by {{harvtxt|Dixmier|1981}}, {{harvtxt|Schwartz|1967}}, {{harvtxt|Blackadar|2005}} and {{harvtxt|Sakai|1971}}. The three volume work by {{Harvtxt|Takesaki|1979}} gives an encyclopedic account of the theory. The book by {{harvtxt|Connes|1994}} discusses more advanced topics.\n\n==Definitions==\nThere are three common ways to define von Neumann algebras.\n\nThe first and most common way is to define them as [[weak operator topology|weakly closed]] [[*-algebra]]s of bounded operators (on a Hilbert space) containing the identity. In this definition the weak (operator) topology can be replaced by  many other [[operator topology|common topologies]] including the [[strong operator topology|strong]], [[ultrastrong topology|ultrastrong]] or [[ultraweak topology|ultraweak]] operator topologies. The *-algebras of bounded operators that are closed in the [[norm topology]] are [[C*-algebra]]s, so in particular any von Neumann algebra is a C*-algebra.\n\nThe second definition is that a von Neumann algebra is a subset of the bounded operators closed under [[Semigroup with involution|involution]] (the *-operation) and equal to its double [[commutant]], or equivalently the [[commutant]] of some subset closed under *. The [[von Neumann double commutant theorem]] {{harv|von Neumann|1930}} says that the first two definitions are equivalent.\n\nThe first two definitions describe a von Neumann algebra concretely as a set of operators acting on some given Hilbert space. {{harvtxt|Sakai|1971}} showed that von Neumann algebras can also be defined abstractly as C*-algebras that have a [[predual]]; in other words the von Neumann algebra, considered as a Banach space, is the dual of some other Banach space called the predual.  The predual of a von Neumann algebra is in fact unique up to isomorphism. Some authors use \"von Neumann algebra\" for the algebras together with a Hilbert space action, and \"W*-algebra\" for the abstract concept, so a von Neumann algebra is a W*-algebra together with a Hilbert space and a suitable faithful unital action on the Hilbert space. The concrete and abstract definitions of a von Neumann algebra are similar to the concrete and abstract definitions of a C*-algebra, which can be defined either as norm-closed *-algebras of operators on a Hilbert space, or as [[Banach *-algebra]]s such that ||''aa*''||=||''a''|| ||''a*''||.\n\n==Terminology==\nSome of the terminology in von Neumann algebra theory can be confusing, and the terms often have different meanings outside the subject.\n\n*A '''factor''' is a von Neumann algebra with trivial center, i.e. a center consisting only of scalar operators.\n*A [[Finite von Neumann algebra|'''finite''' von Neumann algebra]] is one which is the [[direct integral#Direct integrals of von Neumann algebras|direct integral]] of finite factors (meaning the von Neumann algebra has a faithful normal tracial state τ: M →ℂ, see http://perso.ens-lyon.fr/gaboriau/evenements/IHP-trimester/IHP-CIRM/Notes=Cyril=finite-vonNeumann.pdf).  Similarly, '''properly infinite''' von Neumann algebras are the direct integral of properly infinite factors.\n*A von Neumann algebra that acts on a separable Hilbert space is called '''separable'''.  Note that such algebras are rarely [[separable space|separable]] in the norm topology.\n*The von Neumann algebra '''generated''' by a set of bounded operators on a Hilbert space is the smallest von Neumann algebra containing all those operators.\n*The '''tensor product''' of two von Neumann algebras acting on two Hilbert spaces is defined to be the von Neumann algebra generated by their algebraic tensor product, considered as operators on the Hilbert space tensor product of the Hilbert spaces.\n\nBy [[forgetting (mathematics)|forgetting]] about the topology on a von Neumann algebra, we can consider it a (unital) [[star-algebra|*-algebra]], or just a ring. Von Neumann algebras are [[semihereditary ring|semihereditary]]: every finitely generated submodule of a projective module is itself projective. There have been several attempts to axiomatize the underlying rings of von Neumann algebras, including [[Baer *-ring]]s and [[AW* algebra]]s. The [[*-algebra]] of [[affiliated operator]]s of a finite von Neumann algebra is a [[von Neumann regular ring]]. (The von Neumann algebra itself is in general not von Neumann regular.)\n\n== Commutative von Neumann algebras ==\n{{Main article|Abelian von Neumann algebra}}\n\nThe relationship between [[commutative]] von Neumann algebras and [[measure space]]s is analogous to that between commutative [[C*-algebra]]s and [[locally compact]] [[Hausdorff space]]s.  Every commutative von Neumann algebra is isomorphic to [[Lp space|''L''<sup>∞</sup>]](''X'') for some measure space (''X'', μ) and conversely, for every σ-finite measure space ''X'', the *-algebra ''L''<sup>∞</sup>(''X'') is a von Neumann algebra.\n\nDue to this analogy, the theory of von Neumann algebras has been called noncommutative measure theory, while the theory of [[C*-algebra]]s is sometimes called [[noncommutative topology]] {{harv|Connes|1994}}.\n\n== Projections ==\nOperators ''E'' in a von Neumann algebra for which ''E'' = ''EE'' = ''E*'' are called '''projections'''; they are exactly the operators which give an orthogonal projection of ''H'' onto some closed subspace. A subspace of the Hilbert space ''H'' is said to '''belong to''' the von Neumann algebra ''M'' if it is the image of some projection in ''M''. This establishes a 1:1 correspondence between projections of ''M'' and subspaces that belong to ''M''. Informally these are the closed subspaces that can be described using elements of ''M'', or that ''M'' \"knows\" about.\n\nIt can be shown that the closure of the image of any operator in ''M'' and the kernel of any operator in ''M'' belongs to ''M''. Also, the closure of the image under an operator of ''M'' of any subspace belonging to ''M'' also belongs to ''M''.  (These results are a consequence of the [[polar decomposition]]).\n\n===Comparison theory of projections===\nThe basic theory of projections was worked out by {{harvtxt|Murray|von Neumann|1936}}. Two subspaces belonging to ''M'' are called ('''Murray–von Neumann''') '''equivalent''' if there is a partial isometry mapping the first isomorphically onto the other that is an element of the von Neumann algebra (informally, if ''M'' \"knows\" that the subspaces are isomorphic). This induces a natural [[equivalence relation]] on projections by defining ''E'' to be equivalent to ''F'' if the corresponding subspaces are equivalent, or in other words if there is a [[partial isometry]] of ''H'' that maps the image of ''E'' isometrically to the image of ''F'' and is an element of the von Neumann algebra. Another way of stating this is that ''E'' is equivalent to ''F'' if ''E=uu*'' and ''F=u*u'' for some partial isometry ''u'' in ''M''.\n\nThe equivalence relation ~ thus defined is additive in the following sense: Suppose ''E''<sub>1</sub> ~ ''F''<sub>1</sub> and ''E''<sub>2</sub> ~ ''F''<sub>2</sub>. If ''E''<sub>1</sub> ⊥ ''E''<sub>2</sub> and ''F''<sub>1</sub> ⊥ ''F''<sub>2</sub>, then  ''E''<sub>1</sub> + ''E''<sub>2</sub> ~ ''F''<sub>1</sub> + ''F''<sub>2</sub>. Additivity would ''not'' generally hold if one were to require unitary equivalence in the definition of ~, i.e. if we say ''E'' is equivalent to ''F'' if ''u*Eu'' = ''F'' for some unitary ''u''.\n\nThe subspaces belonging to ''M'' are partially ordered by inclusion, and this induces a partial order ≤ of projections. There is also a natural partial order on the set of ''equivalence classes'' of projections, induced by the partial order ≤ of projections. If ''M'' is a factor, ≤ is a total order on equivalence classes of projections, described in the section on traces below.\n\nA projection (or subspace belonging to ''M'') ''E'' is said to be a '''finite projection''' if there is no projection ''F'' &lt; ''E'' (meaning ''F'' &le; ''E''  and ''F'' &ne; ''E'') that is equivalent to ''E''.  For example, all finite-dimensional projections (or subspaces) are finite (since isometries between Hilbert spaces leave the dimension fixed), but the identity operator on an infinite-dimensional Hilbert space is not finite in the von Neumann algebra of all bounded operators on it, since it is isometrically isomorphic to a proper subset of itself. However it is possible for infinite dimensional subspaces to be finite.\n\nOrthogonal projections are noncommutative analogues of indicator functions in ''L''<sup>∞</sup>('''R'''). ''L''<sup>∞</sup>('''R''') is the ||·||<sub>∞</sub>-closure of the subspace generated by the indicator functions. Similarly, a von Neumann algebra is generated by its projections; this is a consequence of the [[Self-adjoint operator#Spectral theorem|spectral theorem for self-adjoint operators]].\n\nThe projections of a finite factor form a [[continuous geometry]].\n\n== Factors ==\nA von Neumann algebra ''N'' whose [[center (algebra)|center]] consists only of multiples of the identity operator is called a '''factor'''.  {{harvtxt|Von Neumann|1949}} showed that every von Neumann algebra on a separable Hilbert space is isomorphic to a [[direct integral]] of factors.  This decomposition is essentially unique.  Thus, the problem of classifying isomorphism classes of von Neumann algebras on separable Hilbert spaces can be reduced to that of classifying isomorphism classes of factors.\n\n{{harvtxt|Murray|von Neumann|1936}} showed that every factor has one of 3 types as described below.  The type classification can be extended to von Neumann algebras that are not factors, and a von Neumann algebra is of type X if it can be decomposed as a direct integral of type X factors;  for example, every commutative von Neumann algebra has type I<sub>1</sub>. Every von Neumann algebra can be written uniquely as a sum of von Neumann algebras of types I, II, and III.\n\nThere are several other ways to divide factors into classes that are sometimes used:\n\n* A factor is called '''discrete''' (or occasionally '''tame''')  if it has type I, and '''continuous''' (or occasionally '''wild''') if it has type II or III.\n* A factor is called '''semifinite''' if it has type I or II, and '''purely infinite''' if it has type  III.\n* A factor is called '''finite''' if the projection 1 is finite and '''properly infinite''' otherwise. Factors of types I and II may be either finite or properly infinite, but factors of type III are always properly infinite.\n\n===Type I factors===\nA factor is said to be of '''type I''' if there is a minimal projection ''E ≠ 0'', i.e. a projection ''E'' such that there is no other projection ''F'' with 0 < ''F'' < ''E''.  Any factor of type I is isomorphic to the von Neumann algebra of ''all'' bounded operators on some Hilbert space;  since there is one Hilbert space for every [[cardinal number]], isomorphism classes of factors of type I correspond exactly to the cardinal numbers.  Since many authors consider von Neumann algebras only on separable Hilbert spaces, it is customary to call the bounded operators on a Hilbert space of finite dimension ''n'' a factor of type I<sub>''n''</sub>, and the bounded operators on a separable infinite-dimensional Hilbert space, a factor of type I<sub>∞</sub>.\n\n===Type II factors===\nA factor is said to be of '''type II''' if there are no minimal projections but there are non-zero [[Von Neumann algebra#Comparison theory of projections|finite projections]]. This implies that every projection ''E'' can be “halved” in the sense that there are two projections ''F'' and ''G'' that are [[Von Neumann algebra#Comparison theory of projections|Murray–von Neumann equivalent]] and satisfy ''E'' = ''F'' + ''G''.  If the identity operator in a type II factor is finite, the factor is said to be of type II<sub>1</sub>; otherwise, it is said to be of type II<sub>∞</sub>.  The best understood factors of type II are the [[hyperfinite type II-1 factor|hyperfinite type II<sub>1</sub> factor]] and the [[hyperfinite type II-infinity factor|hyperfinite type II<sub>∞</sub> factor]], found by {{harvtxt|Murray|von Neumann|1936}}. These are the unique hyperfinite factors of types II<sub>1</sub> and  II<sub>∞</sub>; there are an uncountable number of other  factors of these types that are the subject of intensive study. {{harvtxt|Murray|von Neumann|1937}} proved the fundamental result that a factor of type II<sub>1</sub> has a unique finite tracial state,  and the set of traces of projections is [0,1].\n\nA factor of type II<sub>∞</sub> has a semifinite trace, unique up to rescaling, and the set of traces of projections is [0,∞]. The set of real numbers λ such that there is an automorphism rescaling the trace by a factor of λ is called the '''fundamental group''' of the type II<sub>∞</sub> factor.\n\nThe tensor product of a factor of type II<sub>1</sub> and an infinite type I factor has type II<sub>∞</sub>, and conversely any factor of  type II<sub>∞</sub> can be constructed like this. The '''fundamental group''' of a type II<sub>1</sub>  factor is defined to be the fundamental group of its tensor product with the infinite (separable) factor of type I. For many years it was an open problem to find a type II factor whose fundamental group was not the group of [[positive reals]], but [[Alain Connes|Connes]] then showed that the von Neumann group algebra of a countable discrete group with [[Kazhdan's property (T)]] (the trivial representation is isolated in the dual space), such as SL(3,'''Z'''),  has a countable fundamental group. Subsequently, [[Sorin Popa]] showed that the fundamental group can be trivial for certain groups, including the [[semidirect product]] of '''Z'''<sup>2</sup> by SL(2,'''Z''').\n\nAn example of a type II<sub>1</sub> factor is the von Neumann group algebra of a countable infinite discrete group such that every non-trivial conjugacy class is infinite.\n{{harvtxt|McDuff|1969}} found an uncountable family of such groups with non-isomorphic von Neumann group algebras, thus showing the existence of uncountably many different separable type II<sub>1</sub> factors.\n\n===Type III factors===\nLastly, '''type III''' factors are factors that do not contain any nonzero finite projections at all.  In their first paper {{harvtxt|Murray|von Neumann|1936}} were unable to decide whether or not they existed; the first examples were later found by {{harvtxt|von Neumann|1940}}. Since the identity operator is always infinite in those factors, they were sometimes called type III<sub>∞</sub> in the past, but recently that notation has been superseded by the notation III<sub>λ</sub>, where λ is a real number in the interval [0,1]. More precisely, if the Connes spectrum (of its modular group) is 1 then the factor is of type III<sub>0</sub>, if the Connes spectrum is all integral powers of λ for 0&nbsp;<&nbsp;λ&nbsp;<&nbsp;1, then the type is III<sub>λ</sub>, and if the Connes spectrum is all positive reals then the type is III<sub>1</sub>. (The Connes spectrum is a closed subgroup of the positive reals, so these are the only possibilities.) The only trace on type III factors takes value ∞ on all non-zero positive elements, and any two non-zero projections are equivalent. At one time type III factors were considered to be intractable objects, but [[Tomita–Takesaki theory]] has led to a good structure theory. In particular, any type III factor can be written in a canonical way as the [[crossed product]] of a type II<sub>∞</sub> factor and the real numbers.\n\n==The predual==\nAny von Neumann algebra ''M'' has a '''predual''' ''M''<sub>∗</sub>, which is the Banach space of all ultraweakly continuous linear functionals on ''M''. As the name suggests, ''M'' is (as a Banach space) the dual of its predual. The predual is unique in the sense that any other Banach space whose dual is ''M'' is canonically isomorphic to ''M''<sub>∗</sub>. {{harvtxt|Sakai|1971}} showed that the existence of a predual characterizes von Neumann algebras among C* algebras.\n\nThe definition of the predual given above seems to depend on the choice of Hilbert space that ''M'' acts on, as this determines the ultraweak topology. However the predual can also be defined without using the Hilbert space that ''M'' acts on, by defining it to be the space generated by  all positive '''normal''' linear functionals on ''M''.  (Here \"normal\" means that it preserves suprema when applied to increasing nets of self adjoint operators; or equivalently to increasing sequences of projections.)\n\nThe predual ''M''<sub>∗</sub> is a closed subspace of the dual ''M*'' (which consists of all norm-continuous linear functionals on ''M'') but is generally smaller. The proof that ''M''<sub>∗</sub> is (usually) not the same as ''M*'' is nonconstructive and uses the axiom of choice in an essential way; it is very hard to exhibit explicit elements of  ''M*'' that are not in ''M''<sub>∗</sub>. For example, exotic positive linear forms on the von Neumann algebra ''l''<sup>∞</sup>(''Z'') are given by [[ultrafilter|free ultrafilters]]; they correspond to exotic *-homomorphisms into ''C'' and describe the [[Stone–Čech compactification]] of ''Z''.\n\nExamples:\n#The predual of the von Neumann algebra ''L''<sup>∞</sup>('''R''') of essentially bounded functions on '''R''' is the Banach space ''L''<sup>1</sup>('''R''') of integrable functions. The dual of ''L''<sup>∞</sup>('''R''') is strictly larger than ''L''<sup>1</sup>('''R''') For example, a functional on ''L''<sup>∞</sup>('''R''') that extends the [[Dirac measure]] δ<sub>0</sub> on the closed subspace of bounded continuous functions ''C''<sup>0</sup><sub>b</sub>('''R''') cannot be represented as a function in ''L''<sup>1</sup>('''R''').\n#The predual of the von Neumann algebra ''B''(''H'') of bounded operators on a Hilbert space ''H'' is the Banach space of all [[trace class]] operators with the trace norm ||''A''||= Tr(|''A''|). The Banach space of trace class operators is itself the dual of the C*-algebra of compact operators (which is not a von Neumann algebra).\n\n==Weights, states, and traces==\nWeights and their special cases states and traces are discussed in detail in {{harv|Takesaki|1979}}.\n\n*A '''weight''' ω on a von Neumann algebra is a linear map from the set of [[C*-algebra#Self-adjoint elements|positive elements]] (those of the form ''a*a'') to [0,∞].\n*A '''positive linear functional''' is a weight with ω(1) finite (or rather the extension of ω to the whole algebra by linearity).\n*A '''[[state (functional analysis)|state]]''' is a weight with ω(1)&nbsp;=&nbsp;1.\n*A '''trace''' is a weight with ω(''aa*'')&nbsp;=&nbsp;ω(''a*a'') for all ''a''.\n*A '''tracial state''' is a trace with ω(1)&nbsp;=&nbsp;1.\n\nAny factor has a trace such that the trace of a non-zero projection is non-zero and the trace of a projection is infinite if and only if the projection is infinite. Such a trace is unique up to rescaling.  For factors that are separable or finite, two projections are equivalent if and only if they have the same trace. The type of a factor can be read off from the possible values of this trace as follows:\n*Type I<sub>''n''</sub>: 0, ''x'', 2''x'', ....,''nx'' for some positive ''x'' (usually normalized to be 1/''n'' or 1).\n*Type I<sub>∞</sub>: 0, ''x'', 2''x'', ....,∞ for some positive ''x'' (usually normalized to be  1).\n*Type II<sub>1</sub>: [0,''x''] for some positive ''x'' (usually normalized to be  1).\n*Type II<sub>∞</sub>: [0,∞].\n*Type III: {0,∞}.\n\nIf a von Neumann algebra acts on a Hilbert space containing a norm 1 vector ''v'', then the functional ''a'' → (''av'',''v'') is  a normal state. This construction can be reversed to give an action on a Hilbert space from a normal state: this is the [[GNS construction]] for normal states.\n\n==Modules over a factor==\nGiven an abstract separable factor, one can ask for a classification of its modules, meaning the separable Hilbert spaces that it acts on. The answer is given as follows: every such module ''H'' can be given an ''M''-dimension dim<sub>''M''</sub>(''H'') (not its dimension as a complex vector space) such that modules are isomorphic if and only if they have the same ''M''-dimension. The ''M''-dimension is additive, and a module is isomorphic to a subspace of another module if and only if it has smaller or equal ''M''-dimension.\n\nA module is called '''standard''' if it has a cyclic separating vector. Each factor has a standard representation, which is unique up to isomorphism. The standard representation has an antilinear involution ''J'' such that ''JMJ'' = ''M&prime;''. For finite factors the standard module is given by the [[GNS construction]] applied to the unique normal tracial state and the ''M''-dimension is normalized so that the standard module has ''M''-dimension 1, while  for infinite factors the standard module is the module with ''M''-dimension equal to ∞.\n\nThe possible ''M''-dimensions of modules are given as follows:\n*Type I<sub>''n''</sub> (''n'' finite): The ''M''-dimension can be any of 0/''n'', 1/''n'', 2/''n'', 3/''n'', ..., ∞. The standard module has ''M''-dimension 1 (and complex dimension ''n''<sup>2</sup>.)\n*Type I<sub>∞</sub> The ''M''-dimension  can be any of 0, 1, 2, 3, ..., ∞. The standard representation of ''B''(''H'') is ''H''⊗''H''; its ''M''-dimension is ∞.\n*Type II<sub>1</sub>: The ''M''-dimension can be anything in [0, ∞]. It is normalized so that the standard module has ''M''-dimension 1. The ''M''-dimension is also called the '''coupling constant''' of the module ''H''.\n*Type II<sub>∞</sub>: The ''M''-dimension can be anything in [0, ∞]. There is in general no canonical way to normalize it; the factor may have outer automorphisms multiplying the ''M''-dimension by constants. The standard representation is the one with ''M''-dimension ∞.\n*Type III: The ''M''-dimension can be 0 or ∞. Any two non-zero modules are isomorphic, and all non-zero modules are standard.\n\n==Amenable von Neumann algebras==\n{{harvtxt|Connes|1976}} and others proved that the following conditions on a von Neumann algebra ''M'' on a separable Hilbert space ''H'' are all equivalent:\n\n* ''M'' is '''hyperfinite''' or '''AFD''' or '''approximately finite dimensional''' or '''approximately finite''': this means the algebra contains an ascending sequence of finite dimensional subalgebras with dense union. (Warning: some authors use \"hyperfinite\" to mean \"AFD and finite\".)\n*''M'' is '''amenable''': this means that the [[derivation (abstract algebra)|derivation]]s of ''M'' with values in a normal dual Banach bimodule are all inner.{{clarify|What is inner here?|date=February 2013}}\n*''M'' has Schwartz's '''property P''': for any bounded operator ''T'' on ''H'' the weak operator closed convex hull of the elements ''uTu*'' contains an element commuting with ''M''.\n*''M'' is '''semidiscrete''': this means the identity map from ''M'' to ''M'' is a weak pointwise limit of completely positive maps of finite rank.\n*''M'' has '''property E''' or the '''Hakeda–Tomiyama extension property''': this means that there is a projection of norm 1 from bounded operators on ''H'' to ''M'' '.\n*''M'' is '''injective''': any completely positive linear map from any self adjoint closed subspace containing 1 of any unital C*-algebra ''A'' to ''M'' can be extended to a completely positive map from ''A'' to ''M''.\n\nThere is no generally accepted term for the class of algebras above; Connes has suggested that '''amenable''' should be the standard term.\n\nThe amenable factors have been classified: there is a unique one of each of the types I<sub>''n''</sub>, I<sub>∞</sub>, II<sub>1</sub>, II<sub>∞</sub>, III<sub>λ</sub>, for 0 < λ ≤ 1, and the ones of type III<sub>0</sub> correspond to certain ergodic flows. (For type III<sub>0</sub> calling this a classification is a little misleading, as it is known that there is no easy way to classify the corresponding ergodic flows.) The ones of type I and II<sub>1</sub> were classified by {{harvtxt|Murray|von Neumann|1943}}, and the remaining ones were classified by {{harvtxt|Connes|1976}}, except for the type III<sub>1</sub> case which was completed by Haagerup.\n\nAll amenable factors can be constructed using the '''[[crossed product|group-measure space construction]]''' of [[Francis Joseph Murray|Murray]] and [[John von Neumann|von Neumann]] for a single [[ergodic]] transformation. In fact they are precisely the factors arising as [[crossed product]]s by free ergodic actions of ''Z'' or ''Z/nZ'' on abelian von Neumann algebras ''L''<sup>∞</sup>(''X''). Type I factors occur when the [[measure space]] ''X'' is [[atom (measure theory)|atomic]] and the action transitive. When ''X'' is diffuse or [[atom (measure theory)|non-atomic]], it is [[equivalence (measure theory)|equivalent]] to [0,1] as a [[measure space]]. Type II factors occur when ''X'' admits an [[equivalence (measure theory)|equivalent]] finite (II<sub>1</sub>) or infinite (II<sub>∞</sub>) measure, invariant under an action of ''Z''. Type III factors occur in the remaining cases where there is no invariant measure, but only an [[quasi-invariant measure|invariant measure class]]: these factors are called '''Krieger factors'''.\n\n==Tensor products of von Neumann algebras==\nThe Hilbert space tensor product of two Hilbert spaces is the completion of their algebraic tensor product. One can define a tensor product of von Neumann algebras (a completion of the algebraic tensor product of the algebras considered as rings), which is again a von Neumann algebra, and act on the tensor product of the corresponding Hilbert spaces.  The tensor product of two finite algebras is finite, and the tensor product of an infinite algebra and a non-zero algebra is infinite. The type of the tensor product of two von Neumann algebras  (I, II, or III) is the maximum of their types. The '''commutation theorem for tensor products''' states that\n\n:<math>(M\\otimes N)^\\prime = M^\\prime\\otimes N^\\prime,</math>\n\nwhere ''M''&prime; denotes the [[commutant]] of ''M''.\n\nThe tensor product of an infinite number of von Neumann algebras, if done naively, is usually a ridiculously large non-separable algebra. Instead {{harvtxt|von Neumann|1938}} showed that  one should choose a state on each of the von Neumann algebras, use this to define a state on the algebraic tensor product, which can be used to produce a Hilbert space and a (reasonably small) von Neumann algebra. {{harvtxt|Araki|Woods|1968}} studied the case where all the factors are finite matrix algebras; these factors are called '''Araki–Woods''' factors or '''ITPFI factors''' (ITPFI stands for \"infinite tensor product of finite type I factors\").  The type of the infinite tensor product can vary dramatically as the states are changed; for example, the infinite tensor product of an infinite number of type I<sub>2</sub> factors can have any type depending on the choice of states. In particular {{harvtxt|Powers|1967}} found an uncountable family of non-isomorphic hyperfinite type III<sub>λ</sub> factors for 0 < λ < 1, called '''Powers factors''', by taking an infinite tensor product of type I<sub>2</sub> factors, each with the state given by:\n\n:<math>x\\mapsto {\\rm Tr}\\begin{pmatrix}{1\\over \\lambda+1}&0\\\\ 0&{\\lambda\\over \\lambda+1}\\\\ \\end{pmatrix} x.</math>\n \nAll hyperfinite von Neumann algebras not of type III<sub>0</sub> are isomorphic to Araki–Woods factors, but there are uncountably many of type III<sub>0</sub> that are not.\n\n==Bimodules and subfactors==\nA '''bimodule''' (or correspondence) is a Hilbert space ''H'' with module actions of two commuting von Neumann algebras. Bimodules have a much richer structure than that of modules. Any bimodule over two factors always gives a [[subfactor]] since one of the factors is always contained in the commutant of the other. There is also a subtle relative tensor product operation due to [[Alain Connes|Connes]] on bimodules. The theory of subfactors, initiated by [[Vaughan Jones]], reconciles these two seemingly different points of view.\n\nBimodules are also important for the von Neumann group algebra ''M'' of a discrete group Γ. Indeed, if ''V'' is any [[unitary representation]] of Γ, then, regarding Γ as the diagonal subgroup of Γ × Γ, the corresponding [[induced representation]] on ''l''<sup>2 </sup>(Γ, ''V'') is naturally a bimodule for two commuting copies of ''M''. Important [[representation theory|representation theoretic]] properties of Γ can be formulated entirely in terms of bimodules and therefore make sense for the von Neumann algebra itself. For example, Connes and Jones gave a definition of an analogue of [[Kazhdan's property (T)]] for von Neumann algebras in this way.\n\n==Non-amenable factors==\nVon Neumann algebras of type I are always amenable, but for the other types there are an uncountable number of different non-amenable factors, which seem very hard to classify, or even distinguish from each other. Nevertheless, [[Dan-Virgil Voiculescu|Voiculescu]] has shown that the class of non-amenable factors coming from the group-measure space construction is '''disjoint''' from the class coming from group von Neumann algebras of free groups. Later [[Narutaka Ozawa]] proved that group von Neumann algebras of [[hyperbolic group]]s yield [[prime]] type II<sub>1</sub> factors, i.e. ones that cannot be factored as tensor products of type II<sub>1</sub> factors, a result first proved by Leeming Ge for free group factors using Voiculescu's [[free probability theory|free entropy]]. Popa's work on fundamental groups of non-amenable factors represents another significant advance. The theory of factors \"beyond the hyperfinite\" is rapidly expanding at present, with many new and surprising results; it has close links with [[Grigory Margulis|rigidity phenomena]] in [[geometric group theory]] and [[ergodic theory]].\n\n==Examples==\n*The essentially bounded functions on a σ-finite measure space form a commutative (type I<sub>1</sub>) von Neumann algebra acting on the ''L''<sup>2</sup> functions. For certain non-σ-finite measure spaces, usually considered [[pathological (mathematics)|pathological]], ''L''<sup>∞</sup>(''X'') is not a von Neumann algebra;  for example, the σ-algebra of measurable sets might be the [[countable-cocountable algebra]] on an uncountable set. A fundamental approximation theorem can be represented by the [[Kaplansky density theorem]]. \n*The bounded operators on any Hilbert space form a von Neumann algebra, indeed a factor, of type I.\n*If we have any [[unitary representation]] of a group ''G'' on a Hilbert space ''H'' then the bounded operators commuting with ''G'' form a von Neumann algebra ''G''&prime;, whose projections correspond exactly to the closed subspaces of ''H'' invariant under ''G''. Equivalent subrepresentations correspond to equivalent projections in ''G''&prime;. The double commutant ''G''&prime;&prime; of ''G'' is also a von Neumann algebra.\n* The '''von Neumann group algebra''' of a discrete group ''G'' is the algebra of all bounded operators on ''H'' = ''l''<sup>2</sup>(''G'') commuting with the action of ''G'' on ''H'' through right multiplication.  One can show that this is the von Neumann algebra generated by the operators corresponding to multiplication from the left with an element ''g'' ∈ ''G''. It is a factor (of type II<sub>1</sub>) if every non-trivial conjugacy class of ''G'' is infinite (for example, a non-abelian free group), and is the hyperfinite factor of type II<sub>1</sub> if in addition ''G'' is a union of finite subgroups (for example, the group of all permutations of the integers fixing all but a finite number of elements).\n*The tensor product of two von Neumann algebras, or of a countable number with states, is a von Neumann algebra as described in the section above.\n*The [[crossed product]] of a von Neumann algebra by a discrete (or more generally locally compact) group can be defined, and is a von Neumann algebra. Special cases are the '''group-measure space construction''' of Murray and [[John von Neumann|von Neumann]] and '''Krieger factors'''.\n*The von Neumann algebras of a measurable [[equivalence relation]] and a measurable [[groupoid]] can be defined. These examples generalise von Neumann group algebras and the group-measure space construction.\n\n==Applications==\nVon Neumann algebras have found applications in diverse areas of mathematics like [[knot theory]], [[statistical mechanics]], [[Quantum field theory]], [[Local quantum physics]], [[Free probability]], [[Noncommutative geometry]], [[representation theory]], [[geometry]], and [[probability]].\n\nFor instance, [[C*-algebra]] provides an alternative axiomatization to probability theory. In this case the method goes by the name of [[Gelfand–Naimark–Segal construction]]. This is analogous to the two approaches to measure and integration, where one has the choice to construct measures of sets first and define integrals later, or construct integrals first and define set measures as integrals of characteristic functions.\n\n==See also==\n* [[AW*-algebra]]\n\n==References==\n*{{citation|first=H. |last=Araki|first2=E. J. |last2=Woods|title=A classification of factors|journal=Publ. Res. Inst. Math. Sci. Ser. A|volume=4|year=1968|issue=1|pages=51–130| doi=10.2977/prims/1195195263}}{{MathSciNet|id=0244773}}\n*{{citation|first=B.|last= Blackadar|title=Operator algebras|isbn =3-540-28486-9 |publisher=Springer|year=2005}}, {{citation|url=http://wolfweb.unr.edu/homepage/bruceb/Cycr.pdf| title=corrected manuscript|year=2013}} \n*{{citation|doi=10.2307/1971057|first=A.|last= Connes |title=Classification of Injective Factors|journal=Annals of Mathematics |series=Second Series |volume= 104|issue= 1 |year=1976|pages= 73–115|jstor=1971057}}\n*{{citation|first=A.|last= Connes |url=http://www.alainconnes.org/docs/book94bigpdf.pdf |title=Non-commutative geometry| isbn=0-12-185860-X|year=1994|publisher=Academic Press}}.\n*{{citation|first=J.|last= Dixmier|title=Von Neumann algebras| isbn=0-444-86308-7 |year=1981}} (A translation of {{citation|first=J.|last= Dixmier|title=Les algèbres d'opérateurs dans l'espace hilbertien: algèbres de von Neumann|publisher= Gauthier-Villars  |year=1957}}, the first book about von Neumann algebras.)\n*{{citation|first=V.F.R.|last=Jones |year=2003|url=http://www.math.berkeley.edu/~vfr/MATH20909/VonNeumann2009.pdf |title=von Neumann algebras}}; incomplete notes from a course.\n*{{citation|first=R.P.|last=Kostecki |year=2013|arxiv=1307.4818|title=W*-algebras and noncommutative integration|bibcode=2013arXiv1307.4818P}}.\n*{{citation|first=Dusa|last=McDuff|authorlink=Dusa McDuff|title=Uncountably many II<sub>1</sub> factors|journal=Annals of Mathematics |series=Second Series|volume=90|year=1969|pages=372–377| doi=10.2307/1970730 |jstor=1970730|issue=2}}\n*{{citation|last=Murray|first= F. J.|contribution=The rings of operators papers|title=  The legacy of John von Neumann (Hempstead, NY, 1988)|pages=  57–60|series= Proc. Sympos. Pure Math.|volume= 50|publisher= Amer. Math. Soc.|  isbn=0-8218-4219-6|publication-place= Providence, RI.}} A historical account of the discovery of von Neumann algebras.\n*{{citation|first=F.J.|last= Murray|first2=   J. |last2=von Neumann |title=On rings of operators| journal= Annals of Mathematics | series = Second Series |volume= 37  |year=1936|pages=116–229| doi=10.2307/1968693 |jstor=1968693|issue=1}}. This paper gives their basic properties and the division into types I, II, and III, and in particular finds factors not of type I.  \n*{{citation|first=F.J.|last= Murray|first2=   J. |last2=von Neumann |title=On rings of operators II|journal= Trans. Amer. Math. Soc. |volume= 41  |year=1937|pages= 208–248 |doi=10.2307/1989620|issue=2|jstor=1989620|publisher=American Mathematical Society}}. This is a continuation of the previous paper, that studies properties of the trace of a factor. \n*{{citation|first=F.J.|last= Murray|first2=   J. |last2=von Neumann |title=On rings of operators IV|journal= Annals of Mathematics | series = Second Series |volume= 44  |year=1943|pages= 716–808| doi=10.2307/1969107 |jstor=1969107|issue=4}}. This studies when factors are isomorphic, and in particular shows that all approximately finite factors of type II<sub>1</sub> are isomorphic. \n*{{citation|  doi=  10.2307/1970364|  title=  Representations of Uniformly Hyperfinite Algebras and Their Associated von Neumann Rings|first=Robert T. |last=Powers |journal= Annals of Mathematics | series = Second Series|volume= 86|issue= 1|year= 1967|pages= 138–171|  jstor=  1970364}}\n*{{citation|first=S.|last= Sakai|authorlink=Shoichiro Sakai|title=C*-algebras and W*-algebras|publisher= Springer  |year=1971| isbn =3-540-63633-1}}\n*{{citation|authorlink=Jacob T. Schwartz|first=Jacob|last=Schwartz|title=W-* Algebras|year=1967| isbn =0-677-00670-5}}\n*{{springer|id=V/v096900|title=von Neumann algebra|first=A.I.|last= Shtern}}\n*{{citation|first=M. |last=Takesaki |title=Theory of Operator Algebras I, II, III| isbn=3-540-42248-X|year=1979}}\n<!-- Please do NOT change von to Von: this breaks the citation links. -->\n*{{citation|first=J. |last=von Neumann|doi=10.1007/BF01782352|title= Zur Algebra der Funktionaloperationen und Theorie der normalen Operatoren|journal= Math. Ann.|volume=102 |issue=1 |year=1930|pages= 370–427}}. The original paper on von Neumann algebras.\n*{{citation|doi=10.2307/1968692|first=J. |last=von Neumann |title=On a Certain Topology for Rings of Operators|journal=Annals of Mathematics |series=Second Series|volume=37|issue= 1 |year= 1936|pages= 111–115|jstor=1968692}}. This defines the ultrastrong topology.\n*{{citation|first=J. |last=von Neumann|url=http://www.numdam.org/item?id=CM_1939__6__1_0 |title=On infinite direct products |journal=  Compos. Math. |volume= 6  |year=1938| pages=  1–77}}. This discusses infinite tensor products of Hilbert spaces and the algebras acting on them.\n*{{citation|first=J. |last=von Neumann |title= On rings of operators III|journal=  Annals of Mathematics | series = Second Series |volume= 41  |year=1940|pages= 94–161| doi=10.2307/1968823| jstor=1968823 |issue=1}}. This shows the existence of factors of type III. \n*{{citation|doi=10.2307/1969106|first=J. |last=von Neumann |title=On Some Algebraical Properties of Operator Rings|journal=Annals of Mathematics |series=Second Series|volume=  44|issue= 4 |year= 1943|pages= 709–715|jstor=1969106}}. This shows that some apparently topological properties in von Neumann algebras can be defined purely algebraically. \n*{{citation|doi=10.2307/1969463|first=J. |last=von Neumann |title=On Rings of Operators. Reduction Theory|journal=Annals of Mathematics |series=Second Series |volume= 50|issue= 2 |year= 1949|pages= 401–485|jstor=1969463}}. This discusses how to write a von Neumann algebra as a sum or integral of factors.\n*{{citation|last=von Neumann|first= John|title= Collected Works, Volume III: Rings of Operators|editor-first= A.H.|editor-last= Taub|publication-place= NY |publisher=Pergamon Press|year= 1961}}. Reprints von Neumann's papers on von Neumann algebras.\n*{{citation|first=A. J. |last=Wassermann|authorlink=Antony Wassermann|year=1991|url=http://iml.univ-mrs.fr/~wasserm/OHS.ps |title=Operators on Hilbert space}}\n\n{{Authority control}}\n\n[[Category:Operator theory]]\n[[Category:Von Neumann algebras|*]]\n[[Category:John von Neumann]]"
    },
    {
      "title": "Abelian von Neumann algebra",
      "url": "https://en.wikipedia.org/wiki/Abelian_von_Neumann_algebra",
      "text": "In [[functional analysis]], an '''abelian von Neumann algebra''' is a [[von Neumann algebra]] of operators on a [[Hilbert space]] in which all elements [[commutative|commute]]. \n\nThe prototypical example  of an abelian von Neumann algebra is  the algebra ''L''<sup>∞</sup>(''X'', μ) for μ a σ-finite measure on ''X'' realized as an algebra of operators on the Hilbert space ''L''<sup>2</sup>(''X'', μ) as follows: Each ''f'' ∈ ''L''<sup>∞</sup>(''X'', μ) is identified with the multiplication operator\n\n:<math> \\psi \\mapsto f \\psi. </math>\n\nOf particular importance are the abelian von Neumann algebras on [[separable space|separable]] Hilbert spaces, particularly since they are completely classifiable by simple invariants.\n\nThough there is a theory for von Neumann algebras on non-separable Hilbert spaces (and indeed much of the general theory still holds in that case) the theory is considerably simpler for algebras on separable spaces and most applications to other areas of mathematics or physics only use separable Hilbert spaces.  Note that if the measure spaces (''X'', μ) is a [[standard measure space]] (that is ''X'' − ''N'' is a [[standard Borel space]] for some null set ''N'' and μ is a σ-finite measure) then ''L''<sup>2</sup>(''X'', μ) is separable.\n\n==Classification==\nThe relationship between [[commutative]] von Neumann algebras and [[measure space]]s is analogous to that between [[commutative]] [[C*-algebra]]s and [[locally compact]] [[Hausdorff space]]s.  Every commutative von Neumann algebra on a separable Hilbert space is isomorphic to [[Lp space|''L''<sup>∞</sup>]](''X'') for some standard measure space (''X'', μ) and conversely, for every standard measure space ''X'',  ''L''<sup>∞</sup>(''X'') is a von Neumann algebra. This isomorphism as stated is an algebraic isomorphism.  \nIn fact we can state this more precisely as follows:\n\n'''Theorem'''. Any abelian von Neumann algebra of operators on a separable Hilbert space is *-isomorphic to exactly one of the following\n*<math>\\ell^\\infty(\\{1,2, \\ldots, n\\}), \\quad n \\geq 1 </math>\n* <math>\\ell^\\infty(\\mathbf{N}) </math>\n* <math>L^\\infty([0,1]) </math>\n* <math>L^\\infty([0,1] \\cup \\{1,2, \\ldots, n\\}), \\quad n \\geq 1 </math>\n* <math>L^\\infty([0,1] \\cup \\mathbf{N}). </math>\n\nThe isomorphism can be chosen to preserve the weak operator topology.\n\nIn the above list, the interval [0,1] has Lebesgue measure and the sets {1, 2, ..., ''n''} and '''N''' have counting measure. The unions are disjoint unions.  This classification is essentially a variant of [[Maharam's classification theorem]] for separable measure algebras. The version of Maharam's classification theorem that is most useful involves a point realization of the equivalence, and is somewhat of a [[Mathematical folklore|folk theorem]]. \n\nAlthough every standard measure space is isomorphic to one of the above and the list is exhaustive in this sense, there is a more canonical choice for the measure space in the case of abelian von Neumann algebras ''A'': The set of all projectors is a <math>\\sigma</math>-complete Boolean algebra, that is a pointfree <math>\\sigma</math>-algebra. In the special case <math>A=L^\\infty(X,\\mathfrak{A},\\mu)</math> one recovers the abstract <math>\\sigma</math>-algebra <math>\\mathfrak{A}/\\{A \\mid \\mu(A)=0\\}</math>. This pointfree approach can be turned into a duality theorem analogue to Gelfand-duality between the category of abelian von Neumann algebras and the category of abstract <math>\\sigma</math>-algebras.\n\n: Let μ and ν be [[non-atomic measure|non-atomic]] probability measures on standard Borel spaces ''X'' and ''Y'' respectively.  Then there is a μ null subset ''N'' of ''X'', a ν null subset ''M'' of ''Y'' and a Borel isomorphism \n\n:: <math> \\phi: X \\setminus N \\rightarrow Y \\setminus M, \\quad </math>\n\n:which carries μ into ν.<ref>{{cite book |last=Bogachev|first=V.I. |title=Measure theory. Vol. II|page=275 |publisher=Springer-Verlag|year=2007|isbn=978-3-540-34513-8}}</ref>\n\nNotice that in the above result, it is necessary to clip away sets of measure zero to make the result work.\n\nIn the above theorem, the isomorphism is required to preserve the weak operator topology.  As it turns out (and follows easily from the definitions), for algebras ''L''<sup>∞</sup>(''X'', μ), the following topologies agree on norm bounded sets:\n\n# The weak operator topology on ''L''<sup>∞</sup>(''X'', μ);\n# The ultraweak operator topology on ''L''<sup>∞</sup>(''X'', μ);\n# The topology of weak* convergence on ''L''<sup>∞</sup>(''X'', μ) considered as the dual space of ''L''<sup>1</sup>(''X'', μ).\n\nHowever, for an abelian von Neumann algebra ''A'' the  realization of ''A'' as an algebra of operators on a separable Hilbert space is highly non-unique.  The complete classification of the operator algebra realizations of ''A'' is given by spectral [[multiplicity theory]] and requires the use of [[direct integral]]s.\n\n== Spatial isomorphism ==\nUsing direct integral theory, it can be shown that the abelian von Neumann algebras of the form ''L''<sup>∞</sup>(''X'', μ) acting as operators on ''L''<sup>2</sup>(''X'', μ) are all maximal abelian.  This means that they cannot be extended to properly larger abelian algebras. They are also referred to as ''Maximal abelian self-adjoint algebras'' (or M.A.S.A.s). Another phrase used to describe them is abelian von Neumann algebras of ''uniform multiplicity 1''; this description makes sense only in relation to multiplicity theory described below.\n\nVon Neumann algebras ''A'' on ''H'', ''B'' on ''K'' are ''spatially isomorphic'' (or ''unitarily isomorphic'') if and only if there is a unitary operator ''U'': ''H'' → ''K'' such that\n\n:<math> U A U^* = B.</math>\n\nIn particular spatially isomorphic von Neumann algebras are algebraically isomorphic.\n\nTo describe the most general abelian von Neumann algebra on a separable Hilbert space ''H'' up to spatial isomorphism, we need to refer the direct integral decomposition of ''H''. The details of this decomposition are discussed in [[Direct integral#Decomposition of Abelian von Neumann algebras|decomposition of abelian von Neumann algebras]]. In particular:\n\n'''Theorem''' Any abelian von Neumann algebra on a separable Hilbert space ''H'' is spatially isomorphic to ''L''<sup>∞</sup>(''X'', μ)  acting on \n\n:<math> \\int_X^\\oplus H(x) \\, d \\mu(x) </math>\n\nfor some measurable family of Hilbert spaces {''H''<sub>''x''</sub>}<sub>''x'' ∈ ''X''</sub>.\n\nNote that for abelian von Neumann algebras acting on such direct integral spaces, the equivalence of the weak operator topology, the ultraweak topology and the weak* topology on norm bounded sets still hold.\n\n== Point and spatial realization of automorphisms ==\nMany problems in [[ergodic theory]] reduce to problems about automorphisms of abelian von Neumann algebras.  In that regard, the following results are useful:\n\n'''Theorem'''<ref>{{citation | last = Takesaki | first = Masamichi | authorlink = Masamichi Takesaki | title=Theory of Operator Algebras I  | publisher=[[Springer-Verlag]] | year=2001 | isbn=3-540-42248-X }}, Chapter IV, Lemma 8.22, p. 275</ref> . Suppose μ, ν are standard measures on ''X'', ''Y'' respectively.  Then any involutive isomorphism\n\n: <math> \\Phi: L^\\infty(X, \\mu) \\rightarrow L^\\infty(Y, \\nu)  </math>\n\nwhich is weak*-[[bicontinuous]] corresponds to a point transformation in the following sense:  There are Borel null subsets ''M'' of ''X'' and ''N'' of ''Y'' and a Borel isomorphism\n\n:<math> \\eta: X \\setminus M \\rightarrow Y \\setminus N </math>\n\nsuch that \n# η carries the measure μ into a measure  μ' on ''Y'' which is equivalent to ν in the sense that μ' and ν have the same sets of measure zero;\n# η realizes the transformation Φ, that is\n\n::<math> \\Phi (f) = f \\circ \\eta^{-1}. </math>\n\nNote that in general we cannot expect η to carry μ into ν.  \n\nThe next result concerns unitary transformations which induce a weak*-bicontinuous isomorphism between abelian von Neumann algebras.\n\n'''Theorem'''<ref>{{citation | last = Takesaki | first = Masamichi | authorlink = Masamichi Takesaki | title=Theory of Operator Algebras I  | publisher=[[Springer-Verlag]] | year=2001 | isbn=3-540-42248-X }}, Chapter IV, Theorem 8.23, p. 277</ref> .  Suppose μ, ν are standard measures on ''X'', ''Y'' and \n\n:<math> H = \\int_X^\\oplus H_x d \\mu(x), \\quad K = \\int_Y^\\oplus K_y d \\nu(y) </math>\n\nfor measurable families of Hilbert spaces {''H''<sub>''x''</sub>}<sub>''x'' ∈ ''X''</sub>, {''K''<sub>''y''</sub>}<sub>''y'' ∈ ''Y''</sub>.  If ''U'' : ''H'' → ''K'' is a unitary such that \n\n:<math> U \\, L^\\infty(X, \\mu) \\, U^* = L^\\infty(Y, \\nu) </math>\n\nthen there is an almost everywhere defined Borel point transformation η : ''X'' → ''Y'' as in the previous theorem and a measurable family {''U<sub>x</sub>''}<sub>''x'' ∈ ''X''</sub> of unitary operators \n\n: <math> U_x: H_x \\rightarrow K_{\\eta(x)} </math>\n\nsuch that \n\n:<math> U \\bigg(\\int_X^\\oplus \\psi_x d \\mu(x) \\bigg)= \\int_Y^\\oplus \\sqrt{ \\frac{d (\\mu \\circ \\eta^{-1})}{d \\nu}(y)} \\ U_{\\eta^{-1}(y)} \\bigg(\\psi_{\\eta^{-1}(y)}\\bigg) d \\nu(y),</math>\n\nwhere the expression in square root sign is the [[Radon–Nikodym theorem|Radon–Nikodym derivative]] of μ η<sup>−1</sup> with  respect to ν. The statement follows combining the theorem on point realization of automorphisms stated above with the theorem characterizing the algebra of diagonalizable operators stated in the article on [[direct integral]]s.\n\n==Notes==\n<references/>\n\n==References==\n* J. Dixmier, ''Les algèbres d'opérateurs dans l'espace Hilbertien'', Gauthier-Villars, 1969.  See chapter I, section 6.\n* [[Masamichi Takesaki]] ''Theory of Operator Algebras I,II,III\", encyclopedia of mathematical sciences, Springer-Verlag, 2001–2003 (the first volume was published 1979 in 1. Edition) {{ISBN|3-540-42248-X}}\n\n[[Category:Von Neumann algebras]]"
    },
    {
      "title": "Affiliated operator",
      "url": "https://en.wikipedia.org/wiki/Affiliated_operator",
      "text": "In [[mathematics]], '''affiliated operators''' were introduced by [[Francis Joseph Murray (mathematician)|Murray]] and [[John von Neumann|von Neumann]] in the theory of [[von Neumann algebras]] as a technique for using [[unbounded operator]]s to study modules generated by a single vector. Later [[Michael Francis Atiyah|Atiyah]] and [[Isadore Singer|Singer]] showed that [[Atiyah-Singer index theorem|index theorems]] for [[elliptic operator]]s on [[closed manifold]]s with infinite [[fundamental group]] could naturally be phrased in terms of unbounded operators affiliated with the von Neumann algebra of the group. Algebraic properties of affiliated operators have proved important in [[L2 cohomology|L<sup>2</sup> cohomology]], an area between [[analysis]] and [[geometry]] that evolved from the study of such index theorems.\n\n==Definition==\nLet ''M'' be a [[von Neumann algebra]] acting on a [[Hilbert space]] ''H''. A [[closed linear operator|closed]] and densely defined operator ''A'' is said to be '''affiliated''' with ''M'' if ''A'' commutes with every [[unitary operator]] ''U'' in the [[commutant]] of ''M''. Equivalent conditions\nare that:\n\n*each unitary ''U'' in ''M''' should leave invariant the graph of ''A'' defined by <math> G(A)=\\{(x,Ax):x\\in D(A)\\} \\subseteq H\\oplus H</math>.\n*the projection onto ''G''(''A'') should lie in ''M''<sub>2</sub>(''M'').\n*each unitary ''U'' in ''M''' should carry ''D''(''A''), the [[Domain of a function|domain]] of ''A'', onto itself and  satisfy ''UAU* = A'' there.\n*each unitary ''U'' in ''M''' should commute with both operators in the [[polar decomposition]] of ''A''.\n\nThe last condition follows by uniqueness of the polar decomposition. If ''A'' has a polar decomposition \n:<math>A=V|A|, \\, </math>\nit says that the [[partial isometry]] ''V'' should lie in ''M'' and that the positive [[self-adjoint]] operator ''|A|'' should be affiliated with ''M''. However, by the [[spectral theorem]], a positive self-adjoint operator commutes with a unitary operator if and only if each of its spectral projections <math> E([0,N]) </math>\ndoes. This gives another equivalent condition:\n\n*each spectral projection of |''A''| and the partial isometry in the polar decomposition of ''A'' lies in ''M''.\n\n== Measurable operators ==\n\nIn general the operators affiliated with a von Neumann algebra ''M'' need not necessarily be well-behaved under either addition or composition. However in the presence of a faithful semi-finite normal trace &tau; and the standard [[Gelfand&ndash;Naimark&ndash;Segal]] action of ''M'' on ''H''&nbsp;=&nbsp;''L''<sup>2</sup>(''M'',&nbsp;&tau;), [[Edward Nelson]] proved that the '''measurable''' affiliated operators do form a [[*-algebra]] with nice properties: these are operators such that &tau;(''I''&nbsp;&minus;&nbsp;''E''([0,''N'']))&nbsp;<&nbsp;&infin;\nfor ''N'' sufficiently large. This algebra of unbounded operators is complete for a natural topology, generalising the notion of [[convergence in measure]].\nIt contains all the non-commutative ''L''<sup>''p''</sup> spaces defined by the trace and was introduced to facilitate their study.\n\nThis theory can be applied when the von Neumann algebra ''M'' is '''type I''' or '''type II'''. When ''M''&nbsp;=&nbsp;''B''(''H'') acting on the Hilbert space ''L''<sup>2</sup>(''H'') of [[Hilbert–Schmidt operator]]s, it gives the well-known theory of non-commutative ''L''<sup>''p''</sup> spaces ''L''<sup>''p''</sup> (''H'') due to [[Robert Schatten|Schatten]] and [[John von Neumann|von Neumann]].\n\nWhen ''M'' is in addition a '''finite''' von Neumann algebra, for example a type II<sub>1</sub> factor, then every affiliated operator is automatically measurable, so the affiliated operators form a [[*-algebra]], as originally observed in the first paper of [[Francis Joseph Murray (mathematician)|Murray]] and von Neumann. In this case ''M'' is a [[von Neumann regular ring]]: for on the closure of its image ''|A|'' has a measurable inverse ''B'' and then ''T''&nbsp;=&nbsp;''BV''<sup>*</sup> defines a measurable operator with ''ATA''&nbsp;=&nbsp;''A''. Of course in the classical case when ''X'' is a probability space and ''M''&nbsp;=&nbsp;''L''<sup>&infin;</sup> (''X''), we simply recover the *-algebra of measurable functions on ''X''.\n\nIf however ''M'' is '''type III''', the theory takes a quite different form. Indeed in this case, thanks to the [[Tomita–Takesaki theory]], it is known that the non-commutative ''L''<sup>''p''</sup> spaces are no longer realised by operators affiliated with the von Neumann algebra. As [[Alain Connes|Connes]] showed, these spaces can be realised as unbounded operators only by using a certain positive power of the reference modular operator. Instead of being characterised by the simple affiliation relation ''UAU''<sup>*</sup>&nbsp;=&nbsp;''A'', there is a more complicated bimodule relation involving the analytic continuation of the modular automorphism group.\n\n== References ==\n* A. Connes, ''Non-commutative geometry'', {{ISBN|0-12-185860-X}}\n* J. Dixmier, ''Von Neumann algebras'', {{ISBN|0-444-86308-7}} [Les algèbres d'opérateurs dans l'espace hilbertien: algèbres de von Neumann, Gauthier-Villars (1957 & 1969)]\n* W. Lück, ''L<sup>2</sup>-Invariants: Theory and Applications to Geometry and K-Theory'', (Chapter 8: the algebra of affiliated operators) {{ISBN|3-540-43566-2}}\n* F. J. Murray and J. von Neumann, ''Rings of Operators'', Annals of Mathematics '''37''' (1936), 116&ndash;229 (Chapter XVI).\n* E. Nelson, ''Notes on non-commutative integration'', J. Funct. Anal. '''15''' (1974), 103&ndash;116.\n* M. Takesaki, ''Theory of Operator Algebras I, II, III'', {{ISBN|3-540-42248-X}} {{ISBN|3-540-42914-X}} {{ISBN|3-540-42913-1}}\n\n[[Category:Operator theory]]\n[[Category:Von Neumann algebras]]"
    },
    {
      "title": "Baer ring",
      "url": "https://en.wikipedia.org/wiki/Baer_ring",
      "text": "In [[abstract algebra]] and [[functional analysis]],  '''Baer rings''', '''Baer *-rings''', '''Rickart rings''', '''Rickart *-rings''', and '''[[AW*-algebra]]s''' are various attempts to give an algebraic analogue of [[von Neumann algebra]]s, using axioms about [[Annihilator (ring theory)|annihilators]] of various sets.\n\nAny von Neumann algebra is a Baer *-ring, and much of the theory of [[Von Neumann algebra#Projections|projections]] in von Neumann algebras can be extended to all Baer *-rings, For example, Baer *-rings can be divided into types I, II, and III in the same way as von Neumann algebras.\n\nIn the literature, left Rickart rings have also been termed left '''PP-rings'''. (\"Principal implies projective\": See definitions below.)\n\n==Definitions==\n*An [[idempotent element (ring theory)|idempotent element]] of a ring is an element ''e'' which has the property that ''e''<sup>2</sup> = ''e''.\n*The '''left [[annihilator (ring theory)|annihilator]]''' of a set <math>X \\subseteq R</math> is <math>\\{r\\in R\\mid rX=\\{0\\}\\}</math>\n*A '''(left) Rickart ring'''  is a ring satisfying any of the following conditions:\n# the left annihilator of any single element of ''R'' is generated (as a left ideal) by an idempotent element.\n# (For unital rings) the left annihilator of any element is a direct summand of ''R''.\n# All principal left ideals (ideals of the form ''Rx'') are [[projective module|projective]] ''R'' modules.<ref>Rickart rings are named after {{harvtxt|Rickart|1946}} who studied a similar property in operator algebras.  This \"principal implies projective\" condition is the reason Rickart rings are sometimes called PP-rings. {{harv|Lam|1999}}</ref>\n*A '''Baer ring'''  has the following definitions:\n# The left annihilator of any subset of ''R'' is generated (as a left ideal) by an idempotent element.\n# (For unital rings) The left annihilator of any subset of ''R'' is a direct summand of ''R''.<ref>This condition was studied  by {{harvs|txt|authorlink=Reinhold Baer|first=Reinhold |last=Baer|year=1952}}.</ref>  For unital rings, replacing all occurrences of 'left' with 'right' yields an equivalent definition, that is to say, the definition is left-right symmetric.<ref>T.Y. Lam (1999), \"Lectures on Modules and Rings\" {{ISBN|0-387-98428-3}} pp.260</ref>\n\nIn operator theory, the definitions are strengthened slightly by requiring the ring ''R'' to have an [[ring with involution|involution]] <math>*:R\\rightarrow R</math>.  Since this makes ''R'' isomorphic to its [[opposite ring]] ''R''<sup>op</sup>, the definition of Rickart *-ring is left-right symmetric.\n* A '''projection''' in a [[*-ring]] is an idempotent ''p'' that is [[self-adjoint]] ({{nowrap|1=''p''* = ''p''}}).\n*A '''Rickart *-ring''' is a *-ring such that left annihilator of any element is generated (as a left ideal) by a projection.\n*A '''Baer *-ring''' is a *-ring such that left annihilator of any subset is generated (as a left ideal) by a projection.\n*An '''[[AW*-algebra]]''', introduced by {{harvtxt|Kaplansky|1951}}, is a [[C*-algebra]] that is also a Baer *-ring.\n\n==Examples==\n\n*Since the principal left ideals of a left [[hereditary ring]] or left [[semihereditary ring]] are projective, it is clear that both types are left Rickart rings.  This includes [[von Neumann regular ring]]s, which are left and right semihereditary.  If a von Neumann regular ring ''R'' is also right or left [[injective module#self injective rings|self injective]], then ''R'' is Baer.\n*Any [[semisimple ring]] is Baer, since ''all'' left and right ideals are summands in ''R'', including the annihilators.\n*Any [[domain (ring theory)|domain]] is Baer, since all annihilators are <math>\\{0\\}</math> except for the annihilator of 0, which is ''R'', and both <math>\\{0\\}</math> and ''R'' are summands of ''R''.\n*The ring of [[bounded linear operator]]s on a [[Hilbert space]] are a Baer ring and is also a Baer *-ring with the involution * given by the adjoint.\n*von Neumann algebras are examples of all the different sorts of ring above.\n\n==Properties==\n\nThe projections in a Rickart *-ring form a [[lattice (order)|lattice]], which is [[complete lattice|complete]] if the ring is a Baer *-ring.\n\n== See also ==\n* [[Baer *-semigroup]]\n\n==Notes==\n{{Reflist}}\n\n==References==\n\n* {{Citation | last1=Baer | first1=Reinhold | author1-link=Reinhold Baer | title=Linear algebra and projective geometry | url=https://books.google.com/books?isbn=012072250X | publisher=[[Academic Press]] | location=Boston, MA | isbn=978-0-486-44565-6 | mr=0052795 | year=1952}}\n* {{Citation | last1=Berberian | first1=Sterling K. | title=Baer *-rings | url=https://books.google.com/books?isbn=354005751X | publisher=[[Springer-Verlag]] | location=Berlin, New York | series=Die Grundlehren der mathematischen Wissenschaften | isbn=978-3-540-05751-2 | mr=0429975 | year=1972 | volume=195}}\n* {{Citation | last1=Kaplansky | first1=Irving | author1-link=Irving Kaplansky | title=Projections in Banach algebras | jstor=1969540 | mr=0042067 | year=1951 | journal=[[Annals of Mathematics]] |series=Second Series | issn=0003-486X | volume=53 | pages=235–249 | issue=2 | doi=10.2307/1969540}}\n* {{citation|first=I.|last= Kaplansky|title=Rings of Operators|publisher=W. A. Benjamin, Inc.|place= New York|year= 1968|url=https://books.google.com/books?id=hRaoAAAAIAAJ}}\n* {{citation|last=Rickart|first= C. E.|authorlink=Charles Earl Rickart|title=Banach algebras with an adjoint operation|jstor=1969091|journal=Annals of Mathematics |series=Second Series|volume=47|year=1946|pages=528–550|mr=0017474|issue=3|doi=10.2307/1969091}}\n*{{springer|id=R/r080830|title=Regular ring (in the sense of von Neumann)|author=L.A. Skornyakov}}\n*{{springer|id=R/r081840|title=Rickart ring |author=L.A. Skornyakov}}\n*{{springer|id=A/a120310|title=AW* algebra|author=J.D.M. Wright}}\n\n[[Category:Von Neumann algebras]]\n[[Category:Ring theory]]"
    },
    {
      "title": "Calkin correspondence",
      "url": "https://en.wikipedia.org/wiki/Calkin_correspondence",
      "text": "In mathematics, the '''Calkin correspondence''', named after mathematician {{Interlanguage link multi|John Williams Calkin|de}}, is a bijective correspondence between two-sided [[ideal (ring theory)|ideal]]s of bounded [[linear operators]] of a separable infinite-dimensional [[Hilbert space]] and Calkin sequence spaces (also called rearrangement invariant sequence spaces).  The correspondence is implemented by mapping an operator to its [[singular value]] sequence.\n\nIt originated from [[John von Neumann]]'s study of symmetric norms on [[linear algebra|matrix algebras]].<ref name=\"vN1\">{{cite journal\n| author= J. von Neumann\n| year=1937\n| title=Some matrix inequalities and metrization of matrix space\n| volume = 1\n| journal = Tomsk. University Review\n| pages= 286–300}}</ref> It provides a fundamental classification and tool for the study of two-sided ideals of [[compact operator]]s and their [[singular trace|traces]], by reducing problems about operator spaces to (more resolvable) problems on sequence spaces.\n\n== Definitions ==\n\nA ''two-sided ideal'' ''J'' of the bounded linear operators ''B''(''H'') on a separable Hilbert space ''H'' is a linear subspace such that ''AB'' and ''BA'' belong to ''J'' for all operators ''A'' from ''J'' and ''B'' from ''B''(''H'').\n\nA [[sequence space]] ''j'' within ''l''<sub>∞</sub> can be embedded in ''B''(''H'') using an arbitrary orthonormal basis  {''e''<sub>''n''</sub> }<sub>''n''=0</sub><sup>∞</sup>. Associate to a sequence ''a'' from ''j''  the bounded operator\n::::<math> {\\rm diag}(a) = \\sum_{n=0}^\\infty a_n | e_n \\rangle \\langle e_n |, </math>\nwhere [[bra–ket notation]] has been used for the one-dimensional projections onto the subspaces spanned by individual basis vectors. The sequence of absolute values of the entries of ''a'' in decreasing order is called the [[Lorentz space|decreasing rearrangement]] of&nbsp;''a''.  The decreasing rearrangement can be denoted μ(''n'',''a''), ''n''&nbsp;=&nbsp;0,&nbsp;1,&nbsp;2,&nbsp;... Note that it is identical to the [[singular value]]s of the operator diag(''a'').  Another notation for the decreasing rearrangement is&nbsp;''a''*.\n\nA ''Calkin (or rearrangement invariant) sequence space'' is a linear subspace ''j'' of the bounded sequences ''l''<sub>∞</sub> such that if ''a'' is a bounded sequence and μ(''n'',''a'') ≤ μ(''n'',''b''), ''n''&nbsp;{{=}}&nbsp;0,&nbsp;1,&nbsp;2,&nbsp;..., for some ''b'' in ''j'', then ''a'' belongs to&nbsp;''j''.\n\n== Correspondence ==\n\nAssociate to a two-sided ideal ''J'' the sequence space ''j'' given by\n::::<math> j = \\{ a \\in l_\\infty : {\\rm diag}(\\mu(a)) \\in J \\} . </math>\nAssociate to a sequence space ''j'' the two-sided ideal ''J'' given by\n::::<math> J = \\{ A \\in B(H) : \\mu(A) \\in j \\} . </math>\nHere μ(''A'') and μ(''a'') are the [[singular value]]s of the operators ''A'' and diag(''a''), respectively.\nCalkin's Theorem<ref name=\"Ca1\">{{cite journal\n| author= J. W. Calkin\n| year=1941\n| title=Two-sided ideals and congruences in the ring of bounded operators in Hiulbert space\n| volume =42\n| journal = Ann. Math. |series=2\n| pages= 839–873\n| doi= 10.2307/1968771\n| issue= 4 }}</ref> states that the two maps are inverse to each other. We obtain,\n\n:'''Calkin correspondence:''' The two-sided ideals of [[linear operator|bounded operators]] on an infinite dimensional separable Hilbert space and the Calkin sequence spaces are in bijective correspondence.\n\nIt is sufficient to know the association only between positive operators and positive sequences, hence the map μ: ''J''<sub>+</sub>&nbsp;→&nbsp;''j''<sub>+</sub> from a positive operator to its [[singular value]]s implements the Calkin correspondence.\n\nAnother way of interpreting the Calkin correspondence, since the sequence space ''j'' is equivalent as a Banach space to the operators in the operator ideal ''J'' that are diagonal with respect to an arbitrary orthonormal basis, is that two-sided ideals are completely determined by their diagonal operators.\n\n== Examples ==\n\nSuppose ''H'' is a separable infinite-dimensional Hilbert space.\n\n*'''[[linear operator|Bounded operators]].''' The improper two-sided ideal ''B''(''H'') corresponds to ''l''<sub>∞</sub>.\n*'''[[Compact operator]]s.''' The proper and norm closed two-sided ideal ''K''(''H'') corresponds to ''c''<sub>0</sub>, the [[sequence space|space of sequences converging to zero]].\n*'''[[Finite-rank operator|Finite rank operators]].''' The smallest two-sided ideal ''F''(''H'') of finite rank operators corresponds to ''c''<sub>00</sub>, the space of sequences with finite non-zero terms.\n*'''[[Schatten class operator|Schatten ''p''-ideals]].''' The Schatten ''p''-ideals ''L''<sub>''p''</sub>, ''p''&nbsp;≥&nbsp;1, correspond to the [[sequence space|''l''<sub>''p''</sub> sequence spaces]]. In particular, the trace class operators correspond to ''l''<sub>''1''</sub> and the Hilbert-Schmidt operators correspond to ''l''<sub>''2''</sub> . \n* '''Weak-''L''<sub>''p''</sub> ideals.''' The weak-''L''<sub>''p''</sub> ideals ''L''<sub>''p'',∞</sub>, ''p''&nbsp;≥&nbsp;1, correspond to the [[Lp space|weak-''l''<sub>p</sub> sequence spaces]].\n* '''Lorentz ψ-ideals.''' The Lorentz ψ-ideals for an increasing concave function ψ&nbsp;:&nbsp;[0,∞)&nbsp;→&nbsp;[0,∞) correspond to the [[Lorentz space|Lorentz sequence spaces]].\n\n== Notes ==\n\n{{reflist}}\n\n== References ==\n\n* {{cite book\n| isbn=978-0-8218-3581-4\n| author= B. Simon\n| year=2005\n| title=Trace ideals and their applications\n| publisher=Amer. Math. Soc.\n| location=Providence, Rhode Island }}\n\n* {{cite book\n| isbn=978-3-11-026255-1\n| author= S. Lord, F. A. Sukochev. D. Zanin\n| year=2012\n| url=http://www.degruyter.com/view/product/177778\n| title=Singular traces: theory and applications\n| publisher=De Gruyter\n| location=Berlin }}\n\n[[Category:Operator algebras]]\n[[Category:Hilbert space]]\n[[Category:Von Neumann algebras]]"
    },
    {
      "title": "Central carrier",
      "url": "https://en.wikipedia.org/wiki/Central_carrier",
      "text": "{{Orphan|date=July 2011}}\n\nIn the context of [[von Neumann algebra]]s, the '''central carrier''' of a projection ''E'' is the smallest central projection, in the von Neumann algebra, that dominates ''E''. It is also called the '''central support''' or '''central cover'''.\n\n== Definition ==\n\nLet ''L''(''H'') denote the bounded operators on a Hilbert space ''H'', '''M''' ⊂ ''L''(''H'') be a von Neumann algebra, and '''M`''' the [[commutant]] of '''M'''. The [[center (algebra)|center]] of '''M''' is ''Z''('''M''') = '''M`''' ∩ '''M''' = {''T'' ∈ '''M''' | ''TM'' = ''MT'' for all ''M'' ∈ '''M'''}. The central carrier ''C''(''E'') of a projection ''E'' in '''M''' is defined as follows:\n\n:''C''(''E'') = &and; {''F'' &isin; ''Z''('''M''') | ''F'' is a projection and ''F'' &ge; ''E''}.\n\nThe symbol ∧ denotes the lattice operation on the projections in ''Z''('''M'''): ''F''<sub>1</sub> ∧ ''F''<sub>2</sub> is the projection onto the closed subspace  Ran(''F''<sub>1</sub>) ∩ Ran(''F''<sub>2</sub>).\n\nThe abelian algebra ''Z''('''M'''), being the intersection of two von Neumann algebras, is also a von Neumann algebra. Therefore, ''C''(''E'') lies in ''Z''('''M''').\n\nIf one thinks of '''M''' as a direct sum (or more accurately, a [[direct integral]]) of its factors, then the central projections are the projections that are direct sums (direct integrals) of identity operators of (measurable sets of) the factors. If ''E'' is confined to a single factor, then ''C''(''E'') is the identity operator in that factor. Informally, one would expect ''C''(''E'') to be the direct sum of identity operators ''I'' where ''I'' is in a factor and '' I &middot; E &ne; 0''.\n\n== An explicit description ==\n\nThe projection ''C''(''E'') can be described more explicitly. It can be shown that Ran ''C''(''E'') is the closed subspace generated by '''M'''Ran(''E'').\n\nIf '''N''' is a von Neumann algebra, and ''E'' a projection that does not necessarily belong to '''N''' and has range ''K'' = Ran(''E''). The smallest central projection in '''N''' that dominates ''E'' is precisely the projection onto the closed subspace ['''N' ''' ''K''] generated by '''N' ''' ''K''. In symbols, if\n\n:''F' '' = &and; {''F'' &isin; '''N''' | ''F'' is a projection and ''F'' &ge; ''E''}\n\nthen Ran(''F' '') = ['''N' ''' ''K'']. That ['''N' ''' ''K''] ⊂ Ran(''F' '') follows from the definition of commutant. On the other hand, ['''N' '''''K''] is invariant under every unitary ''U'' in '''N' '''. Therefore the projection onto ['''N' ''' ''K''] lies in ('''N'''')' = '''N'''. Minimality of ''F' '' then yields Ran(''F' '') ⊂ ['''N' ''' ''K''].\n\nNow if ''E'' is a projection in '''M''', applying the above to the von Neumann algebra ''Z''('''M''') gives\n\n:Ran ''C''(''E'') = [ ''Z''('''M''')' Ran(''E'') ] =  [ ('''M' ''' &cap; '''M''')'  Ran(''E'') ] = ['''M'''Ran(''E'')].\n\n== Related results ==\n\nOne can deduce some simple consequences from the above description. Suppose ''E'' and ''F'' are projections in a von Neumann algebra '''M'''.\n\n'''Proposition''' ''ETF'' = 0 for all ''T'' in '''M''' if and only if ''C''(''E'') and ''C''(''F'') are orthogonal, i.e. ''C''(''E'')''C''(''F'') = 0.\n\n'''Proof:''' \n:''ETF'' = 0 for all ''T'' in '''M'''.\n:&hArr; ['''M''' ''Ran''(''F'')] &sub; ''Ker''(''E'').\n:&hArr; ''C''(''F'') &le; 1 - ''E'', by the discussion in the preceding section, where 1 is the unit in '''M'''.\n:&hArr; ''E'' &le; 1 - ''C''(''F'').\n:&hArr; ''C''(''E'') &le; 1 - ''C''(''F''), since 1 - ''C''(''F'') is a central projection that dominates ''E''.\n:This proves the claim.\n\nIn turn, the following is true:\n\n'''Corollary''' Two projections ''E'' and ''F'' in a von Neumann algebra '''M''' contain two nonzero subprojections that are Murray-von Neumann equivalent if ''C''(''E'')''C''(''F'') ≠ 0.\n\n'''Proof:'''\n:''C''(''E'')''C''(''F'') &ne; 0.\n:&rArr; ''ETF'' &ne; 0 for some ''T'' in '''M'''.\n:&rArr; ''ETF'' has [[polar decomposition]] ''UH'' for some partial isometry ''U'' and positive operator ''H'' in '''M'''.\n:&rArr; ''Ran''(''U'') = ''Ran''(''ETF'') &sub; ''Ran''(''E''). Also, ''Ker''(''U'') = ''Ran''(''H'')<sup>&perp;</sup> = ''Ran''(''ETF'')<sup>&perp;</sup> = ''Ker''(''ET*F'') &sup; ''Ker''(''F''); therefore ''Ker''(''U''))<sup>&perp;</sup> &sub; ''Ran''(''F'').\n:&rArr; The two equivalent projections ''UU*'' and ''U*U'' satisfy ''UU*'' &le; ''E'' and ''U*U'' &le; ''F''.\n\nIn particular, when '''M''' is a factor, then there exists a partial isometry ''U'' ∈ ''M'' such that ''UU*'' ≤ ''E'' and ''U*U'' ≤ ''F''. Using this fact and a maximality argument, it can be deduced that the Murray-von Neumann partial order « on the family of projections in '''M''' becomes a total order if '''M''' is a factor.\n\n'''Proposition (Comparability)''' If '''M''' is a factor, and ''E'', ''F'' ∈ '''M''' are projections, then either ''E'' « ''F'' or ''F'' « ''E''.\n\n'''Proof:'''\n:Let ~ denote the Murray-von Neumann equivalence relation. Consider the family ''S'' whose typical element is a set { (''E<sub>i</sub>'', ''F<sub>i</sub>'') } where the orthogonal sets {''E<sub>i</sub>''} and {''F<sub>i</sub>''} satisfy ''E<sub>i</sub>'' &le; ''E'', ''F<sub>i</sub>'' &le; ''F'', and ''E<sub>i</sub>'' ~ ''F<sub>i</sub>''. The family ''S'' is partially ordered by inclusion and the above corollary shows it is non-empty. Zorn's lemma ensures the existence of a maximal element { (''E<sub>j</sub>'', ''F<sub>j</sub>'') }. Maximality ensures that either ''E'' = &sum; ''E<sub>j</sub>'' or ''F'' = &sum; ''F<sub>j</sub>''. The countable additivity of ~ means ''E<sub>j</sub>'' ~ &sum; ''F<sub>j</sub>''. Thus the proposition holds.\n\nWithout the assumption that '''M''' is a factor, we have:\n\n'''Proposition (Generalized Comparability)''' If '''M''' is a von Neumann algebra, and ''E'', ''F'' ∈ '''M''' are projections, then there exists a central projection ''P'' ∈ ''Z''('''M''') such that either ''EP'' « ''FP'' and ''F''(1 - ''P'') « ''E''(1 - ''P'').\n\n'''Proof:'''\n:Let ''S'' be the same as in the previous proposition and again consider a maximal element { (''E<sub>j</sub>'', ''F<sub>j</sub>'') }. Let ''R'' and ''S'' denote the \"remainders\": ''R'' = ''E'' - &sum; ''E<sub>j</sub>'' and ''S'' = ''F'' - &sum; ''F<sub>j</sub>''. By maximality and the corollary, ''RTS'' = 0 for all ''T'' in '''M'''. So ''C''(''R'')''C''(''S'') = 0. In particular ''R'' &middot; ''C''(''S'') = 0 and ''S'' &middot; ''C''(''S'') = 0. So multiplication by ''C''(''S'') removes the remainder ''R'' from ''E'' while leaving ''S'' in ''F''. More precisely, ''E'' &middot; ''C''(''S'') =  (&sum; ''E<sub>j</sub>'' + ''R'') &middot; ''C''(''S'') =  (&sum; ''E<sub>j</sub>'') &middot; ''C''(''S'') ~ (&sum; ''F<sub>j</sub>'') &middot; ''C''(''S'') &le; (&sum; ''F<sub>j</sub>'' + ''S'') &middot; ''C''(''S'') = ''F'' &middot; ''C''(''S''). This shows that ''C''(''S'') is the [[central projection]] with the desired properties.\n\n== References ==\n*B. Blackadar, ''Operator Algebras'', Springer, 2006.\n*[[Shoichiro Sakai|S. Sakai]], ''C*-Algebras and W*-Algebras'', Springer, 1998.\n\n[[Category:Von Neumann algebras]]"
    },
    {
      "title": "Commutator subspace",
      "url": "https://en.wikipedia.org/wiki/Commutator_subspace",
      "text": "{{Orphan|date=September 2013}}\nIn mathematics, the '''commutator subspace''' of a two-sided [[ideal (ring theory)|ideal]] of [[linear operators|bounded linear operators]] on a separable [[Hilbert space]] is the linear subspace spanned by [[commutator#Ring theory|commutators]] of operators in the ideal with bounded operators.\nModern characterisation of the commutator subspace is through the [[Calkin correspondence]] and it involves the invariance of the Calkin sequence space of an operator ideal to taking [[Cesàro mean]]s.  This explicit spectral characterisation reduces problems and questions about commutators and [[singular trace|traces]] on two-sided ideals to (more resolvable) problems and conditions on sequence spaces.\n\n== History ==\n\nCommutators of linear operators on Hilbert spaces came to prominence in the 1930s as they featured in the [[matrix mechanics]], or Heisenberg, formulation of quantum mechanics.  Commutator subspaces, though, received sparse attention until the 1970s. American mathematician [[Paul Halmos]] in 1954 showed that every bounded operator on a separable infinite dimensional Hilbert space is the sum of two commutators of bounded operators.<ref name=\"Ha2\">{{cite journal\n| author=P. Halmos\n| year=1954\n| title=Commutators of operators. II\n| journal=Amer. J. Math.\n| volume=76\n| issue=1\n| pages=191–198\n| doi=10.2307/2372409| jstor=2372409\n}}\n</ref>\nIn 1971 Carl Pearcy and David Topping revisited the topic and studied commutator subspaces for [[Schatten class operator|Schatten ideals]].<ref name=\"PT\">\n{{cite journal\n|author1=C. Pearcy |author2=D. Topping | url = http://projecteuclid.org/DPubS/Repository/1.0/Disseminate?view=body&id=pdf_1&handle=euclid.mmj/1029000686\n| year=1971\n| title=On commutators in ideals of compact operators\n| journal=Michigan Math. J.\n| volume=18\n|issue=3 | pages=247–252\n| doi=10.1307/mmj/1029000686}}\n</ref> As a student American mathematician Gary Weiss began to investigate spectral conditions for commutators of [[Hilbert–Schmidt operators]].<ref name=\"GW1\">{{cite journal\n| author= G. Weiss\n| year=1980\n| title=Commutators of Hilbert–Schmidt Operators, II\n| journal=Integral Equations and Operator Theory\n| volume=4\n| issue=4\n| pages=574–600 | doi=10.1007/BF01702316\n}}\n</ref><ref name=\"GW2\">{{cite journal\n| author= G. Weiss\n| year=1986\n| title=Commutators of Hilbert–Schmidt Operators, I\n| journal=Integral Equations and Operator Theory\n| volume=9\n| issue=6\n| pages=877–892\n| doi=10.1007/bf01202521}}\n</ref>\nBritish mathematician [[Nigel Kalton]], noticing the spectral condition of Weiss, characterised all trace class commutators.<ref name=\"NK2\">\n{{cite journal\n| author= N. J. Kalton\n| year=1989\n| url=http://kaltonmemorial.missouri.edu/docs/jfa1989.pdf\n| title=Trace-class operators and commutators\n| journal=J. Functional Analysis\n| volume=86\n| pages=41–74\n| doi=10.1016/0022-1236(89)90064-5}}</ref>\nKalton's result forms the basis for the modern characterisation of the commutator subspace.\nIn 2004 Ken Dykema, Tadeusz Figiel, Gary Weiss and Mariusz Wodzicki published the spectral characterisation of normal operators in the commutator subspace for every two-sided ideal of compact operators.<ref name=\"DFWW\">\n{{cite journal\n|author1=K. Dykema |author2=T. Figiel |author3=G. Weiss |author4=M. Wodzicki | url=http://math.berkeley.edu/~wodzicki/prace/Advances-185.pdf\n| year=2004\n| title=Commutator structure of operator ideals\n| journal=Adv. Math.\n| volume=185\n| pages=1–79\n| doi=10.1016/s0001-8708(03)00141-5}}\n</ref>\n\n== Definition ==\n\nThe commutator subspace of a two-sided ideal ''J'' of the bounded linear operators ''B''(''H'') on a separable Hilbert space ''H'' is the linear span of operators in ''J'' of the form [''A'',''B'']&nbsp;=&nbsp;''AB''&nbsp;&minus;&nbsp;''BA'' for all operators ''A'' from ''J'' and ''B'' from ''B''(''H'').\n\nThe commutator subspace of ''J'' is a linear subspace of ''J'' denoted by Com(''J'') or [''B''(''H''),''J''].\n\n== Spectral characterisation ==\n\nThe [[Calkin correspondence]] states that a [[compact operator]] ''A'' belongs to a two-sided ideal ''J'' if and only if the [[singular values]] μ(''A'') of ''A'' belongs to the Calkin sequence space ''j'' associated to ''J''.  [[Normal operator]]s that belong to the commutator subspace Com(''J'') can characterised as those ''A'' such that μ(''A'') belongs to ''j'' ''and'' the [[Cesàro mean]] of the sequence μ(''A'') belongs to ''j''.<ref name=\"DFWW\"/> The following theorem is a slight extension to differences of normal operators<ref name=\"KLPS\">\n{{cite journal\n|author1=N. J. Kalton |author2=S. Lord |author3=D. Potapov |author4=F. Sukochev |title=Traces of compact operators and the noncommutative residue\n|journal=Adv. Math.\n|year=2013\n|volume=235\n|pages=1–55\n|url=http://kaltonmemorial.missouri.edu/docs/adv2013.pdf\n|doi=10.1016/j.aim.2012.11.007|arxiv=1210.3423}}\n</ref> (setting ''B''&nbsp;{{=}}&nbsp;0 in the following gives the statement of the previous sentence).\n\n: '''Theorem.'''  Suppose ''A,B'' are compact normal operators that belong to a two-sided ideal ''J''.  Then ''A''&nbsp;&minus;&nbsp;''B'' belongs to the commutator subspace Com(''J'') if and only if\n::::<math> \\left\\{ \\frac{1}{1+n} \\sum_{k=0}^n \\left( \\mu(k,A) - \\mu(k,B) \\right) \\right\\}_{n=0}^\\infty  \\in j </math>\n:where ''j'' is the Calkin sequence space corresponding to ''J'' and μ(''A''), μ(''B'') are the singular values of ''A'' and ''B'', respectively.\n\nProvided that the [[eigenvalue|eigenvalue sequences]] of all operators in ''J'' belong to the Calkin sequence space ''j'' there is a spectral characterisation for arbitrary (non-normal) operators. It is not valid for every two-sided ideal but necessary and sufficient conditions are known. Nigel Kalton and American mathematician Ken Dykema introduced the condition first for countably generated ideals.<ref name=\"N2\">\n{{cite journal\n|author=N. J. Kalton\n|title=Spectral characterization of sums of commutators, I\n|journal=J. Reine Angew. Math.\n|year=1998\n|volume=504\n|pages=115–125 }}</ref><ref name=\"DK\">\n{{cite journal\n|author1=K. Dykema |author2=N. J. Kalton |title=Spectral characterization of sums of commutators, II\n|journal=J. Reine Angew. Math.\n|year=1998\n|volume=504\n|pages=127–137 }}\n</ref>\nUzbek and Australian mathematicians Fedor Sukochev and Dmitriy Zanin completed the eigenvalue characterisation.<ref name=\"SZ1\">{{citation needed|date=September 2013}}\n</ref>\n\n: '''Theorem.''' Suppose ''J'' is a two-sided ideal such that a bounded operator ''A'' belongs to ''J'' whenever there is a bounded operator ''B'' in ''J'' such that\n{{NumBlk|::::| <math> \\prod_{k=0}^n \\mu(k,A) \\leq  \\prod_{k=0}^n \\mu(k,B), \\quad n=0,1,2, \\ldots . </math> | {{EquationRef|1}} }}\n:If the bounded operator ''A'' and ''B'' belong to ''J'' then ''A''&nbsp;&minus;&nbsp;''B'' belongs to the commutator subspace Com(''J'') if and only if\n::::<math> \\left\\{ \\frac{1}{1+n} \\sum_{k=0}^n \\left( \\lambda(k,A) - \\lambda(k,B) \\right) \\right\\}_{n=0}^\\infty  \\in j </math>\n:where ''j'' is the Calkin sequence space corresponding to ''J'' and λ(''A''), λ(''B'')  are the sequence of eigenvalues of the operators ''A'' and ''B'', respectively, rearranged so that the absolute value of the eigenvalues is decreasing.\n\nMost two-sided ideals satisfy the condition in the Theorem, included all Banach ideals and quasi-Banach ideals.\n\n== Consequences of the characterisation ==\n\n* Every operator in ''J'' is a sum of commutators if and only if the corresponding Calkin sequence space ''j'' is invariant under taking [[Cesàro mean]]s. In symbols, Com(''J'')&nbsp;{{=}}&nbsp;''J'' is equivalent to C(''j'')&nbsp;{{=}}&nbsp;''j'', where C denotes the Cesàro operator on sequences.\n* In any two-sided ideal the difference between a positive operator and its diagonalisation is a sum of commutators. That is, ''A''&nbsp;&minus;&nbsp;diag(μ(''A'')) belongs to Com(''J'') for every positive operator ''A'' in ''J'' where diag(μ(''A'')) is the diagonalisation of ''A'' in an arbitrary orthonormal basis of the separable Hilbert space ''H''.\n* In any two-sided ideal satisfying ({{EquationNote|1}}) the difference between an arbitrary operator and its diagonalisation is a sum of commutators. That is, ''A''&nbsp;&minus;&nbsp;diag(λ(''A'')) belongs to Com(''J'') for every operator ''A'' in ''J'' where diag(λ(''A'')) is the diagonalisation of ''A'' in an arbitrary orthonormal basis of the separable Hilbert space ''H'' and λ(''A'') is an eigenvalue sequence.\n* Every [[nilpotent operator|quasi-nilpotent operator]] in a two-sided ideal satisfying ({{EquationNote|1}}) is a sum of commutators.\n\n== Application to traces ==\n\n{{Main|Singular trace}}\n\nA trace φ on a two-sided ideal ''J'' of ''B''(''H)'' is a linear functional φ:''J'' → ℂ that vanishes on Com(''J'').  The consequences above imply\n\n* The two-sided ideal ''J'' has a non-zero trace if and only if C(''j'')&nbsp;≠&nbsp;''j''.\n* φ(''A'') = φ∘diag(μ(''A'')) for every positive operator ''A'' in ''J'' where diag(μ(''A'')) is the diagonalisation of ''A'' in an arbitrary orthonormal basis of the separable Hilbert space ''H''. That is, traces on ''J'' are in direct correspondence with [[symmetric functional]]s on ''j''.\n* In any two-sided ideal satisfying ({{EquationNote|1}}), φ(''A'')&nbsp;=&nbsp;φ∘diag(λ(''A'')) for every operator ''A'' in ''J'' where diag(λ(''A'')) is the diagonalisation of ''A'' in an arbitrary orthonormal basis of the separable Hilbert space ''H'' and λ(''A'') is an eigenvalue sequence.\n* In any two-sided ideal satisfying ({{EquationNote|1}}), φ(''Q'')=0 for every [[nilpotent operator|quasi-nilpotent operator]] ''Q'' from ''J'' and every trace φ on ''J''.\n\n== Examples ==\n\nSuppose ''H'' is a separable infinite dimensional Hilbert space.\n\n* '''Compact operators.''' The [[compact operator on hilbert space|compact linear operators]] ''K''(''H'') correspond to the space of converging to zero sequences, ''c''<sub>0</sub>. For a converging to zero sequence the [[Cesàro mean]]s converge to zero. Therefore, C(''c''<sub>0</sub>) = ''c''<sub>0</sub> and Com(''K''(''H''))&nbsp;{{=}}&nbsp;''K''(''H'').\n* '''Finite rank operators.''' The [[finite-rank operator|finite rank operators]] ''F''(''H'') correspond to the space of sequences with finite non-zero terms, ''c''<sub>00</sub>. The condition\n::::<math> \\left\\{ \\frac{a_1 + a_2 + \\cdots + a_n}{n} \\right\\}_{n=1}^\\infty  \\in c_{00} </math>\n:occurs if and only if\n::::<math>  a_1 + a_2 + \\cdots + a_N = 0 </math>\n:for the sequence (a<sub>1</sub>, a<sub>2</sub>, ... , a<sub>N</sub>, 0, 0 , ...) in ''c''<sub>00</sub>. The kernel of the [[trace class#Definition|operator trace]] Tr on ''F''(''H'') and the commutator subspace of the finite rank operators are equal, ker Tr&nbsp;{{=}}&nbsp;Com(''F''(''H''))&nbsp;⊊&nbsp;''F''(''H'').\n\n* '''Trace class operators.''' The [[trace class operator]]s ''L''<sub>1</sub> correspond to the [[sequence space|summable sequences]]. The condition\n::::<math> \\left\\{ \\frac{a_1 + a_2 + \\cdots + a_n}{n} \\right\\}_{n=1}^\\infty  \\in \\ell_{1} </math>\n:is stronger than the condition that a<sub>1</sub> + a<sub>2</sub> ... = 0. An example is the sequence with\n::::<math> a_n = \\frac{1}{n \\log^2(n)} , \\quad n \\geq 2 . </math>\n:and\n::::<math> a_1 = - \\sum_{n=2}^\\infty a_n. </math>\nwhich has sum zero but does not have a summable sequence of Cesàro means. Hence Com(''L''<sub>1</sub>) ⊊ ker Tr ⊊ ''L''<sub>1</sub>.\n\n* '''Weak trace class operators'''. The [[weak trace-class operator|weak trace class operators]] ''L''<sub>1,∞</sub> correspond to the [[Lp space|weak-''l''<sub>1</sub> sequence space]]. From the condition\n::::<math> \\left\\{ \\frac{a_1 + a_2 + \\cdots + a_n}{n} \\right\\}_{n=1}^\\infty  \\in \\ell_{1,\\infty} </math>\n:or equivalently\n::::<math> \\left\\{ a_1 + a_2 + \\cdots + a_n \\right\\}_{n=1}^\\infty  = O(1) </math>\nit is immediate that Com(''L''<sub>''1'',∞</sub>)<sub>+</sub>&nbsp;{{=}}&nbsp;(''L''<sub>1</sub>)<sub>+</sub>. The commutator subspace of the weak trace class operators contains the trace class operators. The [[harmonic series (mathematics)|harmonic sequence]]\n1,1/2,1/3,...,1/n,... belongs to ''l''<sub>1,∞</sub> and it has a divergent series, and therefore the\nCesàro means of the harmonic sequence do not belong to ''l''<sub>1,∞</sub>.\nIn summary, ''L''<sub>1</sub> ⊊&nbsp;Com(''L''<sub>1,∞</sub>) ⊊&nbsp;''L''<sub>1,∞</sub>.\n\n== Notes ==\n\n{{reflist}}\n\n== References ==\n\n* {{cite journal\n|author1=K. Dykema |author2=T. Figiel |author3=G. Weiss |author4=M. Wodzicki | url=http://math.berkeley.edu/~wodzicki/prace/Advances-185.pdf\n| year=2004\n| title=Commutator structure of operator ideals\n| journal=Adv. Math.\n| volume=185\n| pages=1–79\n| doi=10.1016/s0001-8708(03)00141-5}}\n\n* {{Citation\n | author=G. Weiss\n | contribution=''B''(''H'')-commutators: a historical survey\n |editor1=Dumitru Gaşpar |editor2=Dan Timotin |editor3=László Zsidó |editor4=Israel Gohberg |editor5=Florian-Horia Vasilescu | title = Recent Advances in Operator Theory, Operator Algebras, and their Applications\n | series= Operator Theory: Advances and Applications\n | volume=153\n | pages=307–320\n | publisher = Birkhäuser Basel\n | place = Berlin\n | year = 2005\n | isbn=978-3-7643-7127-2 }}\n\n* {{Citation\n |author1=T. Figiel |author2=N. Kalton | contribution=Symmetric linear functionals on function spaces\n | editor = M. Cwikel |editor2=M. Englis |editor3=A. Kufner |editor4=L.-E. Persson |editor5=G. Sparr\n | title = Function Spaces, Interpolation Theory, and Related Topics: Proceedings of the International Conference in Honour of Jaak Peetre on His 65th Birthday : Lund, Sweden, August 17–22, 2000\n | series= De Gruyter: Proceedings in Mathematics\n | pages=311–332\n | publisher = De Gruyter\n | place = Berlin\n | year = 2002\n | isbn=978-3-11-019805-8 }}\n\n* {{cite book\n| isbn=978-3-11-026255-1\n| author= S. Lord, F. A. Sukochev. D. Zanin\n| year=2012\n| url=http://www.degruyter.com/view/product/177778\n| title=Singular traces: theory and applications\n| publisher=De Gruyter\n| location=Berlin | doi= 10.1515/9783110262551\n}}\n\n[[Category:Hilbert space]]\n[[Category:Von Neumann algebras]]"
    },
    {
      "title": "Connes embedding problem",
      "url": "https://en.wikipedia.org/wiki/Connes_embedding_problem",
      "text": "In [[von Neumann algebra]]s, the '''Connes embedding problem''' or [[conjecture]], due to [[Alain Connes]], asks whether every [[von Neumann algebra#Type II factors|type II<sub>1</sub> factor]] on a separable Hilbert space can be embedded into the ultrapower of the [[Hyperfinite type II factor|hyperfinite type II<sub>1</sub> factor]]  by a [[ultrafilter|free ultrafilter]]. The problem admits a number of equivalent formulations.<ref name = cep>{{cite journal |title= |jstor=2669132}}</ref>\n\n==Statement==\nLet <math>\\omega</math> be a [[ultrafilter|free ultrafilter]] on the natural numbers and let ''R'' be the [[Hyperfinite type II factor|hyperfinite type II<sub>1</sub> factor]] with trace <math>\\tau</math>. One can construct the ultrapower <math>R^\\omega</math> as follows: let <math>l^\\infty(R)=\\{(x_n)_n\\subseteq R:\\sup_n||x_n||<\\infty\\}</math> be the von Neumann algebra of norm-bounded sequences and let <math>I_\\omega=\\{(x_n)\\in l^\\infty(R):\\lim_{n\\rightarrow\\omega}\\tau(x_n^*x_n)^{\\frac{1}{2}}=0\\}</math>. The quotient <math>l^\\infty(R)/I_\\omega</math> turns out to be a II<sub>1</sub> factor with trace <math>\\tau_{R^\\omega}(x)=\\lim_{n\\rightarrow\\omega}\\tau(x_n+I_\\omega)</math>, where <math>(x_n)_n</math> is any representative sequence of <math>x</math>.\n\n'''Connes' Embedding Conjecture''' asks whether every [[von Neumann algebra|type II<sub>1</sub> factor]] on a separable Hilbert space can be embedded into some <math>R^\\omega</math>.\n\nThe isomorphism class of <math>R^\\omega</math> is independent of the ultrafilter if and only if the [[continuum hypothesis]] is true (Ge-Hadwin and Farah-Hart-Sherman), but such an embedding property does not depend on the ultrafilter because von Neumann algebras acting on separable Hilbert spaces are, roughly speaking, very small.\n\n==References==\n*Fields Workshop around Connes' Embedding Problem &ndash; University of Ottawa, May 16&ndash;18, 2008<ref>http://www.fields.utoronto.ca/programs/scientific/07-08/embedding/abstracts.html#brown</ref>\n* Survey on Connes' Embedding Conjecture, Valerio Capraro<ref>https://arxiv.org/PS_cache/arxiv/pdf/1003/1003.2076v1.pdf</ref>\n* Model theory of operator algebras I: stability, I. Farah - B. Hart - D. Sherman<ref>http://people.virginia.edu/~des5e/papers/2009c30-stable-appl.pdf{{dead link|date=August 2017 |bot=InternetArchiveBot |fix-attempted=yes }}</ref>\n* Ultraproducts of C*-algebras, Ge and Hadwin, Oper. Theory Adv. Appl. 127 (2001), 305-326.\n*A linearization of Connes’ embedding problem, Benoıt Collins and Ken Dykema<ref>http://www.emis.de/journals/NYJM/j/2008/14-28.pdf</ref>\n*Notes On Automorphisms Of Ultrapowers Of II<sub>1</sub> Factors, David Sherman, Department of Mathematics, University of Virginia<ref>http://people.virginia.edu/~des5e/papers/sm-autultra.pdf</ref>\n\n==Notes==\n{{reflist}}\n\n[[Category:Von Neumann algebras]]\n\n\n{{mathanalysis-stub}}"
    },
    {
      "title": "Continuous geometry",
      "url": "https://en.wikipedia.org/wiki/Continuous_geometry",
      "text": "In mathematics, '''continuous geometry''' is an analogue of complex [[projective geometry]] introduced  by {{harvs|txt|authorlink=John von Neumann|last=von Neumann|year1=1936|year2=1998}}, where instead of the dimension of a subspace being in a discrete set 0, 1, ..., ''n'', it can be an element of the unit interval [0,1]. Von Neumann was motivated by his discovery of [[von Neumann algebra]]s with a dimension function taking a continuous range of dimensions, and the first example of a continuous geometry other than projective space was the projections of the [[hyperfinite type II factor]].\n\n==Definition==\n\nMenger and Birkhoff gave axioms for projective geometry in terms of the lattice of linear subspaces of projective space. Von Neumann's axioms for continuous geometry are a weakened form of these axioms.\n\nA continuous geometry is a [[lattice (order)|lattice]] ''L'' with the following properties\n\n*''L'' is [[modular lattice|modular]].\n*''L'' is [[Complete lattice|complete]].\n*The lattice operations ∧, ∨ satisfy a certain continuity property,\n*:<math>(\\bigwedge_{\\alpha\\in A} a_\\alpha)\\lor b = \\bigwedge_\\alpha (a_\\alpha\\lor b)</math>, where ''A'' is a [[directed set]] and if {{nowrap|''α'' < ''β''}} then {{nowrap|''a''<sub>''α''</sub> &lt; ''a''<sub>''β''</sub>}}, and the same condition with ∧ and ∨ reversed.\n*Every element in ''L'' has a complement (not necessarily unique). A complement of an element ''a'' is an element ''b'' with {{nowrap|1=''a'' ∧ ''b'' = 0}}, {{nowrap|1=''a'' ∨ ''b'' = 1}}, where 0 and 1 are the minimal and maximal elements of ''L''.\n*''L'' is irreducible: this means that the only elements with unique complements are 0 and 1.\n\n==Examples==\n\n*Finite-dimensional complex projective space, or rather its set of linear subspaces, is a continuous geometry, with dimensions taking values in the discrete set {0, 1/''n'', 2/''n'', ..., 1}\n*The projections of a finite type II von Neumann algebra form a continuous geometry with dimensions taking values in the unit interval [0,1].\n*{{harvtxt|Kaplansky|1955}} showed that any [[Complemented lattice|orthocomplemented]] complete modular lattice is a continuous geometry.\n*If ''V'' is a vector space over a [[Field (mathematics)|field]] (or [[division ring]]) ''F'', then there is a natural map from the lattice PG(''V'') of subspaces of ''V'' to the lattice of subspaces of ''V''⊗''F''<sup>2</sup> that multiplies dimensions by 2. So we can take a [[direct limit]] of\n::<math>PG(F)\\subset PG(F^2)\\subset PG(F^4)\\subset PG(F^8)\\cdots</math>\n:This has a dimension function taking values all [[dyadic rational]]s between 0 and 1. Its completion is a continuous geometry containing elements of every dimension in [0,1]. This geometry was constructed by {{harvtxt|von Neumann|1936b}}, and is called the continuous geometry over \"F\"\n\n==Dimension==\n\nThis section summarizes some of the results of {{harvtxt|von Neumann|1998|loc=Part I}}. These results are similar to, and were motivated by, von Neumann's work on projections in von Neumann algebras.\n\nTwo elements ''a'' and ''b'' of ''L'' are called '''perspective''', written {{nowrap|''a'' ∼ ''b''}},  if they have a common complement. This is an [[equivalence relation]] on ''L''; the proof that it is transitive is quite hard.\n\nThe equivalence classes ''A'', ''B'', ... of ''L'' have a total order on them defined by {{nowrap|''A'' ≤ ''B''}} if there is some ''a'' in ''A'' and ''b'' in ''B'' with {{nowrap|''a'' ≤ ''b''}}. (This need not hold for all ''a'' in ''A'' and ''b'' in ''B''.)\n\nThe dimension function ''D'' from ''L'' to the unit interval is defined as follows. \n*If equivalence classes ''A'' and ''B'' contain elements ''a'' and ''b'' with {{nowrap|1=''a'' ∧ ''b'' = 0}} then their sum {{nowrap|''A'' + ''B''}} is defined to be the equivalence class of {{nowrap|''a'' ∨ ''b''}}. Otherwise the sum {{nowrap|''A'' + ''B''}} is not defined. For a positive integer ''n'', the product ''nA'' is defined to be the sum of ''n'' copies of ''A'', if this sum is defined.\n*For equivalence classes ''A'' and ''B'' with ''A'' not {0} the integer {{nowrap|[''B'' : ''A'']}} is defined to be the unique integer {{nowrap|''n'' ≥ 0}} such that {{nowrap|1=''B'' = ''nA'' + ''C''}} with {{nowrap|''C'' < ''B''}}.\n*For equivalence classes ''A'' and ''B'' with ''A'' not {0} the real number {{nowrap|(''B'' : ''A'')}} is defined to be the limit of {{nowrap|[''B'' : ''C''] / [''A'' : ''C'']}} as ''C'' runs though a minimal sequence: this means that either ''C'' contains a minimal nonzero element, or an infinite sequence of nonzero elements each of which is at most half the preceding one.\n*''D''(''a'') is defined to be {{nowrap|({''a''} : {1})}}, where {''a''} and {1} are the equivalence classes containing ''a'' and 1.\n\nThe image of ''D'' can be the whole unit interval, or the set of numbers 0, 1/''n'', 2/''n'', ..., 1 for some positive integer ''n''. Two elements of ''L'' have the same image under ''D'' if and only if they are perspective, so it gives an injection from the equivalence classes to a subset of the unit interval. The dimension function ''D'' has the properties:\n*If {{nowrap|''a'' < ''b''}} then {{nowrap|''D''(''a'') < ''D''(''b'')}}\n*''D''(''a'' ∨ ''b'') + ''D''(''a'' ∧ ''b'') = ''D''(''a'') + ''D''(''b'')\n*{{nowrap|1=''D''(''a'') = 0}} if and only if {{nowrap|1=''a'' = 0}}, and {{nowrap|1=''D''(''a'') = 1}} if and only if {{nowrap|1=''a'' = 1}}\n*{{nowrap|0 ≤ ''D''(''a'') ≤ 1}}\n\n==Coordinatization theorem==\n\nIn projective geometry, the [[Veblen–Young theorem]] states that a projective geometry of dimension at least 3 is [[isomorph]]ic to the projective geometry of a vector space over a division ring. This can be restated as saying that the subspaces in the projective geometry correspond to the [[Principal ideal ring|principal right ideals]] of a matrix algebra over a division ring.\n\nNeumann generalized this to continuous geometries, and more generally to complemented modular lattices,  as follows {{harv|Neumann|1998|loc=Part II}}. His theorem states that if a complemented modular lattice ''L'' has order{{definition|date=September 2015}} at least 4, then the elements of ''L'' correspond to the principal right ideals of a [[von Neumann regular ring]]. More precisely if the lattice has order ''n'' then the von Neumann regular ring can be taken to be an ''n'' by ''n''  matrix ring ''M''<sub>''n''</sub>(''R'') over another von Neumann regular ring ''R''. Here a complemented modular lattice has order ''n'' if it has a homogeneous basis of ''n'' elements, where a basis is ''n'' elements ''a''<sub>1</sub>, ..., ''a''<sub>''n''</sub> such that {{nowrap|1=''a''<sub>''i''</sub> ∧ ''a''<sub>''j''</sub> = 0}} if {{nowrap|''i'' ≠ ''j''}}, and {{nowrap|1=''a''<sub>1</sub> ∨ ... ∨ ''a''<sub>''n''</sub> = 1}}, and a basis is called homogeneous if any two elements are perspective. The order of a lattice need not be unique; for example, any lattice has order 1. The condition that the lattice has order  at least 4 corresponds to the condition that the dimension is at least 3 in the Veblen–Young theorem, as a projective space has dimension at least 3 if and only if it has a set of at least  4 independent points.\n\nConversely, the principal right ideals of a von Neumann regular ring form a complemented modular lattice {{harv|Neumann|1998|loc=Part II theorem 2.4}}.\n\nSuppose that  ''R'' is a von Neumann regular ring and ''L'' its lattice of principal right ideals, so that ''L'' is a complemented modular lattice. Neumann showed that ''L'' is a continuous geometry if and only if ''R'' is an irreducible complete [[rank ring]].\n\n==References==\n\n*{{Citation | last1=Birkhoff | first1=Garrett | author1-link=Garrett Birkhoff | title=Lattice theory | origyear=1940 | url=https://books.google.com/books?id=o4bu3ex9BdkC | publisher=[[American Mathematical Society]] | location=Providence, R.I. | edition=3rd | series=American Mathematical Society Colloquium Publications | isbn=978-0-8218-1025-5 | mr=598630 | year=1979 | volume=25}}\n*{{eom|id=o/o070450|title=Orthomodular lattice|first=T.S. |last=Fofanova}}\n*{{Citation | last1=Halperin | first1=Israel | author1-link=Israel Halperin| title=Introduction to von Neumann algebras and continuous geometry | doi=10.4153/CMB-1960-034-5 | mr=0123923 | year=1960 | journal=[[Canadian Mathematical Bulletin]] | issn=0008-4395 | volume=3 | pages=273–288}}\n*{{Citation | last1=Halperin | first1=Israel | author1-link=Israel Halperin | title=Books in Review: A survey of John von Neumann's books on continuous geometry | doi=10.1007/BF00383607 | mr=1554221 | year=1985 | journal=Order | issn=0167-8094 | volume=1 | issue=3 | pages=301–305}}\n*{{Citation | last1=Kaplansky | first1=Irving | author1-link=Irving Kaplansky | title=Any orthocomplemented complete modular lattice is a continuous geometry | jstor=1969811 | mr=0088476 | year=1955 | journal=[[Annals of Mathematics]] |series=Second Series | issn=0003-486X | volume=61 | issue=3 | pages=524–541 | doi=10.2307/1969811}}\n*{{Citation | last1=Neumann | first1=John von | author1-link=John von Neumann | title=Continuous geometry | jstor=86390 | doi=10.1073/pnas.22.2.92 | zbl=0014.22307 | year=1936 | journal=[[Proceedings of the National Academy of Sciences|Proceedings of the National Academy of Sciences of the United States of America]] | issn=0027-8424 | volume=22 | issue=2 | pages=92–100}}\n*{{Citation | last1=Neumann | first1=John von| author1-link=John von Neumann | title=Examples of continuous geometries | jstor=86391 | doi=10.1073/pnas.22.2.101 | jfm=62.0648.03 | year=1936b | journal=Proc. Natl. Acad. Sci. USA | volume=22 | issue=2 | pages=101–108 | pmid=16588050 | pmc=1076713}}\n*{{Citation | last1=Neumann | first1=John von| author1-link=John von Neumann | title=Continuous geometry | origyear=1960 | url=https://books.google.com/books?id=onE5HncE-HgC | publisher=[[Princeton University Press]] | series=Princeton Landmarks in Mathematics | isbn=978-0-691-05893-1 | mr=0120174 | year=1998}}\n*{{Citation | last1=Neumann | first1=John von| author1-link=John von Neumann | editor1-last=Taub | editor1-first=A. H. | title=Collected works. Vol. IV: Continuous geometry and other topics | url=https://books.google.com/books?id=HOTXAAAAMAAJ | publisher=Pergamon Press | location=Oxford | mr=0157874 | year=1962}}\n*{{Citation | last1=Neumann | first1=John von| author1-link=John von Neumann | editor1-last=Halperin | editor1-first=Israel | title=Continuous geometries with a transition probability | origyear=1937 | url=https://books.google.com/books?id=ZPkVGr8NXugC | mr=634656 | year=1981 | journal=Memoirs of the American Mathematical Society | issn=0065-9266 | volume=34 | issue=252 | isbn=978-0-8218-2252-4 }}\n*{{Citation | last1=Skornyakov | first1=L. A. | title=Complemented modular lattices and regular rings | url=https://books.google.com/books?id=p54EAQAAIAAJ | publisher=Oliver & Boyd | location=London | mr=0166126 | year=1964}}\n\n[[Category:Projective geometry]]\n[[Category:Von Neumann algebras]]\n[[Category:Lattice theory]]"
    },
    {
      "title": "Crossed product",
      "url": "https://en.wikipedia.org/wiki/Crossed_product",
      "text": "{{Distinguish|cross product}}\n\nIn [[mathematics]], and more specifically in the theory of [[von Neumann algebra]]s, a '''crossed product'''\nis a basic method of constructing a new von Neumann algebra from \na von Neumann algebra [[Group action (mathematics)|acted on]] by a [[Group (mathematics)|group]]. It is related to \nthe [[semidirect product]] construction for groups. (Roughly speaking, ''crossed product'' is the expected structure for a [[group ring]] of a semidirect product group. Therefore crossed products have a [[ring theory]] aspect also. This article concentrates on an important case, where they appear in [[functional analysis]].)\n\n==Motivation== \nRecall that if we have two [[finite group]]s <math>G</math> and ''N'' with an action of ''G'' on ''N'' we can form the semidirect product <math>N \\rtimes G</math>. This contains ''N''\nas a [[normal subgroup]], and the action of ''G'' on ''N'' is given by [[Inner automorphism|conjugation]] in the semidirect product. We can replace ''N'' by its complex [[group algebra]] ''C''[''N''], and again form a product <math>C[N] \\rtimes G</math> in a similar way; this algebra is a [[Direct sum of modules|sum of subspaces]] ''gC''[''N''] as ''g'' runs through the elements of ''G'', and is the group algebra of <math>N \\rtimes G</math>.\nWe can generalize this construction further by replacing ''C''[''N'']\nby any algebra ''A'' acted on by ''G'' to get a crossed product\n<math>A \\rtimes G</math>, which is the sum of subspaces\n''gA'' and where the action of ''G'' on ''A'' is given by conjugation in the crossed product.\n\nThe crossed product of a von Neumann algebra by a group ''G'' acting on it is similar except that we have to be more careful about [[topology|topologies]], and need to construct a [[Hilbert space]] acted on by the crossed product. (Note that the von Neumann algebra crossed product is usually larger than the algebraic crossed product discussed above; in fact it is some sort of completion of the algebraic crossed product.)\n\nIn physics, this structure appears in presence of the so called gauge group of the first kind. ''G'' is the gauge group, and ''N'' the \"field\" algebra. The observables are then defined as the fixed points of ''N'' under the action of ''G''. A result by Doplicher, Haag and Roberts says that under some assumptions the crossed product can be recovered from the algebra of observables.\n\n==Construction==\nSuppose that ''A'' is a [[von Neumann algebra]] of operators acting on a Hilbert space ''H'' and ''G'' is a discrete group acting on ''A''.  We let ''K'' be the Hilbert space of all square summable ''H''-valued functions on ''G''. There is an action of ''A'' on ''K''\ngiven by \n*a(k)(g) = g<sup>−1</sup>(a)k(g)\nfor ''k'' in ''K'', ''g'', ''h'' in ''G'', and ''a'' in ''A'',\nand there is an action of ''G'' on ''K'' given by\n*g(k)(h) = k(g<sup>−1</sup>h).\nThe crossed product <math>A \\rtimes G</math> is the von Neumann algebra acting on ''K'' generated by the actions of ''A'' and ''G'' on ''K''. It does not depend (up to isomorphism) on the choice of the Hilbert space ''H''.\n\nThis construction can be extended to work for any locally compact group ''G'' acting on any von Neumann algebra ''A''. When <math>A</math> is an [[abelian von Neumann algebra]], this is the original '''group-measure space''' construction of [[Francis Joseph Murray|Murray]] and [[John von Neumann|von Neumann]].\n\n==Properties==\n\nWe let ''G'' be an infinite countable discrete group acting on the abelian von Neumann algebra ''A''. The action is called '''free''' if\n''A'' has no non-zero  projections ''p'' such that some nontrivial ''g'' fixes \nall elements of ''pAp''. The action is called '''ergodic''' if \nthe only invariant projections are 0 and 1. \nUsually ''A'' can be identified as the abelian von Neumann algebra <math>L^\\infty(X)</math> of essentially bounded functions on a [[measure space]] ''X'' acted on by ''G'', and then the action of ''G'' on ''X'' is ergodic (for any measurable invariant subset, either the subset or its complement has measure 0) if and only if the action of ''G'' on ''A'' is ergodic.\n\nIf the action of ''G'' on ''A'' is free and ergodic\nthen the crossed product <math>A \\rtimes G</math> is a factor.\nMoreover:\n* The factor is of type I if ''A'' has a minimal projection such that 1 is the sum of the ''G'' conjugates of this projection. This corresponds to the action of ''G'' on ''X'' being transitive. Example: ''X'' is the integers, and ''G'' is the group of integers acting by translations.\n*The factor has type II<sub>1</sub> if ''A'' has a faithful finite normal ''G''-invariant trace. This corresponds to ''X'' having a finite ''G'' invariant measure, absolutely continuous with respect to the measure on ''X''. Example: ''X'' is the unit circle in the complex plane, and ''G'' is the group of all roots of unity. \n*The factor has type  II<sub>∞</sub> if it is not of types I or II<sub>1</sub> and has a faithful semifinite normal ''G''-invariant trace. This corresponds to ''X'' having an infinite ''G'' invariant measure without atoms, absolutely continuous with respect to the measure on ''X''. Example: ''X'' is the real line, and ''G'' is the group of rationals acting by translations.\n*The factor has type III if ''A'' has no faithful semifinite normal ''G''-invariant trace. This corresponds to ''X'' having no non-zero absolutely continuous ''G''-invariant measure. Example: ''X'' is the real line, and ''G'' is the group of all transformations ''ax''+''b'' for ''a'' and ''b'' rational, ''a'' non-zero.\n\nIn particular one can construct examples of all the different types of factors as crossed products.\n\n==Duality==\n\nIf <math>A</math> is a [[von Neumann algebra]] on which a locally compact Abelian <math>G</math> acts, then <math> \\Gamma</math>, the [[Pontryagin duality|dual group]] of [[Character (mathematics)|characters]] <math>\\chi</math> of <math>G</math>, acts by unitaries on <math>K</math> :\n* <math>(\\chi\\cdot k)(h) =\\chi(h) k(h)</math>\nThese unitaries normalise the crossed product, defining the '''dual action''' of <math>\\Gamma</math>. Together with the crossed product, they generate <math>A\\otimes B(L^2(G))</math>, which\ncan be identified with the iterated crossed product by the dual action <math>(A\\rtimes G) \\rtimes \\Gamma</math> . Under this identification, the double dual action of <math>G</math> (the dual group of <math>\\Gamma</math>) corresponds to the tensor product of the original action on <math>A</math> and conjugation by the following unitaries on <math> L^2(G)</math> :\n* <math>(g\\cdot f)(h)=f(hg)</math>\nThe crossed product may be identified with the [[fixed point algebra]] of the double dual action. More generally <math>A</math> is the [[fixed point algebra]] of <math>\\Gamma</math> in the crossed product.\n\nSimilar statements hold when <math>G</math> is replaced by a [[Non-abelian group|non-Abelian]] locally compact group or more generally a [[locally compact quantum group]], a class of [[Hopf algebra]] related to [[von Neumann algebra]]s. An analogous theory has also been developed for actions on [[C* algebras]] and their crossed products.\n\nDuality first appeared for actions of the [[real number|reals]] in the work of [[Alain Connes|Connes]] and Takesaki on the classification of [[Type III factor]]s.\nAccording to [[Tomita–Takesaki theory]], every vector which is cyclic for the factor and its [[commutant]] gives rise to a 1-parameter ''modular automorphism group''. The corresponding crossed product is a Type <math>II_\\infty</math> [[von Neumann algebra]] and the corresponding dual action restricts to an [[ergodic]] action of the [[real number|reals]] on its centre, an [[Abelian von Neumann algebra]]. This [[ergodic flow]] is called the ''flow of weights''; it is independent of the choice of cyclic vector. The ''Connes spectrum'', a closed subgroup of the [[positive reals]] ℝ<sup>+</sup>, is obtained by applying the exponential to the kernel of this flow.\n* When the kernel is the whole of <math> R</math>, the factor is type <math>III_1</math>.\n* When the kernel is <math>(\\log \\lambda) Z</math> for <math>\\lambda</math> in (0,1), the factor is type <math>III_\\lambda</math>. \n* When the kernel is trivial, the factor is type <math>III_0</math>.\n[[Alain Connes|Connes]] and Haagerup proved that the Connes spectrum and the flow of weights are [[Complete set of invariants|complete invariants]] of hyperfinite [[Type III factor]]s.\nFrom this classification and results in [[ergodic theory]], it is known that every infinite-dimensional hyperfinite factor has the form <math>L^\\infty(X)\\rtimes Z</math> for some free ergodic action of <math> Z</math>.\n\n==Examples==\n\n*If we take the algebra ''A'' to be the complex numbers ''C'', then the crossed product <math>A \\rtimes G</math> is called the '''von Neumann group algebra''' of ''G''.\n*If ''G'' is an infinite discrete group such that every conjugacy class has infinite order then the von Neumann group algebra is a factor of  type II<sub>1</sub>. Moreover if every finite set of elements of ''G'' generates a finite subgroup (or more generally if ''G'' is amenable) then the factor is the hyperfinite factor of type II<sub>1</sub>.\n\n==See also==\n* [[Crossed product algebra]]\n\n==References==\n* {{Citation | last=Takesaki | first=Masamichi | title=Theory of Operator Algebras I, II, III | publisher=[[Springer-Verlag]] | location=Berlin, New York | isbn=978-3-540-42248-8 | year=2002}}, {{ISBN|3-540-42914-X}} (II), {{ISBN|3-540-42913-1}} (III)\n* {{Citation | last1=Connes | first1=Alain | author1-link=Alain Connes | title=Non-commutative geometry | url=http://www.alainconnes.org/docs/book94bigpdf.pdf | publisher=[[Academic Press]] | location=Boston, MA | isbn=978-0-12-185860-5 | year=1994 }}\n* {{Citation | last1=Pedersen | first1=Gert Kjaergard | title=C*-algebras and their automorphism groups | publisher=[[Academic Press]] | location=Boston, MA | series=London Math. Soc. Monographs | isbn=978-0-12-549450-2 | year=1979 | volume=14}}\n\n[[Category:Operator theory]]\n[[Category:Von Neumann algebras]]"
    },
    {
      "title": "Direct integral",
      "url": "https://en.wikipedia.org/wiki/Direct_integral",
      "text": "In [[mathematics]] and [[functional analysis]] a '''direct integral''' is a generalization of the concept of [[direct sum]]. The theory is most developed for direct integrals of [[Hilbert space]]s and direct integrals of [[von Neumann algebra]]s. The concept was introduced in 1949 by [[John von Neumann]] in one of the papers in the series ''On Rings of Operators''. One of von Neumann's goals in this paper was to reduce the classification of (what are now called) von Neumann algebras on separable Hilbert spaces to the classification of so-called factors. Factors are analogous to full matrix algebras over a field, and von Neumann wanted to prove a continuous analogue of the [[Artin–Wedderburn theorem]] classifying semi-simple rings.\n\nResults on direct integrals can be viewed as generalizations of results about finite-dimensional [[C*-algebra]]s of matrices; in this case the results are easy to prove directly. The infinite-dimensional case is complicated by measure-theoretic technicalities.\n\nDirect integral theory was also used by [[George Mackey]] in his analysis of [[system of imprimitivity|systems of imprimitivity]] and his general theory of [[induced representation]]s of locally compact separable groups.\n\n== Direct integrals of Hilbert spaces ==\nThe simplest example of a direct integral are the ''L''<sup>2</sup> spaces associated to a (σ-finite) countably additive measure μ on a [[measurable space]] ''X''. Somewhat more generally one can consider a separable Hilbert space ''H'' and the space of square-integrable ''H''-valued functions\n\n:<math> L^2_\\mu(X, H). </math>\n\n'''Terminological note''': The terminology adopted by the literature on the subject is followed here, according to which a measurable space ''X'' is referred to as a ''Borel space'' and the elements of the distinguished σ-algebra of ''X'' as Borel sets, regardless of whether or not the underlying σ-algebra comes from a topological space (in most examples it does). A Borel space is ''standard'' [[if and only if]] it is isomorphic to the underlying Borel space of a [[Polish space]]; all Polish spaces of a given cardinality are isomorphic to each other (as Borel spaces). Given a countably additive measure μ on ''X'', a measurable set is one that differs from a Borel set by a [[null set]].  The measure μ on ''X'' is a ''standard'' measure if and only if there is a null set ''E'' such that its complement ''X'' − ''E'' is a [[standard Borel space]].{{clarify|reason=Is this X assumed in advance to be a Borel space, or to be a standard Borel space?|date=September 2015}} All measures considered here are σ-finite.\n\n'''Definition'''. Let ''X'' be a Borel space equipped with a countably additive measure μ. A ''measurable family of Hilbert spaces'' on (''X'', μ) is a family {''H''<sub>''x''</sub>}<sub>''x''∈ ''X''</sub>, which is locally equivalent to a trivial family in the following sense: There is a countable partition\n\n:<math> \\{X_n\\}_{1 \\leq n \\leq \\omega} </math>\n\nby measurable subsets of ''X'' such that\n\n:<math> H_x = \\mathbf{H}_n \\quad  x \\in X_n </math>\n\nwhere '''H'''<sub>''n''</sub> is the canonical ''n''-dimensional Hilbert space, that is\n\n:<math> \\mathbf{H}_n = \\left\\{ \\begin{matrix} \\mathbb{C}^n & \\mbox{ if } n < \\omega \\\\ \\ell^2 & \\mbox{ if } n = \\omega \\end{matrix}\\right. </math> {{clarify|reason=What is l^2 ?|date=March 2016}}\n\nA ''cross-section'' of {''H''<sub>''x''</sub>}<sub>''x''∈ ''X''</sub> is a family {''s''<sub>''x''</sub>}<sub>''x'' ∈ ''X''</sub> such that ''s''<sub>''x''</sub> ∈ ''H''<sub>''x''</sub> for all ''x'' ∈ ''X''. A cross-section is measurable if and only if its restriction to each partition element ''X''<sub>''n''</sub> is measurable. We will identify measurable cross-sections ''s'', ''t'' that are equal [[almost everywhere]]. Given a measurable family of Hilbert spaces, the direct integral\n\n:<math> \\int^\\oplus_X H_x \\, \\mathrm{d} \\mu(x) </math>\n\nconsists of equivalence classes (with respect to almost everywhere equality) of measurable square integrable cross-sections of {''H''<sub>''x''</sub>}<sub>''x''∈ ''X''</sub>. This is a Hilbert space under the inner product\n\n:<math> \\langle s | t \\rangle = \\int_X \\langle s(x) | t(x) \\rangle  \\, \\mathrm{d} \\mu(x) </math>\n\nGiven the local nature of our definition, many definitions applicable to single Hilbert spaces apply to measurable families of Hilbert spaces as well.\n\n'''Remark'''. This definition is apparently more restrictive than the one given by von Neumann and discussed in Dixmier's classic treatise on von Neumann algebras. In the more general definition, the Hilbert space ''fibers'' ''H''<sub>''x''</sub> are allowed to vary from point to point without having a local triviality requirement (local in a measure-theoretic sense). One of the main theorems of the von Neumann theory is to show that in fact the more general definition can be reduced to the simpler one given here.\n\nNote that the direct integral of a measurable family of Hilbert spaces depends only on the measure class of the measure μ; more precisely:\n\n'''Theorem'''. Suppose μ, ν are σ-finite countably additive measures on ''X'' that have the same sets of measure 0. Then the mapping\n\n:<math> s \\mapsto \\left(\\frac{\\mathrm{d} \\mu}{\\mathrm{d} \\nu}\\right)^{1/2} s </math>\n\nis a unitary operator\n\n:<math> \\int^\\oplus_X H_x \\, \\mathrm{d} \\mu(x) \\rightarrow \\int^\\oplus_X H_x \\, \\mathrm{d} \\nu(x). </math>\n\n=== Example ===\n\nTechnically the simplest examples are when ''X'' is a countable set and μ is a discrete measure. Throughout the article, we will consider the following running example in which ''X'' = '''N''' and μ is counting measure on '''N'''. In this case any sequence {''H''<sub>''k''</sub>} of separable Hilbert spaces can be considered as a measurable family. Moreover,\n\n:<math> \\int^\\oplus_X H_x \\, \\mathrm{d} \\mu(x) \\cong \\bigoplus_{k \\in \\mathbb{N}} H_k </math>\n\n== Decomposable operators ==\n\nIn our running example, any bounded linear operator ''T'' on\n\n: <math> H = \\bigoplus_{k \\in \\mathbb{N}} H_k </math>\n\nis given by an infinite matrix\n\n:<math> \\begin{bmatrix} T_{1 1} & T_{1 2} & \\cdots & T_{1 n} & \\cdots \\\\ T_{2 1} & T_{2 2} & \\cdots & T_{2 n} & \\cdots \\\\\n\\vdots & \\vdots & \\ddots & \\vdots & \\cdots \\\\\nT_{n 1} & T_{n 2} & \\cdots & T_{n n} & \\cdots \\\\\n\\vdots & \\vdots & \\cdots & \\vdots & \\ddots\n\\end{bmatrix}. </math>\n\nConsider operators that are ''block diagonal'', that is all entries off the diagonal are zero. We call these operators ''decomposable''. These operators can be characterized as those that commute with diagonal matrices:\n\n:<math> \\begin{bmatrix} \\lambda_{1} & 0 & \\cdots & 0 & \\cdots \\\\ 0 & \\lambda_{2} & \\cdots & 0 & \\cdots \\\\\n\\vdots & \\vdots & \\ddots & \\vdots & \\cdots \\\\\n0 & 0 & \\cdots & \\lambda_{n} & \\cdots \\\\\n\\vdots & \\vdots & \\cdots & \\vdots & \\ddots\n\\end{bmatrix}. </math>\n\nWe now proceed to the general definition: A family of bounded operators {''T''<sub>''x''</sub>}<sub>''x''∈ ''X''</sub> with ''T''<sub>''x''</sub> ∈ L(''H''<sub>''x''</sub>) is said to be ''strongly measurable'' if and only if its restriction to each ''X''<sub>''n''</sub> is strongly measurable. This makes sense because ''H''<sub>''x''</sub> is constant on ''X''<sub>''n''</sub>.\n\nMeasurable families of operators with an essentially bounded norm, that is\n\n:<math> \\operatorname{ess-sup}_{x \\in X} \\|T_x\\| < \\infty </math>\n\ndefine bounded linear operators\n\n:<math> \\int^\\oplus_X \\ T_x d \\mu(x)  \\in \\operatorname{L}\\bigg(\\int^\\oplus_X H_x \\ d \\mu(x)\\bigg) </math>\n\nacting in a pointwise fashion, that is\n\n:<math> \\bigg[\\int^\\oplus_X \\ T_x d \\mu(x) \\bigg] \\bigg(\\int^\\oplus_X \\ s_x d \\mu(x) \\bigg) =  \\int^\\oplus_X \\ T_x(s_x) d \\mu(x). </math>\n\nSuch operators are said to be ''decomposable''.\n\nExamples of decomposable operators are those defined by scalar-valued (i.e. '''C'''-valued) measurable functions λ on ''X''. In fact,\n\n'''Theorem'''. The mapping\n\n: <math> \\phi: L^\\infty_\\mu(X) \\rightarrow \\operatorname{L}\\bigg(\\int^\\oplus_X H_x \\ d \\mu(x)\\bigg) </math>\n\ngiven by\n\n:<math> \\lambda \\mapsto \\int^\\oplus_X \\ \\lambda_x d \\mu(x) </math>\n\nis an involutive algebraic isomorphism onto its image.\n\nFor this reason we will identify ''L''<sup>∞</sup><sub>μ</sub>(''X'') with the image of φ.\n\n'''Theorem'''<ref>{{citation | last = Takesaki | first = Masamichi | authorlink = Masamichi Takesaki | title=Theory of Operator Algebras I  | publisher=[[Springer-Verlag]] | year=2001 | isbn=3-540-42248-X }}, Chapter IV, Theorem 7.10, p. 259</ref> Decomposable operators are precisely those that are in the operator commutant of the abelian algebra ''L''<sup>∞</sup><sub>μ</sub>(''X'').\n\n=== Decomposition of Abelian von Neumann algebras ===\n\nThe spectral theorem has many variants. A particularly powerful version is as follows:\n\n'''Theorem'''. For any Abelian von Neumann algebra '''A''' on a separable Hilbert space ''H'', there is a standard Borel space ''X'' and a measure μ on ''X'' such that it is unitarily equivalent as an operator algebra to ''L''<sup>∞</sup><sub>μ</sub>(''X'') acting on a direct integral of Hilbert spaces\n\n: <math> \\int_X^\\oplus H_x d \\mu(x). \\quad</math>\n\nTo assert '''A''' is unitarily equivalent to ''L''<sup>∞</sup><sub>μ</sub>(''X'') as an operator algebra means that there is a unitary\n\n:<math> U: H \\rightarrow \\int_X^\\oplus H_x d\\mu(x) </math>\n\nsuch that ''U'' '''A''' ''U''* is the algebra of diagonal operators ''L''<sup>∞</sup><sub>μ</sub>(''X''). Note that this asserts more than just the algebraic equivalence of '''A''' with the algebra of diagonal operators.\n\nThis version however does not explicitly state how the underlying standard Borel space ''X'' is obtained. There is a uniqueness result for the above decomposition.\n\n'''Theorem'''. If the Abelian von Neumann algebra '''A''' is unitarily equivalent to both ''L''<sup>∞</sup><sub>μ</sub>(''X'') and ''L''<sup>∞</sup><sub>ν</sub>(''Y'') acting on the direct integral spaces\n\n: <math> \\int_X^\\oplus H_x d \\mu(x), \\quad  \\int_Y^\\oplus K_y d \\nu(y) </math>\n\nand μ, ν are standard measures, then there is a Borel isomorphism\n\n:<math>\\varphi: X - E \\rightarrow Y - F </math>\n\nwhere ''E'', ''F'' are null sets such that\n\n:<math> K_{\\phi(x)} = H_x \\quad \\mbox{almost everywhere} </math>\n\nφ is a measure class isomorphism, that is φ and its inverse preserve sets of measure 0.\n\nThis previous two theorems provide the complete classification of Abelian von Neumann algebras on separable Hilbert spaces. Note that this classification actually takes into account the realization of the von Neumann algebra as an algebra of operators. If we only consider the underlying von Neumann algebra independently of its realization as a von Neumann algebra, then its structure is determined by very simple measure-theoretic invariants.\n\n== Direct integrals of von Neumann algebras ==\n\nLet {''H''<sub>''x''</sub>}<sub>''x'' ∈ ''X''</sub> be a measurable family of Hilbert spaces. A family of von Neumann algebras {''A''<sub>''x''</sub>}<sub>''x'' ∈ ''X''</sub>\nwith\n\n:<math> A_x \\subseteq \\operatorname{L}(H_x) </math>\n\nis measurable [[if and only if]] there is a countable set ''D'' of measurable operator families that pointwise generate {''A''<sub>''x''</sub>} <sub>''x'' ∈ ''X''</sub>as a von Neumann algebra in the following sense: For almost all ''x'' ∈ ''X'',\n\n:<math> \\operatorname{W^*}(\\{S_x: S \\in D\\}) = A_x </math>\n\nwhere W*(''S'') denotes the von Neumann algebra generated by the set ''S''. If {''A''<sub>''x''</sub>}<sub>''x'' ∈ ''X''</sub> is a measurable family of von Neumann algebras, the direct integral of von Neumann algebras\n\n:<math> \\int_X^\\oplus A_x d\\mu(x) </math>\n\nconsists of all operators of the form\n\n:<math> \\int_X^\\oplus T_x d\\mu(x)  </math>\n\nfor ''T''<sub>''x''</sub> ∈ ''A''<sub>''x''</sub>.\n\nOne of the main theorems of von Neumann and Murray in their original series of papers is a proof of the decomposition theorem: Any von Neumann algebra is a direct integral of factors. We state this precisely below.\n\n'''Theorem'''. If {''A''<sub>''x''</sub>}<sub>''x'' ∈ ''X''</sub> is a measurable family of von Neumann algebras and μ is standard, then the family of operator commutants is also measurable and\n\n:<math> \\bigg[\\int_X^\\oplus A_x d\\mu(x)\\bigg]' = \\int_X^\\oplus A'_x d\\mu(x). </math>\n\n== Central decomposition ==\n\nSuppose ''A'' is a von Neumann algebra. let '''Z'''(''A'') be the [[center (algebra)|center]] of ''A'', that is the set of operators in ''A'' that commute with all operators ''A'', that is\n\n:<math> \\mathbf{Z}(A) = A \\cap A' </math>\n\n'''Z'''(''A'') is an Abelian von Neumann algebra.\n\n'''Example'''. The center of L(''H'') is 1-dimensional. In general, if ''A'' is a von Neumann algebra, if the center is 1-dimensional we say ''A'' is a '''factor'''.\n\nNow suppose ''A'' is a von Neumann algebra whose center contains a sequence of minimal pairwise orthogonal non-zero projections {''E''<sub>''i''</sub>}<sub>''i'' ∈ '''N'''</sub> such that\n\n:<math> 1 = \\sum_{i \\in \\mathbb{N}} E_i </math>\n\nThen ''A'' ''E''<sub>''i''</sub> is a von Neumann algebra on the range ''H''<sub>''i''</sub> of ''E''<sub>''i''</sub>. It is easy to see ''A'' ''E''<sub>''i''</sub> is a factor. Thus in this special case\n\n:<math> A = \\bigoplus_{i \\in \\mathbb{N}} A E_i </math>\n\nrepresents ''A'' as a direct sum of factors.  This is a special case of the central decomposition theorem of von Neumann.\n\nIn general, we can apply the structure theorem of Abelian von Neumann algebras that represents Z('''A''') as an algebra of scalar diagonal operators. In any such representation, all the operators in '''A''' are decomposable operators. In fact, we can use this to prove the basic result of von Neumann that any von Neumann algebra admits a decomposition into factors.\n\n'''Theorem'''. Suppose\n\n:<math> H = \\int_X^\\oplus H_x d \\mu(x) </math>\n\nis a direct integral decomposition of ''H'' and '''A''' is a von Neumann algebra on ''H'' so that Z('''A''') is represented by the algebra of scalar diagonal operators ''L''<sup>∞</sup><sub>μ</sub>(''X'') where ''X'' is a standard Borel space. Then\n\n:<math> \\mathbf{A} = \\int^\\oplus_X A_x d \\mu(x) </math>\n\nwhere for almost all ''x'' ∈ ''X'', ''A''<sub>''x''</sub> is a von Neumann algebra that is a ''factor''.\n\n== Measurable families of representations ==\n\nIf ''A'' is a separable C*-algebra, we can consider measurable families of non-degenerate *-representations of ''A''; recall that in case ''A'' has a unit, non-degeneracy is equivalent to unit-preserving. By the general correspondence that exists between strongly continuous unitary representations of a locally compact group ''G'' and non-degenerate *-representations of the groups C*-algebra C*(''G''), the theory for C*-algebras immediately provides a decomposition theory for representations of separable locally compact groups.\n\n'''Theorem'''. Let ''A'' be a separable C*-algebra and π a non-degenerate involutive representation of ''A'' on a separable Hilbert space ''H''. Let W*(π) be the von Neumann algebra generated by the operators π(''a'') for ''a'' ∈ ''A''. Then corresponding to any central decomposition of W*(π) over a standard measure space (''X'', μ) (which as stated is unique in a measure theoretic sense), there is a measurable family of factor representations\n\n:<math> \\{\\pi_x\\}_{x \\in X} </math>\n\nof ''A'' such that\n\n:<math> \\pi(a) = \\int_X^\\oplus \\pi_x(a) d \\mu(x), \\quad \\forall a \\in A. </math>\n\nMoreover, there is a subset ''N'' of ''X'' with μ measure zero, such that π<sub>''x''</sub>, π<sub>''y''</sub> are disjoint whenever ''x'', ''y'' ∈ ''X'' − ''N'', where representations are said to be ''disjoint'' if and only if there are no [[intertwining operator]]s between them.\n\nOne can show that the direct integral can be indexed on the so-called ''quasi-spectrum'' ''Q'' of ''A'', consisting of quasi-equivalence classes of factor representations of ''A''. \nThus there is a standard measure μ on ''Q'' and a measurable family of factor representations indexed on ''Q'' such that π<sub>''x''</sub> belongs to the class of ''x''. This decomposition is essentially unique. This result is fundamental in the theory of group representations.\n\n== References ==\n{{Reflist}}\n* [[J. Dixmier]],  ''Von Neumann algebras'', {{ISBN|0-444-86308-7}}\n* J. Dixmier, ''C* algebras'' {{ISBN|0-7204-0762-1}}\n* [[G. W. Mackey]], ''The Theory of Unitary Group Representations'', The University of Chicago Press, 1976.\n* [[J. von Neumann]], [https://www.jstor.org/stable/1969463 On Rings of Operators. Reduction Theory] The Annals of Mathematics 2nd Ser., Vol. 50, No. 2 (Apr., 1949), pp.&nbsp;401–485.\n* [[Masamichi Takesaki]] ''Theory of Operator Algebras I,II,III\", encyclopedia of mathematical sciences, Springer-Verlag, 2001–2003 (the first volume was published 1979 in 1. Edition) {{ISBN|3-540-42248-X}}\n\n[[Category:Functional analysis]]\n[[Category:Measure theory]]\n[[Category:Von Neumann algebras]]"
    },
    {
      "title": "Dixmier trace",
      "url": "https://en.wikipedia.org/wiki/Dixmier_trace",
      "text": "In mathematics, the '''Dixmier trace''', introduced by {{harvs |txt |authorlink=Jacques Dixmier |first=Jacques |last=Dixmier |year=1966}}, is a non-normal{{clarify|date=December 2016}} trace on a space of [[linear operator]]s on a [[Hilbert space]] larger than the space of [[trace class operator]]s.  Dixmier traces are examples of [[singular trace]]s.\n\nSome applications of Dixmier traces to [[noncommutative geometry]] are described in {{harv|Connes|1994}}.\n\n==Definition==\nIf ''H'' is a Hilbert space, then ''L''<sup>1,∞</sup>(''H'') is the space of compact linear operators ''T'' on ''H'' such that the norm\n\n:<math>\\|T\\|_{1,\\infty} = \\sup_N\\frac{\\sum_{i=1}^N \\mu_i(T)}{\\log(N)}</math>\n\nis finite, where the numbers ''&mu;''<sub>''i''</sub>(''T'') are the eigenvalues of |''T''| arranged in decreasing order.  Let \n:<math>a_N = \\frac{\\sum_{i=1}^N \\mu_i(T)}{\\log(N)}</math>.\nThe Dixmier trace Tr<sub>''&omega;''</sub>(''T'') of ''T'' is defined for positive operators ''T'' of ''L''<sup>1,∞</sup>(''H'') to be\n\n:<math>\\operatorname{Tr}_\\omega(T)= \\lim_\\omega a_N</math>\n\nwhere lim<sub>''&omega;''</sub> is a scale-invariant positive \"extension\" of the usual limit, to all bounded sequences.  In other words, it has the following properties:\n*lim<sub>''&omega;''</sub>(''&alpha;''<sub>''n''</sub>) ≥ 0 if all ''&alpha;''<sub>''n''</sub> ≥ 0 (positivity)\n*lim<sub>''&omega;''</sub>(''&alpha;''<sub>''n''</sub>) = lim(''&alpha;''<sub>''n''</sub>) whenever the ordinary limit exists\n*lim<sub>''&omega;''</sub>(''&alpha;''<sub>1</sub>, ''&alpha;''<sub>1</sub>, ''&alpha;''<sub>2</sub>, ''&alpha;''<sub>2</sub>, ''&alpha;''<sub>3</sub>, ...) = lim<sub>ω</sub>(''&alpha;''<sub>''n''</sub>) (scale invariance)\n\nThere are many such extensions (such as a [[Banach limit]] of  ''&alpha;''<sub>1</sub>, ''&alpha;''<sub>2</sub>, ''&alpha;''<sub>4</sub>, ''&alpha;''<sub>8</sub>,...) so there are many different Dixmier traces. \nAs the Dixmier trace is linear, it extends by linearity to all operators of ''L''<sup>1,∞</sup>(''H'').\nIf the Dixmier trace of an operator is independent of the choice of lim<sub>''&omega;''</sub> then the operator is called '''measurable'''.\n\n==Properties==\n*Tr<sub>''&omega;''</sub>(''T'') is linear in ''T''.\n*If ''T'' ≥ 0 then Tr<sub>''&omega;''</sub>(''T'') ≥ 0\n*If ''S'' is bounded then Tr<sub>ω</sub>(''ST'') = Tr<sub>''&omega;''</sub>(''TS'')\n*Tr<sub>ω</sub>(''T'') does not depend on the choice of inner product on ''H''.\n*Tr<sub>''&omega;''</sub>(''T'') = 0 for all trace class operators ''T'', but there are compact operators for which it is equal to 1.\n\nA trace ''&phi;'' is called '''normal''' if ''&phi;''(sup ''x''<sub>α</sub>) = sup&nbsp;''&phi;''( ''x''<sub>''&alpha;''</sub>) for every bounded increasing directed family of positive operators.  Any normal trace on <math>L^{1,\\infty}(H)</math> is equal to the usual trace, so the Dixmier trace is an example of a non-normal trace.\n\n==Examples==\nA compact self-adjoint operator with eigenvalues 1, 1/2, 1/3, ... has Dixmier trace equal to 1.\n\nIf the eigenvalues μ<sub>i</sub> of the positive operator ''T'' have the property that \n:<math>\\zeta_T(s)= \\operatorname{Tr}(T^s)= \\sum{\\mu_i^s}</math>\nconverges for Re(''s'')>1 and extends to a meromorphic function near ''s''=1 with at most a simple pole at ''s''=1, then the Dixmier trace\nof ''T'' is the residue at ''s''=1 (and in particular is independent of the choice of ω).\n\n{{harvtxt|Connes|1988}} showed that Wodzicki's [[noncommutative residue]] {{harv|Wodzicki|1984}} of a [[pseudodifferential operator]] on a [[manifold]] is equal to its Dixmier trace.\n\n==References==\n*Albeverio, S.; Guido, D.; Ponosov, A.; Scarlatti, S.: Singular traces and compact operators.  J. Funct. Anal. 137 (1996), no.&nbsp;2, 281—302.\n*{{Citation | doi=10.1007/BF01218391 | last1=Connes | first1=Alain | author1-link=Alain Connes | title=The action functional in noncommutative geometry | url=http://projecteuclid.org/euclid.cmp/1104161823 | mr=953826 | year=1988 | journal=Communications in Mathematical Physics | issn=0010-3616 | volume=117 | issue=4 | pages=673–683}}\n*{{Citation | last1=Connes | first1=Alain | author1-link=Alain Connes | title=Non-commutative geometry | url=ftp://ftp.alainconnes.org/book94bigpdf.pdf | publisher=[[Academic Press]] | location=Boston, MA | isbn=978-0-12-185860-5 | year=1994 }}{{dead link|date=September 2017 |bot=InternetArchiveBot |fix-attempted=yes }}\n*{{Citation | last1=Dixmier | first1=Jacques | title=Existence de traces non normales | mr=0196508 | year=1966 | journal=Comptes Rendus de l'Académie des Sciences, Série A et B | issn=0151-0509 | volume=262 | pages=A1107&ndash;A1108}}\n*{{Citation | last1=Wodzicki | first1=M. | title=Local invariants of spectral asymmetry | doi=10.1007/BF01403095 | mr=728144 | year=1984 | journal=[[Inventiones Mathematicae]] | issn=0020-9910 | volume=75 | issue=1 | pages=143–177}}\n\n== See also ==\n\n* [[Singular trace]]\n\n[[Category:Von Neumann algebras]]\n[[Category:Hilbert space]]\n[[Category:Operator theory]]"
    },
    {
      "title": "Fuglede−Kadison determinant",
      "url": "https://en.wikipedia.org/wiki/Fuglede%E2%88%92Kadison_determinant",
      "text": "{{expert needed|mathematics|reason=review the article|date=October 2018}}\nIn [[mathematics]], the '''Fuglede−Kadison determinant''' of an invertible operator in a finite [[Von Neumann algebra#Factors|factor]] is a positive real number associated with it. It defines a multiplicative homomorphism from the set of invertible operators to the set of positive real numbers. The Fuglede−Kadison determinant of an operator <math>A</math> is often denoted by <math>\\Delta(A)</math>.\n\nFor a [[Matrix (mathematics)|matrix]] <math>A</math> in <math>M_n(\\mathbb{C})</math>,  <math>\\Delta(A) = \\left| \\det (A) \\right|^{1/n}</math> which is the normalized form of the absolute value of the [[determinant]] of <math>A</math>.\n\n==Definition==\nLet <math>\\mathcal{M}</math> be a finite factor with the canonical normalized trace <math>\\tau</math> and let <math>X</math> be an invertible operator in <math>\\mathcal{M}</math>. Then the Fuglede−Kadison determinant of <math>X</math> is defined as\n:<math>\\Delta(X) := \\exp \\tau(\\log (X^*X)^{1/2}),</math> \n(cf. [[Determinant#Relation to eigenvalues and trace|Relation between determinant and trace via eigenvalues]]). The number <math>\\Delta(X)</math> is well-defined by [[continuous functional calculus]].\n\n==Properties==\n* <math>\\Delta(XY) = \\Delta(X) \\Delta(Y)</math> for invertible operators <math>X, Y \\in \\mathcal{M}</math>,\n* <math>\\Delta (\\exp A) = \\left| \\exp \\tau(A) \\right| = \\exp \\Re \\tau(A)</math> for <math>A \\in \\mathcal{M}.</math>\n* <math>\\Delta</math> is norm-continuous on <math>GL_1(\\mathcal{M})</math>, the set of invertible operators in <math>\\mathcal{M},</math>\n* <math>\\Delta(X)</math> does not exceed the spectral radius of <math>X</math>.\n\n==Extensions to singular operators==\nThere are many possible extensions of the Fuglede−Kadison determinant to singular operators in <math>\\mathcal{M}</math>. All of them must assign a value of 0 to operators with non-trivial nullspace. No extension of the determinant <math>\\Delta</math> from the invertible operators to all operators in <math>\\mathcal{M}</math>, is continuous in the uniform topology.\n\n===Algebraic extension===\nThe algebraic extension of <math>\\Delta</math> assigns a value of 0 to a singular operator in <math>\\mathcal{M}</math>.\n\n===Analytic extension===\nFor an operator <math>A</math> in <math>\\mathcal{M}</math>, the analytic extension of <math>\\Delta</math> uses the spectral decomposition of <math>|A| = \\int \\lambda \\; dE_\\lambda</math> to define <math>\\Delta(A) := \\exp \\left( \\int \\log \\lambda \\; d\\tau(E_\\lambda) \\right)</math> with the understanding that <math>\\Delta(A) = 0</math> if <math>\\int \\log \\lambda \\; d\\tau(E_\\lambda) = -\\infty</math>. This extension satisfies the continuity property\n:<math>\\lim_{\\varepsilon \\rightarrow 0} \\Delta(H + \\varepsilon I) = \\Delta(H)</math> for <math>H \\ge 0.</math>\n\n==Generalizations==\nAlthough originally the Fuglede−Kadison determinant was defined for operators in finite factors, it carries over to the case of operators in [[von Neumann algebra]]s with a tracial state (<math>\\tau</math>) in the case of which it is denoted by <math>\\Delta_\\tau(\\cdot)</math>.\n\n==References==\n\n* {{citation\n | last1 = Fuglede | first1 = Bent\n | last2 = Kadison | first2 = Richard\n | journal = Ann. Math. |series=Series 2\n | pages = 520−530\n | title = Determinant theory in finite factors\n | volume = 55\n | year = 1952}}.\n\n* {{citation\n | last = de la Harpe| first = Pierre\n | journal =  Proc. Natl. Acad. Sci. USA\n | pages = 15864–15877\n | title = Fuglede−Kadison determinant: theme and variations\n | volume = 110\n | year = 2013}}.\n\n{{DEFAULTSORT:Fuglede-Kadison determinant}}\n[[Category:Von Neumann algebras]]"
    },
    {
      "title": "Hilbert algebra",
      "url": "https://en.wikipedia.org/wiki/Hilbert_algebra",
      "text": "In mathematics, '''Hilbert algebras''' occur in the theory of von Neumann algebras in:\n\n* [[Commutation theorem]] \n* [[Tomita–Takesaki theory]]\n\n{{Mathematical disambiguation}}\n[[Category:Von Neumann algebras]]\n\n{{Short pages monitor}}<!-- This long comment was added to the page to prevent it from being listed on Special:Shortpages. It and the accompanying monitoring template were generated via Template:Long comment. Please do not remove the monitor template without removing the comment as well.-->"
    },
    {
      "title": "Hyperfinite type II factor",
      "url": "https://en.wikipedia.org/wiki/Hyperfinite_type_II_factor",
      "text": "In [[mathematics]], there are up to isomorphism exactly two separably acting [[Von Neumann algebra|hyperfinite type II factors]]; one infinite and one finite. Murray and von Neumann proved that up to [[isomorphism]] there is a unique [[von Neumann algebra]] that is a [[factor (functional analysis)|factor]] of type II<sub>1</sub> and also [[von Neumann algebra#Amenable von Neumann algebras|hyperfinite]]; it is called the '''hyperfinite type II<sub>1</sub> factor'''.\nThere are an uncountable number of other factors of type II<sub>1</sub>. [[Alain Connes|Connes]] proved that the infinite one is also unique.\n\n==Constructions==\n\n*The [[von Neumann algebra#Examples|von Neumann group algebra]] of a discrete group with the [[infinite conjugacy class property]] is a factor of type II<sub>1</sub>, and if the group is [[Amenable group|amenable]] and [[countable]] the factor is hyperfinite. There are many groups with these properties, as any [[locally finite group]] is amenable.  For example, the  von Neumann group algebra of the infinite symmetric group of all permutations of a countable infinite set that fix all but a finite number of elements gives the hyperfinite type II<sub>1</sub> factor.\n*The hyperfinite type II<sub>1</sub> factor also arises from the [[Crossed_product#Construction|group-measure space construction]] for ergodic free measure-preserving actions of countable amenable groups on probability spaces.\n*The [[Von_Neumann_algebra#Tensor_products_of_von_Neumann_algebras|\ninfinite tensor product]] of a countable number of factors of type I<sub>''n''</sub> with respect to their tracial states is the hyperfinite type II<sub>1</sub> factor.  When ''n''=2,  this is also sometimes called the Clifford algebra of an infinite separable Hilbert space.\n*If ''p'' is any non-zero finite projection in a hyperfinite von Neumann algebra ''A'' of type II, then ''pAp'' is the hyperfinite type II<sub>1</sub> factor. Equivalently the [[Von_Neumann_algebra#Type_II_factors|fundamental group]] of ''A'' is the group of [[positive real numbers]]. This can often be hard to see directly. It is, however, obvious when ''A'' is the infinite tensor product of factors of type I<sub>n</sub>, where n runs over all integers greater than 1 infinitely many times: just take ''p'' [[Von_Neumann_algebra#Projections|equivalent]] to an infinite tensor product of projections ''p''<sub>''n''</sub> on which the tracial state is either <math> 1</math> or <math> 1- 1/n</math>.\n\n==Properties==\nThe hyperfinite II<sub>1</sub> factor ''R'' is the unique smallest infinite\ndimensional factor in the following sense: it is contained in any other infinite dimensional factor, and any infinite dimensional factor contained in ''R'' is isomorphic to ''R''.\n\nThe outer automorphism group of ''R'' is an infinite simple group with countable many conjugacy classes, indexed by pairs consisting of a positive integer ''p'' and a complex ''p''th root of 1.\n\nThe projections of the hyperfinite II<sub>1</sub> factor form a [[continuous geometry]].\n\n==The infinite hyperfinite type II factor==\nWhile there are other factors of [[von Neumann algebra|type II<sub>∞</sub>]], there is a unique hyperfinite one, up to isomorphism.  It consists of those infinite square matrices with entries in the hyperfinite type II<sub>1</sub> factor that define [[bounded operator]]s.\n\n==See also==\n\n*[[Subfactor]]s\n\n==References==\n*A. Connes, [https://www.jstor.org/stable/1971057 ''Classification of Injective Factors''] The Annals of Mathematics  2nd Ser., Vol. 104, No. 1 (Jul., 1976), pp.&nbsp;73–115\n*F.J. Murray,   J. von Neumann,   [https://www.jstor.org/stable/1969107  ''On rings of operators IV'']  Ann. of Math. (2), 44  (1943)  pp.&nbsp;716–808. This shows that all approximately finite factors of type II<sub>1</sub> are isomorphic.\n\n[[Category:Von Neumann algebras]]"
    },
    {
      "title": "Kaplansky density theorem",
      "url": "https://en.wikipedia.org/wiki/Kaplansky_density_theorem",
      "text": "In the theory of [[von Neumann algebra]]s, the '''Kaplansky density theorem''', due to [[Irving Kaplansky]], is a fundamental approximation theorem. The importance and ubiquity of this technical tool led [[Gert Pedersen]] to comment in one of his books<ref>Pg. 25; [[Pedersen, G. K.]], ''C*-algebras and their automorphism groups'', London Mathematical Society Monographs, {{isbn|978-0125494502}}.</ref> that, \n:''The density theorem is Kaplansky's great gift to mankind. It can be used every day, and twice on Sundays.''\n\n==Formal statement==\nLet ''K''<sup>−</sup> denote the [[Strong operator topology|strong-operator closure]] of a set ''K'' in ''B(H)'', the set of bounded operators on the Hilbert space ''H'', and let (''K'')<sub>1</sub> denote the intersection of ''K'' with the unit ball of ''B(H)''.\n:'''Kaplansky density theorem'''.<ref>Theorem 5.3.5; [[Richard Kadison]], ''Fundamentals of the Theory of Operator Algebras, Vol. I : Elementary Theory'', American Mathematical Society. {{isbn|978-0821808191}}.</ref> If <math>A</math> is a self-adjoint algebra of operators in <math>B(H)</math>, then each element <math>a</math> in the unit ball of the strong-operator closure of <math>A</math> is in the strong-operator closure of the unit ball of <math>A</math>. In other words, <math>(A)_1^{-} = (A^{-})_1</math>. If <math>h</math> is a self-adjoint operator in <math>(A^{-})_1</math>, then <math>h</math> is in the strong-operator closure of the set of self-adjoint operators in <math>(A)_1</math>.\n\nThe Kaplansky density theorem can be used to formulate some approximations with respect to the [[strong operator topology]].\n\n1) If ''h'' is a positive operator in (''A''<sup>−</sup>)<sub>1</sub>, then ''h'' is in the strong-operator closure of the set of self-adjoint operators in (''A''<sup>+</sup>)<sub>1</sub>, where ''A''<sup>+</sup> denotes the set of positive operators in ''A''.\n\n2) If ''A'' is a [[C*-algebra]] acting on the Hilbert space ''H'' and ''u'' is a unitary operator in A<sup>−</sup>, then ''u'' is in the strong-operator closure of the set of unitary operators in ''A''.\n\nIn the density theorem and 1) above, the results also hold if one considers a ball of radius ''r'' > ''0'', instead of the unit ball.\n\n==Proof==\nThe standard proof uses the fact that, a bounded continuous real-valued function ''f'' is strong-operator continuous. In other words, for a net {''a<sub>α</sub>''} of [[self adjoint operator]]s in ''A'', the [[continuous functional calculus]] ''a'' &rarr; ''f''(''a'') satisfies,\n\n:<math>\\lim f(a_{\\alpha}) = f (\\lim a_{\\alpha})</math>\n\nin the [[strong operator topology]]. This shows that self-adjoint part of the unit ball in ''A''<sup>−</sup> can be approximated strongly by self-adjoint elements in ''A''. A matrix computation in ''M''<sub>2</sub>(''A'') considering the self-adjoint operator with entries ''0'' on the diagonal and ''a'' and ''a''<sup>*</sup> at the other positions, then removes the self-adjointness restriction and proves the theorem.\n\n==See also==\n*[[Jacobson density theorem]]\n\n==Notes==\n{{Reflist}}\n\n==References==\n*[[Kadison, Richard]], ''Fundamentals of the Theory of Operator Algebras, Vol. I : Elementary Theory'', American Mathematical Society. {{isbn|978-0821808191}}.\n*V.F.R.Jones [http://math.berkeley.edu/~vfr/MATH20909/VonNeumann2009.pdf von Neumann algebras]; incomplete notes from a course.\n*M. Takesaki ''Theory of Operator Algebras I'' {{isbn|3-540-42248-X}}\n\n[[Category:Von Neumann algebras]]\n[[Category:Theorems in functional analysis]]"
    },
    {
      "title": "Sherman–Takeda theorem",
      "url": "https://en.wikipedia.org/wiki/Sherman%E2%80%93Takeda_theorem",
      "text": "In mathematics, the '''Sherman–Takeda theorem''' states that if ''A'' is a [[C*-algebra]] then its double dual is a [[W*-algebra]], and any homomorphism of ''A'' to a W* algebra factors through its double dual. \nThe theorem was announced by {{harvtxt|Sherman|1950}} and proved by {{harvtxt|Takeda|1954}}. The double dual of ''A'' is called the [[universal enveloping W*-algebra]] of ''A''.\n\n== References ==\n\n*{{Citation | last1=Sherman | first1=S. | title=Proceedings of the International Congress of Mathematicians 1950 | url=http://mathunion.org/ICM/ICM1950.1/ | publisher=[[American Mathematical Society]] | location=Providence, R.I. | volume=1 | chapter=The second adjoint of a C* algebra | pages=470|year=1950}}\n*{{Citation | last1=Takeda | first1=Zirô | title=Conjugate spaces of operator algebras | url=http://www.journalarchive.jst.go.jp/english/jnlabstract_en.php?cdjournal=pjab1945&cdvol=30&noissue=2&startpage=90 | mr=0063578 | year=1954 | journal=Proceedings of the Japan Academy | issn=0021-4280 | volume=30 | issue=2 | pages=90–95}}\n\n{{DEFAULTSORT:Sherman-Takeda theorem}}\n[[Category:Operator theory]]\n[[Category:Von Neumann algebras]]"
    },
    {
      "title": "Singular trace",
      "url": "https://en.wikipedia.org/wiki/Singular_trace",
      "text": "In mathematics, a '''singular trace''' is a [[Von Neumann algebra#Weights, states, and traces|trace]] on a space of [[linear operators]] of a separable [[Hilbert space]] that vanishes\non operators of [[finite-rank operator|finite rank]]. Singular traces are a feature of infinite-dimensional Hilbert spaces such as the space of [[Lp space#The p-norm in countably infinite dimensions|square-summable sequences]] and spaces of [[Hilbert space#Examples|square-integrable functions]]. Linear operators on a finite-dimensional Hilbert space have only the zero functional as a singular trace since all operators have finite rank. For example, [[matrix ring|matrix algebras]] have no non-trivial singular traces and the [[Trace (linear algebra)|matrix trace]] is the unique trace up to scaling.\n\nAmerican mathematician Gary Weiss and, later, British mathematician [[Nigel Kalton]] observed in the infinite-dimensional case that there are non-trivial singular traces on the ideal of [[Trace class|trace class operators]].<ref name=\"GW1\">{{cite journal\n| author= G. Weiss\n| year=1980\n| title=Commutators of Hilbert-Schmidt Operators, II\n| journal=Integral Equations and Operator Theory\n| volume=4\n| issue=4\n| pages=574–600\n| doi=10.1007/BF01702316}}</ref><ref name=\"NK2\">\n{{cite journal\n| author= N. J. Kalton\n| year=1989\n| url=http://kaltonmemorial.missouri.edu/docs/jfa1989.pdf\n| title=Trace-class operators and commutators\n| journal=J. Functional Analysis\n| volume=86\n| pages=41–74\n| doi=10.1016/0022-1236(89)90064-5}}</ref>\nTherefore, in distinction to the finite-dimensional case, in infinite dimensions the canonical [[trace class#Definition|operator trace]] is not the unique trace up to scaling. The operator trace is the continuous extension of the matrix trace from finite rank operators to all trace class operators, and the term singular derives from the fact that a singular trace vanishes where the matrix trace is supported, analogous to a [[singular measure]] vanishing where Lebesgue measure is supported.\n\nSingular traces measure the asymptotic spectral behaviour of operators and have found applications in the [[noncommutative geometry]] of French mathematician [[Alain Connes]].<ref name=\"C4\">\n{{cite journal\n| author= A. Connes\n| year=1988\n| url=http://www.alainconnes.org/docs/action88.pdf\n| title=The action functional in noncommutative geometry\n| volume = 117\n| issue=4\n| journal = Comm. Math. Phys.\n| pages= 673–683\n| doi=10.1007/bf01218391}}</ref><ref name=\"CN\">\n{{cite book\n| author= A. Connes\n| isbn=978-0-08-057175-1\n| year=1995\n| url=http://www.alainconnes.org/docs/book94bigpdf.pdf\n| title=Noncommutative Geometry\n| publisher=Academic Press\n| location=New York }}\n</ref>\nIn heuristic terms, a singular trace corresponds to a way of summing\nnumbers ''a''<sub>1</sub>, ''a''<sub>2</sub>, ''a''<sub>3</sub>, ...  that is completely orthogonal or 'singular' with respect to the usual sum ''a''<sub>1</sub> + ''a''<sub>2</sub> + ''a''<sub>3</sub> + ... .\nThis allows mathematicians to sum sequences like the [[harmonic series (mathematics)|harmonic sequence]] (and operators with similar spectral behaviour) that are divergent for the usual [[summation|sum]]. In similar terms a (noncommutative) [[measure theory]] or [[probability]] theory can be built for distributions like the [[Cauchy distribution]] (and operators with similar spectral behaviour) that do not have finite expectation in the usual sense.\n\n== Origin ==\n\nBy 1950 French mathematician [[Jacques Dixmier]], a founder of the semifinite theory of [[von Neumann algebra]]s,<ref name=\"Dx1\">\n{{cite book\n| author=J. Dixmier\n| title=Les algèbres d'opérateurs dans l'espace hilbertien: algèbres de von Neumann\n| publisher= Gauthier-Villars\n| location=Paris\n| year=1957}},\n</ref>\nthought that a trace on the bounded operators of a separable Hilbert space would automatically be normal{{clarify|date=December 2016}} up to some trivial counterexamples.<ref name=\"LSZ\">\n{{cite book\n| isbn=978-3-11-026255-1\n| author= S. Lord, F. A. Sukochev. D. Zanin\n| year=2012\n| url=http://www.degruyter.com/view/product/177778\n| title=Singular traces: theory and applications\n| publisher=De Gruyter\n| location=Berlin }}\n</ref>{{rp|217}} Over the course of 15 years Dixmier, aided by a suggestion of Nachman Aronszajn and inequalities proved by Joseph Hersch, developed an example of a non-trivial yet non-normal{{clarify|date=December 2016}} trace on [[weak trace-class operator]]s,<ref name=\"Dx2\">\n{{cite journal\n| author=J. Dixmier\n| title=Existence de traces non normales\n| year=1966\n| journal=Comptes Rendus de l'Académie des Sciences, Série A et B\n| volume=262\n| pages=A1107–A1108 }}\n</ref>\ndisproving his earlier view.\nSingular traces based on Dixmier's construction are called [[Dixmier trace]]s.\n\nIndependently and by different methods, German mathematician [[:de:Albrecht Pietsch|Albrecht Pietsch (de)]] investigated traces on ideals of operators on Banach spaces.<ref name=\"AP1\">\n{{cite journal\n| author= A. Pietsch\n| year=1981\n| title=Operator ideals with a trace\n| journal=Math. Nachr.\n| volume=100\n| pages=61–91\n| doi=10.1002/mana.19811000105}}\n</ref>\nIn 1987 Nigel Kalton answered a question of Pietsch by showing that the operator trace is not\nthe unique trace on quasi-normed proper subideals of the trace-class operators on a Hilbert space.<ref name=\"NK1\">\n{{cite journal\n| author= N. J. Kalton\n| year=1987\n| url=http://kaltonmemorial.missouri.edu/docs/mn1987.pdf\n| title=Unusual traces on operator ideals\n| journal=Math. Nachr.\n| volume=134\n| pages=119–130\n| doi=10.1002/mana.19871340108}}\n</ref>  József Varga independently studied a similar question.<ref name=\"V1\">\n{{cite journal\n| author= J. V. Varga\n| year=1989\n| url=http://www.ams.org/journals/proc/1989-107-03/S0002-9939-1989-0984818-8/S0002-9939-1989-0984818-8.pdf\n| title=Traces on irregular ideals\n| journal=Proc. Amer. Math. Soc.\n| volume=107\n| issue=3\n| pages=715–723\n| doi=10.1090/s0002-9939-1989-0984818-8}}\n</ref>\nTo solve the question of uniqueness of the trace on the full ideal of trace-class operators, Kalton developed a spectral condition for the [[commutator subspace]] of trace class operators following on from results of Gary Weiss.<ref name=\"GW1\"/> A consequence of the results of Weiss and the spectral condition of Kalton was the existence of non-trivial singular traces on trace class operators\n.<ref name=\"NK2\"/><ref name=\"LSZ\"/>{{rp|185}}\n\nAlso independently, and from a different direction, Mariusz Wodzicki investigated the [[noncommutative residue]], a trace on classical pseudo-differential operators on a compact manifold that vanishes on trace class pseudo-differential operators of order less than the negative of the dimension of the manifold.<ref name=\"W1\">{{cite journal\n| author= M. Wodzicki\n| year=1984\n| url=http://gdz.sub.uni-goettingen.de/dms/load/img/?PPN=PPN356556735_0075&DMDID=DMDLOG_0016&LOGID=LOG_0016&PHYSID=PHYS_0151\n| title=Local invariants of spectral asymmetry\n| journal=Invent. Math.\n| volume=75\n| pages=143–177\n| doi=10.1007/bf01403095}}\n</ref>\n\n== Definition ==\n\nA trace φ on a two-sided ideal ''J'' of the bounded linear operators ''B''(''H'') on a separable Hilbert space ''H''\nis a linear functional φ:''J'' → ℂ such that φ(''AB'') = φ(''BA'') for all operators ''A'' from ''J'' and ''B'' from ''B''(''H'').  That is, a trace is a linear functional on ''J'' that vanishes on the [[commutator subspace]] Com(''J'') of ''J''.\n\nA trace φ is ''singular'' if ''φ''(''A'')&nbsp;=&nbsp;0 for every ''A'' from the subideal of finite rank operators ''F''(''H'') within ''J''.\n\n== Existence and characterisation ==\n\nSingular traces are characterised by the spectral [[Calkin correspondence]] between two-sided ideals of bounded operators on Hilbert space and rearrangement invariant sequence spaces. Using the spectral characterisation of the [[commutator subspace]] due to Ken Dykema, Tadeusz Figiel, Gary Weiss and Mariusz Wodzicki,<ref name=\"DFWW\">\n{{cite journal\n|author1=K. Dykema |author2=T. Figiel |author3=G. Weiss |author4=M. Wodzicki | url=http://math.berkeley.edu/~wodzicki/prace/Advances-185.pdf\n| year=2004\n| title=Commutator structure of operator ideals\n| journal=Adv. Math.\n| volume=185\n| pages=1–79\n| doi=10.1016/s0001-8708(03)00141-5}}\n</ref>\nto every trace φ on a two-sided ideal ''J'' there is a unique [[symmetric functional]] ''f'' on\nthe corresponding Calkin sequence space ''j'' such that\n\n{{NumBlk|::::| <math> \\varphi(A) = {\\rm f}(\\mu(A)) </math> | {{EquationRef|1}} }}\n\nfor every positive operator ''A'' belonging to ''J''.<ref name=\"LSZ\"/>\nHere μ: ''J''<sub>+</sub> → ''j''<sub>+</sub> is the map from a positive operator to its [[singular value]]s. A singular trace φ corresponds to a symmetric functional ''f'' on the sequence space ''j'' that vanishes on ''c''<sub>00</sub>, the sequences with a finite number of non-zero terms.\n\nThe characterisation parallels the construction of the usual [[trace class#Definition|operator trace]] where\n\n::::<math> {\\rm Tr}(A) = \\sum_{n=0}^\\infty \\mu(n,A) = \\sum \\mu(A) </math>\n\nfor ''A'' a positive trace class operator.  The trace class operators and the sequence space of [[Lp space|summable sequences]] are in Calkin correspondence. (The sum ∑ is a symmetric functional on the space of summable sequences.)\n\n=== Existence ===\n\nA non-zero trace φ exists on a two-sided ideal ''J'' of operators on a separable Hilbert space if the co-dimension of its [[commutator subspace]] is not zero. There are ideals that admit infinitely many linearly independent non-zero singular traces. For example, the commutator subspace of the ideal of [[weak trace-class operator]]s contains the ideal of trace class operators and every positive operator in the commutator subspace of the weak trace class is  trace class.<ref name=\"DFWW\"/>\nConsequently, every trace on the weak trace class ideal is singular and the co-dimension of the weak trace class ideal commutator subspace is infinite.<ref name=\"LSZ\"/>{{rp|191}} Not all of the singular traces on the weak trace class ideal are Dixmier traces.<ref name=\"LSZ\"/>{{rp|316}}\n\n=== Lidskii formulation ===\n\nThe trace of a square matrix is the sum of its eigenvalues. [[Trace class|Lidskii's formula]] extends this result to functional analysis and states that the trace of a trace class operator ''A'' is given by the sum of its eigenvalues,<ref name=\"VL\">\n{{cite journal\n| author=V. B. Lidskii\n| title=Conditions for completeness of a system of root subspaces for non-selfadjoint operators with discrete spectrum\n| journal= Tr. Mosk. Mat. Obs.\n| year= 1959\n| volume=8\n| pages=83–120\n| url=http://www.mathnet.ru/php/archive.phtml?wshow=paper&jrnid=mmo&paperid=85&option_lang=eng }}\n</ref>\n::::<math> {\\rm Tr}(A) = \\sum_{n=0}^\\infty \\lambda(n,A) = \\sum ( \\lambda(A) ). </math>\nThe characterisation ({{EquationNote|1}}) of a trace φ on positive operators of a two-ideal ''J'' as a symmetric functional applied to singular values can be improved to the statement that the trace φ on any operator in ''J'' is given by the same symmetric functional applied to [[eigenvalue|eigenvalue sequences]], provided that the eigenvalues of all operators in ''J'' belong to the Calkin sequence space ''j''.<ref name=\"SZ1\">{{citation needed|date=September 2013}}\n</ref>\nIn particular, if a bounded operator ''A'' belongs to ''J'' whenever there is a bounded operator ''B'' in ''J'' such that\n\n{{NumBlk|::::| <math> \\prod_{k=0}^n \\mu(k,A) \\leq  \\prod_{k=0}^n \\mu(k,B) </math> | {{EquationRef|2}} }}\n\nfor every natural number ''n'', then for each trace φ on ''J'' there is a unique symmetric functional ''f'' on the Calkin space ''j'' with\n\n{{NumBlk|::::| <math> \\varphi(A) = {\\rm f}(\\lambda(A)) </math> | {{EquationRef|3}} }}\n\nwhere λ(''A'') is the sequence of eigenvalues of an operator ''A'' in ''J'' rearranged so that the absolute value of the eigenvalues is decreasing.  If ''A'' is [[nilpotent operator|quasi-nilpotent]] then λ(''A'') is the zero sequence. Most two-sided ideals satisfy the property ({{EquationNote|2}}), including all Banach ideals and quasi-Banach ideals.\n\nEquation ({{EquationNote|3}}) is the precise statement that singular traces measure asymptotic spectral behaviour of operators.\n\n=== Fredholm formulation ===\n\nThe trace of a square matrix is the sum of its diagonal elements. In functional analysis the corresponding formula for trace class operators is\n::::<math> {\\rm Tr}(A) = \\sum_{n=0}^\\infty \\langle A e_n , e_n \\rangle = \\sum (\\{ \\langle A e_n , e_n \\rangle \\}_{n=0}^\\infty )</math>\nwhere { ''e''<sub>''n''</sub> }<sub>''n''=0</sub><sup>∞</sup> is an arbitrary [[orthonormal basis]] of the separable Hilbert space ''H''.\nSingular traces do not have an equivalent formulation for arbitrary bases. Only when φ(''A'')=0 will an operator ''A'' generally satisfy\n::::<math> \\varphi(A) = {\\rm f} (\\{ \\langle A e_n , e_n \\rangle \\}_{n=0}^\\infty ) </math>\nfor a singular trace φ and an arbitrary orthonormal basis { ''e''<sub>''n''</sub> }<sub>''n''=0</sub><sup>∞</sup>\n.<ref name=\"LSZ\"/>{{rp|242}}\n\nThe diagonal formulation is often used instead of the Lidskii formulation to calculate the trace of products, since eigenvalues of products are hard to determine.\nFor example, in [[quantum statistical mechanics]] the expectation of an observable ''S'' is calculated against a fixed trace-class energy density operator ''T'' by the formula\n::::<math> \\langle S \\rangle = {\\rm Tr} (ST) = \\sum_{n=0}^\\infty \\langle S e_n , e_n \\rangle \\lambda(n,T) = v_T(\\{ \\langle S e_n , e_n \\rangle \\}_{n=0}^\\infty ) </math>\nwhere ''v''<sub>''T''</sub> belongs to (''l''<sub>∞</sub>)<sub>*</sub> ≅ ''l''<sub>1</sub>. The expectation is calculated from the expectation values  ⟨''Se''<sub>''n''</sub>, ''e''<sub>''n''</sub>⟩ and the probability ⟨''P''<sub>''n''</sub>⟩ {{=}} λ(''n'',''T'') of the system being in the bound quantum state ''e''<sub>''n''</sub>. Here ''P''<sub>''n''</sub> is the projection operator onto the one-dimensional subspace spanned by the energy [[eigenstate]] ''e''<sub>''n''</sub>. The eigenvalues of the product, λ(''n'',''ST''), have no equivalent interpretation.\n\nThere are results for singular traces of products.<ref name=\"KLPS\">\n{{cite journal\n|author1=N. J. Kalton |author2=S. Lord |author3=D. Potapov |author4=F. Sukochev |title=Traces of compact operators and the noncommutative residue\n|journal=Adv. Math.\n|year=2013\n|volume=235\n|pages=1–55\n|url=http://kaltonmemorial.missouri.edu/docs/adv2013.pdf\n|doi=10.1016/j.aim.2012.11.007|arxiv=1210.3423}}\n</ref> For a product ''ST'' where ''S'' is bounded and ''T'' is [[selfadjoint]] and belongs to a two-sided ideal ''J'' then\n::::<math> \\varphi(ST) = {\\rm f}( \\{ \\langle S e_n , e_n \\rangle \\lambda(n,T) \\}_{n=0}^\\infty)\n= v_{\\varphi,T}( \\{ \\langle S e_n , e_n \\rangle \\}_{n=0}^\\infty ) </math>\nfor any trace φ on ''J''. The orthonormal basis { ''e''<sub>''n''</sub> }<sub>''n''=0</sub><sup>∞</sup> must be ordered so that ''Te''<sub>''n''</sub> {{=}} μ(''n'',''T'')''e''<sub>''n''</sub>, ''n''{{=}}0,1,2... .  When φ is singular and φ(''T''){{=}}1 then ''v''<sub>''φ'',''T''</sub> is a linear functional on ''l''<sub>∞</sub> that extends the [[limit of a function|limit at infinity]] on the convergent sequences ''c''. The expectation ⟨''S''⟩ {{=}} φ(''ST'') in this case has the property that ⟨''P''<sub>''n''</sub>⟩{{=}} 0 for each ''n'', or that there is no probability of being in a bound quantum state. That\n::::<math> \\langle S \\rangle = \\text{``limit at infinity''} \\langle S e_n , e_n \\rangle </math>\nhas led to a link between singular traces, the [[correspondence principle]], and classical limits,.<ref name=\"LSZ\"/>{{rp|ch 12}}\n\n== Use in noncommutative geometry ==\n{{see also|Dixmier trace|Local index formula|Noncommutative residue}}\nThe first application of singular traces was the [[noncommutative residue]], a trace on classical pseudo-differential operators on a compact manifold that vanishes on trace class pseudo-differential operators of order less than the negative of the dimension of the manifold, introduced Mariusz Wodzicki and [[Victor Guillemin]] independently\n.<ref name=\"W1\"/><ref name=\"G1\">{{cite journal\n| author=V. Guillemin\n| title=A new proof of Weyl's formula on the asymptotic distribution of eigenvalues\n| url=http://www.sciencedirect.com/science/article/pii/0001870885900180/pdf?md5=70b40c38baf915cfdfbde03d86e31ed2&pid=1-s2.0-0001870885900180-main.pdf\n| year=1985\n| journal=Adv. Math.\n| volume=55\n| issue=2\n| pages=131–160\n| doi=10.1016/0001-8708(85)90018-0}}\n</ref>\nAlain Connes characterised the noncommutative residue within [[noncommutative geometry]], Connes' generalisation of differential geometry, using Dixmier traces.<ref name=\"C4\"/>\n\nAn expectation involving a singular trace and non-trace class density is used in [[noncommutative geometry]],\n{{NumBlk|::::|<math> \\int S = {\\rm Tr}_\\omega( S |D|^{-d} ). </math> | {{EquationRef|4}} }}\nHere ''S'' is a bounded linear operator on the Hilbert space ''L''<sub>2</sub>(''X'') of square-integrable functions on a ''d''-dimensional [[closed manifold]] ''X'', Tr<sub>ω</sub> is a Dixmier trace on the weak trace class ideal, and the density |''D''|<sup>−''d''</sup> in the weak trace class ideal is the ''d''th power\nof the 'line element' |''D''|<sup>−1</sup> where ''D'' is a [[Dirac operator|Dirac type operator]] suitably normalised so that Tr<sub>ω</sub>(|''D''|<sup>−''d''</sup>){{=}}1.\n\nThe expectation ({{EquationRef|4}}) is an extension of the Lebesgue integral on the commutative algebra of essentially bounded functions acting by multiplication  on ''L''<sub>2</sub>(''X'') to the full ''noncommutative'' algebra of bounded operators on ''L''<sub>2</sub>(''X'').<ref name=\"KLPS\"/> That is,\n::::<math> \\int M_f = \\int_X f(x) \\, dx . </math>\nwhere ''dx'' is the [[volume form]] on ''X'', ''f'' is an essentially bounded function, and ''M''<sub>''f''</sub>\nis the bounded operator  ''M''<sub>''f''</sub> ''h''(''x'') = (''fh'')(''x'') for any square-integrable function ''h'' in ''L''<sub>2</sub>(''X'').\nSimultaneously, the expectation ({{EquationRef|4}}) is the limit at infinity of the quantum expectations ''S'' → ⟨''Se''<sub>''n''</sub>,''e''<sub>''n''</sub>⟩ defined by the eigenvectors of the [[Laplace-Beltrami operator|Laplacian]] on ''X''. More precisely, for many bounded operators on ''L''<sub>2</sub>(''X''), included all zero-order classical [[pseudo-differential operators]] and operators of the form ''M''<sub>''f''</sub> where ''f'' is an essentially bounded function, the sequence ⟨''Se''<sub>''n''</sub>, ''e''<sub>''n''</sub>⟩ logarithmically converges and<ref name=\"LSZ\"/>{{rp|384}}\n::::<math> \\int S = \\lim_{n \\to \\infty} \\frac{\\sum_{k=0}^n \\frac{1}{1+k} \\langle S e_k , e_k \\rangle}{\\sum_{k=0}^n \\frac{1}{1+k}} </math>\nThese properties are linked to the spectrum of Dirac type operators and not to Dixmier traces; they still hold if the Dixmier trace in ({{EquationRef|4}}) is replaced by any trace on weak trace class operators.<ref name=\"KLPS\"/>\n\n== Examples ==\n\nSuppose ''H'' is a separable infinite-dimensional Hilbert space.\n\n=== Ideals without traces ===\n\n* '''Bounded operators.''' [[Paul Halmos]] showed in 1954 that every bounded operator on a separable infinite-dimensional Hilbert space is the sum of two commutators.<ref name=\"Ha2\">\n{{cite journal\n| author=P. Halmos\n| year=1954\n| title=Commutators of operators. II\n| journal=Amer. J. Math.\n| volume=76\n| issue=1\n| pages=191–198\n| doi=10.2307/2372409| jstor=2372409\n}}\n</ref> That is, Com(''B''(''H'')) {{=}} ''B''(''H'') and the co-dimension of the commutator subspace of ''B''(''H'') is zero. The bounded linear operators admit no ''everywhere defined'' traces. The qualification is relevant; as a [[von Neumann algebra]] ''B''(''H'') admits semifinite (strong-densely defined) traces.\n\nModern examination of the commutator subspace involves checking its [[commutator subspace|spectral characterisation]]. The following ideals have no traces since the [[Cesàro mean]]s of positive sequences from the Calkin corresponding sequence space belong back in the sequence space, indicating that the ideal and its commutator subspace are equal.\n\n* '''Compact operators.''' The commutator subspace Com(''K''(''H'')) {{=}} ''K''(''H'') where ''K''(''H'') denotes the [[compact operator on hilbert space|compact linear operators]].  The ideal of compact operators admits no traces.\n* '''Schatten ''p''-ideals.''' The commutator subspace Com(''L''<sub>''p''</sub>) {{=}} ''L''<sub>''p''</sub>, ''p'' > 1,  where ''L''<sub>''p''</sub> denotes the [[Schatten class operator|Schatten ''p''-ideal]],\n::::<math> L_{p} = \\{ A \\in K(H) : \\left( \\sum_{n=0}^\\infty \\mu(n,A)^p \\right)^{\\frac{1}{p}} < \\infty \\}, </math>\n:and μ(''A'') denotes the sequence of singular values of a compact operator ''A''. The Schatten ideals for ''p'' > 1 admit no traces.\n\n* '''Lorentz ''p''-ideals or weak-''L''<sub>''p''</sub> ideals'''. The commutator subspace Com(''L''<sub>''p'',∞</sub>) {{=}} ''L''<sub>''p'',∞</sub>, ''p'' > 1,  where\n::::<math> L_{p,\\infty} = \\{ A \\in K(H) : \\mu(n,A) = O(n^{-\\frac{1}{p}}) \\} </math>\n:is the weak-''L''<sub>''p''</sub> ideal. The weak-''L''<sub>''p''</sub> ideals, ''p'' > 1, admit no traces.  The weak-''L''<sub>''p''</sub> ideals are equal to the Lorentz ideals (below) with concave function ψ(''n''){{=}}''n''<sup>1−1/''p''</sup>.\n\n=== Ideals with traces ===\n\n* '''Finite rank operators.''' It is checked from the spectral condition that the kernel of the [[trace class#Definition|operator trace]] Tr and the commutator subspace of the finite rank operators are equal, ker Tr = Com(''F''(''H'')). It follows that the commutator subspace Com(''F''(''H'')) has co-dimension 1 in ''F''(''H''). Up to scaling Tr is the unique trace on ''F''(''H'').\n* '''Trace class operators.''' The trace class operators ''L''<sub>1</sub> have Com(''L''<sub>1</sub>) strictly contained in ker Tr. The co-dimension of the [[commutator subspace]] is therefore greater than one, and is shown to be infinite.<ref name=\"GW2\">\n{{cite journal\n|author1=V. Kaftal |author2=G. Weiss | year=2002\n| url=http://www.pnas.org/content/99/11/7356.full.pdf\n| title=Traces, ideals, and arithmetic means\n| journal=PNAS\n| volume=99\n| pages=7356–7360\n| issue=11\n| doi=10.1073/pnas.112074699\n | pmid=12032287\n | pmc=124235}}\n</ref> Whilst Tr is, up to scaling, the unique continuous trace on ''L''<sub>1</sub> for the norm ||A||<sub>1</sub> = Tr(|A|), the ideal of trace class operators admits infinitely many linearly independent and non-trivial singular traces.\n\n* '''Weak trace class operators'''. Since Com(''L''<sub>''1'',∞</sub>)<sub>+</sub> {{=}} (''L''<sub>1</sub>)<sub>+</sub> the co-dimension of the commutator subspace of the weak-''L''<sub>''1''</sub> ideal is infinite.  Every trace on weak trace class operators vanishes on trace class operators, and hence is singular. The weak trace class operators form the smallest ideal where every trace on the ideal must be singular.<ref name=\"GW2\"/> [[Dixmier trace]]s provide an explicit construction of traces on the weak trace class operators.\n::::<math> {\\rm Tr}_\\omega(A) = \\omega \\left( \\left\\{ \\frac{1}{\\log(1+n)} \\sum_{k=0}^n \\lambda(k,A) \\right\\}_{n=0}^\\infty \\right), \\quad A \\in L_{1,\\infty} . </math>\n:This formula is valid for every weak trace class operator ''A'' and involves the eigenvalues ordered in decreasing absolute value. Also ω can be any extension to ''l''<sub>∞</sub> of the ordinary limit, it does not need to be dilation invariant as in Dixmier's original formulation.  Not all of the singular traces on the weak trace class ideal are Dixmier traces.<ref name=\"LSZ\"/>{{rp|316}}\n\n* '''''k''-tensor weak trace class ideals'''. The weak-''L''<sub>''p''</sub> ideals, ''p'' > 1, admit no traces as explained above. They are not the right setting for higher order factorisations of the traces on the weak trace class ideal ''L''<sub>''1'',∞</sub>. For a natural number ''k'' ≥ 1 the ideals\n::::<math> E_{\\otimes k} = \\{ A \\in K(H) :\n\\mu(n,A) = O (\\log^{k-1}(n)/n ) \\} </math>\n:form the appropriate setting. They have commutator subspaces of infinite co-dimension that form a chain such that ''E''<sub>⊗''k''-1</sub> ⊂ Com(''E''<sub>⊗''k''</sub>) (with the convention that ''E''<sub>0</sub> = ''L''<sub>1</sub>). Dixmier traces on ''E''<sub>⊗''k''</sub> have the form\n::::<math> {\\rm Tr}^k_\\omega(A) = \\omega \\left( \\left\\{ \\frac{1}{\\log^k(1+n)} \\sum_{j=0}^n \\lambda(j,A) \\right\\}_{n=0}^\\infty \\right), \\quad A \\in E_{\\otimes k} . </math>\n\n* '''Lorentz ψ-ideals.''' The natural setting for Dixmier traces is on a Lorentz ψ-ideal for a concave increasing function ψ : [0,∞) → [0,∞),\n::::<math> L_{\\psi} = \\{ A \\in K(H) : \\frac{1}{\\psi(1+n)} \\sum_{j=0}^n \\mu(n,A) < \\infty \\}. </math>\n:There are ''some'' ω that extend the ordinary limit to ''l''<sub>∞</sub> such that\n::::<math> {\\rm Tr}^\\psi_\\omega(A) = \\omega \\left( \\left\\{ \\frac{1}{\\psi(1+n)} \\sum_{j=0}^n \\lambda(j,A) \\right\\}_{n=0}^\\infty \\right), \\quad A \\in L_{\\psi} </math>\n:is a singular trace if and only if<ref name=\"LSZ\"/>{{rp|225}}\n::::<math> \\liminf_{n \\to \\infty} \\frac{\\psi(2n)}{\\psi(n)} = 1 . </math>\n:The principal ideal generated by any compact operator ''A'' with μ(''A'')=ψ' is called the 'small ideal' inside ''L''<sub>ψ</sub>. The ''k''-tensor weak trace class ideal is the small ideal inside the Lorentz ideal with ψ{{=}}log<sup>k</sup>.\n\n* '''[[Fully symmetric ideal]]s''' generalise Lorentz ideals. Dixmier traces form all the fully symmetric traces on a Lorentz ideal up to scaling, and form a [[Weak topology#the weak-* topology|weak* dense]] subset of the fully symmetric traces on a general fully symmetric ideal. It is known the fully symmetric traces are a strict subset of the positive traces on a fully symmetric ideal.<ref name=\"LSZ\"/>{{rp|109}} Therefore, Dixmier traces are not the full set of positive traces on Lorentz ideals.\n\n== Notes ==\n\n{{reflist}}\n\n== References ==\n\n* {{cite book\n| isbn=978-3-11-026255-1\n| author= S. Lord, F. A. Sukochev. D. Zanin\n| year=2012\n| url=http://www.degruyter.com/view/product/177778\n| title=Singular traces: theory and applications\n| publisher=De Gruyter\n| location=Berlin }}\n\n* {{cite book\n| isbn=978-0-82-183581-4\n| author= B. Simon\n| year=2005\n| title=Trace ideals and their applications\n| publisher=Amer. Math. Soc.\n| location=Providence, RI }}\n\n* {{cite journal\n| author= A. Pietsch\n| year=1981\n| title=Operator ideals with a trace\n| journal=Math. Nachr.\n| volume=100\n| pages=61–91\n| doi=10.1002/mana.19811000105}}\n\n* {{cite book\n| isbn=978-0-52-132532-5\n| author= A. Pietsch\n| year=1987\n| title=Eigenvalues and s-numbers\n| publisher=Cambridge University Press\n| location=Cambridge, UK }}\n\n* {{cite journal\n|author1=S. Albeverio |author2=D. Guido |author3=A. Ponosov |author4=S. Scarlatti | year=1996\n| url=http://www.mat.uniroma2.it/~guido/research/papers/AGPS4.pdf\n| title=Singular traces and compact operators\n| journal=J. Functional Analysis\n| volume=137\n|issue=2 | pages=281–302\n| doi=10.1006/jfan.1996.0047}}\n\n* {{cite journal\n| author= M. Wodzicki\n| year=2002\n| url=http://math.berkeley.edu/~wodzicki/prace/Vestigia.pdf\n| title=Vestigia investiganda\n| journal=Mosc. Math. J.\n| volume=2\n| pages=769–798 }}\n\n*{{cite book\n| author=A. Connes\n| title=Noncommutative geometry\n| url=http://www.alainconnes.org/docs/book94bigpdf.pdf\n| publisher=Academic Press\n| location=Boston, MA\n| isbn=978-0-12-185860-5\n| year=1994 }}\n\n== See also ==\n\n* [[Dixmier trace]]\n\n[[Category:Hilbert space]]\n[[Category:Von Neumann algebras]]"
    },
    {
      "title": "Subfactor",
      "url": "https://en.wikipedia.org/wiki/Subfactor",
      "text": "In the theory of [[von Neumann algebra]]s, a '''subfactor''' of a [[factor (functional analysis)|factor]] <math> M </math> is a subalgebra that is a factor and contains <math> 1 </math>. The theory of subfactors led to the discovery of the \n[[Jones polynomial]] in [[knot theory]].\n\n==Index of a subfactor==\n\nUsually <math> M </math> is taken to be a factor of type <math> {\\rm II}_1 </math>, so that it has a finite trace.\nIn this case every Hilbert space module <math> H </math> has a dimension <math> \\dim_M(H)</math> which is a non-negative real number or <math> + \\infty </math>. \nThe '''index''' <math> [M:N] </math>  of a subfactor <math> N </math> is defined to be <math> \\dim_N(L^2(M)) </math>. Here <math> L^2(M) </math> is the representation \nof  <math> N </math> obtained from the [[GNS construction]] of the trace of <math> M </math>.\n\n==Jones index theorem==\n\nThis states that if <math> N </math> is a subfactor of <math> M </math> (both of type <math> {\\rm II}_1 </math>) then the index <math>[M:N]</math> is either of the form <math> 4 cos(\\pi /n)^2</math> for <math> n = 3,4,5,... </math>, or is at least <math> 4 </math>.  All these values occur.\n\nThe first few values of  <math> 4 \\cos(\\pi /n)^2</math> are  <math> 1, 2, (3 + \\sqrt{5})/2 = 2.618..., 3, 3.247..., ... </math>\n\n==Basic construction==\n\nSuppose that   <math> N </math> is a subfactor of <math> M </math>, and that both are finite von Neumann algebras. \nThe GNS construction produces a Hilbert space  <math> L^2(M)</math> acted on by <math> M </math>\nwith a cyclic vector <math>\\Omega</math>. Let <math>e_N</math> be the projection onto the subspace <math>N \\Omega</math>. Then <math> M </math> and <math>e_N</math> generate a new von Neumann algebra <math> \\langle M, e_N \\rangle </math> acting on  <math> L^2(M) </math>, containing <math>M</math> as a subfactor. The passage from the inclusion of <math>N</math> in <math>M</math> to the inclusion of <math>M</math> in <math> \\langle M, e_N \\rangle </math> is called the '''basic construction'''.\n\nIf <math>N</math> and <math>M</math> are both factors of type <math> {\\rm II}_1 </math> and <math>N</math> has finite index in <math>M</math> then <math> \\langle M, e_N \\rangle </math> is also of type <math> {\\rm II}_1 </math>.\nMoreover the inclusions have the same index: <math> [M:N] = [\\langle M, e_N \\rangle :M],</math> and  <math>tr_{\\langle M, e_N \\rangle}(e_N) = [M:N]^{-1} </math>.\n\n==Jones tower==\nSuppose that <math> N \\subset M </math> is an inclusion of type <math> {\\rm II}_1 </math> factors of finite index. By iterating the basic construction we get a tower of inclusions\n\n:  <math> M_{-1} \\subset M_0 \\subset M_{1} \\subset M_{2} \\subset \\cdots </math>\n\nwhere <math> M_{-1} = N </math> and  <math> M_{0}=M </math>, and each <math> M_{n+1} =  \\langle M_n, e_{n+1} \\rangle </math> is generated by the previous algebra and a projection. The union of all these algebras has a tracial state <math> tr </math> whose restriction to each <math> M_n </math> is the tracial state, and so the closure of the union is another type <math> {\\rm II}_1 </math> von Neumann algebra <math> M_{\\infty} </math>.\n\nThe algebra <math> M_{\\infty} </math> contains a sequence of projections <math> e_1, e_2, e_3, ...,  </math> which satisfy the [[Temperley&ndash;Lieb algebra|Temperley&ndash;Lieb relations]] at parameter <math> \\lambda = [M:N]^{-1} </math>. Moreover, the algebra generated by the <math> e_n </math> is a <math> {\\rm C}^{\\star}</math>-algebra in which the <math> e_n </math> are self-adjoint, and such that <math> tr(xe_n)= \\lambda tr(x) </math> when <math> x </math> is in the algebra generated by <math> e_1 </math> up to <math> e_{n-1} </math>. Whenever these extra conditions are satisfied, the algebra is called a Temperly&ndash;Lieb&ndash;Jones algebra at parameter <math> \\lambda </math>. It can be shown to be unique up to <math> \\star </math>-isomorphism. It exists only when <math> \\lambda </math> takes on those special values <math> 4 cos(\\pi /n)^2</math> for <math> n = 3,4,5,... </math>, or the values larger than <math> 4 </math>.\n\n==Standard invariant==\nSuppose that <math> N \\subset M </math> is an inclusion of type <math> {\\rm II}_1 </math> factors of finite index. Let the higher relative commutants be <math> \\mathcal{P}_{n,+}= N' \\cap M_{n-1}</math>  and <math> \\mathcal{P}_{n,-}= M' \\cap M_{n} </math>.\n\nThe '''standard invariant''' of the subfactor <math> N \\subset M </math> is the following grid:\n\n: <math> \\mathbb{C} = \\mathcal{P}_{0,+} \\subset \\mathcal{P}_{1,+} \\subset \\mathcal{P}_{2,+} \\subset \\cdots \\subset \\mathcal{P}_{n,+} \\subset \\cdots  </math>  \n:  <math>  \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\cup  \\ \\ \\ \\ \\ \\ \\ \\ \\ \\cup \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\cup </math> \n: <math> \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\   \\mathbb{C} \\  = \\mathcal{P}_{0,-} \\subset \\mathcal{P}_{1,-} \\subset \\cdots \\subset \\mathcal{P}_{n-1,-} \\subset \\cdots  </math> \nwhich is a complete invariant in the amenable case.<ref>\n{{citation\n | last = Popa | first = Sorin | authorlink = Sorin Popa\n | doi = 10.1007/BF02392646\n | number= 2\n | journal = [[Acta Mathematica]]\n | mr = 1278111 \n | pages = 163–255\n | title = Classification of amenable subfactors of type II\n | volume = 172\n | year = 1994}}</ref> A diagrammatic axiomatization of the standard invariant is given by the notion of [[planar algebra]].\n\n==Principal graphs==\nA subfactor of finite index <math> N  \\subset  M </math> is said to be '''irreducible''' if either of the following equivalent conditions is satisfied:\n\n* <math>L^2(M)</math> is irreducible as an <math>(N,M)</math> bimodule;\n* the [[commutant|relative commutant]] <math> N'  \\cap M </math>  is <math> \\mathbb{C} </math>.\n\nIn this case <math>L^2(M)</math> defines a <math>(N,M)</math> bimodule <math> X </math> as well as its conjugate <math>(M,N)</math> bimodule <math>X^{\\star}</math>. The relative tensor product, described in {{harvtxt|Jones|1983}} and often called '''Connes fusion''' after a prior definition for general von Neumann algebras of [[Alain Connes]], can be used to define new bimodules over <math>(N,M)</math>, <math>(M,N)</math>, <math>(M,M)</math> and <math>(N,N)</math> by decomposing the following tensor products into irreducible components:\n\n:<math> X\\boxtimes X^{\\star} \\boxtimes \\cdots \\boxtimes X,\\,\\, X^{\\star}\\boxtimes X \\boxtimes \\cdots \\boxtimes X^{\\star}, \\,\\, X^{\\star} \\boxtimes X \\boxtimes \\cdots \\boxtimes X,\\,\\, X\\boxtimes X^{\\star} \\boxtimes  \\cdots \\boxtimes X^{\\star}.</math>\n\nThe irreducible <math>(M,M)</math> and <math>(M,N)</math> bimodules arising in this way form the vertices of the '''principal graph''', a [[bipartite graph]]. The directed edges of these graphs describe the way an irreducible bimodule decomposes when tensored with <math>X</math> and <math>X^{\\star}</math> on the right. \nThe '''dual principal''' graph is defined in a similar way using <math>(N,N)</math> and <math>(N,M)</math> bimodules.\n\nSince any bimodule corresponds to the commuting actions of two factors, each factor is contained in the commutant of the other and therefore defines a subfactor. When the bimodule is irreducible, its dimension is defined to be the square root of the index of this subfactor. The dimension is extended additively to direct sums of irreducible bimodules. It is multiplicative with respect to Connes fusion.\n\nThe subfactor is said to have '''finite depth''' if the principal graph and its dual are finite, i.e. if only finitely many irreducible bimodules occur in these decompositions. In this case if <math>M</math> and <math>N</math> are hyperfinite, Sorin Popa showed that the inclusion <math>N \\subset M </math>  is isomorphic to the model\n\n:<math>(\\mathbb{C}\\otimes \\mathrm{End}\\, X^{\\star} \\boxtimes X \\boxtimes X^{\\star} \\boxtimes \\cdots)^{\\prime\\prime} \\subset (\\mathrm{End}\\, X\\boxtimes X^{\\star} \\boxtimes X \\boxtimes X^{\\star} \\boxtimes\\cdots )^{\\prime\\prime},</math>\n\nwhere the <math> {\\rm II}_1 </math> factors are obtained from the GNS construction with respect to the canonical trace.\n\n==Knot polynomials==\n\nThe algebra generated by the elements <math> e_n </math> with the relations above is called the [[Temperley–Lieb algebra]]. This is a quotient of the group algebra of the [[braid group]], so representations of the Temperley–Lieb algebra give representations of the braid group, which in turn often give invariants for knots.\n\n==References==\n{{Reflist}}\n\n*{{citation|last=Jones|first=Vaughan F.R.|authorlink=Vaughan Jones|title=Index for subfactors|journal=[[Inventiones Mathematicae]]|volume= 72|\nurl=http://gdz.sub.uni-goettingen.de/no_cache/dms/load/img/?IDDOC=175031|year=1983| pages=1–25|doi=10.1007/BF01389127}}\n*{{citation|last= Wenzl|first=H.G.|title=Hecke algebras of type A<sub>n</sub> and subfactors|journal=Invent. Math.|volume= 92 \n|url=http://gdz.sub.uni-goettingen.de/no_cache/dms/load/img/?IDDOC=179061|year=1988|pages= 349–383|doi= 10.1007/BF01404457|issue= 2|mr=696688|}}\n* {{cite book|last1=Jones |first1=Vaughan F.R.| author1-link=Vaughan Jones| last2=Sunder|first2=Viakalathur Shankar|title=Introduction to subfactors|series=London Mathematical Society Lecture Note Series|volume= 234|year=1997|publisher=[[Cambridge University Press]]|location=Cambridge|doi=10.1017/CBO9780511566219|isbn=0-521-58420-5|mr=1473221}}\n*Theory of Operator Algebras  III  by M. Takesaki  {{isbn|3-540-42913-1}}\n*{{cite web|first=Antony|last=Wassermann|authorlink=Antony Wassermann| url=http://iml.univ-mrs.fr/~wasserm/OHS.ps |title=Operators on Hilbert space}}\n\n[[Category:Operator theory]]\n[[Category:Von Neumann algebras]]"
    },
    {
      "title": "Tomita–Takesaki theory",
      "url": "https://en.wikipedia.org/wiki/Tomita%E2%80%93Takesaki_theory",
      "text": "In the theory of [[von Neumann algebra]]s, a part of the mathematical field of [[functional analysis]], '''Tomita–Takesaki theory'''  is a method for constructing '''modular automorphisms''' of von Neumann algebras from the [[polar decomposition]] of a certain involution. It is essential for the theory of [[von Neumann algebra#Type III factors|type III factors]], and has led to a good structure theory for these previously intractable objects.\n\nThe theory was introduced by {{harvs|txt|first=Minoru |last=Tomita|authorlink=Minoru Tomita|year=1967}}, but his work was hard to follow and mostly unpublished, and little notice was taken of it until {{harvs|txt|first=Masamichi |last=Takesaki|year=1970|authorlink=Masamichi Takesaki}} wrote an account of Tomita's theory.\n\n==Modular automorphisms of a state==\n\nSuppose that ''M'' is a von Neumann algebra acting on a Hilbert space ''H'', and Ω is a separating and cyclic vector of ''H'' of norm 1. ('''Cyclic''' means that ''MΩ'' is dense in ''H'', and '''separating''' means that the map from ''M'' to ''MΩ'' is injective.) We write <math>\\phi</math> for the state <math>\\phi(x)=(x\\Omega,\\Omega)</math> of ''M'', so that ''H'' is constructed from <math>\\phi</math> using the [[GNS construction]].\n\nWe can define an unbounded antilinear operator ''S''<sub>0</sub> on ''H'' with domain ''MΩ'' by setting\n<math>S_0(m\\Omega) = m^*\\Omega</math>\nfor all ''m'' in ''M'', and similarly we can define an unbounded antilinear operator ''F''<sub>0</sub> on ''H'' with domain ''M'Ω'' by setting\n<math>F_0(m\\Omega) = m^*\\Omega</math>\nfor ''m'' in ''M''&prime;, where ''M''&prime; is the commutant of ''M''.\n\nThese operators are closable, and we denote their closures by ''S'' and ''F'' = ''S''*. They have [[polar decomposition]]s\n\n: <math>S = J|S| = J\\Delta^\\frac{1}{2} = \\Delta^{-\\frac{1}{2}}J</math>\n: <math>F = J|F| =J \\Delta^{-\\frac{1}{2}} = \\Delta^\\frac{1}{2}J</math>\n\nwhere <math>J = J^{-1} = J^*</math>  is an antilinear isometry called the modular conjugation and <math>\\Delta = S^*S = FS</math> is a  positive self adjoint operator called the modular operator.\n\nThe main result of Tomita–Takesaki theory states that:\n: <math>\\Delta^{it}M\\Delta^{-it} = M</math>\n\nfor all ''t'' and that\n: <math>JMJ = M',</math>\n\nthe commutant of ''M''.\n\nThere is a 1-parameter family of '''modular automorphisms''' σ<sup>φ</sup><sub>''t''</sub> of ''M'' associated to the state <math>\\phi</math>, defined  by <math>\\sigma^{\\phi_t}(x) = \\Delta^{it}x\\Delta^{-it}</math>\n\n==The Connes cocycle==\n\nThe modular automorphism group of a von Neumann algebra ''M'' depends on the choice of state φ. [[Alain Connes|Connes]] discovered that changing the state does not change the image of the modular automorphism in the [[outer automorphism group]] of ''M''. More precisely, given two faithful states φ and ψ of ''M'', we can find unitary elements ''u<sub>t</sub>'' of ''M'' for all real ''t'' such that\n\n: <math>\\sigma^{\\psi_t}(x) = u_t\\sigma^{\\phi_t}(x)u_t^{-1} </math> \nso that the modular automorphisms differ by inner automorphisms, and moreover ''u<sub>t</sub>'' satisfies the 1-cocycle condition\n\n: <math>u_{s+t} = u_s\\sigma^{\\phi_s}(u_t)</math>\nIn particular, there is a canonical homomorphism from the additive group of reals to the outer automorphism group of ''M'', that is independent of the choice of faithful state.\n\n==KMS states==\nThe term ''KMS state'' comes from the Kubo–Martin–Schwinger condition in [[quantum statistical mechanics]].\n\nA '''[[KMS state]]''' φ on a von Neumann algebra ''M'' with a given 1-parameter group of automorphisms α<sub>''t''</sub> is a state fixed by the automorphisms  such that for every pair of elements ''A'', ''B'' of ''M'' there is a bounded continuous function ''F'' in the strip 0≤Im(''t'')≤1, holomorphic in the interior, such that\n\n: <math>F(t) = \\phi(A\\alpha_t(B)), F(t + i) = \\phi(a_t(B)A)</math>,\n\nTakesaki and Winnink showed that a (faithful semi finite normal) state φ is a KMS state for the 1-parameter group of modular automorphisms σ<sup>φ</sup><sub>&minus;''t''</sub>. Moreover, this characterizes the modular automorphisms of φ.\n\n(There is often an extra parameter, denoted by β, used in the theory of KMS states. In the description above this has been  normalized to be 1 by rescaling the 1-parameter family of automorphisms.)\n\n==Structure of type III factors==\n\nWe have seen above that there is a canonical homomorphism δ from the group of reals to the outer automorphism group of a von Neumann algebra, given by modular automorphisms.  The kernel of δ is an important invariant of the algebra. For simplicity assume that the von Neumann algebra is a factor. Then the possibilities for the kernel  of δ are:\n\n* The whole real line. In this case δ is trivial and the factor is type I or II.\n* A proper dense subgroup of the real line. Then the factor is called a factor of type III<sub>0</sub>.\n* A discrete subgroup generated by some ''x''&nbsp;>&nbsp;0. Then the factor is called a factor of type III<sub>λ</sub> with 0&nbsp;<&nbsp;λ&nbsp;=&nbsp;exp(&minus;2''π''/''x'')&nbsp;<&nbsp;1, or sometimes a Powers factor.\n* The trivial group 0. Then the factor is called a factor of type III<sub>1</sub>. (This is in some sense the generic case.)\n\n==Hilbert algebras==\n{{see also|Commutation theorems}}\n\nThe main results of Tomita–Takesaki theory were proved using left and right Hilbert algebras.\n\nA '''left Hilbert algebra''' is an algebra with involution ''x''&rarr;''x''<sup>♯</sup> and an inner product (,) such that\n# Left multiplication by a fixed ''a'' &isin; ''A'' is a bounded operator.\n# ♯ is the adjoint; in other words (''xy'',''z'') = (''y'', ''x''<sup>♯</sup>''z'').\n#The involution <sup>♯</sup> is preclosed\n# The subalgebra spanned by all products ''xy'' is dense in ''A''.\n\nA '''right Hilbert algebra''' is defined similarly (with an involution ♭) with left and right reversed in the conditions above.\n\nA '''Hilbert algebra''' is a left Hilbert algebra such that in  addition ♯ is an isometry, in other words (''x'',''y'') = (''y''<sup>♯</sup>, ''x''<sup>♯</sup>).\n\nExamples:\nIf ''M'' is a von Neumann algebra acting on a Hilbert space ''H'' with a cyclic separating vector ''v'', then put ''A'' = ''Mv'' and define (''xv'')(''yv'') = ''xyv'' and (''xv'')<sup>♯</sup> = ''x''*''v''. Tomita's key discovery was that this makes ''A'' into a left Hilbert algebra, so in particular the closure of the operator <sup>♯</sup> has a polar decomposition as above. The vector ''v'' is the identity of ''A'', so ''A'' is a unital left Hilbert algebra.\n\nIf ''G'' is a locally compact group, then the vector space of all continuous complex functions on ''G'' with compact support is a right Hilbert algebra if multiplication is given by convolution, and ''x''<sup>♭</sup>(''g'')  = ''x''(''g''<sup>&minus;1</sup>)*.\n\n==References==\n*{{Citation | last1=Borchers | first1=H. J. | title=On revolutionizing quantum field theory with Tomita's modular theory | doi=10.1063/1.533323 | mr=1768633 | year=2000 | journal=[[Journal of Mathematical Physics]] | volume=41 | issue=6 | pages=3604–3673| bibcode=2000JMP....41.3604B }}\n**[http://www.lqp.uni-goettingen.de/papers/99/04/99042900.html Longer version with proofs]\n*{{citation|first=O.|last=Bratteli|first2=D.W.|last2=Robinson|title=Operator Algebras and Quantum Statistical Mechanics 1, Second Edition|publisher=Springer-Verlag|year=1987|isbn=3-540-17093-6}}\n*{{Citation | last1=Connes | first1=Alain | author1-link=Alain Connes | title=Non-commutative geometry | url=ftp://ftp.alainconnes.org/book94bigpdf.pdf | publisher=[[Academic Press]] | location=Boston, MA | isbn=978-0-12-185860-5 | year=1994 }}{{dead link|date=January 2018 |bot=InternetArchiveBot |fix-attempted=yes }}\n*{{Citation | last1=Dixmier | first1=Jacques | title=von Neumann algebras | publisher=North-Holland | location=Amsterdam | series=North-Holland Mathematical Library | isbn=978-0-444-86308-9 | mr=641217 | year=1981 | volume=27}}\n*{{eom|id=T/t120150|title=Tomita–Takesaki theory|first=A.|last=Inoue}}\n*{{Citation | last1=Nakano | first1=Hidegorô | title=Hilbert algebras | mr=0041362 | year=1950 | journal=The Tohoku Mathematical Journal. Second Series   | volume=2 | pages=4–23 | doi=10.2748/tmj/1178245666}}\n*{{eom|id=H/h047230|title=Hilbert algebra|first=A.I.|last= Shtern}}\n*{{Citation | first=S. J. |last=Summers|chapter=Tomita–Takesaki Modular Theory|arxiv=math-ph/0511034|editor1-last=Françoise | editor1-first=Jean-Pierre | editor2-last=Naber | editor2-first=Gregory L. | editor3-last=Tsun | editor3-first=Tsou Sheung | title=Encyclopedia of mathematical physics| publisher=Academic Press/Elsevier Science, Oxford | isbn=978-0-12-512660-1 | mr=2238867 | year=2006|bibcode=2005math.ph..11034S}}\n*{{citation|first=M.|last= Takesaki|title=Tomita's theory of modular Hilbert algebras and its applications|series= Lecture Notes Math.|volume= 128 |publisher= Springer  |year=1970|doi=10.1007/BFb0065832 |isbn =978-3-540-04917-3}}\n*{{Citation | last1=Takesaki | first1=Masamichi | title=Theory of operator algebras. II | publisher=[[Springer-Verlag]] | location=Berlin, New York | series=Encyclopaedia of Mathematical Sciences | isbn=978-3-540-42914-2 | mr=1943006 | year=2003 | volume=125}}\n*{{Citation | last1=Tomita | first1=Minoru | title=Fifth Functional Analysis Sympos. (Tôhoku Univ., Sendai, 1967) | publisher=Math. Inst. | location=Tôhoku Univ., Sendai | mr=0284822 | year=1967 | chapter=On canonical forms of von Neumann algebras | pages=101–102|language = Japanese}}\n*{{citation|first=M.|last=Tomita|year=1967|title=Quasi-standard von Neumann algebras|publisher=unpublished|series=mimographed note}}\n\n{{DEFAULTSORT:Tomita-Takesaki theory}}\n[[Category:Operator theory]]\n[[Category:Von Neumann algebras]]"
    },
    {
      "title": "Ultrastrong topology",
      "url": "https://en.wikipedia.org/wiki/Ultrastrong_topology",
      "text": "In [[functional analysis]], the '''ultrastrong topology''',  or '''&sigma;-strong topology''', or '''strongest topology''' on the set ''B(H)'' of [[bounded operator]]s on a [[Hilbert space]] is the topology defined by the family of seminorms\n:<math>\np_\\omega(x) = \\omega(x^{*} x)^{1/2}\n</math>\nfor positive elements <math>\\omega</math> of the [[predual]] <math>L_{*}(H)</math> that consists of [[trace class]] operators.\n<ref name=\"TakesakiI\">{{Cite book\n|last=Takesaki\n|first=Masamichi\n|title=Theory of operator algebras. I.\n|publisher=Springer-Verlag|location=[[Berlin]]\n|year=2002\n|isbn=3-540-42248-X\n}}</ref>{{rp|68}}\n\nIt was introduced by [[John von Neumann]] in 1936.\n<ref>{{Citation\n | last=von Neumann\n | first=John\n | title=On a Certain Topology for Rings of Operators\n | journal=Annals of Mathematics |series=Second Series\n | volume=37\n | issue=1\n | year=1936\n | pages=111–115\n | jstor=1968692\n | doi=10.2307/1968692\n }}</ref>\n\n==Relation with the strong (operator) topology==\n\nThe ultrastrong topology is similar to the strong (operator) topology. \nFor example, on any norm-bounded set the strong operator and ultrastrong topologies \nare the same. The ultrastrong topology is stronger than the strong operator topology.\n\nOne problem with the strong operator topology is that the dual of ''B(H)'' with the strong operator topology is \n\"too small\". The ultrastrong topology fixes this problem: the dual is the full predual\n''B<sub>*</sub>(H)'' of all trace class operators. In general the ultrastrong topology is better than the strong operator topology, but is more complicated to define so people usually use the strong operator topology if they can get away with it.\n\nThe ultrastrong topology can be obtained from the strong operator topology as follows. \nIf  ''H''<sub>1</sub> is a separable infinite dimensional Hilbert space\nthen ''B(H)'' can be embedded in ''B''(''H''&otimes;''H''<sub>1</sub>) by tensoring with the identity map on ''H''<sub>1</sub>. Then the restriction of the strong operator topology on \n''B''(''H''&otimes;''H''<sub>1</sub>) is the ultrastrong topology of ''B(H)''.\nEquivalently, it is given by the family of seminorms\n:<math>\nx \\mapsto \\left( \\sum_{n=1}^\\infty ||x\\xi_n||^2 \\right)^{1/2},\n</math>\nwhere <math>\\sum_{n=1}^\\infty ||\\xi_n||^2 < \\infty</math>.<ref name=TakesakiI/>{{rp|68}}\n\nThe adjoint map is not continuous in the ultrastrong topology. There is another topology called the ultrastrong<sup>*</sup>  topology, which is the weakest topology stronger than the ultrastrong topology such that the adjoint map is continuous.<ref name=TakesakiI/>{{rp|68}}\n\n== See also ==\n*[[Topologies on the set of operators on a Hilbert space]]\n*[[ultraweak topology]]\n*[[strong operator topology]]\n\n==References==\n{{Reflist}}\n\n{{Functional Analysis}}\n\n[[Category:Topology of function spaces]]\n[[Category:Von Neumann algebras]]"
    },
    {
      "title": "Ultraweak topology",
      "url": "https://en.wikipedia.org/wiki/Ultraweak_topology",
      "text": "{{Unreferenced|date=December 2009}}\nIn [[functional analysis]], a branch of [[mathematics]], the '''ultraweak topology''', also called the '''weak-* topology''', or '''weak-*  operator topology''' or '''σ-weak topology''', on the set ''B''(''H'') of [[bounded operator]]s on a [[Hilbert space]] is the [[weak topology|weak-* topology]] obtained from the [[predual]] ''B''<sub>*</sub>(''H'') of ''B''(''H''), the [[trace class]] operators on ''H''. In other words it is the weakest topology such that all elements of the predual are continuous (when considered as functions on ''B''(''H'')).\n\n==Relation with the weak (operator) topology==\nThe ultraweak topology is similar to the weak operator topology. \nFor example, on any norm-bounded set the weak operator and ultraweak topologies \nare the same, and in particular the unit ball is compact in both topologies. The ultraweak topology is stronger than the weak operator topology.  \n\nOne problem with the weak operator topology is that the dual of ''B''(''H'') with the weak operator topology is  \"too small\". The ultraweak topology fixes this problem: the dual is the full predual ''B''<sub>*</sub>(''H'') of all trace class operators. In general the ultraweak topology is more useful than the weak operator topology, but it is more complicated to define, and the weak operator topology is often more apparently convenient. \n\nThe ultraweak topology can be obtained from the weak operator topology as follows. \nIf  ''H''<sub>1</sub> is a separable infinite dimensional Hilbert space\nthen ''B''(''H'') can be embedded in ''B''(''H''⊗''H''<sub>1</sub>) by tensoring with the identity map on ''H''<sub>1</sub>. Then the restriction of the weak operator topology on  ''B''(''H''⊗''H''<sub>1</sub>) is the ultraweak topology of ''B''(''H'').\n\n==See also==\n*[[Topologies on the set of operators on a Hilbert space]]\n*[[ultrastrong topology]]\n*[[weak operator topology]]\n\n{{Functional Analysis}}\n\n{{DEFAULTSORT:Ultraweak Topology}}\n[[Category:Topology of function spaces]]\n[[Category:Von Neumann algebras]]"
    },
    {
      "title": "Von Neumann bicommutant theorem",
      "url": "https://en.wikipedia.org/wiki/Von_Neumann_bicommutant_theorem",
      "text": "{{cleanup|reason=As mentioned on the talk page, the proof of item (iii) is incomplete.|date=September 2018}}  \n\nIn [[mathematics]], specifically [[functional analysis]], the '''von Neumann bicommutant theorem''' relates the [[closure (mathematics)|closure]] of a set of [[bounded operator]]s on a [[Hilbert space]] in certain [[operator topology|topologies]] to the [[bicommutant]] of that set. In essence, it is a connection between the [[algebra]]ic and topological sides of [[operator theory]].\n\nThe formal statement of the theorem is as follows:\n\n:'''Von Neumann Bicommutant Theorem.''' Let {{math|'''M'''}} be an [[Operator algebra|algebra]] of bounded operators on a Hilbert space {{mvar|H}}, containing the identity operator and closed under taking [[Hermitian adjoint|adjoint]]s. Then the [[closure (topology)|closure]]s of {{math|'''M'''}} in the [[weak operator topology]] and the [[strong operator topology]] are equal, and are in turn equal to the [[bicommutant]] {{math|'''M'''′′}} of {{math|'''M'''}}.{{clarify|Algebra of all bounded operators is undefined|date=February 2013}} This algebra is the [[von Neumann algebra]] generated by {{math|'''M'''}}.\n\nThere are several other topologies on the space of bounded operators, and one can ask what are the *-algebras closed in these topologies. If {{math|'''M'''}} is closed in the [[norm topology]] then it is a [[C*-algebra]], but not necessarily a von Neumann algebra. One such example is the C*-algebra of [[compact operator on Hilbert space|compact operator]]s (on an infinite dimensional Hilbert space). For most other common topologies the closed *-algebras containing 1 are still von Neumann algebras; this applies in particular to the weak operator, strong operator, *-strong operator, [[ultraweak topology|ultraweak]], [[ultrastrong topology|ultrastrong]], and *-ultrastrong topologies.\n \nIt is related to the [[Jacobson density theorem]].\n\n== Proof ==\nLet {{mvar|H}} be a Hilbert space and {{math|''L''(''H'')}} the bounded operators on {{mvar|H}}. Consider a self-adjoint unital [[subalgebra]] {{math|'''M'''}} of {{math|''L''(''H'')}}. (this means that {{math|'''M'''}} contains the adjoints of its members, and the identity operator on {{mvar|H}})\n\nThe theorem is equivalent to the combination of the following three statements:\n\n:(i) {{math|cl<sub>''W''</sub>('''M''') ⊆ '''M'''′′}}\n:(ii) {{math|cl<sub>''S''</sub>('''M''') ⊆ cl<sub>''W''</sub>('''M''')}}\n:(iii) {{math|'''M'''′′ ⊆ cl<sub>''S''</sub>('''M''')}}\n\nwhere the {{mvar|W}} and {{mvar|S}} subscripts stand for [[Closure (topology)|closure]]s in the [[weak operator topology|weak]] and [[strong operator topology|strong]] operator topologies, respectively.\n\n===Proof of (i)===\nBy definition of the weak operator topology, for any {{mvar|x}} and {{mvar|y}} in {{mvar|H}}, the map ''T'' → <''Tx'', ''y''> is continuous in this topology. Therefore, for any operator {{mvar|O}} (and by substituting once {{math|''y'' → ''O<sup>∗</sup>y''}} and once {{math|''x'' → ''Ox''}}), so is the map\n\n:<math>T \\to \\langle Tx, O^*y\\rangle - \\langle TOx, y\\rangle = \\langle OTx, y\\rangle - \\langle TOx, y\\rangle.</math>\n\nLet ''S'' be any subset of {{math|''L''(''H'')}}, and ''S’'' its [[commutant]]. For any operator {{mvar|T}} not in ''S’'', <''OTx'', ''y''> - <''TOx'', ''y''> is nonzero for some ''O'' in ''S'' and some ''x'' and ''y'' in {{mvar|H}}. By the continuity of the abovementioned mapping, there is an open neighborhood of {{mvar|T}} in the weak operator topology for which this is nonzero, therefore this open neighborhood is also not in ''S’''. Thus ''S’'' is [[Closed set|closed]] in the weak operator, i.e. ''S''' is ''weakly closed''. Thus every [[commutant]] is weakly closed, and so is {{math|'''M'''′′}}; since it contains {{math|'''M'''}}, it also contains its weak closure.\n\n===Proof of (ii)===\nThis follows directly from the weak operator topology being coarser than the strong operator topology: for every point {{mvar|x}} in {{math|cl<sub>''S''</sub>('''M''')}}, every open neighborhood of {{mvar|x}} in the weak operator topology is also open in the strong operator topology and therefore contains a member of {{math|'''M'''}}; therefore {{mvar|x}} is also a member of {{math|cl<sub>''W''</sub>('''M''')}}.\n\n===Proof of (iii)===\nFix {{math|''X'' ∈ '''M'''′′}}. We will show {{math|''X'' ∈ cl<sub>''S''</sub>('''M''')}}.\n\nFix an open neighborhood {{mvar|U}} of {{mvar|X}} in the strong operator topology. By definition of the strong operator topology, ''U'' contains a finite intersection ''U''(''h''<sub>1</sub>,ε<sub>1</sub>) ∩...∩''U''(''h''<sub>n</sub>,ε<sub>n</sub>) of subbasic open sets of the form ''U''(''h'',ε) = {''O'' ∈ ''L''(''H''): ||''Oh'' - ''Xh''|| < ε}, where ''h'' is in ''H'' and ε > 0.\n\nFix ''h'' in {{mvar|H}}. Consider the [[Closure (topology)|closure]] {{math|cl('''M'''''h'')}} of {{math|'''M'''''h'' {{=}} {''Mh'' : ''M'' ∈ '''M'''}}} with respect to the norm of ''H'' and equipped with the inner product of ''H''. It is a [[Hilbert space]] (being a closed subspace of a Hilbert space {{mvar|H}}), and so has a corresponding [[orthogonal projection]] which we denote {{mvar|P}}. {{mvar|P}} is bounded, so it is in {{math|''L''(''H'')}}. Next we prove:\n\n:'''Lemma.''' {{math|''P'' ∈ '''M'''′}}.\n\n:'''Proof.''' Fix {{math|''x'' ∈ ''H''}}. Then {{math|''Px'' ∈ cl('''M'''''h'')}}, so it is the limit of a sequence {{mvar|O<sub>n</sub>h}} with {{mvar|O<sub>n</sub>}} in {{math|'''M'''}} for all {{mvar|n}}. Then for all {{math|''T'' ∈ '''M'''}}, {{mvar|TO<sub>n</sub>h}} is also in {{math|'''M'''''h''}} and thus its limit is in {{math|cl('''M'''''h'')}}. By continuity of {{mvar|T}} (since it is in {{math|''L''(''H'')}} and thus [[Bounded operator#Further properties|Lipschitz continuous]]), this limit is {{mvar|TPx}}. Since {{math|''TPx'' ∈ cl('''M'''''h'')}}, ''PTPx'' = ''TPx''. From this it follows that ''PTP'' = ''TP'' for all {{mvar|T}} in {{math|'''M'''}}.\n\n:By using the closure of {{math|'''M'''}} under the adjoint we further have, for every {{mvar|T}} in {{math|'''M'''}} and all {{math|''x'', ''y'' ∈ ''H''}}:\n\n::<math>\\langle x,TPy\\rangle = \\langle x,PTPy\\rangle = \\langle Px,TPy\\rangle = \\langle T^*Px,Py\\rangle = \\langle PT^*Px,y\\rangle = \\langle T^*Px,y\\rangle = \\langle Px,Ty\\rangle = \\langle x,PTy\\rangle</math>\n\n:thus ''TP'' = ''PT'' and ''P'' lies in {{math|'''M'''′}}.\n\nBy definition of the [[bicommutant]] ''XP'' = ''PX''. Since {{math|'''M'''}} is unital, {{math|''h'' ∈ '''M'''''h''}}, hence {{math|''Xh'' {{=}} ''XPh'' {{=}} ''PXh'' ∈ cl('''M'''''h'')}}. Thus for every {{math|''ε'' > 0}}, there exists ''T'' in {{math|'''M'''}} with {{math|{{!!}}''Xh'' − ''Th''{{!!}} < ''ε''}}. Then ''T'' lies in ''U''(''h'',ε).{{clarify|reason=This part is incomplete since we must intersect a finite number of these subbasic open sets.|date=September 2015}}\n\nThus in every open neighborhood {{mvar|U}} of {{mvar|X}} in the strong operator topology there is a member of {{math|'''M'''}}, and so {{mvar|X}} is in the strong operator topology closure of {{math|'''M'''}}.\n\n=== Non-unital case ===\nAn algebra {{math|'''M'''}}{{clarify|reason=What kind of algebra?|date=September 2015}} acting on '''H''' is said to act ''non-degenerately'' if for ''h'' in {{mvar|H}}, {{math|'''M'''''h'' {{=}} {0} }} implies {{math|''h'' {{=}} 0}}. If {{math|'''M'''}} acts non-degenerately, and is a sub [[C*-algebra]] of {{math|''L''(''H'')}},{{clarify|reason=If M acts non-degenerately, it can be identified bijectively with its image A in L(H). Is the image being a sub-C*-algebra an additional hypothesis on the representation, or is it automatic at this point? The only obstacle I can see is being weakly closed, but maybe this is automatic.|date=September 2015}}  it can be shown using an [[approximate identity]] in {{math|'''M'''}} that the identity operator ''I'' lies in the strong closure of {{math|'''M'''}}. Therefore, the conclusion of the bicommutant theorem still holds.\n\n== References ==\n*W.B. Arveson, ''An Invitation to C*-algebras'', Springer, New York, 1976.\n\n[[Category:Operator theory]]\n[[Category:Von Neumann algebras]]\n[[Category:Articles containing proofs]]\n[[Category:Theorems in functional analysis]]"
    },
    {
      "title": "Weak trace-class operator",
      "url": "https://en.wikipedia.org/wiki/Weak_trace-class_operator",
      "text": "<!-- (redirect weak L1 ideal) -->\nIn mathematics, a '''weak trace class''' operator  is a [[compact operator]] on a [[separable space|separable]] [[Hilbert space]] ''H'' with [[singular value]]s the same order as the [[harmonic series (mathematics)|harmonic sequence]].\nWhen the dimension of ''H'' is infinite, the ideal of weak trace-class operators is strictly larger than the ideal of [[trace class operator]]s, and has fundamentally different properties. The usual [[trace class#Definition|operator trace]] on the trace-class operators does not extend to the weak trace class. Instead the ideal of weak trace-class operators admits an infinite number of linearly independent quasi-continuous traces, and it is the smallest two-sided ideal for which all traces on it are [[singular trace]]s.\n\nWeak trace-class operators feature in the [[noncommutative geometry]] of French mathematician [[Alain Connes]].\n\n== Definition ==\n\nA [[compact operator]] ''A'' on an infinite dimensional [[separable space|separable]] [[Hilbert space]] ''H'' is ''weak trace class'' if μ(''n'',''A'') {{=}} O(''n''<sup>−1</sup>), where μ(''A'') is the sequence of [[singular value]]s.  In mathematical notation the two-sided [[ideal (ring theory)|ideal]] of all weak trace-class operators is denoted,\n::::<math> L_{1,\\infty} = \\{ A \\in K(H) : \\mu(n,A) = O(n^{-1}) \\}. </math>\nwhere <math>K(H) </math> are the compact operators.{{what|reason= This definition disagrees with the definition in the article on the [[Dixmier trace]].|date=December 2016}} The term weak trace-class, or weak-''L''<sub>1</sub>, is used because the operator ideal corresponds, in J. W. Calkin's [[Calkin correspondence|correspondence]] between two-sided ideals of bounded linear operators and rearrangement invariant sequence spaces, to the [[Lp space|weak-''l''<sub>1</sub> sequence space]].\n\n== Properties ==\n\n* the weak trace-class operators admit a [[quasinorm|quasi-norm]] defined by\n::::<math> \\| A \\|_{w} = \\sup_{n \\geq 0} (1+n)\\mu(n,A), </math>\n:making ''L''<sub>1,∞</sub> a quasi-Banach operator ideal, that is an ideal that is also a [[quasi-Banach space]].\n\n== See also ==\n\n* [[Lp space]]\n* [[Spectral triple]]\n* [[Singular trace]]\n* [[Dixmier trace]]\n\n== References ==\n{{reflist}}\n* {{cite book\n| isbn=978-0-82-183581-4\n| author= B. Simon\n| year=2005\n| title=Trace ideals and their applications\n| publisher=Amer. Math. Soc.\n| location=Providence, RI }}\n* {{cite book\n| isbn=978-0-52-132532-5\n| author= A. Pietsch\n| year=1987\n| title=Eigenvalues and s-numbers\n| publisher=Cambridge University Press\n| location=Cambridge, UK }}\n*{{cite book\n| author=A. Connes\n| title=Noncommutative geometry\n| url=http://www.alainconnes.org/docs/book94bigpdf.pdf\n| publisher=Academic Press\n| location=Boston, MA\n| isbn=978-0-12-185860-5\n| year=1994 }}\n* {{cite book\n| isbn=978-3-11-026255-1\n| author= S. Lord, F. A. Sukochev. D. Zanin\n| year=2012\n| url=http://www.degruyter.com/view/product/177778\n| title=Singular traces: theory and applications\n| publisher=De Gruyter\n| location=Berlin }}\n\n[[Category:Operator algebras]]\n[[Category:Hilbert space]]\n[[Category:Von Neumann algebras]]"
    },
    {
      "title": "Spectral graph theory",
      "url": "https://en.wikipedia.org/wiki/Spectral_graph_theory",
      "text": "In [[mathematics]], '''spectral [[graph theory]]''' is the study of the properties of a [[Graph (discrete mathematics)|graph]] in relationship to the [[characteristic polynomial]], [[eigenvalue]]s, and [[eigenvector]]s of matrices associated with the graph, such as its [[adjacency matrix]] or [[Laplacian matrix]].\n\nThe adjacency matrix of a [[undirected graph|simple graph]] is a [[Real number|real]] [[symmetric matrix]] and is therefore [[Orthogonal diagonalization|orthogonally diagonalizable]]; its eigenvalues are real [[algebraic integer]]s.\n\nWhile the adjacency matrix depends on the vertex labeling, its [[Spectrum of a matrix|spectrum]] is a [[graph invariant]], although not a complete one.\n\nSpectral graph theory is also concerned with graph parameters that are defined via multiplicities of eigenvalues of matrices associated to the graph, such as the [[Colin de Verdière graph invariant|Colin de Verdière number]].\n\n==Cospectral graphs==\nTwo graphs are called '''cospectral''' or '''[[isospectral]]''' if the adjacency matrices of the graphs have equal multisets of eigenvalues.\n\n[[File:Isospectral enneahedra.svg|thumb|300px|Two cospectral [[enneahedron|enneahedra]], the smallest possible cospectral [[polyhedral graph]]s]]\nCospectral graphs need not be [[Graph isomorphism|isomorphic]], but isomorphic graphs are always cospectral.\n\n=== Graphs determined by their spectrum ===\nA graph <math>G</math> is said to be determined by its spectrum if any other graph with the same spectrum as <math>G</math> is isomorphic to <math>G</math>.\n\nSome first examples of families of graphs that are determined by their spectrum include:\n* The [[complete graph]]s.\n* The finite [[starlike tree]]s.\n\n=== Cospectral mates ===\nA pair of graphs are said to be cospectral mates if they have the same spectrum, but are non-isomorphic.\n\nThe smallest pair of cospectral mates is {''K''<sub>1,4</sub>, ''C''<sub>4</sub> U ''K''<sub>1</sub>}, comprising the 5-vertex [[star (graph theory)|star]] and the [[graph union]] of the 4-vertex [[cycle (graph theory)|cycle]] and the single-vertex graph, as reported by Collatz and Sinogowitz<ref>Collatz, L. and Sinogowitz, U. \"Spektren endlicher Grafen.\" Abh. Math. Sem. Univ. Hamburg 21, 63&#x2013;77, 1957.</ref><ref>{{mathworld|CospectralGraphs|Cospectral Graphs}}</ref> in 1957.\n\nThe smallest pair of [[polyhedral graph|polyhedral]] cospectral mates are [[enneahedron|enneahedra]] with eight vertices each.<ref>{{citation|title=Topological twin graphs. Smallest pair of isospectral polyhedral graphs with eight vertices|year=1994|last1=Hosoya|last2=Nagashima|last3=Hyugaji|first1=Haruo|first2=Umpei|first3=Sachiko|author1-link=Haruo Hosoya|journal=Journal of Chemical Information and Modeling|volume=34|issue=2|pages=428–431|doi=10.1021/ci00018a033}}.</ref>\n\n=== Finding cospectral graphs ===\n[[Almost all]] [[tree (graph theory)|tree]]s are cospectral, i.e., as the number of vertices grows, the fraction of trees for which there exists a cospectral tree goes to 1.<ref>[[A. J. Schwenk|Schwenk, A. J.]] \"Almost All Trees are Cospectral\"  In:\n''New Directions in the Theory of Graphs'' (F. Harary, Ed.), Academic Press, New York, 1973, pp. 275&#x2013;307.</ref>\n\nA pair of [[regular graph]]s are cospectral if and only if their complements are cospectral.<ref>{{Cite web|url=http://www.math.uwaterloo.ca/~cgodsil/pdfs/cospectral.pdf|title=Are Almost All Graphs Cospectral?|last=Godsil|first=Chris|date=November 7, 2007|website=|archive-url=|archive-date=|dead-url=|access-date=}}</ref>\n\nA pair of [[distance-regular graph]]s are cospectral if and only if they have the same intersection array.\n\nCospectral graphs can also be constructed by means of the [[isospectral|Sunada method]].<ref>{{citation\n | last = Sunada | first = Toshikazu | journal = Ann. of Math.\n | pages = 169–186\n | title = Riemannian coverings and isospectral manifolds\n | volume = 121\n | year = 1985\n | doi = 10.2307/1971195 }}.</ref>\n\nAnother important source of cospectral graphs are the point-collinearity graphs and the line-intersection graphs of [[incidence geometry|point-line geometries]]. These graphs are always cospectral but are often non-isomorphic.<ref>{{cite web| first1=Andries |last1=Brouwer| first2 = Willem H. | last2 = Haemers| url=http://www.win.tue.nl/~aeb/2WF02/spectra.pdf |title=Spectra of Graphs |year=2011}}</ref>\n\n==Cheeger inequality==\nThe famous [[Cheeger constant#Cheeger.27s inequality|Cheeger's inequality]] from [[Riemannian geometry]] has a discrete analogue involving the Laplacian matrix; this is perhaps the most important theorem in spectral graph theory and one of the most useful facts in algorithmic applications. It approximates the sparsest cut of a graph through the second eigenvalue of its Laplacian.\n\n===Cheeger constant===\n{{main|Cheeger constant (graph theory)}}\nThe '''Cheeger constant''' (also '''Cheeger number''' or '''isoperimetric number''') of a [[Graph (discrete mathematics)|graph]] is a numerical measure of whether or not a graph has a \"bottleneck\". The Cheeger constant as a measure of \"bottleneckedness\" is of great interest in many areas: for example, constructing well-connected [[Computer networking|networks of computers]], [[Shuffling|card shuffling]], and [[Geometric topology|low-dimensional topology]] (in particular, the study of [[Hyperbolic geometry|hyperbolic]] 3-[[manifold]]s).\n\nMore formally, the Cheeger constant ''h''(''G'') of a graph ''G'' on ''n'' vertices is defined as\n: <math>h(G) = \\min_{0 < |S| \\le \\frac{n}{2} } \\frac{|\\partial(S)|}{|S|},</math>\nwhere the minimum is over all nonempty sets ''S'' of at most ''n''/2 vertices and ∂(''S'') is the ''edge boundary'' of ''S'', i.e., the set of edges with exactly one endpoint in ''S''.<ref>Definition 2.1 in {{harvtxt|Hoory|Linial|Widgerson|2006}}</ref>\n\n===Cheeger inequality===\nWhen the graph ''G'' is ''d''-regular, there is a relationship between ''h''(''G'') and the spectral gap ''d'' − λ<sub>2</sub> of ''G''. An inequality due to Dodziuk<ref>J.Dodziuk, Difference Equations, Isoperimetric inequality and Transience of Certain Random Walks, Trans. Amer. Math. Soc. 284 (1984), no. 2, 787-794.</ref> and independently [[Noga Alon|Alon]] and [[Vitali Milman|Milman]]{{Sfn|Alon|Spencer|2011}} states that<ref>Theorem 2.4 in {{harvtxt|Hoory|Linial|Widgerson|2006}}</ref>\n\n: <math>\\tfrac{1}{2}(d - \\lambda_2) \\le h(G) \\le \\sqrt{2d(d - \\lambda_2)}.</math>\n\nThis inequality is closely related to the [[Cheeger bound]] for [[Markov chains]] and can be seen as a discrete version of [[Cheeger constant#Cheeger.27s inequality|Cheeger's inequality]] in [[Riemannian geometry]].\n\n== Hoffman-Delsarte inequality ==\nThere is an eigenvalue bound for [[Independent set (graph theory)|independent sets]] in [[regular graph]]s, originally due to [[Alan J. Hoffman]] and Philippe Delsarte.<ref>{{Cite web|url=https://www.math.uwaterloo.ca/~cgodsil/pdfs/ekrs-clg.pdf|title=Erdős-Ko-Rado Theorems|last=Godsil|first=Chris|date=May 2009|website=|archive-url=|archive-date=|dead-url=|access-date=}}</ref>\n\nSuppose that <math>G</math> is a <math>k</math>-regular graph on <math>n</math> vertices with least eigenvalue <math>\\lambda_{\\mathrm{min}}</math>. Then:<math display=\"block\">\\alpha(G) \\leq \\frac{n}{1 - \\frac{k}{\\lambda_{\\mathrm{min}}}}</math>where <math>\\alpha(G)</math> denotes its [[independence number]].\n\nThis bound has been applied to establish e.g. algebraic proofs of the [[Erdős–Ko–Rado theorem]] and its analogue for intersecting families of subspaces over [[finite field]]s.<ref>{{Cite book|url=https://www.worldcat.org/oclc/935456305|title=Erdős-Ko-Rado theorems : algebraic approaches|last=1949-|first=Godsil, C. D. (Christopher David)|others=Meagher, Karen (College teacher),|isbn=9781107128446|location=Cambridge, United Kingdom|oclc=935456305}}</ref>\n\n==Historical outline==\nSpectral graph theory emerged in the 1950s and 1960s. Besides [[graph theory|graph theoretic]] research on the relationship between structural and spectral properties of graphs, another major source was research in [[quantum chemistry]], but the connections between these two lines of work were not discovered until much later.<ref name= cvet2>''Eigenspaces of Graphs'', by [[Dragoš Cvetković]], Peter Rowlinson, Slobodan Simić (1997) {{isbn|0-521-57352-1}}</ref> The 1980 monograph ''Spectra of Graphs''<ref>Dragoš M. Cvetković, Michael Doob, [[Horst Sachs]], ''Spectra of Graphs'' (1980)</ref> by Cvetković, Doob, and Sachs summarised nearly all research to date in the area. In 1988 it was updated by the survey ''Recent Results in the Theory of Graph Spectra''.<ref>{{cite book|first1=Dragoš M.|last1=Cvetković |first2=Michael |last2=Doob |first3=Ivan |last3=Gutman |first4=A. |last4=Torgasev |title=Recent Results in the Theory of Graph Spectra |series=Annals of Discrete mathematics |number=36 |year=1988 |isbn=0-444-70361-6 |url=http://www.sciencedirect.com/science/bookseries/01675060/36}}</ref> The 3rd edition of ''Spectra of Graphs'' (1995) contains a summary of the further recent contributions to the subject.<ref name= cvet2/> Discrete geometric analysis created and developed by [[Toshikazu Sunada]] in the 2000s deals with spectral graph theory in terms of discrete Laplacians associated with weighted graphs,<ref>{{citation | last = Sunada | first = Toshikazu | journal = Proceedings of Symposia in Pure Mathematics | pages = 51–86 | title =  Discrete geometric analysis | volume = 77 | year = 2008}}.</ref> and finds application in various fields, including [[Spectral shape analysis|shape analysis]]. In most recent years, the spectral graph theory has expanded to vertex-varying graphs often encountered in many real-life applications.<ref>{{Cite journal|last=Shuman|first=David I|last2=Ricaud|first2=Benjamin|last3=Vandergheynst|first3=Pierre|date=March 2016|title=Vertex-frequency analysis on graphs|url=https://linkinghub.elsevier.com/retrieve/pii/S1063520315000214|journal=Applied and Computational Harmonic Analysis|volume=40|issue=2|pages=260–291|doi=10.1016/j.acha.2015.02.005|issn=1063-5203|arxiv=1307.5708}}</ref><ref>{{Cite journal|last=Stankovic|first=Ljubisa|last2=Dakovic|first2=Milos|last3=Sejdic|first3=Ervin|date=July 2017|title=Vertex-Frequency Analysis: A Way to Localize Graph Spectral Components [Lecture Notes]|url=https://ieeexplore.ieee.org/document/7974871/?reload=true|journal=IEEE Signal Processing Magazine|language=en-US|volume=34|issue=4|pages=176–182|doi=10.1109/msp.2017.2696572|issn=1053-5888}}</ref><ref>{{Cite journal|last=Sakiyama|first=Akie|last2=Watanabe|first2=Kana|last3=Tanaka|first3=Yuichi|date=September 2016|title=Spectral Graph Wavelets and Filter Banks With Low Approximation Error|url=https://ieeexplore.ieee.org/document/7492192/?reload=true|journal=IEEE Transactions on Signal and Information Processing over Networks|language=en-US|volume=2|issue=3|pages=230–245|doi=10.1109/tsipn.2016.2581303|issn=2373-776X}}</ref><ref>{{Cite journal|last=Behjat|first=Hamid|last2=Richter|first2=Ulrike|last3=Van De Ville|first3=Dimitri|last4=Sornmo|first4=Leif|date=2016-11-15|title=Signal-Adapted Tight Frames on Graphs|url=https://ieeexplore.ieee.org/document/7513383/?reload=true|journal=IEEE Transactions on Signal Processing|language=en-US|volume=64|issue=22|pages=6017–6029|doi=10.1109/tsp.2016.2591513|issn=1053-587X}}</ref>\n\n==See also==\n* [[Strongly regular graph]]\n* [[Algebraic connectivity]]\n* [[Algebraic graph theory]]\n* [[Spectral clustering]]\n* [[Spectral shape analysis]]\n* [[Estrada index]]\n* [[Lovász theta]]\n* [[Expander graph]]\n\n==References==\n{{reflist}}\n\n==External links==\n* {{cite web| first1=Andries |last1=Brouwer| first2 = Willem H. | last2 = Haemers| author-link = Andries Brouwer| url=http://www.win.tue.nl/~aeb/2WF02/spectra.pdf |title=Spectra of Graphs |year=2011}} \n* {{cite book|first1=Fan|last1=Chung|url=http://www.math.ucsd.edu/~fan/research/revised.html |title=Spectral Graph theory|mr=1421568}} [first 4 chapters are available]\n* {{cite web| first1=Daniel |last1=Spielman | url=http://www.cs.yale.edu/~spielman/PAPERS/SGTChapter.pdf |title=Spectral Graph Theory |year=2011}} [chapter from Combinatorial Scientific Computing]\n* {{cite web| first1=Daniel |last1=Spielman |url=http://cs-www.cs.yale.edu/homes/spielman/sgta/ |title=Spectral Graph Theory and its Applications |year=2007}} [presented at FOCS 2007 Conference]\n* {{cite web| first1=Daniel |last1=Spielman | url=http://www.cs.yale.edu/homes/spielman/eigs/ |title=Spectral Graph Theory and its Applications |year=2004}} [course page and lecture notes]\n\n{{DEFAULTSORT:Spectral Graph Theory}}\n[[Category:Algebraic graph theory|*]]\n[[Category:Spectral theory|*]]"
    },
    {
      "title": "Spectral theory",
      "url": "https://en.wikipedia.org/wiki/Spectral_theory",
      "text": "In [[mathematics]], '''spectral theory''' is an inclusive term for theories extending the [[eigenvector]] and [[eigenvalue]] theory of a single [[square matrix]] to a much broader theory of the structure of [[operator (mathematics)|operator]]s in a variety of [[mathematical space]]s.<ref name=\"Dieudonné\">{{cite book |title=History of functional analysis |author=Jean Alexandre Dieudonné |url=https://books.google.com/books?id=mg7r4acKgq0C&printsec=frontcover |isbn=0-444-86148-3 |year=1981 |publisher=Elsevier}}</ref> It is a result of studies of [[linear algebra]] and the solutions of [[System of linear equations|systems of linear equations]] and their generalizations.<ref name=Arveson>{{cite book |title=A short course on spectral theory |author=William Arveson |chapter=Chapter 1: spectral theory and Banach algebras |url =https://books.google.com/books?id=ARdehHGWV1QC |isbn=0-387-95300-0 |year=2002 |publisher=Springer}}</ref> The theory is connected to that of [[analytic functions]] because the spectral properties of an operator are related to analytic functions of the spectral parameter.<ref name=\"Sadovnichiĭ\">{{cite book |title=Theory of Operators |author=Viktor Antonovich Sadovnichiĭ |chapter=Chapter 4: The geometry of Hilbert space: the spectral theory of operators |url=https://books.google.com/books?id=SR1QkG6OkVEC&pg=PA181&lpg=PA181 |page= 181 ''et seq'' |isbn=0-306-11028-8 |year=1991 |publisher=Springer}}\n</ref>\n\n==Mathematical background==\nThe name ''spectral theory'' was introduced by [[David Hilbert]] in his original formulation of [[Hilbert space]] theory, which was cast in terms of [[quadratic form]]s in infinitely many variables. The original [[spectral theorem]] was therefore conceived as a version of the theorem on [[Principal axis theorem|principal axes]] of an [[ellipsoid]], in an infinite-dimensional setting. The later discovery in [[quantum mechanics]] that spectral theory could explain features of [[Emission spectrum|atomic spectra]] was therefore fortuitous. Hilbert himself was surprised by the unexpected application of this theory, noting that \"I developed my theory of infinitely many variables from purely mathematical interests, and even called it 'spectral analysis' without any presentiment that it would later find application to the actual spectrum of physics.\"<ref>{{cite web|last1=Steen|first1=Lynn Arthur|title=Highlights in the History of Spectral Theory|url=http://www.stolaf.edu/people/steen/Papers/73spectral.pdf|website=St. Olaf College|publisher=St. Olaf College|accessdate=14 December 2015|deadurl=yes|archiveurl=https://web.archive.org/web/20160304050120/http://www.stolaf.edu/people/steen/Papers/73spectral.pdf|archivedate=4 March 2016|df=}}</ref>\n\nThere have been three main ways to formulate spectral theory, all of which retain their usefulness.{{clarify|reason=What are these three ways?|date=May 2015}} After Hilbert's initial formulation, the later development of abstract [[Hilbert space]] and the spectral theory of a single [[normal operator]] on it did very much go in parallel with the requirements of [[physics]]; particularly in the hands of [[John von Neumann|von Neumann]].<ref name= vonNeumann>\n\n{{Cite book |title=The mathematical foundations of quantum mechanics; ''Volume 2 in Princeton'' Landmarks in Mathematics ''series'' |author=John von Neumann |url=https://books.google.com/books?id=JLyCo3RO4qUC&printsec=frontcover&dq=mathematical+foundations+of+quantum+mechanics+inauthor:von+inauthor:neumann&cd=1#v=onepage&q=&f=false |isbn=0-691-02893-1 |year=1996 |publisher =Princeton University Press |edition=Reprint of translation of original 1932 }}\n\n</ref> The further theory built on this to include [[Banach algebra]]s, which can be given abstractly. This development leads to the [[Gelfand representation]], which covers the [[commutative Banach algebra|commutative case]], and further into [[non-commutative harmonic analysis]].\n\nThe difference can be seen in making the connection with [[Fourier analysis]]. The [[Fourier transform]] on the [[real line]] is in one sense the spectral theory of [[derivative|differentiation]] ''qua'' [[differential operator]]. But for that to cover the phenomena one has already to deal with [[generalized eigenfunction]]s (for example, by means of a [[rigged Hilbert space]]). On the other hand it is simple to construct a [[group algebra]], the spectrum of which captures the Fourier transform's basic properties, and this is carried out by means of [[Pontryagin duality]].\n\nOne can also study the spectral properties of operators on [[Banach spaces]]. For example, [[compact operator]]s on Banach spaces have many spectral properties similar to that of [[Matrix (mathematics)|matrices]].\n\n==Physical background==\nThe background in the physics of [[vibration]]s has been explained in this way:<ref name=Davies>[[E. Brian Davies]], quoted on the King's College London analysis group website {{Cite web |url=http://www.kcl.ac.uk/schools/pse/maths/research/analysis/research.html |title=Research at the analysis group}}</ref>\n\n{{Cquote|Spectral theory is connected with the investigation of localized vibrations of a variety of different objects, from [[atom]]s and [[molecule]]s in [[chemistry]] to obstacles in [[Waveguide (acoustics)|acoustic waveguide]]s. These vibrations have [[frequency|frequencies]], and the issue is to decide when such localized vibrations occur, and how to go about computing the frequencies. This is a very complicated problem since every object has not only a [[fundamental tone]] but also a complicated series of [[overtone]]s, which vary radically from one body to another.}}\n\nThe mathematical theory is not dependent on such physical ideas on a technical level, but there are examples of mutual influence (see for example [[Mark Kac]]'s question ''[[Can you hear the shape of a drum?]]''). Hilbert's adoption of the term \"spectrum\" has been attributed to an 1897 paper of [[Wilhelm Wirtinger]] on [[Hill differential equation]] (by [[Jean Dieudonné]]), and it was taken up by his students during the first decade of the twentieth century, among them [[Erhard Schmidt]] and [[Hermann Weyl]]. The conceptual basis for [[Hilbert space]] was developed from Hilbert's ideas by [[Erhard Schmidt]] and [[Frigyes Riesz]].<ref name=Young>{{Cite book |title=An introduction to Hilbert space |author=Nicholas Young |url=https://books.google.com/books?id=_igwFHKwcyYC&pg=PA3 |page=3 |isbn=0-521-33717-8 |publisher=Cambridge University Press |year=1988}}</ref><ref name=Dorier>{{Cite book |title=On the teaching of linear algebra; ''Vol. 23 of'' Mathematics education library |author=Jean-Luc Dorier |url=https://books.google.com/books?id=gqZUGMKtNuoC&pg=PA50&dq=%22thinking+geometrically+in+Hilbert%27s+%22&cd=1#v=onepage&q=%22thinking%20geometrically%20in%20Hilbert%27s%20%22&f=false |isbn=0-7923-6539-9 |publisher=Springer |year=2000 }}\n\n</ref>  It was almost twenty years later, when [[quantum mechanics]] was formulated in terms of the [[Schrödinger equation]], that the connection was made to [[atomic spectra]]; a connection with the mathematical physics of vibration had been suspected before, as remarked by [[Henri Poincaré]], but rejected for simple quantitative reasons, absent an explanation of the [[Balmer series]].<ref>Cf. [http://www.dm.unito.it/personalpages/capietto/Spectra.pdf Spectra in mathematics and in physics] {{webarchive|url=https://web.archive.org/web/20110727024805/http://www.dm.unito.it/personalpages/capietto/Spectra.pdf |date=2011-07-27 }} by Jean Mawhin, p.4 and pp. 10-11.</ref> The later discovery in quantum mechanics that spectral theory could explain features of atomic spectra was therefore fortuitous, rather than being an object of Hilbert's spectral theory.\n\n==A definition of spectrum==\n{{main article|Spectrum (functional analysis)}}\nConsider a [[Bounded linear operator|bounded linear transformation]] ''T'' defined everywhere over a general [[Banach space]]. We form the transformation:\n\n:<math> R_{\\zeta} = \\left( \\zeta I -  T \\right)^{-1}.</math>\n\nHere ''I'' is the [[identity operator]] and ζ is a [[complex number]]. The ''inverse'' of an operator ''T'', that is ''T''<sup>−1</sup>, is defined by:\n\n:<math>T T^{-1} = T^{-1} T = I. </math>\n\nIf the inverse exists, ''T'' is called ''regular''. If it does not exist, ''T'' is called ''singular''.\n\nWith these definitions, the ''[[resolvent set]]'' of ''T'' is the set of all complex numbers ζ such that ''R<sub>ζ</sub>'' exists and is [[Bounded operator|bounded]]. This set often is denoted as ''ρ(T)''. The ''spectrum'' of ''T'' is the set of all complex numbers ζ such that ''R<sub>ζ</sub>'' <u>fails</u> to exist or is unbounded. Often the spectrum of ''T'' is denoted by ''σ(T)''. The function ''R<sub>ζ</sub>'' for all ζ in ''ρ(T)'' (that is, wherever ''R<sub>ζ</sub>'' exists as a bounded operator) is called the [[Resolvent formalism|resolvent]] of ''T''. The ''spectrum'' of ''T'' is therefore the complement of the ''resolvent set'' of ''T'' in the complex plane.<ref name=Lorch>\n\n{{Cite book |title=Spectral Theory |author=Edgar Raymond Lorch |year=2003 |edition=Reprint of Oxford 1962 |page=89 |publisher=Textbook Publishers |isbn=0-7581-7156-0 |url=https://books.google.com/books?id=X3U2AAAACAAJ&dq=intitle:spectral+intitle:theory+inauthor:Lorch&cd=1}}</ref> Every [[eigenvalue]] of ''T'' belongs to ''σ(T)'', but ''σ(T)'' may contain non-eigenvalues.<ref name= Young2>{{cite book |title=''op. cit'' |author= Nicholas Young |url=https://books.google.com/books?id=_igwFHKwcyYC&pg=PA81 |page=81 |isbn=0-521-33717-8}}</ref>\n\nThis definition applies to a Banach space, but of course other types of space exist as well, for example, [[topological vector spaces]] include Banach spaces, but can be more general.<ref name=Wolff>{{Cite book |title=Topological vector spaces |author=Helmut H. Schaefer, Manfred P. H. Wolff |url=https://books.google.com/books?id=9kXY742pABoC&pg=PA36 |page=36 |year=1999 |isbn=0-387-98726-6 |edition=2nd |publisher=Springer}}</ref><ref name= Zhelobenko>\n\n{{Cite book |title=Principal structures and methods of representation theory |author=Dmitriĭ Petrovich Zhelobenko |url=https://books.google.com/books?id=3TkmvZktjp8C&pg=PA24 |isbn=\t0821837311 |publisher=American Mathematical Society |year=2006}}</ref> On the other hand, Banach spaces include [[Hilbert space]]s, and it is these spaces that find the greatest application and the richest theoretical results.<ref name=Lorch2>{{Cite book |title=''op. cit.'' |author=Edgar Raymond Lorch |year=2003 |isbn=0-7581-7156-0 |url=https://books.google.com/books?id=X3U2AAAACAAJ&dq=intitle:spectral+intitle:theory+inauthor:Lorch&cd=1 |page=57 |chapter=Chapter III: Hilbert Space}}</ref> With suitable restrictions, much can be said about the structure of the [[Hilbert space#Spectral theory|spectra of transformations]] in a Hilbert space. In particular, for [[self-adjoint operator]]s, the spectrum lies on the [[real line]] and (in general) is a [[Decomposition of spectrum (functional analysis)|spectral combination]] of a point spectrum of discrete [[Eigenvalues#Computation of eigenvalues.2C and the characteristic equation|eigenvalues]] and a [[continuous spectrum]].<ref name=Lorch3>{{Cite book |title=''op. cit.'' |author=Edgar Raymond Lorch |year=2003 |isbn=0-7581-7156-0 |url=https://books.google.com/books?id=X3U2AAAACAAJ&dq=intitle:spectral+intitle:theory+inauthor:Lorch&cd=1 |page=106 ''ff'' |chapter=Chapter V: The Structure of Self-Adjoint Transformations}}</ref>\n\n==Spectral theory briefly==\n{{Main article|Spectral theorem}}\n{{See also|Eigenvalue, eigenvector and eigenspace}}\nIn [[functional analysis]] and [[linear algebra]] the spectral theorem establishes conditions under which an operator can be expressed in simple form as a sum of simpler operators. As a full rigorous presentation is not appropriate for this article, we take an approach that avoids much of the rigor and satisfaction of a formal treatment with the aim of being more comprehensible to a non-specialist.\n\nThis topic is easiest to describe by introducing the [[bra–ket notation]] of [[Paul Dirac|Dirac]] for operators.<ref name= Friedman>{{Cite book |title=Principles and Techniques of Applied Mathematics |author=Bernard Friedman |year=1990 |publisher=Dover Publications |page=26 |isbn=0-486-66444-9 |url=https://books.google.com/books?id=gnQeAQAAIAAJ&dq=intitle:applied+intitle:mathematics+inauthor:Friedman&cd=1 |edition=Reprint of 1956 Wiley}}</ref><ref name=Dirac>{{Cite book |title=The principles of quantum mechanics |author=PAM Dirac |edition=4th |isbn=0-19-852011-5 |publisher=Oxford University Press |year=1981 |page=29 ''ff'' |url=https://books.google.com/books?id=XehUpGiM6FIC&pg=PA29}}</ref> As an example, a very particular linear operator ''L'' might be written as a [[dyadic product]]:<ref name=Audretsch>{{Cite book |title=Entangled systems: new directions in quantum physics |author=Jürgen Audretsch |page=5 |url=https://books.google.com/books?id=8NxIgwAOU6IC&pg=PA5 |chapter=Chapter 1.1.2: Linear operators on the Hilbert space |isbn=3-527-40684-0 |publisher=Wiley-VCH |year=2007}}</ref><ref name=Howland>{{Cite book |title=Intermediate dynamics: a linear algebraic approach |url=https://books.google.com/books?id=SepP8-W3M0AC&pg=PA69&dq=dyad+representation+operator&cd=32#v=onepage&q=dyad%20representation%20operator&f=false |page=69 ''ff'' |author=R. A. Howland |publisher=Birkhäuser |year=2006 |isbn=0-387-28059-6 |edition=2nd}}</ref>\n\n:<math> L = | k_1 \\rangle \\langle b_1 |, </math>\n\nin terms of the \"bra\"  ⟨{{mvar|b}}<sub>1</sub>|  and the \"ket\"  |{{mvar|k}}<sub>1</sub>⟩. A function {{mvar|f}} is described by a ''ket'' as |{{mvar|f}} ⟩. The function {{math|''f''(''x'')}} defined on the coordinates <math>(x_1, x_2, x_3, \\dots)</math> is denoted as\n:<math> f(x)=\\langle x, f\\rangle </math>\nand the magnitude of ''f'' by\n:<math> \\|f \\|^2 = \\langle f, f\\rangle =\\int \\langle f, x\\rangle \\langle x, f \\rangle \\, dx = \\int f^*(x) f(x) \\, dx </math>\nwhere the notation '*' denotes a [[complex conjugate]]. This [[inner product]] choice defines a very specific [[inner product space]], restricting the generality of the arguments that follow.<ref name=Lorch2/>\n\nThe effect of ''L'' upon a function ''f'' is then described as:\n\n:<math> L | f\\rangle = | k_1 \\rangle \\langle b_1 | f \\rangle </math>\n\nexpressing the result that the effect of ''L'' on ''f'' is to produce a new function <math> | k_1 \\rangle </math> multiplied by the inner product represented by <math>\\langle b_1 | f \\rangle </math>.\n \nA more general linear operator ''L'' might be expressed as:\n\n:<math> L = \\lambda_1 | e_1\\rangle\\langle f_1| +  \\lambda_2 | e_2\\rangle \\langle f_2| +   \\lambda_3 | e_3\\rangle\\langle f_3| + \\dots , </math>\n\nwhere the <math> \\{ \\, \\lambda_i \\, \\}</math> are scalars and the <math> \\{ \\, | e_i \\rangle \\, \\} </math> are a [[Basis (linear algebra)|basis]] and the <math> \\{ \\, \\langle f_i | \\, \\} </math> a [[Dual basis|reciprocal basis]] for the space. The relation between the basis and the reciprocal basis is described, in part, by:\n\n:<math> \\langle f_i | e_j \\rangle = \\delta_{ij} </math>\n\nIf such a formalism applies, the <math> \\{ \\, \\lambda_i \\, \\}</math> are [[eigenvalues]] of ''L'' and the functions <math> \\{ \\, | e_i \\rangle \\, \\} </math> are [[eigenfunctions]] of ''L''. The eigenvalues are in the ''spectrum'' of ''L''.<ref name= Friedman2>{{Cite book |title=op. cit. |author=Bernard Friedman |year=1990 |page=57 |chapter=Chapter 2: Spectral theory of operators |isbn=0-486-66444-9 |url=https://books.google.com/books?id=gnQeAQAAIAAJ&dq=intitle:applied+intitle:mathematics+inauthor:Friedman&cd=1}}</ref>\n\nSome natural questions are: under what circumstances does this formalism work, and for what operators ''L'' are expansions in series of other operators like this possible? Can any function ''f'' be expressed in terms of the eigenfunctions (are they a [[Schauder basis]]) and under what circumstances does a point spectrum or a continuous spectrum arise? How do the formalisms for infinite-dimensional spaces and finite-dimensional spaces differ, or do they differ? Can these ideas be extended to a broader class of spaces? Answering such questions is the realm of spectral theory and requires considerable background in [[functional analysis]] and [[Matrix (mathematics)|matrix algebra]].\n\n==Resolution of the identity==\n{{See also |Borel functional calculus#Resolution of the identity}}\n\nThis section continues in the rough and ready manner of the above section using the bra–ket notation, and glossing over the many important details of a rigorous treatment.<ref name=\"Vujičić\">\n\nSee discussion in Dirac's book referred to above, and {{Cite book |title=Linear algebra thoroughly explained |author=Milan Vujičić |url= https://books.google.com/books?id=pifStNLaXGkC&pg=PA274 |page=274 |isbn=3-540-74637-4 |year=2008 |publisher=Springer }}</ref> A rigorous mathematical treatment may be found in various references.<ref name=rigor>See, for example, the fundamental text of {{Cite book |title=''op. cit'' |author=John von Neumann |url=https://books.google.com/books?id=JLyCo3RO4qUC&printsec=frontcover|isbn=0-691-02893-1 }} and {{Cite book\n|title=Linear Operator Theory in Engineering and Science; ''Vol. 40 of'' Applied mathematical science  |page=401 |url=https://books.google.com/books?id=t3SXs4-KrE0C&pg=PA401 |author=Arch W. Naylor, George R. Sell |isbn=0-387-95001-X |publisher=Springer |year=2000}}, {{Cite book\n|title=Advanced linear algebra |author=Steven Roman |url=https://books.google.com/books?id=bSyQr-wUys8C&pg=PA233 |isbn=0-387-72828-7 |edition=3rd |year=2008 |publisher=Springer}}, {{Cite book |title=Expansions in eigenfunctions of selfadjoint operators; ''Vol. 17 in'' Translations of mathematical monographs |url=https://books.google.com/books?id=OPPWBE3WQqkC&pg=PA317 |author=I︠U︡riĭ Makarovich Berezanskiĭ |isbn=0-8218-1567-9 |year=1968 |publisher=American Mathematical Society}}</ref> In particular, the dimension ''n'' of the space will be finite.\n\nUsing the bra–ket notation of the above section, the identity operator may be written as:\n\n:<math>I = \\sum _{i=1} ^{n} | e_i \\rangle \\langle f_i |  </math>\n\nwhere it is supposed as above that {&nbsp;<math>|e_i\\rangle</math>&nbsp;} are a [[Basis (linear algebra)|basis]] and the {&nbsp;<math> \\langle f_i |</math>&nbsp;} a reciprocal basis for the space satisfying the relation:\n\n:<math>\\langle f_i | e_j\\rangle = \\delta_{ij} . </math>\n\nThis expression of the identity operation is called a ''representation'' or a ''resolution'' of the identity.<ref name= \"Vujičić\"/><sup>,</sup><ref name= rigor/> This formal representation satisfies the basic property of the identity:\n\n:<math> I^k = I\\, </math>\n\nvalid for every positive integer ''k''.\n\nApplying the resolution of the identity to any function in the space ''<math>| \\psi \\rangle</math>'', one obtains:\n\n:<math>I |\\psi \\rangle = |\\psi \\rangle = \\sum_{i=1}^{n} | e_i \\rangle \\langle f_i | \\psi \\rangle =  \\sum_{i=1}^{n} \\ c_i | e_i \\rangle  </math>\n\nwhich is the generalized [[Fourier series|Fourier expansion]] of ψ in terms of the basis functions {&nbsp;e<sub>i</sub>&nbsp;}.<ref name=Folland>\n\nSee for example, {{cite book |author=Gerald B Folland |title=Fourier Analysis and its Applications |publisher=American Mathematical Society |edition=Reprint of  Wadsworth & Brooks/Cole 1992 |url=https://books.google.com/books?id=idAomhpwI8MC&pg=PA77 |pages = 77 ''ff'' |chapter=Convergence and completeness |year=2009 |isbn=0-8218-4790-2}}\n\n</ref>\nHere ''<math>c_i = \\langle f_i | \\psi \\rangle</math>''.\n\nGiven some operator equation of the form:\n\n:<math>O | \\psi \\rangle = | h \\rangle  </math>\n\nwith ''h'' in the space, this equation can be solved in the above basis through the formal manipulations:\n\n:<math> O | \\psi \\rangle = \\sum_{i=1}^{n} c_i \\left( O | e_i \\rangle \\right)  =  \\sum_{i=1}^{n} | e_i \\rangle \\langle f_i |  h \\rangle , </math>\n\n:<math>\\langle f_j|O| \\psi \\rangle = \\sum_{i=1}^{n}  c_i \\langle f_j| O | e_i \\rangle  =  \\sum_{i=1}^{n} \\langle f_j| e_i \\rangle \\langle f_i | h \\rangle  = \\langle f_j |  h \\rangle, \\quad \\forall j </math>\n\nwhich converts the operator equation to a [[matrix equation]] determining the unknown coefficients ''c<sub>j</sub>'' in terms of the generalized Fourier coefficients <math>\\langle f_j | h \\rangle</math> of ''h'' and the matrix elements <math>O_{ji}= \\langle f_j| O | e_i \\rangle </math> of the operator ''O''.\n\nThe role of spectral theory arises in establishing the nature and existence of the basis and the reciprocal basis. In particular, the basis might consist of the eigenfunctions of some linear operator ''L'':\n\n:<math>L | e_i \\rangle = \\lambda_i | e_i \\rangle \\, ; </math>\n\nwith the {&nbsp;''λ<sub>i</sub>''&nbsp;} the eigenvalues of ''L'' from the spectrum of ''L''. Then the resolution of the identity above provides the dyad expansion of ''L'':\n\n:<math>LI = L = \\sum_{i=1}^{n} L | e_i \\rangle \\langle f_i|  = \\sum_{i=1}^{n} \\lambda _i | e_i \\rangle \\langle f_i | . </math>\n\n==Resolvent operator==\n{{main article|Resolvent formalism}}\n{{See also|Green's function|Dirac delta function}}\nUsing spectral theory, the resolvent operator ''R'':\n\n:<math>R =  (\\lambda I - L)^{-1},\\, </math>\n\ncan be evaluated  in terms of the eigenfunctions and eigenvalues of ''L'', and the Green's function corresponding to ''L'' can be found.\n\nApplying ''R'' to some arbitrary function in the space, say <math>\\varphi</math>,\n\n:<math>R  |\\varphi \\rangle = (\\lambda I - L)^{-1} |\\varphi \\rangle = \\sum_{i=1}^n \\frac{1}{\\lambda- \\lambda_i} |e_i \\rangle \\langle f_i | \\varphi \\rangle. </math>\n\nThis function has [[Pole (complex analysis)|poles]] in the complex ''λ''-plane at each eigenvalue of ''L''. Thus, using the [[calculus of residues]]:\n\n:<math>\\frac{1}{2\\pi i } \\oint_C R  |\\varphi \\rangle d \\lambda = -\\sum_{i=1}^n |e_i \\rangle   \\langle f_i | \\varphi \\rangle  = -|\\varphi \\rangle,</math>\n\nwhere the [[line integral]] is over a contour ''C'' that includes all the eigenvalues of ''L''.\n\nSuppose our functions are defined over some coordinates {''x<sub>j</sub>''}, that is:\n\n:<math>\\langle x, \\varphi \\rangle = \\varphi (x_1, x_2, ...). </math>\n\nIntroducing the notation\n\n:<math> \\langle x , y \\rangle = \\delta (x-y), </math>\n\nwhere ''δ(x − y)'' = ''δ(x<sub>1</sub> − y<sub>1</sub>, x<sub>2</sub> − y<sub>2</sub>, x<sub>3</sub> − y<sub>3</sub>,  ...)'' is the [[Dirac delta function]],<ref name=Dirac3>{{cite book |url=https://books.google.com/books?id=XehUpGiM6FIC&pg=PA60#v=onepage&q=&f=false |page=60 ''ff'' |author=PAM Dirac |title=''op. cit'' |isbn=0-19-852011-5}}</ref>\nwe can write\n\n:<math>\\langle x, \\varphi \\rangle = \\int \\langle x , y \\rangle \\langle y, \\varphi \\rangle dy. </math>\n\nThen:\n\n:<math>\\begin{align}\n\\left\\langle x, \\frac{1}{2\\pi i } \\oint_C \\frac{\\varphi}{\\lambda I - L} d \\lambda\\right\\rangle &= \\frac{1}{2\\pi i }\\oint_C d \\lambda \\left \\langle x, \\frac{\\varphi}{\\lambda I - L} \\right \\rangle\\\\\n&= \\frac{1}{2\\pi i } \\oint_C d \\lambda \\int dy \\left \\langle x,  \\frac{y}{\\lambda I - L} \\right \\rangle  \\langle y, \\varphi \\rangle\n\\end{align}</math>\n\nThe function ''G(x, y; λ)'' defined by:\n\n:<math>\\begin{align}\nG(x, y; \\lambda) &= \\left \\langle x, \\frac{y}{\\lambda I - L} \\right \\rangle \\\\\n&= \\sum_{i=1}^n \\sum_{j=1}^n \\langle x, e_i \\rangle \\left \\langle f_i, \\frac{e_j}{\\lambda I - L} \\right \\rangle \\langle f_j , y\\rangle \\\\\n&= \\sum_{i=1}^n \\frac{\\langle x,  e_i \\rangle \\langle f_i , y\\rangle }{\\lambda  - \\lambda_i} \\\\\n&= \\sum_{i=1}^n \\frac{e_i (x) f_i^*(y) }{\\lambda  - \\lambda_i},\n\\end{align}</math>\n\nis called the ''[[Green's function]]'' for operator ''L'', and satisfies:<ref name=Friedman3>{{cite book |title=''op. cit'' |page=214, Eq. 2.14 |author=Bernard Friedman |isbn=0-486-66444-9 |url=https://books.google.com/books?id=gnQeAQAAIAAJ&dq=intitle:applied+intitle:mathematics+inauthor:Friedman&cd=1 }}</ref>\n\n:<math>\\frac{1}{2\\pi i }\\oint_C G(x,y;\\lambda)  d \\lambda = -\\sum_{i=1}^n  \\langle x, e_i \\rangle \\langle f_i , y\\rangle = -\\langle x, y\\rangle = -\\delta (x-y). </math>\n\n==Operator equations==\n{{See also|Spectral theory of ordinary differential equations|Integral equation}}\nConsider the operator equation:\n\n:<math>(O-\\lambda I ) |\\psi \\rangle = |h \\rangle; </math>\n\nin terms of coordinates:\n\n:<math>\\int \\langle x, (O-\\lambda I)y \\rangle \\langle y, \\psi \\rangle dy = h(x). </math>\n\nA particular case is λ = 0.\n\nThe Green's function of the previous section is:\n\n:<math>\\langle y, G(\\lambda) z\\rangle = \\left \\langle y, (O-\\lambda I)^{-1} z \\right \\rangle = G(y, z; \\lambda),</math>\n\nand satisfies:\n\n:<math>\\int \\langle x, (O - \\lambda I) y \\rangle \\langle y, G(\\lambda) z \\rangle dy = \\int \\langle x, (O-\\lambda I) y \\rangle \\left \\langle y, (O-\\lambda I)^{-1} z \\right \\rangle dy = \\langle x , z \\rangle = \\delta (x-z).</math>\n\nUsing this Green's function property:\n\n:<math>\\int \\langle x, (O-\\lambda I) y \\rangle G(y, z; \\lambda ) dy = \\delta (x-z). </math>\n\nThen, multiplying both sides of this equation by ''h''(''z'') and integrating:\n\n:<math>\\int dz h(z) \\int dy \\langle x, (O-\\lambda I)y \\rangle G(y, z; \\lambda)=\\int dy \\langle x, (O-\\lambda I) y \\rangle \\int dz h(z)G(y, z; \\lambda) = h(x), </math>\n\nwhich suggests the solution is:\n\n:<math>\\psi(x) = \\int h(z) G(x, z; \\lambda) dz.</math>\n\nThat is, the function ψ(''x'') satisfying the operator equation is found if we can  find the spectrum of ''O'', and construct ''G'', for example by using:\n\n:<math>G(x, z; \\lambda)  = \\sum_{i=1}^n \\frac{e_i (x) f_i^*(z)}{\\lambda - \\lambda_i}.</math>\n\nThere are many other ways to find ''G'', of course.<ref name=Green>\n\nFor example, see {{cite book |title=Mathematical physics: a modern introduction to its foundations |author= Sadri Hassani |chapter=Chapter 20: Green's functions in one dimension |page=553 ''et seq'' |publisher=Springer |url=https://books.google.com/books?id=BCMLOp6DyFIC&pg=RA1-PA553 |year=1999 |isbn=0-387-98579-4}} and {{cite book |title=Green's function and boundary elements of multifield materials |author=Qing-Hua Qin |url=https://books.google.com/books?id=UUfy8CcJiDkC&printsec=frontcover|isbn=0-08-045134-9 |year=2007 |publisher=Elsevier}}</ref> See the articles on [[Green's function#Green.27s functions for solving inhomogeneous boundary value problems|Green's functions]] and on [[Fredholm theory#Inhomogeneous equations|Fredholm integral equations]]. It must be kept in mind that the above mathematics is purely formal, and a rigorous treatment involves some pretty sophisticated mathematics, including a good background knowledge of [[functional analysis]], [[Hilbert spaces]], [[Distribution (mathematics)|distributions]] and so forth. Consult these articles and the references for more detail.\n\n==Spectral theorem and Rayleigh quotient==\n[[Optimization problem]]s may be the most useful examples about the combinatorial significance of the eigenvalues and eigenvectors in symmetric matrices, especially for the [[Rayleigh quotient]] with respect to a matrix '''M'''.\n\n'''Theorem''' ''Let '''M''' be a symmetric matrix and let '''x''' be the non-zero vector that maximizes the [[Rayleigh quotient]] with respect to '''M'''. Then, '''x''' is an eigenvector of '''M''' with eigenvalue equal to the [[Rayleigh quotient]]. Moreover, this eigenvalue is the largest eigenvalue of '''M'''. ''\n\n'''Proof'''   Assume the spectral theorem. Let the eigenvalues of '''M''' be <math>\\lambda_1\\le\\lambda_2\\le\\cdots\\le\\lambda_n</math>. Since the '''{<math>v_i</math>}''' form an [[orthonormal basis]], any vector x can be expressed in this [[Basis (linear algebra)|basis]] as\n\n<math>x = \\sum_{i}\\ v_{i}^{T} x v_{i}</math>\n\nThe way to prove this formula is pretty easy. Namely,\n:<math> v_j^{T}\\sum_{i} v_i^{T} x v_i </math>\n:<math> = \\sum_{i} v_i^{T} x v_j^{T} v_i</math>\n:<math> = (v_j^{T} x ) v_j^{T} v_j</math>\n:<math> = v_j^{T} x</math>\nevaluate the [[Rayleigh quotient]] with respect to x:\n:<math>x^{T} M x</math>\n:<math>= (\\sum_{i} (v_i^{T} x) v_i)^{T} M (\\sum_{j} (v_j^{T} x) v_j)</math>\n:<math>= (\\sum_{i} (v_i^{T} x) v_i^{T}) (\\sum_{j} (v_j^{T} x) v_j\\lambda_j)</math>\n:<math>= \\sum_{i,j}  (v_i^{T} x) v_i^{T}(v_j^{T} x) v_j\\lambda_j</math>\n:<math>= \\sum_{j} (v_j^{T} x)(v_j^{T} x)\\lambda_j</math>\n:<math>= \\sum_{j} (v_j^{T} x)^2\\lambda_j\\le\\lambda_n \\sum_{j} (v_j^{T} x)^2</math>\n:<math>= \\lambda_n x^{T} x </math>,\nwhere we used [[Parseval's identity]] in the last line.\nFinally we obtain that \n:<math>\\frac{x^{T} M x}{x^{T} x}\\le \\lambda_n</math>\n\nso the [[Rayleigh quotient]] is always less than <math>\\lambda_n</math>.\n\n<ref>Spielman,Daniel A. \"Lecture Note of Spectral Graph Theory\" Yale University(2012) http://cs.yale.edu/homes/spielman/561/ .</ref>\n\n==See also==\n{{Portal|Mathematics}}\n* [[Spectrum (functional analysis)]], [[Resolvent formalism]], [[Decomposition of spectrum (functional analysis)]]\n* [[Spectral radius]], [[Spectrum of an operator]], [[Spectral theorem]]\n* [[Self-adjoint operator]], [[functional calculus|Functions of operators]], [[Operator theory]]\n* [[Sturm&ndash;Liouville theory]], [[Integral equation]]s, [[Fredholm theory]]\n* [[Compact operator]]s, [[Isospectral]] operators, [[complete metric space|Completeness]]\n* [[Lax pair]]s\n* [[Spectral geometry]]\n* [[Spectral graph theory]]\n* [[List of functional analysis topics]]\n\n==Notes==\n{{Reflist|2}}\n\n==References==\n\n* {{Cite book |title=Spectral Theory and Differential Operators; ''Volume 42 in the ''Cambridge Studies in Advanced Mathematics |author=Edward Brian Davies |publisher=Cambridge University Press |year=1996 |url=https://books.google.com/books?id=EXtKuJAksSUC&printsec=frontcover&dq=intitle:Spectral+intitle:Theory+intitle:and+intitle:Differential+intitle:Operators&cd=1#v=onepage&q=Spectral%20theory%20&f=false |isbn=0-521-58710-7 }}\n* {{Cite book |title=Linear Operators, Spectral Theory, Self Adjoint Operators in Hilbert Space (Part 2) |author= Nelson Dunford; Jacob T Schwartz |publisher=Wiley |year=1988 |url=https://books.google.com/books?id=eOFfQQAACAAJ&dq=isbn:0471608475&cd=1 |isbn=0-471-60847-5 |edition=Paperback reprint of 1967  }}\n*{{Cite book |title=Linear Operators, Spectral Operators (Part 3) |author= Nelson Dunford; Jacob T Schwartz |publisher=Wiley |year=1988 |isbn=0-471-60846-7 |url=https://books.google.com/books?id=B0SeJNIh3BwC&printsec=frontcover&dq=isbn:0471608467&cd=1#v=onepage&q=&f=false |edition=Paperback reprint of 1971}}\n* {{Cite book |title=Mathematical Physics: a Modern Introduction to its Foundations |author= Sadri Hassani |publisher=Springer |year=1999 |url=https://books.google.com/books?id=BCMLOp6DyFIC&pg=RA1-PA109#v=onepage&q=&f=false|chapter=Chapter 4: Spectral decomposition |isbn=0-387-98579-4   }}\n*{{Springer|id=S/s086520|title=Spectral theory of linear operators}}\n* {{Cite book |title=Spectral Theory of Banach Space Operators; |author=Shmuel Kantorovitz|year=1983 | publisher= Springer}}\n* {{Cite book |title=Linear Operator Theory in Engineering and Science; ''Volume 40 of Applied mathematical sciences'' |author=Arch W. Naylor, George R. Sell |page=411 |chapter=Chapter 5, Part B: The Spectrum |url=https://books.google.com/books?id=t3SXs4-KrE0C&pg=PA411&dq=%22resolution+of+the+identity%22&cd=8#v=onepage&q=%22resolution%20of%20the%20identity%22&f=false |isbn=0-387-95001-X |year=2000 |publisher=Springer}}\n* {{Cite book |title=Mathematical Methods in Quantum Mechanics; With Applications to Schrödinger Operators |author= Gerald Teschl |authorlink= Gerald Teschl |publisher= American Mathematical Society |year=2009 |url=http://www.mat.univie.ac.at/~gerald/ftp/book-schroe/ |isbn=978-0-8218-4660-5   }}\n* {{Cite book |title=Spectral Theory and Quantum Mechanics; Mathematical Foundations of Quantum Theories, Symmetries and Introduction to the Algebraic Formulation 2nd Edition |author= Valter Moretti |authorlink= Valter Moretti |publisher= Springer |year=2018 |url=https://www.springer.com/it/book/9783319707051|isbn=978-3-319-70705-1 }}\n\n==External links==\n*[http://www.mathphysics.com/opthy/OpHistory.html Evans M. Harrell II]: A Short History of Operator Theory\n*{{cite journal |doi=10.1006/hmat.1995.1025 |author=Gregory H. Moore |title= The axiomatization of linear algebra: 1875-1940 |journal=Historia Mathematica |year=1995 |volume=22 |pages=262–303}}\n\n{{Functional Analysis}}\n\n{{DEFAULTSORT:Spectral Theory}}\n[[Category:Linear algebra]]\n[[Category:Spectral theory|*]]\n\n[[de:Spektrum (Operatortheorie)]]"
    },
    {
      "title": "Transform theory",
      "url": "https://en.wikipedia.org/wiki/Transform_theory",
      "text": "In [[mathematics]], '''transform theory''' is the study of transforms, which relate a function in one domain to another function in a second domain. The essence of transform theory is that by a suitable choice of [[Basis (linear algebra)|basis]] for a [[vector space]] a problem may be simplified&mdash;or ''diagonalized'' as in [[spectral theory]].\n\n==Spectral theory==\n\nIn [[spectral theory]], the [[spectral theorem]] says that if ''A'' is an ''n''×''n'' [[self-adjoint]] matrix, there is an [[orthonormal basis]] of [[eigenvector]]s of ''A''. This implies that ''A'' is [[diagonalizable matrix|diagonalizable]].\n\nFurthermore, each [[eigenvalue]] is [[real number|real]].\n\n==Transforms==\n*[[Laplace transform]]\n*[[Fourier transform]]\n*[[Mellin transform]]\n*[[Hankel transform]]\n*[[Z-transform]]\n\n==References==\n\n*Keener, James P. 2000. ''Principles of Applied Mathematics: Transformation and Approximation''. Cambridge: Westview Press. {{isbn|0-7382-0129-4}}\n\n[[Category:Transforms|*]]\n[[Category:Spectral theory|*]]\n\n{{mathanalysis-stub}}"
    },
    {
      "title": "Almost Mathieu operator",
      "url": "https://en.wikipedia.org/wiki/Almost_Mathieu_operator",
      "text": "In [[mathematical physics]], the '''almost Mathieu operator'''<!--, named after [[?????? Mathieu]], --> arises in the study of the [[quantum Hall effect]]. It is given by\n: <math> [H^{\\lambda,\\alpha}_\\omega u](n) = u(n+1) + u(n-1) + 2 \\lambda \\cos(2\\pi (\\omega + n\\alpha)) u(n), \\, </math>\n\nacting as a [[self-adjoint operator]] on the Hilbert space <math>\\ell^2(\\mathbb{Z})</math>. Here <math>\\alpha,\\omega \\in\\mathbb{T}, \\lambda > 0</math> are parameters. In [[pure mathematics]], its importance comes from the fact of being one of the best-understood examples of an [[ergodic]] [[Schrödinger operator]].  For example, three problems (now all solved) of [[Barry Simon]]'s fifteen problems about Schrödinger operators \"for the twenty-first century\" featured the almost Mathieu operator.<ref>{{cite book |first=Barry |last=Simon |chapter=Schrödinger operators in the twenty-first century |title=Mathematical Physics 2000 |pages=283–288 |publisher=Imp. Coll. Press |location=London |year=2000 |isbn=978-1860942303 }}</ref>\n\nFor <math>\\lambda = 1</math>, the almost Mathieu operator is sometimes called '''Harper's equation'''.\n\n==The spectral type==\nIf <math>\\alpha</math> is a [[rational number]], then <math>H^{\\lambda,\\alpha}_\\omega</math>\nis a periodic operator and by [[Floquet theory]] its [[spectrum (functional analysis)|spectrum]] is purely [[absolutely continuous]].\n\nNow to the case when <math>\\alpha</math> is [[Irrational number|irrational]].\nSince the transformation <math> \\omega \\mapsto \\omega + \\alpha </math> is minimal, it follows that the spectrum of <math>H^{\\lambda,\\alpha}_\\omega</math> does not depend on <math> \\omega </math>. On the other hand, by ergodicity, the supports of absolutely continuous, singular continuous, and pure point parts of the spectrum are almost surely independent of <math> \\omega </math>.\nIt is now known, that\n*For <math>0 < \\lambda < 1</math>, <math>H^{\\lambda,\\alpha}_\\omega</math> has surely purely absolutely continuous spectrum.<ref>{{cite arxiv |first=A. |last=Avila |year=2008 |title=The absolutely continuous spectrum of the almost Mathieu operator |journal= |eprint=0810.2965|class=math.DS }}</ref> (This was one of Simon's problems.)\n*For <math>\\lambda= 1</math>, <math>H^{\\lambda,\\alpha}_\\omega</math> has almost surely purely singular continuous spectrum.<ref>{{cite journal |last=Gordon |first=A. Y. |last2=Jitomirskaya |first2=S. |last3=Last |first3=Y. |last4=Simon |first4=B. |title=Duality and singular continuous spectrum in the almost Mathieu equation |journal=[[Acta Mathematica|Acta Math.]] |volume=178 |year=1997 |issue=2 |pages=169–183 |doi=10.1007/BF02392693 }}</ref> (It is not known whether eigenvalues can exist for exceptional parameters.)\n*For <math>\\lambda > 1</math>, <math>H^{\\lambda,\\alpha}_\\omega</math> has almost surely pure point spectrum and exhibits [[Anderson localization]].<ref>{{cite journal |last=Jitomirskaya |first=Svetlana Ya. |title=Metal-insulator transition for the almost Mathieu operator |journal=[[Annals of Mathematics|Ann. of Math.]] |volume=150 |year=1999 |issue=3 |pages=1159–1175 |doi= 10.2307/121066|jstor=121066 |arxiv=math/9911265}}</ref> (It is known that almost surely can not be replaced by surely.)<ref>{{cite journal |first=J. |last=Avron |first2=B. |last2=Simon |title=Singular continuous spectrum for a class of almost periodic Jacobi matrices |journal=[[Bulletin of the American Mathematical Society|Bull. Amer. Math. Soc.]] |volume=6 |year=1982 |issue=1 |pages=81–85 |doi= 10.1090/s0273-0979-1982-14971-0|zbl=0491.47014 }}</ref><ref>{{cite journal |first=S. |last=Jitomirskaya |first2=B. |last2=Simon |title=Operators with singular continuous spectrum, III. Almost periodic Schrödinger operators |journal=[[Communications in Mathematical Physics|Comm. Math. Phys.]] |volume=165 |year=1994 |issue=1 |pages=201–205 |zbl=0830.34074 |doi=10.1007/bf02099743|bibcode=1994CMaPh.165..201J |url=http://www.math.caltech.edu/papers/bsimon/p235.pdf|citeseerx=10.1.1.31.4995 }}</ref>\n\nThat the spectral measures are singular when <math> \\lambda \\geq 1 </math> follows (through the work of Last and Simon)\n<ref>{{cite journal |first=Y. |last=Last |first2=B. |last2=Simon |title=Eigenfunctions, transfer matrices, and absolutely continuous spectrum of one-dimensional Schrödinger operators |journal=[[Inventiones Mathematicae|Invent. Math.]] |volume=135 |year=1999 |issue=2 |pages=329–367 |doi=10.1007/s002220050288 |arxiv=math-ph/9907023 |bibcode=1999InMat.135..329L }}</ref>\nfrom the lower bound on the [[Lyapunov exponent]] <math>\\gamma(E)</math> given by\n: <math> \\gamma(E) \\geq \\max \\{0,\\log(\\lambda)\\}. \\, </math>\n\nThis lower bound was proved independently by Avron, Simon and [[Michael Herman (mathematician)|Michael Herman]], after an earlier almost rigorous argument of Aubry and André.  In fact, when <math> E </math> belongs to the spectrum, the inequality becomes an equality (the Aubry–André formula), proved by [[Jean Bourgain]] and [[Svetlana Jitomirskaya]].<ref>{{cite journal |first=J. |last=Bourgain |first2=S. |last2=Jitomirskaya |title=Continuity of the Lyapunov exponent for quasiperiodic operators with analytic potential |journal=[[Journal of Statistical Physics]] |volume=108 |year=2002 |issue=5–6 |pages=1203–1218 |doi=10.1023/A:1019751801035 }}</ref>\n\n==The structure of the spectrum==\n[[Image:Hofstadter's_butterfly.png|thumb|Hofstadter's butterfly]]\n\nAnother striking characteristic of the almost Mathieu operator is that its spectrum is a [[Cantor set]] for all irrational <math>\\alpha</math> and <math>\\lambda > 0</math>. This was shown by [[Artur Avila|Avila]] and [[Svetlana Jitomirskaya|Jitomirskaya]] solving the by-then famous \"ten martini problem\"<ref>{{Cite book|first=A. |last=Avila |first2=S. |last2=Jitomirskaya |title=The Ten Martini problem |journal= |volume=690 |pages=5–16 |year=2005 |arxiv=math/0503363 |bibcode=2006LNP...690....5A |doi=10.1007/3-540-34273-7_2 |chapter=Solving the Ten Martini Problem |series=Lecture Notes in Physics |isbn=978-3-540-31026-6 }}</ref> (also one of Simon's problems) after several earlier results (including generically<ref>{{cite journal |first=J. |last=Bellissard |first2=B. |last2=Simon |title=Cantor spectrum for the almost Mathieu equation |journal=[[Journal of Functional Analysis|J. Funct. Anal.]] |volume=48 |year=1982 |issue=3 |pages=408–419 |doi=10.1016/0022-1236(82)90094-5 }}</ref> and almost surely<ref>{{cite journal |last=Puig |first=Joaquim |title=Cantor spectrum for the almost Mathieu operator |journal=Comm. Math. Phys. |volume=244 |year=2004 |issue=2 |pages=297–309 |doi=10.1007/s00220-003-0977-3 |arxiv=math-ph/0309004 |bibcode=2004CMaPh.244..297P }}</ref> with respect to the parameters).\n\nFurthermore, the [[Lebesgue measure]] of the spectrum of the almost Mathieu operator is known to be\n: <math> \\operatorname{Leb}(\\sigma(H^{\\lambda,\\alpha}_\\omega)) = |4 - 4 \\lambda| \\, </math>\n\nfor all <math>\\lambda > 0</math>. For <math> \\lambda = 1 </math> this means that the spectrum has zero measure (this was first proposed by [[Douglas Hofstadter]] and later became one of Simon's problems<ref>{{cite journal |first=A. |last=Avila |first2=R. |last2=Krikorian |title=Reducibility or non-uniform hyperbolicity for quasiperiodic Schrödinger cocycles |journal=[[Annals of Mathematics]] |volume=164 |year=2006 |issue=3 |pages=911–940 |doi=10.4007/annals.2006.164.911 |arxiv=math/0306382 }}</ref>). For <math> \\lambda \\neq 1 </math>, the formula was discovered numerically by Aubry and André and proved by Jitomirskaya and Krasovsky.\n\nThe study of the spectrum for <math> \\lambda =1 </math> leads to the [[Hofstadter's butterfly]], where the spectrum is shown as a set.\n\n==References==\n\n{{reflist|2}}\n\n[[Category:Spectral theory]]\n[[Category:Mathematical physics]]"
    },
    {
      "title": "Bauer–Fike theorem",
      "url": "https://en.wikipedia.org/wiki/Bauer%E2%80%93Fike_theorem",
      "text": "{{for|the theorem in algebraic number theory|Bauer's theorem}}\nIn [[mathematics]], the '''Bauer–Fike theorem''' is a standard result in the [[perturbation theory]] of the [[eigenvalue]] of a complex-valued [[diagonalizable|diagonalizable matrix]]. In its substance, it states an absolute upper bound for the deviation of one perturbed matrix eigenvalue from a properly chosen eigenvalue of the exact matrix. Informally speaking, what it says is that ''the sensitivity of the eigenvalues is estimated by the condition number of the matrix of eigenvectors''.\n\nThe theorem was proved by [[Friedrich L. Bauer]] and C. T. Fike in 1960.\n\n==The setup==\nIn what follows we assume that:\n* {{math|''A'' ∈ '''C'''<sup>''n'',''n''</sup>}} is a [[diagonalizable|diagonalizable matrix]];\n* {{math|''V'' ∈ '''C'''<sup>''n'',''n''</sup>}} is the non-singular [[eigenvector]] matrix such that {{math|''A'' {{=}} ''V''Λ''V''&thinsp;<sup>−1</sup>}}, where {{math|Λ}} is a diagonal matrix. \n* If {{math|''X'' ∈ '''C'''<sup>''n'',''n''</sup>}} is invertible, its [[condition number]] in [[matrix norm|{{mvar|p}}-norm]] is denoted by {{math|''κ<sub>p</sub>''(''X'')}} and defined by:\n::<math>\\kappa_p(X)=\\|X\\|_p \\left \\|X^{-1} \\right \\|_p.</math> \n\n==The Bauer–Fike Theorem==\n:'''Bauer–Fike Theorem.''' Let {{mvar|μ}} be an eigenvalue of {{math|''A'' + ''δA''}}. Then there exists {{math|''λ'' ∈ ''Λ''(''A'')}} such that:\n::<math>|\\lambda-\\mu| \\leq \\kappa_p (V) \\| \\delta A \\|_p</math>\n\n'''Proof.''' We can suppose {{math|''μ'' ∉ ''Λ''(''A'')}}, otherwise take {{math|''λ'' {{=}} ''μ''}} and the result is trivially true since {{math|''κ<sub>p</sub>''(''V'') ≥ 1}}. Since {{mvar|μ}} is an eigenvalue of {{math|''A'' + ''δA''}}, we have {{math|det(''A'' + ''δA'' − ''μI'') {{=}} 0}} and so\n\n:<math>\\begin{align}\n0 &= \\det(A+\\delta A-\\mu I) \\\\\n  &= \\det(V^{-1})\\det(A+\\delta A-\\mu I)\\det(V) \\\\\n  &= \\det \\left ( V^{-1} (A+\\delta A-\\mu I) V \\right ) \\\\\n  &= \\det \\left ( V^{-1}AV + V^{-1}\\delta AV- V^{-1} \\mu I V \\right ) \\\\\n  &= \\det \\left (\\Lambda+V^{-1}\\delta AV-\\mu I \\right ) \\\\\n  &= \\det(\\Lambda-\\mu I)\\det \\left ((\\Lambda-\\mu I)^{-1}V^{-1}\\delta AV +I \\right ) \\\\\n\\end{align}</math>\n\nHowever our assumption, {{math|''μ'' ∉ ''Λ''(''A'')}}, implies that: {{math|det(Λ − ''μI'') ≠ 0}} and therefore we can write:\n\n:<math>\\det \\left ((\\Lambda-\\mu I)^{-1}V^{-1}\\delta AV +I \\right ) = 0.</math>\n\nThis reveals {{math|−1}} to be an eigenvalue of \n\n:<math>(\\Lambda-\\mu I)^{-1}V^{-1}\\delta AV.</math>\n\nSince all {{mvar|p}}-norms are [[matrix norm|consistent matrix norms]] we have {{math|{{!}}''λ''{{!}} ≤ {{!!}}''A''{{!!}}<sub>''p''</sub>}} where {{mvar|λ}} is an eigenvalue of {{mvar|A}}. In this instance this gives us:\n\n:<math>1 = |-1| \\leq \\left \\|(\\Lambda-\\mu I)^{-1}V^{-1}\\delta AV \\right \\|_p \\leq \\left \\|(\\Lambda-\\mu I)^{-1} \\right \\|_p \\left \\|V^{-1}\\right \\|_p \\|V\\|_p\\|\\delta A\\|_p = \\left \\|(\\Lambda-\\mu I)^{-1} \\right \\|_p\\ \\kappa_p(V)\\|\\delta A\\|_p</math>\n\nBut {{math|(Λ − ''μI'')<sup>−1</sup>}} is a diagonal matrix, the {{mvar|p}}-norm of which is easily computed:\n\n:<math>\\left \\| \\left (\\Lambda-\\mu I \\right )^{-1} \\right \\|_p\\ =\\max_{\\|\\boldsymbol{x}\\|_p\\ne 0} \\frac{\\left \\|\\left (\\Lambda-\\mu I \\right )^{-1} \\boldsymbol{x} \\right \\|_p}{\\|\\boldsymbol{x}\\|_p} =\\max_{\\lambda\\in\\Lambda(A)}\\frac{1}{|\\lambda -\\mu|}\\ = \\frac{1}{\\min_{\\lambda\\in\\Lambda(A)}|\\lambda-\\mu|}</math>\n\nwhence:\n\n:<math>\\min_{\\lambda\\in\\Lambda(A)}|\\lambda-\\mu|\\leq\\ \\kappa_p(V)\\|\\delta A\\|_p.</math>\n\n==An Alternate Formulation==\nThe theorem can also be reformulated to better suit numerical methods. In fact, dealing with real eigensystem problems, one often has an exact matrix {{mvar|A}}, but knows only an approximate eigenvalue-eigenvector couple, {{math|(''λ<sup>a</sup>'', '''''v'''<sup>a</sup>''&thinsp;)}} and needs to bound the error. The following version comes in help.\n\n:'''Bauer–Fike Theorem (Alternate Formulation).''' Let {{math|(''λ<sup>a</sup>'', '''''v'''<sup>a</sup>''&thinsp;)}} be an approximate eigenvalue-eigenvector couple, and {{math|'''''r''''' {{=}} ''A'''v'''<sup>a</sup>'' − ''λ<sup>a</sup>'''v'''<sup>a</sup>''}}. Then there exists {{math|''λ'' ∈ ''Λ''(''A'')}} such that:\n::<math> \\left |\\lambda-\\lambda^a \\right |\\leq \\kappa_p (V)\\frac{\\|\\boldsymbol{r}\\|_p}{\\left \\|\\boldsymbol{v}^a \\right \\|_p}</math>\n\n'''Proof.''' We can suppose {{math|''λ<sup>a</sup>'' ∉ ''Λ''(''A'')}}, otherwise take {{math|''λ'' {{=}} ''λ<sup>a</sup>''}} and the result is trivially true since {{math|''κ<sub>p</sub>''(''V'') ≥ 1}}. So {{math|(''A'' − ''λ<sup>a</sup>I'')<sup>−1</sup>}} exists, so we can write:\n\n:<math>\\boldsymbol{v}^a = \\left (A-\\lambda^a I \\right )^{-1} \\boldsymbol{r}= V \\left (D-\\lambda^a I \\right )^{-1}V^{-1}\\boldsymbol{r}</math>\n\nsince {{mvar|A}} is diagonalizable; taking the {{mvar|p}}-norm of both sides, we obtain:\n\n:<math>\\left \\| \\boldsymbol{v}^a \\right \\|_p= \\left \\|V \\left (D-\\lambda^a I \\right )^{-1}V^{-1}\\boldsymbol{r} \\right \\|_p \\leq \\|V\\|_p \\left \\| \\left (D-\\lambda^a I \\right )^{-1} \\right \\|_p \\left \\|V^{-1} \\right \\|_p \\|\\boldsymbol{r}\\|_p =\\kappa_p(V) \\left \\| \\left (D-\\lambda^a I \\right )^{-1} \\right \\|_p \\|\\boldsymbol{r}\\|_p.</math>\n\nHowever \n\n:<math>\\left (D- \\lambda^a I \\right )^{-1}</math> \n\nis a diagonal matrix and its {{mvar|p}}-norm is easily computed:\n\n:<math>\\left \\|\\left (D-\\lambda^a I \\right )^{-1} \\right \\|_p = \\max_{\\|\\boldsymbol{x}\\|_p \\ne 0}\\frac{\\left \\|\\left (D-\\lambda^a I \\right )^{-1}\\boldsymbol{x} \\right \\|_p}{\\|\\boldsymbol{x}\\|_p} =\\max_{\\lambda\\in\\sigma(A)} \\frac{1}{\\left |\\lambda-\\lambda^a \\right |}=\\frac{1}{\\min_{\\lambda\\in\\sigma(A)} \\left |\\lambda- \\lambda^a \\right |}</math>\n\nwhence:\n\n:<math>\\min_{\\lambda\\in\\lambda(A)} \\left |\\lambda-\\lambda^a \\right | \\leq\\kappa_p(V) \\frac{\\|\\boldsymbol{r}\\|_p}{\\left \\|\\boldsymbol{v}^a \\right \\|_p}.</math>\n\n==A Relative Bound==\nBoth formulations of Bauer–Fike theorem yield an absolute bound. The following corollary is useful whenever a relative bound is needed:\n\n:'''Corollary.''' Suppose {{mvar|A}} is invertible and that {{mvar|μ}} is an eigenvalue of {{math|''A'' + ''δA''}}. Then there exists {{math|''λ'' ∈ ''Λ''(''A'')}} such that:\n::<math>\\frac{|\\lambda-\\mu|}{|\\lambda|}\\leq\\kappa_p (V) \\left \\|A^{-1}\\delta A \\right \\|_p</math>\n\n'''Note.''' {{math|{{!!}}''A''<sup>−1</sup>''δA''{{!!}}}} can be formally viewed as the ''relative variation of'' {{mvar|A}}, just as {{math|{{sfrac|{{!}}''λ'' − ''μ''{{!}}|{{!}}''λ''{{!}}}}}} is the relative variation of {{mvar|λ}}.\n\n'''Proof.''' Since {{mvar|μ}} is an eigenvalue of {{math|''A'' + ''δA''}} and {{math|det(''A'') ≠ 0}}, by multiplying by {{math|−''A''<sup>−1</sup>}} from left we have:\n\n:<math>-A^{-1}(A+\\delta A)\\boldsymbol{v}=-\\mu A^{-1}\\boldsymbol{v}.</math>\n\nIf we set:\n\n:<math>A^a =\\mu A^{-1}, \\qquad (\\delta A)^a = -A^{-1}\\delta A</math>\n\nthen we have:\n\n:<math>\\left (A^a + (\\delta A)^a - I \\right )\\boldsymbol{v} = \\boldsymbol{0}</math>\n\nwhich means that {{math|1}} is an eigenvalue of {{math|''A<sup>a</sup>'' + (''δA'')<sup>''a''</sup>}}, with {{math|'''''v'''''}} as an eigenvector. Now, the eigenvalues of {{math|''A<sup>a</sup>''}} are {{math|{{sfrac|''μ''|''λ<sub>i</sub>''}}}}, while it has the same eigenvector matrix as {{mvar|A}}. Applying the Bauer–Fike theorem to {{math|''A<sup>a</sup>'' + (''δA'')<sup>''a''</sup>}} with eigenvalue {{math|1}}, gives us:\n\n:<math>\\min_{\\lambda\\in\\Lambda(A)} \\left|\\frac{\\mu}{\\lambda}-1\\right| = \\min_{\\lambda\\in\\Lambda(A)}\\frac{|\\lambda-\\mu|}{|\\lambda|} \\leq \\kappa_p (V) \\left \\|A^{-1}\\delta A \\right \\|_p</math>\n\n== The Case of Normal Matrices ==\nIf {{mvar|A}} is [[normal matrix|normal]], {{mvar|V}} is a [[unitary matrix]], therefore:\n\n:<math>\\|V\\|_2= \\left \\|V^{-1} \\right \\|_2 = 1,</math>\n\nso that {{math|''κ''<sub>2</sub>(''V'') {{=}} 1}}. The Bauer–Fike theorem then becomes:\n\n:<math>\\exists\\lambda\\in\\Lambda(A): \\quad  |\\lambda-\\mu|\\leq\\|\\delta A\\|_2</math>\n\nOr in alternate formulation:\n\n:<math>\\exists\\lambda\\in\\Lambda(A): \\quad \\left |\\lambda-\\lambda^a \\right |\\leq\\frac{\\|\\boldsymbol{r}\\|_2}{\\left \\|\\boldsymbol{v}^a\\right \\|_2}</math>\n\nwhich obviously remains true if {{mvar|A}} is a [[Hermitian matrix]]. In this case, however, a much stronger result holds, known as the [[Weyl's inequality|Weyl's theorem on eigenvalues]]. In the hermitian case one can also restate the Bauer–Fike theorem in the form that the map {{math|''A'' ↦ ''Λ''(''A'')}} that maps a matrix to its [[spectrum]] is a [[non-expansive function]] with respect to the [[Hausdorff distance]] on the set of compact subsets of {{math|'''C'''}}.\n\n== References ==\n* {{cite journal |first=F. L. |last=Bauer |first2=C. T. |last2=Fike |title=Norms and Exclusion Theorems |journal=Numer. Math. |volume=2 |issue=1 |year=1960 |pages=137–141 |doi=10.1007/BF01386217 }}\n* {{cite journal |first=S. C. |last=Eisenstat |first2=I. C. F. |last2=Ipsen |title=Three absolute perturbation bounds for matrix eigenvalues imply relative bounds |journal=SIAM Journal on Matrix Analysis and Applications |volume=20 |issue=1 |year=1998 |pages=149–158 |doi=10.1137/S0895479897323282 |citeseerx=10.1.1.45.3999 }}\n\n{{DEFAULTSORT:Bauer-Fike theorem}}\n[[Category:Spectral theory]]\n[[Category:Theorems in analysis]]\n[[Category:Articles containing proofs]]"
    },
    {
      "title": "Decomposition of spectrum (functional analysis)",
      "url": "https://en.wikipedia.org/wiki/Decomposition_of_spectrum_%28functional_analysis%29",
      "text": "The [[spectrum (functional analysis)|spectrum]] of a [[linear operator]] <math>T</math> that operates on a [[Banach space]] <math>X</math> (a fundamental concept of [[functional analysis]]) consists of all [[scalar (mathematics)|scalars]] <math>\\lambda</math> such that the operator <math>T-\\lambda</math> does not have a bounded [[inverse function|inverse]] on <math>X</math>.  The spectrum has a standard '''decomposition''' into three parts: \n* a '''point spectrum''', consisting of the [[eigenvalues and eigenvectors|eigenvalues]] of <math>T</math>\n* a '''continuous spectrum''', consisting of the scalars that are not eigenvalues but make the range of <math>T-\\lambda</math> a [[proper subset|proper]] [[dense subset]] of the space;\n* a '''residual spectrum''', consisting of all other scalars in the spectrum\n\nThis decomposition is relevant to the study of [[differential equation]]s, and has applications to many branches of science and engineering. A well-known example from [[quantum mechanics]] is the explanation for the [[discrete spectrum (physics)|discrete spectral lines]] and the continuous band in the light emitted by [[excited state|excited]] atoms of [[hydrogen]].\n\n== Definitions ==\n\n=== For bounded Banach space operators ===\n\nLet ''X'' be a [[Banach space]], ''L''(''X'') the family of [[bounded operator]]s on ''X'', and ''T''&nbsp;∈&nbsp;''L''(''X''). By [[spectrum (functional analysis)|definition]], a complex number ''λ'' is in the '''spectrum''' of ''T'', denoted ''σ''(''T''), if ''T''&nbsp;&minus;&nbsp;''λ'' does not have an inverse in ''L''(''X'').\n\nIf ''T''&nbsp;&minus;&nbsp;''λ'' is [[injective|one-to-one]] and [[surjective|onto]], then its inverse is bounded; this follows directly from the [[open mapping theorem (functional analysis)|open mapping theorem]] of functional analysis.  So, ''λ'' is in the spectrum of ''T'' if and only if ''T''&nbsp;&minus;&nbsp;''λ'' is either not one-to-one or not onto. One distinguishes three separate cases:\n\n#''T''&nbsp;&minus;&nbsp;''λ'' is not [[injective]].  That is, there exist two distinct elements ''x'',''y'' in ''X'' such that (''T''&nbsp;&minus;&nbsp;''λ'')(''x'') = (''T''&nbsp;&minus;&nbsp;''λ'')(''y''). Then ''z'' = ''x''&nbsp;&minus;&nbsp;''y'' is a non-zero vector such that ''T''(''z'') = ''λz''.  In other words, ''λ'' is an eigenvalue of ''T'' in the sense of [[linear algebra]].  In this case, ''λ'' is said to be in the '''point spectrum''' of ''T'', denoted ''σ''<sub>p</sub>(''T'').\n#''T''&nbsp;&minus;&nbsp;''λ'' is injective, and its [[range (mathematics)|range]] is a [[dense subset]] '' R'' of ''X''; but is not the whole of ''X''.  In other words, there exists some element ''x'' in ''X'' such that (''T''&nbsp;&minus;&nbsp;''λ'')(''y'') can be as close to ''x'' as desired, with ''y'' in ''X''; but is never equal to ''x''.  It can be proved that, in this case, ''T''&nbsp;&minus;&nbsp;''λ'' is not bounded below (i.e. it sends far apart elements of ''X'' too close together).  Equivalently, the inverse linear operator (''T''&nbsp;&minus;&nbsp;''λ'')<sup>&minus;1</sup>, which is defined on the dense subset ''R'', is not a bounded operator, and therefore cannot be extended to the whole of ''X''.  Then ''λ'' is said to be in the '''continuous spectrum''', ''σ<sub>c</sub>''(''T''), of ''T''.\n#''T''&nbsp;&minus;&nbsp;''λ'' is injective but does not have dense range.  That is, there is some element ''x'' in ''X'' and a neighborhood ''N'' of ''x'' such that (''T''&nbsp;&minus;&nbsp;''λ'')(''y'') is never in ''N''. In this case, the map (''T''&nbsp;&minus;&nbsp;''λ'')<sup>&minus;1</sup> ''x'' → ''x'' may be bounded or unbounded, but in any case does not admit a unique extension to a bounded linear map on all of ''X''.  Then ''λ'' is said to be in the '''residual spectrum''' of ''T'', ''σ<sub>r</sub>''(''T'').\n\nSo ''σ''(''T'') is the disjoint union of these three sets,\n\n:<math>\\sigma(T) = \\sigma_p (T) \\cup \\sigma_c (T) \\cup \\sigma_r (T).</math>\n\n==== Spectrum of dual operator ====\n\nIf ''X*'' is the dual space of ''X'', and ''T*'' : ''X*'' → ''X*'' is the transpose operator of ''T'', then\n''σ''(''T'') = ''σ''(''T*'').\n\n'''Theorem''' For a bounded operator ''T'', ''σ<sub>r</sub>''(''T'') ⊂ ''σ<sub>p</sub>''(''T*'') ⊂ ''σ<sub>r</sub>''(''T'') ∪ ''σ<sub>p</sub>''(''T'').\n\n'''Proof''' \nThe notation <·, ''φ''> will denote an element of ''X*'', i.e. ''x'' → <''x'', ''φ''> is the action of a bounded linear functional ''φ''. Let λ ∈ ''σ<sub>r</sub>''(''T''). So ''Ran''(''T'' - ''λ'') is not dense in ''X''. By the [[Hahn–Banach theorem]], there exists a non-zero ''φ'' ∈ ''X*'' that vanishes on ''Ran''(''T'' - ''λ''). For all ''x'' ∈ ''X'',\n\n:<math>\\langle (T - \\lambda)x, \\varphi \\rangle = \\langle x, (T^* - {\\lambda}) \\varphi \\rangle = 0.</math>\n\nTherefore, (''T*'' - ''λ'')''φ'' = 0 ∈ ''X*'' and ''λ'' is an eigenvalue of ''T*''. This shows the former inclusion. Next suppose that (''T*'' - ''λ'')''φ'' = 0 where ''φ'' ≠ 0, i.e.\n\n:<math>\\forall x \\in X,\\; \\langle x, (T^* - \\lambda) \\varphi \\rangle = \\langle (T - \\lambda) x, \\varphi \\rangle = 0.</math>\n\nIf ''Ran''(''T''&nbsp;&minus;&nbsp;''λ'') is dense, then ''φ'' must be the zero functional, a contradiction. The claim is proved.\n\nWe also get  ''σ<sub>p</sub>''(''T'')  ⊂ ''σ<sub>r</sub>''(''T''*) ∪ ''σ<sub>p</sub>''(''T''*) by the following argument: ''X'' embeds isometrically into ''X**''. Therefore, for every non-zero element in den kernel of ''T-λ'' there exists a non-zero element in ''X**'' which vanishes on ''Ran''(''T*'' - ''λ''). Thus ''Ran''(''T*'' - ''λ'') can not be dense.\n\nFurthermore, if ''X'' is reflexive we have ''σ<sub>r</sub>''(''T*'') ⊂  ''σ<sub>p</sub>''(''T'').\n\n=== For unbounded operators ===\nThe spectrum of an unbounded operator can be divided into three parts in the same way as in the bounded case, but because the operator is not defined everywhere, the definitions of domain, inverse, etc. are more involved.\n\n=== Examples ===\n\n==== Multiplication operator ====\n\nGiven a σ-finite [[measure space]] (''S'', ''Σ'', ''μ''), consider the Banach space [[Lp space|''L<sup>p</sup>''(''&mu;'')]]. A function ''h'': ''S'' → '''C''' is called [[essentially bounded]] if ''h'' is bounded ''μ''-almost everywhere. An essentially bounded ''h'' induces a bounded multiplication operator ''T<sub>h</sub>'' on ''L<sup>p</sup>''(''μ''):\n\n:<math>(T_h f)(s) = h(s) \\cdot f(s).</math>\n\nThe operator norm of ''T'' is the essential supremum of ''h''. The [[essential range]] of ''h'' is defined in the following way: a complex number ''λ'' is in the essential range of ''h'' if for all ''ε'' > 0, the preimage of the open ball ''B<sub>ε</sub>''(''λ'') under ''h'' has strictly positive measure. We will show first that ''σ''(''T<sub>h</sub>'') coincides with the essential range of ''h'' and then examine its various parts.\n\nIf ''λ'' is not in the essential range of ''h'', take ''ε'' > 0 such that ''h''<sup>&minus;1</sup>(''B<sub>ε</sub>''(''λ'')) has zero measure. The function ''g''(''s'') = 1/(''h''(''s'')&nbsp;&minus;&nbsp;''λ'') is bounded almost everywhere by 1/''ε''. The multiplication operator ''T<sub>g</sub>'' satisfies\n''T''<sub>''g''</sub> · (''T''<sub>''h''</sub>&nbsp;&minus;&nbsp;''λ'') = (''T''<sub>''h''</sub> &nbsp;&minus;&nbsp;''λ'')· ''T''<sub>''g''</sub> = ''I''. So ''λ'' does not lie in spectrum of ''T<sub>h</sub>''.  On the other hand, if ''λ'' lies in the essential range of ''h'', consider the sequence of sets {''S<sub>n</sub>'' = \n''h''<sup>−1</sup>(''B''<sub>1/n</sub>(''λ''))}. Each ''S<sub>n</sub>'' has positive measure. Let ''f<sub>n</sub>'' be the characteristic function of ''S<sub>n</sub>''. We can compute directly\n\n:<math>\n\\| (T_h - \\lambda) f_n \\|_p ^p = \\| (h - \\lambda) f_n \\|_p ^p = \\int_{S_n} | h - \\lambda \\; |^p d \\mu \n\\leq \\frac{1}{n^p} \\; \\mu(S_n) = \\frac{1}{n^p} \\| f_n \\|_p ^p.\n</math>\n\nThis shows ''T<sub>h</sub>''&nbsp;&minus;&nbsp;''λ'' is not bounded below, therefore not invertible.\n\nIf ''λ'' is such that ''μ''( ''h''<sup>&minus;1</sup>({''λ''})) > 0, then ''λ'' lies in the point spectrum of ''T<sub>h</sub>'' as follows. Let ''f'' be the characteristic function of the measurable set ''h''<sup>&minus;1</sup>(''λ''), then by considering two cases, we find\n\n:<math>\\forall s \\in S, \\; (T_h f)(s) = \\lambda f(s),</math>\n\nso λ is an eigenvalue of ''T''<sub>''h''</sub>.\n\nAny ''λ'' in the essential range of ''h'' that does not have a positive measure preimage is in the continuous spectrum of ''T<sub>h</sub>''. To show this, we must show that ''T<sub>h</sub>''&nbsp;&minus;&nbsp;''λ'' has dense range. Given ''f'' ∈ ''L<sup>p</sup>''(''μ''), again we  consider the sequence of sets {''S<sub>n</sub>'' = ''h''<sup>&minus;1</sup>(''B''<sub>1/n</sub>(''λ''))}. Let ''g<sub>n</sub>'' be the characteristic function of ''S''&nbsp;&minus;&nbsp;''S<sub>n</sub>''. Define\n\n:<math>f_n(s) = \\frac{1}{ h(s) - \\lambda} \\cdot g_n(s) \\cdot f(s).</math>\n\nDirect calculation shows that ''f<sub>n</sub>'' ∈ ''L<sup>p</sup>''(''μ''), with <math>\\| f_n\\|_p\\leq n \\|f\\|_p</math>. Then by the [[dominated convergence theorem]],\n\n:<math>(T_h - \\lambda) f_n \\rightarrow f</math>\n\nin the ''L<sup>p</sup>''(''μ'') norm.\n\nTherefore, multiplication operators have no residual spectrum. In particular, by the [[spectral theorem]], [[normal operator]]s on a Hilbert space have no residual spectrum.\n\n==== Shifts ====\n{{main|Shift space}}\nIn the special case when ''S'' is the set of natural numbers and ''μ'' is the counting measure, the corresponding ''L<sup>p</sup>''(''μ'') is denoted by l<sup>''p''</sup>. This space consists of complex valued sequences {''x<sub>n</sub>''} such that\n\n:<math>\\sum_{n \\geq 0} | x_n |^p < \\infty.</math>\n\nFor 1 < ''p'' < ∞, ''l <sup>p</sup>'' is [[Reflexive space|reflexive]]. Define the [[shift operator|left shift]] ''T'' : ''l <sup>p</sup>'' → ''l <sup>p</sup>'' by\n\n:<math>T(x_1, x_2, x_3, \\dots) = (x_2, x_3, x_4, \\dots).</math>\n\n''T'' is a [[partial isometry]] with operator norm 1. So ''σ''(''T'') lies in the closed unit disk of the complex plane.\n\n''T*'' is the right shift (or [[unilateral shift]]), which is an isometry on ''l <sup>q</sup>'', where 1/''p'' + 1/''q'' = 1:\n\n:<math>T^*(x_1, x_2, x_3, \\dots) = (0, x_1, x_2, \\dots).</math>\n\nFor ''λ'' ∈ '''C''' with |''λ''| < 1,\n\n:<math>x = (1, \\lambda, \\lambda ^2, \\dots) \\in l^p</math>\n\nand ''T x'' = ''λ x''. Consequently, the point spectrum of ''T'' contains the open unit disk. Now, ''T*'' has no eigenvalues, i.e. ''σ<sub>p</sub>''(''T*'') is empty. Thus, invoking reflexivity and the theorem given above (that ''σ<sub>p</sub>''(''T'')  ⊂ ''σ<sub>r</sub>''(''T''*) ∪ ''σ<sub>p</sub>''(''T''*)), we can deduce that the open unit disk lies in the residual spectrum of ''T*''.\n\nThe spectrum of a bounded operator is closed, which implies the unit circle, { |''λ''| = 1 } ⊂ '''C''', is in ''σ''(''T''). Again by reflexivity of ''l <sup>p</sup>'' and the theorem given above (this time, that ''σ<sub>r</sub>''(''T'') ⊂  ''σ<sub>p</sub>''(''T''*)), we have that ''σ<sub>r</sub>''(''T'')\nis also empty. Therefore, for a complex number ''λ'' with unit norm, one must have ''λ'' ∈  ''σ<sub>p</sub>''(''T'') or ''λ'' ∈  ''σ<sub>c</sub>''(''T''). Now if |''λ''| = 1 and\n\n:<math>T x = \\lambda x, \\qquad i.e. \\; (x_2, x_3, x_4, \\dots) = \\lambda (x_1, x_2, x_3, \\dots),</math>\n\nthen\n\n:<math>x = x_1 (1, \\lambda, \\lambda^2, \\dots),</math>\n\nwhich cannot be in ''l <sup>p</sup>'', a contradiction. This means the unit circle must lie in the continuous spectrum of ''T''.\n\nSo for the left shift ''T'', ''σ<sub>p</sub>''(''T'') is the open unit disk and ''σ<sub>c</sub>''(''T'') is the unit circle, whereas for the right shift ''T*'', ''σ<sub>r</sub>''(''T*'') is the open unit disk and ''σ<sub>c</sub>''(''T*'') is the unit circle.\n\nFor ''p'' = 1, one can perform a similar analysis.  The results will not be exactly the same, since reflexivity no longer holds.\n\n== Self adjoint operators on Hilbert space ==\n\n[[Hilbert space]]s are Banach spaces, so the above discussion applies to bounded operators on Hilbert spaces as well. A subtle point concerns the spectrum of ''T''*. For a Banach space, ''T''* denotes the transpose and  ''σ''(''T*'') = ''σ''(''T''). For a Hilbert space, ''T''* normally denotes the [[adjoint]] of an operator ''T'' ∈ ''L''(''H''), not the transpose, and ''σ''(''T*'') is not ''σ''(''T'') but rather its image under complex conjugation.\n\nFor a self adjoint ''T'' ∈ ''L''(''H''), the [[Borel functional calculus]] gives additional ways to break up the spectrum naturally.\n\n=== Borel functional calculus ===\n{{further information|Borel functional calculus}}\n\nThis subsection briefly sketches the development of this calculus.  The idea is to first establish the continuous functional calculus then pass to measurable functions via the [[Riesz representation theorem|Riesz-Markov representation theorem]].  For the continuous functional calculus, the key ingredients are the following:\n\n:1. If ''T'' is self adjoint, then for any polynomial ''P'', the operator norm satisfies\n\n::<math>\\| P(T) \\| = \\sup_{\\lambda \\in \\sigma(T)} |P(\\lambda)|.</math>\n:2. The [[Stone-Weierstrass theorem]], which implies that the family of polynomials (with complex coefficients), is dense in ''C''(''&sigma;''(''T'')), the continuous functions on ''&sigma;''(''T'').\n\nThe family ''C''(''σ''(''T'')) is a [[Banach algebra]] when endowed with the uniform norm. So the mapping\n\n:<math>P \\rightarrow P(T)</math>\n\nis an isometric homomorphism from a dense subset of ''C''(''σ''(''T'')) to ''L''(''H''). Extending the mapping by continuity gives ''f''(''T'') for ''f'' ∈ C(''σ''(''T'')): let ''P<sub>n</sub>'' be polynomials such that ''P<sub>n</sub>'' → ''f'' uniformly and define ''f''(''T'') = lim  ''P<sub>n</sub>''(''T''). This is the continuous functional calculus.\n\nFor a fixed ''h'' ∈ ''H'', we notice that\n\n:<math>f \\rightarrow \\langle h, f(T) h \\rangle</math>\n\nis a positive linear functional on ''C''(''σ''(''T'')). According to the Riesz-Markov representation theorem that there exists a unique measure ''μ<sub>h</sub>'' on ''σ''(''T'') such that\n\n:<math>\\int_{\\sigma(T)} f \\, d \\mu_h = \\langle h, f(T) h \\rangle.</math>\n\nThis measure is sometimes called the '''spectral measure associated to h'''. The spectral measures can be used to extend the continuous functional calculus to bounded Borel functions. For a bounded function ''g'' that is Borel measurable, define, for a proposed ''g''(''T'')\n\n:<math>\\int_{\\sigma(T)} g \\, d \\mu_h = \\langle h, g(T) h \\rangle.</math>\n\nVia the [[polarization identity]], one can recover (since ''H'' is assumed to be complex)\n\n:<math>\\langle k, g(T) h \\rangle.</math>\n\nand therefore ''g''(''T'') ''h'' for arbitrary ''h''.\n\nIn the present context, the spectral measures, combined with a result from measure theory, give a decomposition of ''σ''(''T'').\n\n=== Decomposing the spectrum ===\n\nLet ''h'' ∈ ''H'' and ''μ<sub>h</sub>'' be its corresponding spectral measure on ''σ''(''T'') ⊂ '''R'''. According to a refinement of [[Lebesgue's decomposition theorem]], ''μ<sub>h</sub>'' can be decomposed into three mutually singular parts:\n\n:<math>\\, \\mu_h = \\mu_{\\mathrm{ac}} + \\mu_{\\mathrm{sc}} + \\mu_{\\mathrm{pp}}</math>\n\n\nwhere ''μ''<sub>ac</sub> is absolutely continuous with respect to the Lebesgue measure, ''μ''<sub>sc</sub> is singular with respect to the Lebesgue measure and atomless,\nand ''μ''<sub>pp</sub> is a pure point measure.<ref>{{cite book|last1=Bogachev|first1=Vladimir|title=Measure Theory volume 1|date=2007|publisher=Springer|page=344}}</ref>\n\nAll three types of measures are invariant under linear operations. Let ''H''<sub>ac</sub> be the subspace consisting of vectors whose spectral measures are absolutely continuous with respect to the [[Lebesgue measure]]. Define ''H''<sub>pp</sub> and ''H''<sub>sc</sub> in analogous fashion.  These subspaces are invariant under ''T''. For example, if ''h'' ∈ ''H''<sub>ac</sub> and ''k'' = ''T h''. Let ''χ'' be the characteristic function of some Borel set in ''σ''(''T''), then\n\n:<math>\n\\langle k, \\chi(T) k \\rangle = \\int_{\\sigma(T)} \\chi(\\lambda) \\cdot \\lambda^2 d \\mu_{h}(\\lambda) = \\int_{\\sigma(T)} \\chi(\\lambda) \\; d \\mu_k(\\lambda).\n</math>\n\nSo\n\n:<math>\\lambda^2  d \\mu_{h} = d \\mu_{k}\\,</math>\n\nand ''k'' ∈ ''H''<sub>ac</sub>. Furthermore, applying the spectral theorem gives\n\n:<math>H = H_{\\mathrm{ac}} \\oplus H_{\\mathrm{sc}} \\oplus H_{\\mathrm{pp}}.</math>\n\nThis leads to the following definitions:\n\n#The spectrum of ''T'' restricted to ''H''<sub>ac</sub> is called the '''absolutely continuous spectrum''' of ''T'', ''σ''<sub>ac</sub>(''T'').\n#The spectrum of ''T'' restricted to ''H''<sub>sc</sub> is called its '''singular spectrum''', ''σ''<sub>sc</sub>(''T'').\n#The set of eigenvalues of ''T'' are called the '''pure point spectrum''' of ''T'', ''σ''<sub>pp</sub>(''T'').\n\nThe closure of the eigenvalues is the spectrum of ''T'' restricted to ''H''<sub>pp</sub>. So\n\n:<math>\\sigma(T) = \\sigma_{\\mathrm{ac}}(T) \\cup \\sigma_{\\mathrm{sc}}(T) \\cup {\\bar \\sigma_{\\mathrm{pp}}(T)}.</math>\n\n=== Comparison ===\n\nA bounded self adjoint operator on Hilbert space is, a fortiori, a bounded operator on a Banach space. Therefore, one can also apply to ''T'' the decomposition of the spectrum that was achieved above for bounded operators on a Banach space. Unlike the Banach space formulation,{{clarify|reason=Why should they be related? The definition is quite different.|date=May 2015}} the union\n\n:<math>\\sigma(T) = {\\bar \\sigma_{\\mathrm{pp}}(T)} \\cup \\sigma_{\\mathrm{ac}}(T) \\cup \\sigma_{\\mathrm{sc}}(T).</math>\n\nneed not be disjoint. It is disjoint when the operator ''T'' is of uniform multiplicity, say ''m'', i.e. if ''T'' is unitarily equivalent to multiplication by ''λ'' on the direct sum\n\n:<math>\\oplus _{i = 1} ^m L^2(\\mathbb{R}, \\mu_i)</math>\n\nfor some Borel measures <math>\\mu_i</math>. When more than one measure appears in the above expression, we see that it is possible for the union of the three types of spectra to not be disjoint. If ''λ'' ∈ ''σ<sub>ac</sub>''(''T'') ∩ ''σ<sub>pp</sub>''(''T''), ''λ'' is sometimes called an eigenvalue ''embedded'' in the absolutely continuous spectrum.\n\nWhen ''T'' is unitarily equivalent to multiplication by ''λ'' on\n\n:<math>L^2(\\mathbb{R}, \\mu),</math>\n\nthe decomposition of ''σ''(''T'') from Borel functional calculus is a refinement of the Banach space case.\n\n=== Physics ===\n\nThe preceding comments can be extended to the unbounded self-adjoint operators since Riesz-Markov holds for [[locally compact]] [[Hausdorff space]]s.\n\nIn [[mathematical formulation of quantum mechanics|quantum mechanics]], observables are [[self adjoint operator]]s, often not bounded, and their spectra are the possible outcomes of measurements. Absolutely continuous spectrum of a physical observable corresponds to free states of a system, while the pure point spectrum corresponds to [[bound state]]s.  The singular spectrum correspond to physically impossible outcomes.  An example of a quantum mechanical observable which has purely continuous spectrum is the [[position operator]] of a free particle moving on a line. Its spectrum is the entire real line. Also, since the [[momentum operator]] is unitarily equivalent to the position operator, via the [[Fourier transform]], they have the same spectrum.\n\nIntuition may induce one to say that the discreteness of the spectrum is intimately related to the corresponding states being \"localized\". However, a careful mathematical analysis shows that this is not true. The following <math>f</math>\nis an element of <math>L^2(\\mathbb{R})</math> and increasing as <math>x \\to \\infty</math>.\n:<math> f(x) = \\begin{cases} n & \\text{if }x \\in \\left[n, n+\\frac{1}{n^4}\\right], \\\\ 0 & \\text{else.} \\end{cases} </math>\nHowever, the phenomena of [[Anderson localization]] and [[dynamical localization]] describe, when the eigenfunctions are localized in a physical sense. Anderson Localization means that eigenfunctions decay exponentially as <math> x \\to \\infty </math>. Dynamical localization is more subtle to define.\n\nSometimes, when performing physical quantum mechanical calculations, one encounters \"eigenvectors\" that do not lie in ''L''<sup>2</sup>('''R'''), i.e. wave functions that are not localized.  These are the free states of the system.  As stated above, in the mathematical formulation, the free states correspond to the absolutely continuous spectrum. Alternatively, if it is insisted that the notion of eigenvectors and eigenvalues survive the passage to the rigorous, one can consider operators on [[rigged Hilbert space]]s.\n\nIt was believed for some time that singular spectrum is something artificial. However, examples as the [[almost Mathieu operator]] and [[random Schrödinger operator]]s have shown, that all types of spectra arise naturally in physics.\n\n== See also ==\n\n* [[Essential spectrum]], spectrum of an operator modulo compact perturbations.\n\n== References ==\n{{Reflist}}\n\n* N. Dunford and J.T. Schwartz, ''Linear Operators, Part I: General Theory'', Interscience, 1958.\n* M. Reed and B. Simon, ''Methods of Modern Mathematical Physics I: Functional Analysis'', Academic Press, 1972.\n\n[[Category:Spectral theory]]"
    },
    {
      "title": "Dirac spectrum",
      "url": "https://en.wikipedia.org/wiki/Dirac_spectrum",
      "text": "In [[mathematics]], a '''Dirac spectrum''', named after [[Paul Dirac]], is the spectrum of [[eigenvalue]]s of a [[Dirac operator]] on a [[Riemannian manifold]] with a [[spin structure]].  The [[isospectral problem]] for the Dirac spectrum asks whether two Riemannian spin manifolds have identical spectra.  The Dirac spectrum depends on the [[spin structure]] in the sense that there exists a Riemannian manifold with two different spin structures that have different Dirac spectra.<ref>{{cite journal|url=http://www.emis.de/journals/SC/2000/4/pdf/smf_sem-cong_4_17-33.pdf |title=Dependence of the Dirac spectrum on the spin structure |author=Bar |year=2000 }}</ref>\n\n==See also==\n*[[Can you hear the shape of a drum?]]\n*[[Dirichlet eigenvalue]]\n*[[Spectral asymmetry]]\n*[[ARPES|Angle-resolved photoemission spectroscopy]]\n\n==References==\n{{reflist}}\n\n[[Category:Spectral theory]]\n[[Category:Quantum mechanics]]\n\n\n{{quantum-stub}}\n{{mathanalysis-stub}}"
    },
    {
      "title": "Dirichlet eigenvalue",
      "url": "https://en.wikipedia.org/wiki/Dirichlet_eigenvalue",
      "text": "In [[mathematics]], the '''Dirichlet eigenvalues''' are the [[fundamental mode]]s of [[vibration]] of an idealized drum with a given shape.  The problem of whether one can [[hearing the shape of a drum|hear the shape of a drum]] is: given the Dirichlet eigenvalues, what features of the shape of the drum can one deduce.  Here a \"drum\" is thought of as an elastic membrane Ω, which is represented as a planar domain whose boundary is fixed. The Dirichlet eigenvalues are found by solving the following problem for an unknown function ''u''&nbsp;≠&nbsp;0 and [[eigenvalue]] λ\n{{NumBlk|:|<math>\\begin{cases}\n\\Delta u + \\lambda u = 0& \\rm{in\\ }\\Omega\\\\\nu|_{\\partial\\Omega} =0.&\n\\end{cases}\n</math>|{{EquationRef|1}}}}\nHere Δ is the [[Laplacian]], which is given in ''xy''-coordinates by\n:<math>\\Delta u = \\frac{\\partial^2u}{\\partial x^2} + \\frac{\\partial^2 u}{\\partial y^2}.</math>\nThe [[boundary value problem]] ({{EquationNote|1}}) is the [[Dirichlet problem]] for the [[Helmholtz equation]], and so λ is known as a Dirichlet eigenvalue for Ω. Dirichlet eigenvalues are contrasted with [[Neumann eigenvalue]]s: eigenvalues for the corresponding [[Neumann problem]].  The Laplace operator Δ appearing in ({{EquationNote|1}}) is often known as the '''Dirichlet Laplacian''' when it is considered as accepting only functions ''u'' satisfying the Dirichlet boundary condition.  More generally, in [[spectral geometry]] one considers ({{EquationNote|1}}) on a [[manifold with boundary]] Ω.  Then Δ is taken to be the [[Laplace-Beltrami operator]], also with Dirichlet boundary conditions.\n\nIt can be shown, using the [[spectral theorem#The spectral theorem for compact self-adjoint operators|spectral theorem for compact self-adjoint operators]] that the eigenspaces are finite-dimensional and that the Dirichlet eigenvalues λ are real, positive, and have no [[limit point]].  Thus they can be arranged in increasing order:\n:<math>0<\\lambda_1\\le\\lambda_2\\le\\cdots,\\quad \\lambda_n\\to\\infty,</math>\nwhere each eigenvalue is counted according to its geometric multiplicity.  The eigenspaces are orthogonal in the space of [[square-integrable function]]s, and consist of [[smooth function]]s.  In fact, the Dirichlet Laplacian has a continuous extension to an operator from the [[Sobolev space]] <math>H^2_0(\\Omega)</math> into <math>L^2(\\Omega)</math>.  This operator is invertible, and its inverse is compact and self-adjoint so that the usual spectral theorem can be applied to obtain the eigenspaces of Δ and the reciprocals 1/λ of its eigenvalues.\n\nOne of the primary tools in the study of the Dirichlet eigenvalues is the [[Raleigh quotient|max-min principle]]: the first eigenvalue λ<sub>1</sub> minimizes the [[Dirichlet energy]].  To wit,\n:<math>\\lambda_1 = \\inf_{u\\not=0}\\frac{\\int_\\Omega |\\nabla u|^2}{\\int_\\Omega |u|^2},</math>\nthe [[infimum]] is taken over all ''u'' of [[compact support]] that do not vanish identically in Ω.  By a [[Meyers-Serrin theorem|density argument]], this infimum agrees with that taken over nonzero <math>u\\in H_0^1(\\Omega)</math>.  Moreover, using results from the [[calculus of variations]] analogous to the [[Lax&ndash;Milgram theorem]], one can show that a minimizer exists in <math>H_0^1(\\Omega)</math>.  More generally, one has\n:<math>\\lambda_k = \\sup\\inf \\frac{\\int_\\Omega |\\nabla u|^2}{\\int_\\Omega |u|^2}</math>\nwhere the [[supremum]] is taken over all (''k''&minus;1)-tuples <math>\\phi_1,\\dots,\\phi_{k-1}\\in H^1_0(\\Omega)</math> and the infimum over all ''u'' orthogonal to the <math>\\phi_i</math>.\n\n==Applications==\n[[File:SpiralCladding.png|200px|thumb|right|Fig.1. Spiral-shaped boundary of the domain (blue), its chunk (red), and 3 segments of a ray (green).\n]]\nThe Dirichlet Laplacian may arise from various problems of [[mathematical physics]];\nit may refer to modes of at idealized [[drum]], small waves at the surface of an idealized [[pond|pool]],\nas well as to a mode of an idealized [[optical fiber]] in the [[paraxial approximation]].\nThe last application is most practical in connection to the [[double-clad fiber]]s;\nin such fibers, it is important, that most of modes of the fill the domain uniformly,\nor the most of rays cross the core. The poorest shape seems to be the circularly-symmetric domain<ref name=bedo>{{cite journal| author=S. Bedo|author2=W. Luthy|author3=H. P. Weber |\ntitle=The effective absorption coefficient in double-clad fibers|\njournal=[[Optics Communications]]|\nvolume=99| issue=5–6| pages=331–335| year=1993| url=http://www.sciencedirect.com/science?_ob=ArticleURL&_udi=B6TVF-46JGTGD-M5&_user=10&_coverDate=06%2F15%2F1993&_alid=550903253&_rdoc=1&_fmt=summary&_orig=search&_cdi=5533&_sort=d&_docanchor=&view=c&_ct=1&_acct=C000050221&_version=1&_urlVersion=0&_userid=10&md5=c8a4c3ecc3d9a4e9ecb84f96cfef0333 | archive-url=https://web.archive.org/web/20071213214117/http://www.sciencedirect.com/science?_ob=ArticleURL&_udi=B6TVF-46JGTGD-M5&_user=10&_coverDate=06%2F15%2F1993&_alid=550903253&_rdoc=1&_fmt=summary&_orig=search&_cdi=5533&_sort=d&_docanchor=&view=c&_ct=1&_acct=C000050221&_version=1&_urlVersion=0&_userid=10&md5=c8a4c3ecc3d9a4e9ecb84f96cfef0333 | dead-url=yes | archive-date=2007-12-13 |\ndoi=10.1016/0030-4018(93)90338-6 | bibcode=1993OptCo..99..331B}}\n</ref><ref name=\"Doya\">{{cite journal|title=Modeling and optimization of double-clad fiber amplifiers using chaotic propagation of pump|\n author= Leproux, P.|author2=S. Fevrier |author3=V. Doya |author4=P. Roy |author5=D. Pagnoux | journal=[[Optical Fiber Technology]]| url=http://www.ingentaconnect.com/content/ap/of/2001/00000007/00000004/art00361|\nvolume=7 | year=2003 | issue=4 | pages=324–339|doi=10.1006/ofte.2001.0361 | bibcode=2001OptFT...7..324L}}</ref>\n,.<ref name=\"Liu\">{{cite journal|\ntitle=The absorption characteristics of circular, offset, and rectangular double-clad fibers|\nauthor=A. Liu|author2=K. Ueda| url= http://www.sciencedirect.com/science?_ob=ArticleURL&_udi=B6TVF-497C4YV-BW&_user=10&_coverDate=12%2F15%2F1996&_alid=550869877&_rdoc=3&_fmt=summary&_orig=search&_cdi=5533&_sort=d&_docanchor=&view=c&_ct=3&_acct=C000050221&_version=1&_urlVersion=0&_userid=10&md5=688bbca25fdd98e29caadb676b003c1e\n| archive-url= https://web.archive.org/web/20071213214122/http://www.sciencedirect.com/science?_ob=ArticleURL&_udi=B6TVF-497C4YV-BW&_user=10&_coverDate=12%2F15%2F1996&_alid=550869877&_rdoc=3&_fmt=summary&_orig=search&_cdi=5533&_sort=d&_docanchor=&view=c&_ct=3&_acct=C000050221&_version=1&_urlVersion=0&_userid=10&md5=688bbca25fdd98e29caadb676b003c1e\n| dead-url= yes\n| archive-date= 2007-12-13\n| journal=[[Optics Communications]]| volume=132| year=1996|\nissue=5–6| pages= 511–518|\ndoi=10.1016/0030-4018(96)00368-9|bibcode = 1996OptCo.132..511A }}</ref>\nThe modes of pump should not avoid the active core used in double-clad [[fiber amplifier]]s.\nThe spiral-shaped domain happens to be especially efficient for such an application due to the\nboundary behavior of modes of '''Dirichlet laplacian'''.<ref name=\"Kouznetsov\">{{cite journal\n|title=Boundary behavior of modes of Dirichlet laplacian\n| author= Kouznetsov, D.|author2=Moloney, J.V.| journal=[[Journal of Modern Optics]]\n|volume=51 | year=2004 | issue=13 | pages=1955–1962\n|ref=http://www.ils.uec.ac.jp/~dima/TMOP102136.pdf | doi=10.1080/09500340408232504 | bibcode=2004JMOp...51.1955K}}</ref>\n\nThe theorem about boundary behavior of the Dirichlet Laplacian if analogy of the property of rays in geometrical optics (Fig.1);\nthe angular momentum of a ray (green) increases at each reflection from the spiral part of the boundary (blue), until the ray hits the chunk (red); all rays (except those parallel to the optical axis) unavoidly visit the region in vicinity of the chunk to frop the excess of the\nangular momentum. Similarly, all the modes of the Dirichlet Laplacian have non-zero values in vicinity of the chunk. The normal component of the derivative\nof the mode at the boundary can be interpreted as [[pressure]]; the pressure integrated over the surface gives the [[force]]. As the mode is steady-state\nsolution of the propagation equation (with trivial dependence of the longitudinal coordinate), the total force should be zero.\nSimilarly, the [[angular momentum]] of the force of pressure should be also zero. However, there exists a formal proof, which \ndoes not refer to the analogy with the physical system.<ref name=\"Kouznetsov\"/>\n\n==Notes==\n<references/>\n\n==References==\n* {{springer|title=Dirichlet eigenvalues|id=d/d130170|year=2001|first=Rafael D.|last=Benguria}}.\n* {{Cite book|first=Isaac|last=Chavel|title=Eigenvalues in Riemannian geometry|series=Pure Appl. Math.|volume=115|publisher=[[Academic Press]]|year=1984|isbn=978-0-12-170640-1}}.\n* {{Cite book|first1=Richard|last1=Courant|authorlink1=Richard Courant|first2=David|last2=Hilbert|authorlink2=David Hilbert|title=Methods of Mathematical Physics, Volume I|publisher=Wiley-Interscience|year=1962}}.\n\n{{DEFAULTSORT:Dirichlet Eigenvalue}}\n[[Category:Differential operators]]\n[[Category:Partial differential equations]]\n[[Category:Spectral theory]]"
    },
    {
      "title": "Essential spectrum",
      "url": "https://en.wikipedia.org/wiki/Essential_spectrum",
      "text": "In [[mathematics]], the '''essential spectrum''' of a [[bounded operator]] is a certain subset of its [[spectrum (functional analysis)|spectrum]], defined by a condition of the type that says, roughly speaking, \"fails badly to be invertible\".\n\n==The essential spectrum of self-adjoint operators==\n\nIn formal terms, let ''X'' be a [[Hilbert space]] and let ''T'' be a [[Operator norm|bounded]] [[self-adjoint operator|self-adjoint]] operator on ''X''. \n\n===Definition===\n\nThe '''essential spectrum''' of ''T'', usually denoted σ<sub>ess</sub>(''T''), is the set of all [[complex number]]s λ such that \n\n:<math> \\lambda\\, I - T </math>\n\nis not a [[Fredholm operator]], where ''I'' denotes the ''identity operator'' on ''X'', so that ''I''(''x'') = ''x'' for all ''x'' in ''X''.\n\nAn operator is Fredholm if  its [[kernel (algebra)|kernel]] and [[cokernel]] are finite-dimensional. \n\n===Properties===\n\nThe essential spectrum is always [[closed set|closed]], and it is a subset of the [[spectrum (functional analysis)|spectrum]]. Since ''T'' is self-adjoint, the spectrum is contained on the real axis.\n\nThe essential spectrum is invariant under compact perturbations. That is, if ''K'' is a [[Compact operator on Hilbert space|compact]] self-adjoint operator on ''X'', then the essential spectra of ''T'' and that of ''T''&nbsp;+ ''K'' coincide. This explains why it is called the ''essential'' spectrum: [[Hermann Weyl|Weyl]] (1910) originally defined the essential spectrum of a certain differential operator to be the spectrum independent of boundary conditions.\n\n''Weyl's criterion'' for the essential spectrum is as follows. First, a number λ is in the ''spectrum'' of ''T'' if and only if there exists a [[sequence]] {ψ<sub>''k''</sub>} in the space ''X'' such that ||ψ<sub>''k''</sub>||&nbsp;=&nbsp;1 and\n\n:<math> \\lim_{k\\to\\infty} \\left\\| T\\psi_k - \\lambda\\psi_k \\right\\| = 0. </math>\n\nFurthermore, λ is in the ''essential spectrum'' if there is a sequence satisfying this condition, but such that it contains no convergent [[subsequence]] (this is the case if, for example <math>\\{\\psi_k\\}</math> is an [[orthonormal]] sequence); such a sequence is called a ''singular sequence''.\n\n===The discrete spectrum===\n\nThe essential spectrum is a subset of the spectrum σ, and its complement is called the ''discrete spectrum'', so\n:<math> \\sigma_{\\mathrm{discr}}(T) = \\sigma(T) \\setminus \\sigma_{\\mathrm{ess}}(T). </math>\nA number λ is in the discrete spectrum if{{what|reason=And only if?|date=December 2016}} it is an isolated eigenvalue of finite multiplicity, meaning that the dimension of the space\n:<math> \\{ \\psi \\in X : T\\psi = \\lambda\\psi \\} </math>\nhas finite but non-zero dimension and that there is an ε > 0 such that μ ∈ σ(''T'') and |μ&minus;λ| < ε imply that μ and λ are equal.\n\n==The essential spectrum of general bounded operators==\n\nIn the general case, ''X'' denotes a [[Banach space]] and ''T'' is a bounded operator on ''X''. There are several definitions of the essential spectrum in the literature, which are not equivalent.\n# The essential spectrum σ<sub>ess,1</sub>(''T'') is the set of all λ such that λI &minus; ''T'' is not semi-Fredholm (an operator is semi-Fredholm if its range is closed and its kernel or its cokernel is finite-dimensional).\n# The essential spectrum σ<sub>ess,2</sub>(''T'') is the set of all λ such that the range of λI &minus; ''T'' is not closed or the kernel of λI &minus; ''T'' is infinite-dimensional.\n# The essential spectrum σ<sub>ess,3</sub>(''T'') is the set of all λ such that λI &minus; ''T'' is not Fredholm (an operator is Fredholm if its range is closed and both its kernel and its cokernel are finite-dimensional).\n# The essential spectrum σ<sub>ess,4</sub>(''T'') is the set of all λ such that λI &minus; ''T'' is not Fredholm with index zero (the index of a Fredholm operator is the difference between the dimension of the kernel and the dimension of the cokernel).\n# The essential spectrum σ<sub>ess,5</sub>(''T'') is the union of σ<sub>ess,1</sub>(''T'') with all components of '''C''' \\ σ<sub>ess,1</sub>(''T'') that do not intersect with the resolvent set '''C''' \\ σ(''T'').\n\nThe essential spectrum of an operator is closed, whatever definition is used. Furthermore,\n:<math> \\sigma_{\\mathrm{ess},1}(T) \\subset \\sigma_{\\mathrm{ess},2}(T) \\subset \\sigma_{\\mathrm{ess},3}(T) \\subset \\sigma_{\\mathrm{ess},4}(T) \\subset \\sigma_{\\mathrm{ess},5}(T) \\subset \\sigma(T) \\subset \\mathbf{C}, </math>\nbut any of these inclusions may be strict. However, for self-adjoint operators, all the above definitions for the essential spectrum coincide.\n\nDefine the ''radius'' of the essential spectrum by\n:<math> r_{\\mathrm{ess},k}(T) = \\max \\{ |\\lambda| : \\lambda\\in\\sigma_{\\mathrm{ess},k}(T) \\}. </math>\nEven though the spectra may be different, the radius is the same for all ''k''.\n\nThe essential spectrum σ<sub>ess,''k''</sub>(''T'') is invariant under compact perturbations for ''k'' = 1,2,3,4, but not for ''k'' = 5. The case ''k'' = 4 gives the part of the spectrum that is independent of compact perturbations, that is,\n:<math> \\sigma_{\\mathrm{ess},4}(T) = \\bigcap_{K \\in K(X)} \\sigma(T+K), </math>\nwhere ''K''(''X'') denotes the set of compact operators on ''X''.\n\nThe second definition generalizes Weyl's criterion: σ<sub>ess,2</sub>(''T'') is the set of all λ for which there exists a singular sequence.\n\n==References==\n\nThe self-adjoint case is discussed in\n*{{citation |first1 = Michael C. |last1 = Reed|author1-link=Michael C. Reed |first2 = Barry |last2 = Simon |author2-link = Barry Simon |title = Methods of modern mathematical physics: Functional Analysis |volume=1 |place = San Diego |publisher = Academic Press |year = 1980 |isbn = 0-12-585050-6}}\n* {{Cite book |title=Mathematical Methods in Quantum Mechanics; With Applications to Schrödinger Operators |first= Gerald |last=Teschl |authorlink= Gerald Teschl |publisher= American Mathematical Society |year=2009 |url=http://www.mat.univie.ac.at/~gerald/ftp/book-schroe/ |isbn=978-0-8218-4660-5   }}\n\nA discussion of the spectrum for general operators can be found in\n*D.E. Edmunds and W.D. Evans (1987), ''Spectral theory and differential operators,'' Oxford University Press. {{ISBN|0-19-853542-2}}.\n\nThe original definition of the essential spectrum goes back to\n*[[Hermann Weyl|H. Weyl]] (1910), Über gewöhnliche Differentialgleichungen mit Singularitäten und die zugehörigen Entwicklungen willkürlicher Funktionen, ''Mathematische Annalen'' '''68''', 220&ndash;269.\n\n[[Category:Spectral theory]]"
    },
    {
      "title": "Fractional Chebyshev collocation method",
      "url": "https://en.wikipedia.org/wiki/Fractional_Chebyshev_collocation_method",
      "text": "{{Multiple issues|\n{{Underlinked|date=September 2016}}\n{{Orphan|date=September 2016}}\n}}\n\nThe '''fractional Chebyshev collocation (FCC) method'''<ref>{{cite journal |last=Doha |first=E.H. |last2=Bhrawy |first2=A.H. |last3=Ezz-Eldien|first3=S.S.  |date=December 2011 |title= Efficient Chebyshev spectral methods for solving multi-term fractional orders differential equations |url=http://www.sciencedirect.com/science/article/pii/S0307904X11003052 |journal=Applied Mathematical Modelling - |volume=35 |issue=12 |pages=5662–5672 |doi=10.1016/j.apm.2011.05.011 |access-date=18 December 2016 }}</ref> is an efficient [[spectral method]] for solving a system of linear [[fractional differentiation|fractional-order]] differential equations (FDEs) with discrete delays. The FCC method overcomes several limitations of current numerical methods for solving linear FDEs. For instance, the FCC method can be used for linear  incommensurate order FDEs and it does not require to be in canonical form. The essence of the method is that a discretization of the solution at the Chebyshev Gauss–Lobatto collocation points results in having spectral convergence and smaller computation time compared to finite difference methods. To accomplish this, a fractional differentiation matrix is derived at the Chebyshev Gauss–Lobatto collocation points by using the discrete orthogonal relationship of the Chebyshev polynomials. Then, using two proposed discretization operators for matrix functions results in an explicit form of solution for a system of linear FDEs with discrete delays. Moreover, it is shown that the proposed method can treat two common classes of linear FDEs: a system of linear commensurate order FDEs and a system of linear fractional-order delay-differential equations.\n\nThe fractional Chebyshev differentiation matrix in the sense of Caputo, <math> _{t_0} \\text{D}_{t_N}^\\alpha </math> , is a linear map that maps the discretized function at the CGL points <math> \\mathbf t=[t_0,t_1,\\ldots,t_N] </math> onto the discretized fractional derivative of the function at those points\n\n: <math>_{t_0}\\text{D}_{t_N}^\\alpha \\mathbf{x} = \\begin{bmatrix}\n{}_{t_0}^C\\mathcal{D}_t^\\alpha x(t_0) &\n{}_{t_0}^C\\mathcal{D}_t^\\alpha x(t_1) &\n\\cdots &\n{}_{t_0}^C\\mathcal{D}_t^\\alpha x(t_N)\n\\end{bmatrix}^T</math>\n\nThen, it is shown that how a matrix function can be discretized in an interval at the CGL points by using two discretization operators. Finally, in two theories the solution of a system of linear commensurate order FDEs and a system of linear FDDEs are given by a state transition matrix.\n\n==References==\n{{reflist}}\n\n\n[[Category:Spectral theory]]"
    },
    {
      "title": "Hearing the shape of a drum",
      "url": "https://en.wikipedia.org/wiki/Hearing_the_shape_of_a_drum",
      "text": "[[Image:Isospectral drums.svg|frame|right|Mathematically ideal drums with membranes of these two different shapes (but otherwise identical) would sound the same, because the [[eigenfrequency|eigenfrequencies]] are all equal, so the [[Timbre#Spectra|timbral spectra]] would contain the same overtones. This example was constructed by Gordon, Webb and Wolpert. Notice that both polygons have the same area and perimeter.]]\n\nTo '''hear the shape of a drum''' is to infer information about the shape of the [[drumhead]] from the sound it makes, i.e., from the list of [[overtones]], via the use of [[mathematics|mathematical]] theory.  \"Can One Hear the Shape of a Drum?\" was the title of an article by [[Mark Kac]] in the ''[[American Mathematical Monthly]]'' in 1966, but the phrasing of the title is due to [[Lipman Bers]]. These questions can be traced back all the way to [[Hermann Weyl]].\n\nFor the 1966 paper that made the question famous, Kac was given the [[Lester R. Ford Award]] in 1967 and the [[Chauvenet Prize]] in 1968.<ref>{{Cite web | url=http://www.maa.org/programs/maa-awards/writing-awards/can-one-hear-the-shape-of-a-drum | title=Can One Hear the Shape of a Drum? &#124; Mathematical Association of America}}</ref>\n\nThe frequencies at which a drumhead can vibrate depend on its shape. The [[Helmholtz equation]] calculates the frequencies if the shape is known.  These frequencies are the [[eigenvalues]] of the [[Laplacian]] in the space. A central question is whether the shape can be predicted if the frequencies are known; for example a circle-shaped triangle can be recognized in this way<ref>{{cite journal|last=Kac|authorlink=Mark Kac|first=Mark|title=Can One Hear the Shape of a Drum?|url=http://www.maa.org/sites/default/files/pdf/upload_library/22/Ford/MarkKac.pdf|journal=[[American Mathematical Monthly]]|date=April 1966|volume=73|issue=4, part 2|pages=16}}</ref>. Kac did not know if it was possible for two different shapes to yield the same set of frequencies; the question of whether the frequencies determine the shape was finally answered by the negative in the early 90's by Gordon, Webb and Wolpert. \n\n==Formal statement==\n\nMore formally, the drum is conceived as an elastic membrane whose boundary is clamped.  It is represented as a [[Domain (mathematical analysis)|domain]] ''D'' in the [[Plane (mathematics)|plane]]. Denote by λ<sub>''n''</sub> the [[Dirichlet eigenvalue]]s for ''D'': that is, the [[eigenvalue]]s of the [[Dirichlet problem]] for the [[Laplacian]]:\n\n:<math>\n\\begin{cases}\n\\Delta u + \\lambda u = 0\\\\\nu|_{\\partial D} = 0\n\\end{cases}\n</math>\n\nTwo domains are said to be [[isospectral]] (or homophonic) if they have the same eigenvalues.  The term \"homophonic\" is justified because the Dirichlet eigenvalues are precisely the fundamental tones that the drum is capable of producing: they appear naturally as [[Fourier series|Fourier coefficients]] in the solution [[wave equation]] with clamped boundary.\n\nTherefore the question may be reformulated as: what can be inferred on ''D'' if one knows only the values of λ<sub>''n''</sub>?  Or, more specifically: are there two distinct domains that are isospectral?\n\nRelated problems can be formulated for the Dirichlet problem for the Laplacian on domains in higher dimensions or on [[Riemannian manifold]]s, as well as for other [[elliptic differential operator]]s such as the [[Cauchy–Riemann equations|Cauchy–Riemann operator]] or [[Dirac operator]].  Other boundary conditions besides the Dirichlet condition, such as the [[Neumann boundary condition]], can be imposed.  See [[spectral geometry]] and [[isospectral]] as related articles.\n\n==The answer==\n[[File:Барабаны.gif|thumb|One-parameter family of isospectral drums]]\n\nAlmost immediately, [[John Milnor]] observed that a theorem due to [[Ernst Witt]] implied the existence of a pair of 16-dimensional tori that have the same eigenvalues but different shapes. However, the problem in two dimensions remained open until 1992, when [[Carolyn S. Gordon|Carolyn Gordon]], [[David Webb (mathematician)|David Webb]], and Scott Wolpert constructed, based on the [[Toshikazu Sunada|Sunada method]], a pair of regions in the plane that have different shapes but identical eigenvalues. The regions are [[concave polygon]]s. The proof that both regions have the same eigenvalues is rather elementary and uses the symmetries of the Laplacian. This idea has been generalized by Buser et al., who constructed numerous similar examples.  So, the answer to Kac's question is: for many shapes, one cannot hear the shape of the drum ''completely''. However, some information can be inferred.\n\nOn the other hand, [[Steve Zelditch]] proved that the answer to Kac's question is positive if one imposes restrictions to certain [[convex set|convex]] planar regions with [[analytic function|analytic]] boundary. It is not known whether two non-convex analytic domains can have the same eigenvalues. It is known that the set of domains isospectral with a given one is compact in the C<sup>∞</sup> topology.  Moreover, the sphere (for instance) is spectrally rigid, by [[Cheng's eigenvalue comparison theorem]].  It is also known, by a result of Osgood, Phillips, and Sarnak that the moduli space of Riemann surfaces of a given genus does not admit a continuous isospectral flow through any point, and is compact in the Fréchet–Schwartz topology.\n\n==Weyl's formula==\n{{main|Weyl law}}\nWeyl's formula states that one can infer the area ''V'' of the drum by counting how rapidly the λ<sub>''n''</sub> grow. We define ''N''(''R'') to be the number of eigenvalues smaller than ''R'' and we get\n\n:<math>V=\\omega_d^{-1}(2\\pi)^d \\lim_{R\\to\\infty}\\frac{N(R)}{R^{d/2}}\\,</math>\n\nwhere ''d'' is the dimension and ''<math>\\omega_d</math>'' is the volume of the ''d''-dimensional unit ball. Weyl also conjectured that the next term in the approximation below would give the perimeter of ''D''. In other words, if ''A'' denotes the length of the perimeter (or the surface area in higher dimension), then one should have\n\n:<math>\\,N(R)=(2\\pi)^{-d}\\omega_d VR^{d/2}+\\frac{1}{4}(2\\pi)^{-d+1}\\omega_{d-1} AR^{(d-1)/2}+o(R^{(d-1)/2}).\\,</math>\n\nFor a smooth boundary, this was proved by  [[Victor Ivrii]] in 1980. The manifold is also not allowed to have a two parameter family of periodic geodesics such as a sphere would have.\n\n==The Weyl–Berry conjecture==\nFor non-smooth boundaries, [[Michael Berry (physicist)|Michael Berry]] conjectured in 1979 that the correction should be of the order of\n\n:<math>R^{D/2}\\,</math>\n\nwhere ''D'' is the [[Hausdorff dimension]] of the boundary. This was disproved by J. Brossard and R. A. Carmona, who then suggested one should replace the Hausdorff dimension with the [[upper box dimension]]. In the plane, this was proved if the boundary has dimension 1 (1993), but mostly disproved for higher dimensions (1996); both results are by Lapidus and [[Carl Pomerance|Pomerance]].\n\n==See also==\n* [[Vibrations of a circular drum]]\n* [[Gassmann triple]]\n* [[Isospectral]]\n* [[Spectral geometry]]\n* an extension to [[iterated function system]] fractals<ref>{{cite book|first1=W.|last1=Arrighetti|first2=G.|last2=Gerosa|title=Can you hear the fractal dimension of a drum?|arxiv=math.SP/0503748 |journal=Applied and Industrial Mathematics in Italy|series=Series on Advances in Mathematics for Applied Sciences|volume=69|pages=65–75|publisher=World Scientific|year=2005|isbn=978-981-256-368-2|doi=10.1142/9789812701817_0007}}</ref>\n\n==Notes==\n<references />\n\n==References==\n* {{citation|url=http://www.ams.org/notices/199501/bers.pdf|first=William|last=Abikoff|title=Remembering Lipman Bers|journal=[[Notices of the AMS]]|date=January 1995|pages=8–18|volume=42|issue=1}}\n* {{cite journal|doi=10.1007/BF01210795|first1=Jean|last1=Brossard|first2=René|last2=Carmona|title=Can one hear the dimension of a fractal?|journal=Comm. Math. Phys.|volume=104|issue=1|year=1986|pages=103–122|bibcode=1986CMaPh.104..103B}}\n* {{citation|first1=Peter|last1=Buser|first2=John|last2=Conway|authorlink2=John Horton Conway|first3=Peter|last3=Doyle|first4=Klaus-Dieter|last4=Semmler|title=Some planar isospectral domains|journal=International Mathematics Research Notices|volume=9|year=1994|pages=391ff}}\n* {{cite journal|last=Chapman|first=S.J.|year=1995|title=Drums that sound the same|journal=[[American Mathematical Monthly]]|volume=102|issue=February|pages=124–138|doi=10.2307/2975346|jstor=2975346}}\n* {{cite journal|last=Giraud|first=Olivier|author2=[[Thas, Koen]] |title=Hearing shapes of drums – mathematical and physical aspects of isospectrality|journal=Reviews of Modern Physics|year=2010|volume=82|issue=3|pages=2213–2255|doi=10.1103/RevModPhys.82.2213|arxiv=1101.1239|bibcode=2010RvMP...82.2213G}}\n* {{citation|first1=Carolyn|last1=Gordon|author1-link=Carolyn S. Gordon|first2=David|last2=Webb|author2-link=David Webb (mathematician)|title=You can't hear the shape of a drum|journal=[[American Scientist]] |volume=84|issue=January–February|pages=46–55}}\n* {{citation|doi=10.1007/BF01231320|first1=C.|last1=Gordon|author1-link=Carolyn S. Gordon|first2=D.|last2=Webb|author2-link=David Webb (mathematician)|first3=S.|last3=Wolpert|title=Isospectral plane domains and surfaces via Riemannian orbifolds|journal=Inventiones Mathematicae|volume=110|year=1992|issue=1|pages=1–22|bibcode = 1992InMat.110....1G }}\n* {{citation|first=V. Ja.|last=Ivrii|title=The second term of the spectral asymptotics for a Laplace–Beltrami operator on manifolds with boundary|journal=Funktsional. Anal. I Prilozhen|volume=14|issue=2|year=1980|pages=25–34|doi=10.1007/BF01086550}} (In [[Russian language|Russian]]).\n* {{cite journal|last=Kac|authorlink=Mark Kac|first=Mark|title=Can One Hear the Shape of a Drum?|url=http://www.maa.org/sites/default/files/pdf/upload_library/22/Ford/MarkKac.pdf|journal=[[American Mathematical Monthly]]|date=April 1966|volume=73|issue=4, part 2|pages=1–23|doi=10.2307/2313748|jstor=2313748}}\n* {{citation|first=Michel L.|last=Lapidus|title=Can one hear the shape of a fractal drum? Partial resolution of the Weyl–Berry conjecture|journal=Geometric Analysis and Computer Graphics (Berkeley, CA, 1988)|volume=17|pages=119–126|series=Math. Sci. Res. Inst. Publ.|issue=17|publisher=Springer|location=New York|year=1991|doi=10.1007/978-1-4613-9711-3_13|isbn=978-1-4613-9713-7}}\n* {{citation|first=Michel L.|last=Lapidus|contribution=Vibrations of fractal drums, the [[Riemann hypothesis]], waves in fractal media, and the Weyl–Berry conjecture|title=Ordinary and Partial Differential Equations, Vol IV, Proc. Twelfth Internat. Conf. (Dundee, Scotland,UK, June 1992)|editors=B. D. Sleeman and R. J. Jarvis|series=Pitman Research Notes in Math. Series|volume=289|publisher=Longman and Technical|location=London|year=1993|pages=126–209}}\n* {{citation|first1=M. L.|last1=Lapidus|first2=M.|last2=van Frankenhuysen|title=Fractal Geometry and Number Theory: Complex dimensions of fractal strings and zeros of zeta functions|publisher=Birkhauser|location=Boston|year=2000}}. (Revised and enlarged second edition to appear in 2005.)\n* {{citation|doi=10.1112/plms/s3-66.1.41|first1=Michel L.|last1=Lapidus|first2=Carl|last2=Pomerance|title=The Riemann zeta-function and the one-dimensional Weyl-Berry conjecture for fractal drums|journal=Proc. London Math. Soc. |series=Series 3|volume=66|issue=1|year=1993|pages=41–69|title-link=Riemann zeta-function|citeseerx=10.1.1.526.854}}\n* {{citation|doi=10.1017/S0305004100074053|first1=Michel L.|last1=Lapidus|first2=Carl|last2=Pomerance|title=Counterexamples to the modified Weyl–Berry conjecture on fractal drums|journal=Math. Proc. Cambridge Philos. Soc.|volume=119|issue=1|year=1996|pages=167–178|bibcode = 1996MPCPS.119..167L }}\n* {{citation|first=John|last=Milnor|authorlink=John Milnor|title=Eigenvalues of the Laplace operator on certain manifolds|journal=Proceedings of the National Academy of Sciences of the United States of America|volume=51|issue=4|year=1964|pages=542ff|bibcode = 1964PNAS...51..542M |doi = 10.1073/pnas.51.4.542|pmid=16591156|pmc=300113}}\n* {{citation|doi=10.2307/1971195|first=T.|last=Sunada|authorlink=Toshikazu Sunada|title=Riemannian coverings and isospectral manifolds|journal=Ann. of Math. |series= 2|volume=121|issue=1|year=1985|pages=169–186|jstor=1971195}}\n* {{citation|doi=10.1007/PL00001633|first=S.|last=Zelditch|title=Spectral determination of analytic bi-axisymmetric plane domains|journal=Geometric and Functional Analysis|volume=10|issue=3|year=2000|pages=628–677|arxiv=math/9901005}}\n\n==External links==\n* [http://www.math.udel.edu/~driscoll/research/drums.html Isospectral Drums] by Toby Driscoll at the University of Delaware\n* [http://math.dartmouth.edu/~doyle/docs/drum/drum.pdf Some planar isospectral domains] by Peter Buser, [[John Horton Conway]], Peter Doyle, and Klaus-Dieter Semmler\n* [http://enterprise.maa.org/mathland/mathland_4_14.html Drums That Sound Alike] by Ivars Peterson at the Mathematical Association of America web site\n* {{MathWorld | title=Isospectral Manifolds | urlname=IsospectralManifolds}}\n* {{springer|title=Dirichlet eigenvalue|id=d/d130170|first=Rafael D.|last=Benguria}}\n\n{{Disproved conjectures}}\n\n{{DEFAULTSORT:Hearing The Shape Of A Drum}}\n[[Category:Partial differential equations]]\n[[Category:Spectral theory]]\n[[Category:Drumming]]"
    },
    {
      "title": "Heat kernel",
      "url": "https://en.wikipedia.org/wiki/Heat_kernel",
      "text": "In the [[mathematics|mathematical]] study of [[heat conduction]] and [[diffusion]], a '''heat kernel''' is the [[fundamental solution]] to the [[heat equation]] on a specified domain with appropriate [[boundary conditions]].  It is also one of the main tools in the study of the [[spectral theory|spectrum]] of the [[Laplace operator]], and is thus of some auxiliary importance throughout [[mathematical physics]].  The heat kernel represents the evolution of [[temperature]] in a region whose boundary is held fixed at a particular temperature (typically zero), such that an initial unit of heat energy is placed at a point at time ''t''&nbsp;=&nbsp;0.\n\n\n[[Image:Fundamental solution to the heat equation.gif|right|thumb|upright=2|Fundamental solution of the one-dimensional heat equation. Red: time course of <math>\\Phi(x,t)</math>. Blue: time courses of <math>\\Phi(x_0,t)</math> for two selected points. [https://www.geogebra.org/classic/SV6PruXx Interactive version.]]]\n\nThe most well-known heat kernel is the heat kernel of ''d''-dimensional [[Euclidean space]] '''R'''<sup>''d''</sup>, which has the form of a time-varying [[Gaussian function]],\n:<math>K(t,x,y) = \\frac{1}{(4\\pi t)^{d/2}} e^{-|x-y|^2/4t}\\,</math>\nThis solves the heat equation\n:<math>\\frac{\\partial K}{\\partial t}(t,x,y) = \\Delta_x K(t,x,y)\\,</math>\nfor all ''t''&nbsp;>&nbsp;0 and ''x'',''y''&nbsp;∈&nbsp;'''R'''<sup>''d''</sup>, where Δ is the Laplacian operator, with the initial condition\n:<math>\\lim_{t \\to 0} K(t,x,y) = \\delta(x-y)=\\delta_x(y)</math>\nwhere δ is a [[Dirac delta distribution]] and the limit is taken in the sense of [[distribution (mathematics)|distributions]].  To wit, for every smooth function φ of [[compact support]],\n:<math>\\lim_{t \\to 0}\\int_{\\mathbf{R}^d} K(t,x,y)\\phi(y)\\,dy = \\phi(x).</math>\n\nOn a more general domain Ω in '''R'''<sup>''d''</sup>, such an explicit formula is not generally possible.  The next simplest cases of a disc or square involve, respectively, [[Bessel functions]] and [[Jacobi theta function]]s.  Nevertheless, the heat kernel (for, say, the [[Dirichlet problem]]) still exists and is [[smooth function|smooth]] for ''t'' > 0 on arbitrary domains and indeed on any [[Riemannian manifold]] [[manifold with boundary|with boundary]], provided the boundary is sufficiently regular.  More precisely, in these more general domains, the heat kernel for the Dirichlet problem is the solution of the initial boundary value problem\n\n: <math>\n\\begin{align}\n& \\frac{\\partial K}{\\partial t}(t,x,y) = \\Delta K(t,x,y) \\text{ for all } t>0 \\text{ and } x,y\\in\\Omega \\\\[6pt]\n& \\lim_{t \\to 0} K(t,x,y) = \\delta_x(y) \\text{ for all } x,y\\in\\Omega \\\\[6pt]\n& K(t,x,y) = 0, \\quad x\\in\\partial\\Omega \\text{ or } y\\in\\partial\\Omega.\n\\end{align}\n</math>\n\nIt is not difficult to derive a formal expression for the heat kernel on an arbitrary domain.  Consider the Dirichlet problem in a connected domain (or manifold with boundary) ''U''.  Let ''λ''<sub>''n''</sub> be the [[eigenvalue]]s for the Dirichlet problem of the Laplacian\n:<math>\\left\\{\n\\begin{array}{ll}\n\\Delta \\phi + \\lambda \\phi = 0 & \\text{in } U\\\\\n\\phi=0 & \\text{on }\\ \\partial U.\n\\end{array}\\right.\n</math>\nLet φ<sub>''n''</sub> denote the associated [[eigenfunction]]s, normalized to be orthonormal in [[Lp space|L<sup>2</sup>(''U'')]].  The inverse Dirichlet Laplacian Δ<sup>−1</sup> is a [[compact operator|compact]] and [[selfadjoint operator]], and so the [[spectral theorem]] implies that the eigenvalues satisfy\n:<math>0 < \\lambda_1 < \\lambda_2\\le \\lambda_3\\le\\cdots,\\quad \\lambda_n\\to\\infty.</math>\nThe heat kernel has the following expression:\n{{NumBlk|:|<math>K(t,x,y) = \\sum_{n=0}^\\infty e^{-\\lambda_n t}\\phi_n(x)\\phi_n(y).</math>|{{EquationRef|1}}}}\nFormally differentiating the series under the sign of the summation shows that this should satisfy the heat equation.  However, convergence and regularity of the series are quite delicate.\n\nThe heat kernel is also sometimes identified with the associated [[integral transform]], defined for compactly supported smooth φ by\n:<math>T\\phi = \\int_\\Omega K(t,x,y)\\phi(y)\\,dy.</math>\nThe [[spectral mapping theorem]] gives a representation of ''T'' in the form\n:<math>T = e^{t\\Delta}.</math>\n\nThere are several geometric results on heat kernels on manifolds; say, short-time asymptotics, long-time asymptotics, and upper/lower bounds of Gaussian type.\n\n==See also==\n\n*[[Heat kernel signature]]\n*[[Minakshisundaram–Pleijel zeta function]]\n*[[Mehler kernel]]\n*[[Weierstrass transform#Generalizations]]\n\n==References==\n\n* {{Citation | last1=Berline | first1=Nicole | last2=Getzler | first2=E. | last3=Vergne | first3=Michèle | title=Heat Kernels and Dirac Operators | publisher=[[Springer-Verlag]] | location=Berlin, New York | year=2004}}\n* {{Citation | last1=Chavel | first1=Isaac | title=Eigenvalues in Riemannian geometry | publisher=[[Academic Press]] | location=Boston, MA | series=Pure and Applied Mathematics | isbn=978-0-12-170640-1 | mr=768584 | year=1984 | volume=115}}.\n* {{Citation | last1=Evans | first1=Lawrence C. | title=Partial differential equations | publisher=[[American Mathematical Society]] | location=Providence, R.I. | isbn=978-0-8218-0772-9 | year=1998}}\n* {{Citation | last1=Gilkey | first1=Peter B. | title=Invariance Theory, the Heat Equation, and the Atiyah–Singer Theorem | url=http://www.emis.de/monographs/gilkey/ | isbn=978-0-8493-7874-4 | year=1994}}\n*{{Citation | last1=Grigor'yan | first1=Alexander | title=Heat kernel and analysis on manifolds | url=https://books.google.com/books?id=X7QQcVa2EWsC | publisher=[[American Mathematical Society]] | location=Providence, R.I. | series=AMS/IP Studies in Advanced Mathematics | isbn=978-0-8218-4935-4 | mr=2569498 | year=2009 | volume=47}}\n*{{citation | first1=Motoko | last1=Kotani | first2=Toshikazu |last2=[[Toshikazu Sunada|Sunada]]|  title=Albanese maps and an off diagonal long time asymptotic for the heat kernel | journal=Comm. Math. Phys. | volume=209 | year=2000 | pages=633–670 | doi=10.1007/s002200050033|bibcode = 2000CMaPh.209..633K }}\n\n{{DEFAULTSORT:Heat Kernel}}\n[[Category:Heat conduction]]\n[[Category:Spectral theory]]\n[[Category:Parabolic partial differential equations]]"
    },
    {
      "title": "Isospectral",
      "url": "https://en.wikipedia.org/wiki/Isospectral",
      "text": "In [[mathematics]], two [[linear operator]]s are called '''isospectral''' or '''cospectral''' if they have the same [[spectrum of an operator|spectrum]]. Roughly speaking, they are supposed to have the same [[Set (mathematics)|sets]] of [[eigenvalue]]s, when those are counted with [[Multiplicity (mathematics)|multiplicity]].\n\nThe theory of isospectral operators is markedly different depending on whether the space is finite or infinite dimensional.  In finite-dimensions, one essentially deals with square [[matrix (mathematics)|matrices]].\n\nIn infinite dimensions, the spectrum need not consist solely of isolated eigenvalues.  However, the case of a [[compact operator]] on a [[Hilbert space]] (or [[Banach space]]) is still tractable, since the eigenvalues are at most countable with at most a single limit point λ&nbsp;=&nbsp;0.  The most studied isospectral problem in infinite dimensions is that of the [[Laplace operator]] on a domain in '''R'''<sup>2</sup>.  Two such domains are called isospectral if their Laplacians are isospectral.  The problem of inferring the geometrical properties of a domain from the spectrum of its Laplacian is often known as [[hearing the shape of a drum]].\n\n==Finite dimensional spaces==\n\nIn the case of operators on finite-dimensional vector spaces, for [[complex number|complex]] square matrices, the relation of being isospectral for two [[diagonalizable matrix|diagonalizable matrices]] is just [[similar (linear algebra)|similarity]]. This doesn't however reduce completely the interest of the concept, since we can have an '''isospectral family''' of matrices of shape ''A''(''t'') = ''M''(''t'')<sup>&minus;1</sup>''AM''(''t'') depending on a [[parameter]] ''t'' in a complicated way. This is an evolution of a matrix that happens inside one similarity class.\n\nA fundamental insight in [[soliton]] theory was that the [[infinitesimal]] analogue of that equation, namely\n\n:''A'' &prime; = [''A'', ''M''] = ''AM'' &minus; ''MA''\n\nwas behind the conservation laws that were responsible for keeping solitons from dissipating. That is, the preservation of spectrum was an interpretation of the conservation mechanism. The identification of so-called [[Lax pair]]s (P,L) giving rise to analogous equations, by [[Peter Lax]], showed how linear machinery could explain the non-linear behaviour.\n\n== Isospectral manifolds ==\n\nTwo closed Riemannian manifolds are said to be isospectral if the eigenvalues of their [[Laplace–Beltrami operator]] (Laplacians), counted multiplicities, coincide. One of fundamental problems in spectral geometry is to ask to what extent the eigenvalues determine the geometry of a given manifold.\n\nThere are many examples of isospectral manifolds which are not isometric. The first example was given in 1964 by [[John Milnor]]. He constructed a pair of flat tori of 16 dimension, using arithmetic lattices first studied by [[Ernst Witt]]. After this example, many isospectral pairs in dimension two and higher were constructed (for instance, by M. F. Vignéras, A. Ikeda, H. Urakawa, C. Gordon). In particular {{harvtxt|Vignéras|1980}}, based on the [[Selberg trace formula]] for PSL(2,'''R''') and PSL(2,'''C'''), constructed examples of isospectral, non-isometric closed hyperbolic 2-manifolds and 3-manifolds as quotients of hyperbolic 2-space and 3-space by arithmetic subgroups, constructed using quaternion algebras associated with quadratic extensions of the rationals by [[class field theory]].<ref>{{harvnb|Maclachlan|Reid|2003}}</ref>  In this case Selberg's trace formula shows that the spectrum of the Laplacian fully determines the ''length spectrum''{{Citation needed|date=May 2010}}, the set of lengths of closed geodesics in each free homotopy class, along with the twist along the geodesic in the 3-dimensional case.<ref>This amounts to knowing the conjugacy class of the corresponding group element in PSL(2,'''R''') or PSL(2,'''C''').\n</ref>\n\nIn 1985 [[Toshikazu Sunada]] found a general method of construction based on a [[covering space]] technique, which, either in its original or certain generalized versions, came to be known as the Sunada method or Sunada construction. Like the previous methods it is based on the trace formula, via the [[Selberg zeta function]]. Sunada noticed that the method of constructing number fields with the same [[Dedekind zeta function]] could be adapted to compact manifolds. His method relies on the fact that if ''M'' is a finite covering of a compact Riemannian manifold\n''M''<sub>0</sub> with ''G'' the [[finite group]] of [[deck transformation]]s and ''H''<sub>1</sub>, ''H''<sub>2</sub> are subgroups of ''G'' meeting each conjugacy class of ''G'' in the same number of elements, then the manifolds ''H''<sub>1</sub> \\ ''M'' and ''H''<sub>2</sub> \\ ''M'' are isospectral\nbut not necessarily isometric. Although this does not recapture the arithmetic examples of Milnor and Vignéras{{Citation needed|date=May 2010}}, Sunada's method yields many known examples of isospectral manifolds. It led C. Gordon, [[David Webb (mathematician)|D. Webb]] and S. Wolpert to the discovery in 1991 of a counter example to [[Mark Kac]]'s problem \"[[Hearing the shape of a drum|Can one hear the shape of a drum?]]\" An elementary treatment, based on Sunada's method, was later given in {{harvtxt|Buser|Conway|Doyle|Semmler|1994}}.\n\nSunada's idea also stimulated the attempt to find isospectral examples which could not be obtained by his technique. Among many examples, the most striking one is a simply connected example of {{harvtxt|Schueth|1999}}.\n\n==See also==\n*[[Hearing the shape of a drum]]\n*[[Spectral geometry]]\n\n==Notes==\n{{Reflist}}\n\n== References ==\n*{{citation|last=Bérard|first=Pierre|title=Variétés riemanniennes isospectrales non isométriques, exposé 705|series=Séminaire Bourbaki|volume=31|year=1988–1989|url=http://archive.numdam.org/ARCHIVE/SB/SB_1988-1989__31_/SB_1988-1989__31__127_0/SB_1988-1989__31__127_0.pdf|postscript=<!--none-->}}\n*{{citation|doi=10.2307/2322897|title=Constructing Isospectral Manifolds\n |first=Robert\n |last= Brooks\n |author1-link= Robert W. Brooks\n |journal=American Mathematical Monthly|volume= 95|year= 1988|pages=823–839|issue=9|publisher=Mathematical Association of America|postscript=<!--none-->|jstor=2322897}}\n*{{citation|last=Buser|first=Peter|title=Isospectral Riemann surfaces|journal=Annales de l'Institut Fourier |year=1986|\nurl=http://archive.numdam.org/ARCHIVE/AIF/AIF_1986__36_2/AIF_1986__36_2_167_0/AIF_1986__36_2_167_0.pdf| volume=36|pages= 167–192|postscript=<!--none-->|doi=10.5802/aif.1054}}\n*{{citation|first=Peter|last= Buser|first2= John|last2=Conway|first3= Peter|last3= Doyle|first4= Klaus-Dieter|last4= Semmler|\ntitle=Some planar isospectral domains|journal=Int. Math. Res. Notices| year=1994|pages= 391–400|url=http://www.geom.uiuc.edu/docs/research/drums/cover/cover.html|postscript=<!--none-->}}\n*{{citation|doi=10.1002/cpa.3160250302|last=McKean|first=H. P.|title=Selberg's trace formula as applied to a compact Riemann surface|journal=Comm. Pure Appl. Math.\n|volume=25|year=1972|issue=3|pages= 225–246|postscript=<!--none-->}}\n*{{citation|title=The Arithmetic of Hyperbolic 3-manifolds|first=C.|last=Maclachlan|first2= Alan W. |last2=Reid|publisher= Springer|year= 2003\n|isbn=0387983864|pages=383–394|postscript=<!--none-->}},\n* {{Citation | doi=10.1073/pnas.51.4.542 | first=John|last=Milnor | title=Eigenvalues of the Laplace operator on certain manifolds | journal=Proc. Natl. Acad. Sci. USA | volume=51 | year=1964 | pages=542 | pmid=16591156 | issue=4 | pmc=300113 | postscript=<!--none--> | bibcode=1964PNAS...51..542M }}\n* {{Citation | doi=10.2307/121026 | first=D.|last= Schueth | title=Continuous families of isospectral metrics on simply connected manifolds | journal=Annals of Mathematics  | volume=149 | issue=1 | year=1999 | pages=287–308 | postscript=<!--none--> | jstor=121026 | arxiv=dg-ga/9711010 }}\n*{{citation|last=Selberg|first= Atle|title=Harmonic analysis and discontinuous groups in weakly symmetric Riemannian spaces with applications to Dirichlet series|journal=J. Indian Math. Soc.|volume= 20|year=1956| pages=47–87|postscript=<!--none-->}}\n* {{Citation | doi=10.2307/1971195 | first=T.|last= Sunada | title=Riemannian coverings and isospectral manifolds | journal=Annals of Mathematics | volume=121 | issue=1 | year=1985 | pages=169&ndash;186 | postscript=<!--none--> | jstor=1971195 }}\n*{{citation|doi=10.2307/1971319|first=Marie-France|last=Vignéras|title=Variétés riemanniennes isospectrales et non isométriques|journal=Annals of Mathematics|year=1980|pages=21–32| volume=112|issue=1|publisher=Annals of Mathematics|postscript=<!--none-->|jstor=1971319}}\n*{{citation|doi=10.1090/S0002-9904-1977-14425-X|last=Wolpert|first=Scott|title=The eigenvalue spectrum as moduli for compact Riemann surfaces|journal=Bull. Amer. Math. Soc.|volume= 83|issue=6\n|year=1977|pages= 1306–1308|url=http://www.ams.org/bull/1977-83-06/S0002-9904-1977-14425-X/S0002-9904-1977-14425-X.pdf|postscript=<!--none-->}}\n*{{citation|doi=10.2307/1971114|last=Wolpert|first=Scott|title=The length spectra as moduli for compact Riemann surfaces|journal=Annals of Mathematics|volume= 109|issue=2|year=1979|pages= 323–351|postscript=<!--none-->|jstor=1971114}}\n\n[[Category:Spectral theory]]"
    },
    {
      "title": "Krein–Rutman theorem",
      "url": "https://en.wikipedia.org/wiki/Krein%E2%80%93Rutman_theorem",
      "text": "In [[functional analysis]], the '''Krein&ndash;Rutman theorem''' is a generalisation of the [[Perron–Frobenius theorem]] to infinite-dimensional [[Banach space]]s.<ref>{{cite book|mr=2205529|last=Du|first=Y.|title=Order structure and topological methods in nonlinear partial differential equations. Vol. 1. Maximum principles and applications|series=Series in Partial Differential Equations and Applications|publisher=World Scientific Publishing Co. Pte. Ltd.|location=Hackensack, NJ|year=2006|isbn=981-256-624-4|chapter=1. Krein&ndash;Rutman Theorem and the Principal Eigenvalue}}</ref> It was proved by [[Mark Krein|Krein]] and [[Rutman]] in 1948.<ref>{{cite journal|mr=0027128|last1=Kreĭn|first1=M.G.|last2=Rutman|first2=M.A.|title=Linear operators leaving invariant a cone in a Banach space|language=Russian|journal=\nUspehi Matem. Nauk (N. S.)|volume=3|year=1948|issue=1(23)|pages=1&ndash;95}}. English translation: {{cite journal|mr=0038008|last1=Kreĭn|first1=M.G.|last2=Rutman|first2=M.A.|title=Linear operators leaving invariant a cone in a Banach space|journal=Amer. Math. Soc. Transl.|year=1950|volume=1950|issue=26}}</ref>\n\n==Statement==\n\nLet <math>X</math> be a [[Banach space]], and let <math>K\\subset X</math> be a [[convex cone]] such that <math>K-K</math> is [[dense set|dense]] in <math>X</math>. Let <math>T:X\\to X</math> be a non-zero [[compact operator]] which is ''positive'', meaning that <math>T(K)\\subset K</math>, and assume that its [[spectral radius]] <math>r(T)</math> is strictly positive.\n\nThen <math>r(T)</math> is an [[eigenvalue]] <math>T</math> of with positive [[eigenvector]], meaning that there exists <math>u\\in K\\setminus {0}</math> such that <math>T(u)=r(T)u</math>.\n\n==De Pagter's theorem==\n\nIf the positive operator <math>T</math> is assumed  to be ideal ''irreducible'', namely, \nthere is no ideal <math>J\\ne0</math>,<math>X</math> such that <math>TJ \\subset J</math>, then de Pagter's theorem<ref>{{cite journal|mr=0835399|last=de Pagter|first=B.|title=Irreducible compact operators|journal=Math. Z.|volume=192|year=1986|issue=1|pages=149&ndash;153|doi=10.1007/bf01162028}}</ref> asserts that <math>r(T)>0</math>.\n\nTherefore, for ideal irreducible operators the assumption <math>r(T)>0</math> is not needed.\n\n==Notes==\n{{Reflist}}\n\n{{DEFAULTSORT:Krein-Rutman theorem}}\n[[Category:Spectral theory]]\n[[Category:Theorems in functional analysis]]"
    },
    {
      "title": "Kuznetsov trace formula",
      "url": "https://en.wikipedia.org/wiki/Kuznetsov_trace_formula",
      "text": "In [[analytic number theory]], the '''Kuznetsov trace formula''' is an extension of the [[Petersson trace formula]].\n\nThe Kuznetsov or ''relative trace'' formula connects [[Kloosterman sum]]s at a deep level with the spectral theory of [[automorphic form]]s. Originally this could have been stated as follows. Let \n\n:<math> g: \\mathbb{R}\\rightarrow \\mathbb{R} </math> \n\nbe a sufficiently \"[[well behaved]]\" function. Then one calls identities of the following type ''Kuznetsov trace formula'':\n\n:<math>\n\\sum_{c\\equiv 0\\, \\text{mod}\\ N} c^{-r} K(m,n,c) g\\left(\\frac{4\\pi \\sqrt{mn}}{c}\\right) = \\text{Integral transform}\\ +\\ \\text{Spectral terms}.\n</math>\n\nThe integral transform part is some [[integral transform]] of ''g'' and the spectral part is a sum of Fourier coefficients, taken over spaces of holomorphic and non-holomorphic modular forms twisted with some integral transform of ''g''. The Kuznetsov trace formula was found by Kuznetsov while studying the growth of weight zero automorphic functions.<ref>N.V. Kuznecov, ''Petersson's conjecture for forms of weight zero and Linnik's conjecture. Sums of Kloosterman sums'', Mathematics of the USSR-Sbornik 39(3), (1981).</ref> Using estimates on Kloosterman sums he was able to derive estimates for Fourier coefficients of modular forms in cases where [[Pierre Deligne]]'s proof of the [[Weil conjectures]] was not applicable. \n\nIt was later translated by Jacquet to a [[representation theory|representation theoretic]] framework. Let <math> G </math> be a [[reductive group]] over a [[number field]] ''F'' and <math> H\\subset G </math> be a subgroup. While the usual [[Selberg trace formula|trace formula]] studies the [[harmonic analysis]] on ''G'', the relative trace formula is a tool for studying the harmonic analysis on the [[symmetric space]] <math> G/H </math>. For an overview and numerous applications Cogdell, J.W. and I. Piatetski-Shapiro, ''The arithmetic and spectral analysis of Poincaré series'', volume 13 of ''Perspectives in mathematics''. Academic Press Inc., Boston, MA, (1990).\n\n== References ==\n\n<references/>\n*{{Citation | last1=Kuznecov | first1=N. V. | title=The Petersson conjecture for cusp forms of weight zero and the Linnik conjecture. Sums of Kloosterman sums |mr=568983 | year=1980 | journal=Matematicheskii Sbornik|series=Novaya Seriya | issn=0368-8666 | volume=111(153) | issue=3 | pages=334–383}}\n\n[[Category:Automorphic forms]]\n[[Category:Spectral theory]]\n[[Category:Theorems in analytic number theory]]"
    },
    {
      "title": "Lax pair",
      "url": "https://en.wikipedia.org/wiki/Lax_pair",
      "text": "{{more footnotes|date=June 2017}}\nIn [[mathematics]], in the theory of [[integrable systems]], a '''Lax pair''' is a pair of time-dependent matrices or [[operator (mathematics)|operator]]s that satisfy a corresponding [[differential equation]], called the ''Lax equation''. Lax pairs were introduced by [[Peter Lax]] to discuss [[soliton]]s in [[continuous media]]. The [[inverse scattering transform]] makes use of the Lax equations to solve such systems.\n\n==Definition==\nA Lax pair is a pair of matrices or operators <math>L(t), P(t)</math> dependent on time and acting on a fixed [[Hilbert space]], and satisfying '''Lax's equation''':\n\n:<math>\\frac{dL}{dt}=[P,L]</math>\n\nwhere <math>[P,L]=PL-LP</math> is the [[commutator]].\nOften, as in the example below, <math>P</math> depends on  <math>L</math> in a prescribed way, so this is a nonlinear equation for  <math>L</math> as a function of <math>t</math>.\n\n==Isospectral property==\nIt can then be shown that the [[eigenvalue]]s and more generally the [[Operator spectrum|spectrum]] of ''L'' are independent of ''t''. The matrices/operators ''L'' are said to be  ''[[isospectral]]'' as <math>t</math> varies.\n\nThe core observation is that the matrices <math>L(t)</math> are all similar by virtue of\n\n:<math>L(t)=U(t,s) L(s) U(t,s)^{-1}</math>\n\nwhere <math>U(t,s)</math> is the solution of the [[Cauchy problem]]\n\n:<math> \\frac{d}{dt} U(t,s) = P(t) U(t,s), \\qquad U(s,s) = I,</math>\n\nwhere ''I'' denotes the identity matrix. Note that if ''P(t)'' is [[skew-adjoint]], ''U(t,s)'' will be [[unitary operator|unitary]].\n\nIn other words, to solve the eigenvalue problem ''Lψ = λψ'' at time ''t'', it is possible to solve the same problem at time 0 where L is generally known better, and to propagate the solution with the following formulas:\n:<math>\\lambda(t)=\\lambda(0)</math> (no change in spectrum)\n:<math>\\frac{\\partial \\psi}{\\partial t}=P \\psi.</math>\n\n=== Link with the inverse scattering method ===\nThe above property is the basis for the inverse scattering method. In this method, ''L'' and ''P'' act on a [[functional space]] (thus ''ψ = ψ(t,x)''), and depend on an unknown function ''u(t,x)'' which is to be determined. It is generally assumed that ''u(0,x)'' is known, and that ''P'' does not depend on ''u'' in the scattering region where <math>\\Vert x \\Vert\\to \\infty</math>.\nThe method then takes the following form:\n# Compute the spectrum of <math>L(0)</math>, giving <math>\\lambda</math> and <math>\\psi(0,x)</math>,\n# In the scattering region where <math>P</math> is known, propagate <math>\\psi</math> in time by using <math>\\frac{\\partial \\psi}{\\partial t}(t,x)=P \\psi(t,x)</math> with initial condition <math>\\psi(0,x)</math>,\n# Knowing <math>\\psi</math> in the scattering region, compute <math>L(t)</math> and/or <math>u(t,x)</math>.\n\n== Example – Korteweg–de Vries ==\nThe [[Korteweg–de Vries equation]] \n:<math>u_t=6uu_x-u_{xxx}.\\,</math>\ncan be reformulated as the Lax equation\n:<math>L_t=[P,L]\\,</math>\nwith\n:<math>L=-\\partial_{x}^2+u\\,</math> (a [[Sturm–Liouville operator]])\n:<math>P= -4\\partial_{x}^3+6u\\partial_{x}+3u_x\\,</math>\nwhere all derivatives act on all objects to the right. This accounts for the infinite number of first integrals of the KdV equation.\n\n== Example – Kovalevskaya ==\nThe previous example used an infinite dimensional Hilbert space. Examples are also possible with finite dimensional Hilbert spaces. These include [[Kovalevskaya top]] and the generalization to include an electric Field <math>\\vec{h}</math>.<ref>{{Cite journal|last=Bobenko|first=A. I.|last2=Reyman|first2=A. G.|last3=Semenov-Tian-Shansky|first3=M. A.|date=1989|title=The Kowalewski top 99 years later: a Lax pair, generalizations and explicit solutions|url=https://projecteuclid.org/euclid.cmp/1104178400|journal=Communications in Mathematical Physics|volume=122|issue=2|pages=321–354|issn=0010-3616|bibcode=1989CMaPh.122..321B|doi=10.1007/BF01257419}}</ref>\n\n<math>\\begin{align}\nL &= \\begin{pmatrix}\ng_1 + h_2 & g_2 + h_1 & g_3 & h_3\\\\\ng_2 + h_1 & -g_1 + h_2 & h_3 & -g_3\\\\\ng_3 & h_3 & -g_1 - h_2 & g_2 - h_1\\\\\nh_3 & -g_3 & g_2 - h_1 & g_1 + h_2\\\\\n\\end{pmatrix} \\lambda^{-1}\\\\\n&+ \\begin{pmatrix}\n0 & 0 & -l_2 & -l_1\\\\\n0 & 0 & l_1 & -l_2\\\\\nl_2 & -l_1 & -2 \\lambda & -2 l_3 \\\\\nl_1 & l_2 & 2 l_3 & 2 \\lambda\\\\\n\\end{pmatrix}\n\\\\\nP &= \\frac{-1}{2} \\begin{pmatrix}\n0 & -2 l_3 & l_2 & l_1\\\\\n2 l_3 & 0 & -l_1 & l_2\\\\\n-l_2 & l_1 & 2 \\lambda & 2 l_3 + \\gamma\\\\\n-l_1 & -l_2 & -2 l_3 & -2\\lambda\\\\\n\\end{pmatrix}\n\\end{align}</math>\n\n==Equations with a Lax pair==\nFurther examples of systems of equations that can be formulated as a Lax pair include:\n\n* [[Benjamin–Ono equation]]\n* One-dimensional cubic [[non-linear Schrödinger equation]]\n* [[Davey–Stewartson equation|Davey–Stewartson system]]\n* Integrable systems with contact Lax pairs<ref>A. Sergyeyev, New integrable (3+1)-dimensional systems and contact geometry, Lett. Math. Phys. 108 (2018), no. 2, 359-376, {{arXiv|1401.2122}} {{doi|10.1007/s11005-017-1013-4}}</ref>\n* [[Kadomtsev–Petviashvili equation]]\n* [[Korteweg–de Vries equation]]\n* [[KdV hierarchy]]\n* [[Modified Korteweg–de Vries equation]]\n* [[Sine-Gordon equation]]\n* [[Toda lattice]]\n* [[Lagrange, Euler, and Kovalevskaya tops]]\n\n==References==\n{{Reflist}}\n* {{citation|first=P.|last= Lax|title=Integrals of nonlinear equations of evolution and solitary waves|journal=Comm. Pure Applied Math.|volume=21|year=1968|pages= 467–490|doi=10.1002/cpa.3160210503|issue=5 }} [https://archive.org/details/integralsofnonli00laxp archive]\n* P. Lax and R.S. Phillips, ''Scattering Theory for Automorphic Functions''[https://projecteuclid.org/euclid.bams/1183546232], (1976) Princeton University Press.\n\n[[Category:Differential equations]]\n[[Category:Automorphic forms]]\n[[Category:Spectral theory]]\n[[Category:Exactly solvable models]]"
    },
    {
      "title": "Limiting absorption principle",
      "url": "https://en.wikipedia.org/wiki/Limiting_absorption_principle",
      "text": "In mathematics, the '''limiting absorption principle (LAP)''' is a concept from [[operator theory]] and [[scattering theory]] that consists of choosing the \"correct\" [[resolvent formalism|resolvent]] of a [[linear operator]] at the [[essential spectrum]] based on the behavior of the resolvent near the essential spectrum. The term is often used to indicate that the resolvent, when considered not in the original space (which is usually <math>L^2</math>), but in certain weighted spaces (usually <math>L^2_s</math>, see below), has a limit as the spectral parameter approaches the essential spectrum.\n\n=Relation to the scattering theory=\nAs an example, let us consider the resolvent of the [[Laplace operator]] in one dimension, <math>A=-\\partial_x^2,</math> acting in <math>L^2(\\R)</math> and defined on the [[Unbounded_operator|domain]] <math>D(A)=H^2(\\R)</math>. Let us describe its resolvent, <math>R(\\lambda)=(A-\\lambda I)^{-1}</math>. Given the equation\n:<math>(-\\partial_x^2-\\lambda)u(x)=f(x),\\quad x\\in\\R,\\quad f\\in L^2(\\R)</math>,\nthen, for the spectral parameter <math>\\lambda</math> from the [[resolvent set]] <math>\\C\\smallsetminus\\overline{\\R_+}</math>, the solution <math>u\\in L^2(\\R)</math> is given by\n<math>u(x)=(R(\\lambda)f)(x)=(G(\\cdot,\\lambda)*f)(x),</math>\nwhere <math>G(\\cdot,\\lambda)*f</math> is the [[convolution]] of {{mvar|f}} with the [[fundamental solution]] {{mvar|G}}:\n:<math>(G(\\cdot,\\lambda)*f)(x)=\\int_\\R G(x-y;\\lambda)f(y) \\, dy,</math>\nwith the fundamental solution given by\n:<math>\nG(x;\\lambda)=\\frac{1}{2\\sqrt{-\\lambda}}e^{-|x|\\sqrt{-\\lambda}},\n\\quad\n\\lambda\\in\\C\\smallsetminus\\overline{\\R_{+}}.\n</math>\nIt is clear which of the branches of the square root one needs to pick: the one with positive real part (which decays for large absolute value of {{mvar|x}}), so that the convolution of {{mvar|G}} with <math>f\\in L^2(\\R)</math> makes sense.\n\nOne can consider the limit of the fundamental solution <math>G(x;\\lambda)</math> as <math>\\lambda</math> approaches the spectrum of <math>-\\partial_x^2</math>, given by\n<math>\\sigma(-\\partial_x^2)=\\overline{\\R_+}=[0,+\\infty)</math>.\nDepending on whether <math>\\lambda</math> approaches the spectrum from above or from below, there will be two different limiting expressions:\n<math>G_+(x;\\lambda)=\\lim_{\\varepsilon\\to 0+}G(x;\\lambda+i\\varepsilon)=-\\frac{1}{2i\\sqrt{\\lambda}}e^{i |x| \\sqrt{\\lambda}}</math>\nif <math>\\lambda=|\\lambda|+i 0</math> (when <math>\\lambda</math> approaches <math>\\R_+</math> from above) and\n<math>G_-(x;\\lambda)=\\lim_{\\varepsilon\\to 0+}G(x;\\lambda-i\\varepsilon)=\\frac{1}{2i\\sqrt{\\lambda}}e^{-i |x| \\sqrt{\\lambda}}</math>\n(when approaching <math>\\R_+</math> from below).\n\nWhat do these two different limits correspond to?\nLet us recall that one arrives at the above spectral problem when studying the [[Schrodinger equation|Schr&ouml;dinger equation]],\n\n:<math>i\\,\\partial_t\\psi(t,x)=-\\partial_x^2\\psi(t,x),\\quad t\\in\\R, \\quad x\\in\\R.</math>\n\nThe word \"absorption\" is due to the fact that if the medium were absorbing, then the equation would be\n<math>i\\,\\partial_t\\psi(t,x)=-\\partial_x^2\\psi(t,x)-i\\varepsilon\\psi(t,x)</math>, the solution with <math>\\varepsilon>0</math> would gain a temporal decay: <math>\\psi(t,x)\\to\\psi(t,x)e^{-\\varepsilon t}</math>, <math>t\\to+\\infty</math>; the \"limiting absorption\" means that this imaginary part tends to zero. Due to this decay in time for positive times, the Fourier transform in time of the solution,\n\n:<math>\\hat\\psi(t,x)=\\int_\\R e^{i\\lambda t}\\psi(t,x) \\, dt,</math>\n\ncould be analytically extended into a small region of the lower half-plane, <math>\\lambda\\in\\C</math>, with <math>\\Im\\lambda>-\\varepsilon</math>. In this sense, the \"correct\" resolvent, the one corresponding to the outgoing waves, would be represented by the operator <math>R_-(\\lambda)</math> with the integral kernel <math>G_-(x-y,\\lambda)</math>, which is defined as the limit of the resolvent when approaching the spectrum from the region <math>\\Im\\lambda<0</math>.<ref>{{ cite book\n|author=Smirnov, V.I.\n|title=Course in Higher Mathematics\n|volume=4\n|publisher=Moscow, Nauka\n|url=http://edu.sernam.ru/book_sm_math42.php?id=133\n}}</ref>\n\n=Estimates in the weighted spaces=\nLet <math>A:\\,X\\to X</math> be a [[linear operator]] in a [[Banach space]] <math>X</math>, defined on the domain <math>D(A)\\subset X</math>.\nFor the values of the spectral parameter from the resolvent set of the operator, <math>\\lambda\\in\\rho(A)\\subset\\C</math>, the resolvent <math>R(\\lambda)=(A-\\lambda I)^{-1}</math> is bounded when considered as a linear operator acting from <math>X</math> to itself, <math>R(\\lambda):\\,X\\to X</math>, but its bound depends on the spectral parameter <math>\\lambda</math> and tends to infinity as <math>\\lambda</math> approaches the spectrum of the operator, <math>\\sigma(A)=\\C\\smallsetminus\\rho(A)</math>. More precisely, there is the relation\n\n:<math>\n\\Vert R(\\lambda)\\Vert\\ge\\frac{1}{\\operatorname{dist}(\\lambda,\\sigma(A))}, \\qquad \\lambda\\in\\rho(A).\n</math>\n\nIn recent years, many scientists refer to the \"limiting absorption principle\" when they want to say that the resolvent <math>R(\\lambda)</math> of a particular operator {{mvar|A}}, when considered as acting in certain weighted spaces, has a limit (and/or remains uniformly bounded) as the spectral parameter <math>\\lambda</math> approaches the essential spectrum, <math>\\sigma_{ess}(A)</math>. \nFor instance, in the above example of the Laplace operator in one dimension, <math>A=-\\partial_x^2:\\,L^2(\\R)\\to L^2(\\R)</math>, defined on the domain <math>D(A)=H^2(\\R)</math>, for <math>\\lambda>0</math>, both operators <math>R_\\pm(\\lambda)</math> with the integral kernels <math>G_\\pm(x-y;\\lambda)</math> are not bounded in <math>L^2</math> (that is, as operators from <math>L^2</math> to itself), but will both be bounded when considered as operators\n:<math>R_\\pm(\\lambda):\\;L^2_s(\\R)\\to L^2_{-s}(\\R),\\quad s>1/2,\\quad\\lambda\\in\\C\\smallsetminus\\overline{\\R_+},</math>\n\nwhere the spaces <math>L^2_s(\\R)</math> are defined as spaces of [[locally integrable]] functions such that their <math>L^2_s</math>-norm,\n\n:<math>\n\\Vert u\\Vert_{L^2_s(\\R)}^2=\\int_\\R (1+x^2)^s|u(x)|^2 \\, dx,\n</math>\n\nis finite.<ref>{{cite journal\n|author1=Agmon, S\n|title=Spectral properties of Schr&ouml;dinger operators and scattering theory,\n|journal=Ann. Scuola Norm. Sup. Pisa Cl. Sci. (4)\n|volume=2\n|year=1975\n|pages=151–218\n|url=http://archive.numdam.org/ARCHIVE/ASNSP/ASNSP_1975_4_2_2/ASNSP_1975_4_2_2_151_0/ASNSP_1975_4_2_2_151_0.pdf\n}}</ref><ref>{{cite book |first1 = Michael C. |last1 = Reed|author1-link=Michael C. Reed |first2 = Barry |last2 = Simon |author2-link = Barry Simon |title = Methods of modern mathematical physics. Analysis of operators |volume=4 |publisher = Academic Press |year = 1978 |isbn = 0-12-585004-2}}</ref>\n\n==References==\n{{reflist}}\n\n{{Functional Analysis}}\n\n[[Category:Linear operators]]\n[[Category:Operator theory]]\n[[Category:Scattering theory]]\n[[Category:Spectral theory]]"
    },
    {
      "title": "Min-max theorem",
      "url": "https://en.wikipedia.org/wiki/Min-max_theorem",
      "text": "{{confuse|Minimax theorem}}\n{{redirect-distinguish|Variational theorem|variational principle}}\n{{Refimprove|date=November 2011}}\n\nIn [[linear algebra]] and [[functional analysis]], the '''min-max theorem''', or '''variational theorem''', or '''Courant&ndash;Fischer&ndash;Weyl min-max principle''', is a result that gives a variational characterization of [[Eigenvalues and eigenvectors|eigenvalues]] of [[Compact operator on Hilbert space|compact]] Hermitian operators on [[Hilbert spaces]]. It can be viewed as the starting point of many results of similar nature.\n\nThis article first discusses the finite-dimensional case and its applications before considering compact operators on infinite-dimensional Hilbert spaces. We will see that for compact operators, the proof of the main theorem uses essentially the same idea from the finite-dimensional argument.\n\nIn the case that the operator is non-Hermitian, the theorem provides an equivalent characterization of the associated [[singular values]]. The min-max theorem can be extended to [[self-adjoint operator]]s that are bounded below.\n\n== Matrices ==\nLet {{mvar|A}} be a {{math|''n'' × ''n''}} [[Hermitian matrix]]. As with many other variational results on eigenvalues, one considers the [[Rayleigh quotient|Rayleigh&ndash;Ritz quotient]] {{math|''R<sub>A</sub>'' : '''C'''<sup>''n''</sup> \\ {0} → '''R'''}} defined by\n\n:<math>R_A(x) = \\frac{(Ax, x)}{(x,x)}</math>\n\nwhere {{math|(⋅, ⋅)}} denotes the Euclidean inner product on {{math|'''C'''<sup>''n''</sup>}}. Clearly, the Rayleigh quotient of an eigenvector is its associated eigenvalue. Equivalently, the Rayleigh&ndash;Ritz quotient can be replaced by\n\n:<math>f(x) = (Ax, x), \\; \\|x\\| = 1.</math>\n\nFor Hermitian matrices, the range of the continuous function ''R<sub>A</sub>''(''x''), or ''f''(''x''), is a compact subset [''a'', ''b''] of the real line. The maximum ''b'' and the minimum ''a'' are the largest and smallest eigenvalue of ''A'', respectively. The min-max theorem is a refinement of this fact.\n\n=== Min-max theorem ===\nLet {{mvar|A}} be an {{math|''n'' × ''n''}} [[Hermitian matrix]] with eigenvalues {{math|''λ''<sub>1</sub> ≤ ... ≤ ''λ<sub>k</sub>'' ≤ ... ≤ ''λ<sub>n</sub>''}} then\n\n:<math>\\lambda_k = \\min_U \\{ \\max_x \\{ R_A(x) \\mid x \\in U \\text{ and } x \\neq 0 \\} \\mid \\dim(U)=k \\}</math>\nand\n:<math>\\lambda_k = \\max_U \\{ \\min_x \\{ R_A(x) \\mid x \\in U \\text{ and } x \\neq 0 \\} \\mid \\dim(U)=n-k+1 \\}</math>\nin particular,\n:<math>\\lambda_1 \\leq R_A(x) \\leq \\lambda_n \\quad\\forall x \\in \\mathbf{C}^n\\backslash\\{0\\}</math>\nand these bounds are attained when {{mvar|x}} is an eigenvector of the appropriate eigenvalues.\n\nAlso note that the simpler formulation for the maximal eigenvalue ''λ''<sub>n</sub> is given by: \n:<math> \\lambda_n = \\max \\{R_A(x) : x \\neq 0 \\}.  </math>\nSimilarly, the minimal eigenvalue ''λ''<sub>1</sub> is given by: \n:<math> \\lambda_1 = \\min \\{R_A(x) : x \\neq 0 \\}. </math>\n\n=== Proof ===\nSince the matrix {{mvar|A}} is Hermitian it is diagonalizable and we can choose an orthonormal basis of eigenvectors {''u''<sub>1</sub>, ..., ''u<sub>n</sub>''} that is, ''u<sub>i</sub>'' is an eigenvector for the eigenvalue ''λ<sub>i</sub>'' and such that (''u<sub>i</sub>'', ''u<sub>i</sub>'') = 1 and (''u<sub>i</sub>'', ''u<sub>j</sub>'') = 0 for all ''i'' ≠ ''j''.\n\nIf ''U'' is a subspace of dimension ''k'' then its intersection with the subspace {{math|span{''u<sub>k</sub>'', ..., ''u<sub>n</sub>''} }} isn't zero (by simply checking dimensions) and hence there exists a vector {{math|''v'' ≠ 0}} in this intersection that we can write as\n\n:<math>v = \\sum_{i=k}^n \\alpha_i u_i</math>\n\nand whose Rayleigh quotient is\n\n:<math>R_A(v) = \\frac{\\sum_{i=k}^n \\lambda_i \\alpha_i^2}{\\sum_{i=k}^n \\alpha_i^2} \\geq \\lambda_k</math>\n(as all <math>\\lambda_i \\geq \\lambda_k</math> for i=k,..,n)\nand hence\n:<math>\\max \\{ R_A(x) \\mid x \\in U \\} \\geq \\lambda_k</math>\nSince this is true for all U, we can conclude that \n:<math>\\min \\{ \\max \\{ R_A(x) \\mid x \\in U \\text{ and } x \\neq 0 \\} \\mid \\dim(U)=k \\} \\geq \\lambda_k</math>\n\nThis is one inequality. To establish the other inequality, chose the specific k-dimensional space\n{{math|''V'' {{=}} span{''u''<sub>1</sub>, ..., ''u<sub>k</sub>''} }}, for which\n:<math> \\max \\{ R_A(x) \\mid x \\in V \\text{ and } x \\neq 0 \\} \\leq \\lambda_k</math>\nbecause <math>\\lambda_k</math> is the largest eigenvalue in V. Therefore, also\n:<math>\\min \\{ \\max \\{ R_A(x) \\mid x \\in U \\text{ and } x \\neq 0 \\} \\mid \\dim(U)=k \\} \\leq \\lambda_k</math>\n\n\nIn the case where ''U'' is a subspace of dimension ''n-k+1'', we proceed in a similar fashion: Consider the subspace of dimension ''k'', {{math|span{''u''<sub>1</sub>, ..., ''u<sub>k</sub>''}.}} Its intersection with the subspace ''U'' isn't zero (by simply checking dimensions) and hence there exists a vector ''v'' in this intersection that we can write as\n\n:<math>v = \\sum_{i=1}^k \\alpha_i u_i</math>\nand whose Rayleigh quotient is\n:<math>R_A(v) = \\frac{\\sum_{i=1}^k \\lambda_i \\alpha_i^2}{\\sum_{i=1}^k \\alpha_i^2} \\leq \\lambda_k</math>\nand hence\n:<math>\\min \\{ R_A(x) \\mid x \\in U \\} \\leq \\lambda_k</math>\nSince this is true for all U, we can conclude that \n:<math>\\max \\{ \\min \\{ R_A(x) \\mid x \\in U \\text{ and } x \\neq 0 \\} \\mid \\dim(U)=n-k+1 \\} \\leq \\lambda_k</math>\n\nAgain, this is one part of the equation. To get the other inequality, note again that the eigenvector u of \n<math>\\lambda_k</math> is contained in {{math|''U'' {{=}} span{''u<sub>k</sub>'', ..., ''u<sub>n</sub>''} }}so that we can conclude the equality.\n\n=== Counterexample in the non-Hermitian case ===\nLet ''N'' be the nilpotent matrix\n\n:<math>\\begin{bmatrix} 0 & 1 \\\\ 0 & 0 \\end{bmatrix}.</math>\n\nDefine the Rayleigh quotient <math> R_N(x) </math> exactly as above in the Hermitian case. Then it is easy to see that the only eigenvalue of ''N'' is zero, while the maximum value of the Rayleigh ratio is {{math|{{sfrac|1|2}}}}. That is, the maximum value of the Rayleigh quotient is larger than the maximum eigenvalue.\n\n== Applications ==\n\n=== Min-max principle for singular values ===\nThe [[singular value]]s {''σ<sub>k</sub>''} of a square matrix ''M'' are the square roots of the eigenvalues of ''M''*''M'' (equivalently ''MM*''). An immediate consequence{{Citation needed|reason=claim is unreferenced and maybe suspicious|date=April 2014}} of the first equality in the min-max theorem is:\n\n:<math>\\sigma_k^{\\uparrow} = \\min_{S:\\dim(S)=k} \\max_{x \\in S, \\|x\\| = 1} (M^* Mx, x)^{\\frac{1}{2}}=\\min_{S:\\dim(S)=k} \\max_{x \\in S, \\|x\\| = 1} \\| Mx \\|.</math>\n\nSimilarly,\n\n:<math>\\sigma_k^{\\uparrow} = \\max_{S:\\dim(S)=n-k+1} \\min_{x \\in S, \\|x\\| = 1} \\| Mx \\|.</math>\n\nHere <math>\\sigma_k=\\sigma_k^\\uparrow</math> denotes the ''k''<sup>th</sup> entry in the increasing sequence of &sigma;'s, so that <math>\\sigma_1\\leq\\sigma_2\\leq\\cdots </math>.\n\n=== Cauchy interlacing theorem ===\n{{Main|Poincaré separation theorem}}\nLet {{mvar|A}} be a symmetric ''n'' × ''n'' matrix. The ''m'' × ''m'' matrix ''B'', where ''m'' ≤ ''n'', is called a '''[[compression (functional analysis)|compression]]''' of {{mvar|A}} if there exists an [[Projection_(linear_algebra)#Orthogonal_projections|orthogonal projection]] ''P'' onto a subspace of dimension ''m'' such that ''P*AP'' = ''B''. The Cauchy interlacing theorem states:\n\n:'''Theorem.''' If the eigenvalues of {{mvar|A}} are {{math|''α''<sub>1</sub> ≤ ... ≤ ''α<sub>n</sub>''}}, and those of ''B'' are {{math|''β''<sub>1</sub> ≤ ... ≤ ''β<sub>j</sub>'' ≤ ... ≤ ''β<sub>m</sub>''}}, then for all {{math|''j'' ≤ ''m''}},\n::<math>\\alpha_j \\leq \\beta_j \\leq \\alpha_{n-m+j}.</math>\n\nThis can be proven using the min-max principle. Let ''β<sub>i</sub>'' have corresponding eigenvector ''b<sub>i</sub>'' and ''S<sub>j</sub>'' be the ''j'' dimensional subspace {{math|''S<sub>j</sub>'' {{=}} span{''b''<sub>1</sub>, ..., ''b<sub>j</sub>''},}} then\n\n:<math>\\beta_j = \\max_{x \\in S_j, \\|x\\| = 1} (Bx, x) = \\max_{x \\in S_j, \\|x\\| = 1} (P^*APx, x) \\geq \\min_{S_j} \\max_{x \\in \nS_j, \\|x\\| = 1} (A(Px), Px) = \\alpha_j.</math>\n\nAccording to first part of min-max, {{math|''α<sub>j</sub>'' ≤ ''β<sub>j</sub>''.}} On the other hand, if we define {{math|''S''<sub>''m''−''j''+1</sub> {{=}} span{''b<sub>j</sub>'', ..., ''b<sub>m</sub>''},}} then\n\n:<math>\\beta_j = \\min_{x \\in S_{m-j+1}, \\|x\\| = 1} (Bx, x) = \\min_{x \\in S_{m-j+1}, \\|x\\| = 1} (P^*APx, x)= \\min_{x \\in S_{m-j+1}, \\|x\\| = 1} (A(Px), Px) \\leq \\alpha_{n-m+j},</math>\n\nwhere the last inequality is given by the second part of min-max.\n\nNotice that, when {{math|''n'' − ''m'' {{=}} 1}}, we have {{math|''α<sub>j</sub>'' ≤ ''β<sub>j</sub>'' ≤ ''α''<sub>''j''+1</sub>}}, hence the name ''interlacing'' theorem.\n\n== Compact operators ==\nLet {{mvar|A}} be a [[Compact operator on Hilbert space|compact]], [[Hermitian]] operator on a Hilbert space ''H''. Recall that the [[spectrum (functional analysis)|spectrum]] of such an operator (the set of eigenvalues) is a set of real numbers whose only possible [[cluster point]] is zero. It is thus convenient to list the positive eigenvalues of {{mvar|A}} as\n\n:<math>\\cdots \\le \\lambda_k \\le \\cdots \\le \\lambda_1,</math>\n\nwhere entries are repeated with [[Multiplicity (mathematics)|multiplicity]], as in the matrix case. (To emphasize that the sequence is decreasing, we may write <math>\\lambda_k = \\lambda_k^\\downarrow</math>.) When ''H'' is infinite-dimensional, the above sequence of eigenvalues is necessarily infinite. We now apply the same reasoning as in the matrix case. Letting ''S<sub>k</sub>'' ⊂ ''H'' be a ''k'' dimensional subspace, we can obtain the following theorem.\n\n:'''Theorem (Min-Max).''' Let {{mvar|A}} be a compact, self-adjoint operator on a Hilbert space {{mvar|H}}, whose positive eigenvalues are listed in decreasing order {{math|... ≤ ''λ<sub>k</sub>'' ≤ ... ≤ ''λ''<sub>1</sub>}}. Then:\n::<math>\\begin{align}\n\\max_{S_k} \\min_{x \\in S_k, \\|x\\| = 1} (Ax,x) &= \\lambda_k ^{\\downarrow}, \\\\\n\\min_{S_{k-1}} \\max_{x \\in S_{k-1}^{\\perp}, \\|x\\|=1} (Ax, x) &= \\lambda_k^{\\downarrow}.\n\\end{align}</math>\n\nA similar pair of equalities hold for negative eigenvalues.\n\nProof:\n{{hidden\n|(Click \"show\" at right to see the proof of this theorem or \"hide\" to hide it.)\n|2=\n\nLet ''S' '' be the closure of the linear span <math>S' =\\operatorname{span}\\{u_k,u_{k+1},\\ldots\\}</math>.\nThe subspace ''S' '' has codimension ''k'' − 1. By the same dimension count argument as in the matrix case, ''S' '' ∩ ''S<sub>k</sub>'' is non empty. So there exists ''x'' ∈ ''S'&nbsp;'' ∩ ''S<sub>k</sub>'' with <math>\\|x\\|=1</math>. Since it is an element of ''S' '', such an ''x'' necessarily satisfy\n\n:<math>(Ax, x) \\le \\lambda_k.</math>\n\nTherefore, for all ''S<sub>k</sub>''\n\n:<math>\\inf_{x \\in S_k, \\|x\\| = 1}(Ax,x) \\le \\lambda_k</math>\n\nBut {{mvar|A}} is compact, therefore the function ''f''(''x'') = (''Ax'', ''x'') is weakly continuous. Furthermore, any bounded set in ''H'' is weakly compact. This lets us replace the infimum by minimum:\n\n:<math>\\min_{x \\in S_k, \\|x\\| = 1}(Ax,x) \\le \\lambda_k.</math>\n\nSo\n\n:<math>\\sup_{S_k} \\min_{x \\in S_k, \\|x\\| = 1}(Ax,x) \\le \\lambda_k.</math>\n \nBecause equality is achieved when <math>S_k=\\operatorname{span}\\{u_1,\\ldots,u_k\\}</math>,\n\n:<math>\\max_{S_k} \\min_{x \\in S_k, \\|x\\| = 1}(Ax,x) = \\lambda_k.</math>\n\nThis is the first part of min-max theorem for compact self-adjoint operators.\n\nAnalogously, consider now a {{math|(''k'' − 1)}}-dimensional subspace ''S''<sub>''k''−1</sub>, whose the orthogonal complement is denoted by ''S''<sub>''k''−1</sub><sup>&perp;</sup>. If ''S' '' =&nbsp;span{''u''<sub>1</sub>...''u<sub>k</sub>''},\n\n:<math>S' \\cap S_{k-1}^{\\perp} \\ne {0}.</math>\n\nSo\n\n:<math>\\exists x \\in S_{k-1}^{\\perp} \\, \\|x\\| = 1, (Ax, x) \\ge \\lambda_k.</math>\n\nThis implies\n\n:<math>\\max_{x \\in S_{k-1}^{\\perp}, \\|x\\| = 1} (Ax, x) \\ge \\lambda_k</math>\n\nwhere the compactness of ''A'' was applied. Index the above by the collection of ''k-1''-dimensional subspaces gives\n\n:<math>\\inf_{S_{k-1}} \\max_{x \\in S_{k-1}^{\\perp}, \\|x\\|=1} (Ax, x) \\ge \\lambda_k.</math>\n\nPick ''S''<sub>''k''−1</sub> = span{''u''<sub>1</sub>, ..., ''u''<sub>''k''−1</sub>} and we deduce\n\n:<math>\\min_{S_{k-1}} \\max_{x \\in S_{k-1}^{\\perp}, \\|x\\|=1} (Ax, x) = \\lambda_k.</math>\n}}\n\n==Self-adjoint operators==\nThe min-max theorem also applies to (possibly unbounded) self-adjoint operators.<ref name=\"teschl\">G. Teschl, Mathematical Methods in Quantum Mechanics (GSM 99) http://www.mat.univie.ac.at/~gerald/ftp/book-schroe/schroe.pdf</ref>\n<ref name=\"lieb-loss\">Lieb-Loss, Analysis 2nd ed. (GSM 14)</ref> Recall the [[essential spectrum]] is the spectrum without isolated eigenvalues of finite multiplicity. Sometimes we have some eigenvalues below the essential spectrum, and we would like to approximate the eigenvalues and eigenfunctions.\n\n'''Theorem (Min-Max).''' Let ''A'' be self-adjoint, and let <math>E_1\\le E_2\\le E_3\\le\\cdots</math> be the eigenvalues of ''A'' below the essential spectrum. Then\n\n<math>E_n=\\min_{\\psi_1,\\ldots,\\psi_{n}}\\max\\{\\langle\\psi,A\\psi\\rangle:\\psi\\in\\operatorname{span}(\\psi_1,\\ldots,\\psi_{n}), \\, \\| \\psi \\| = 1\\}</math>.\n\nIf we only have ''N'' eigenvalues and hence run out of eigenvalues, then we let <math>E_n:=\\inf\\sigma_{ess}(A)</math> (the bottom of the essential spectrum) for ''n>N'', and the above statement holds after replacing min-max with inf-sup.\n\n'''Theorem (Max-Min).''' Let ''A'' be self-adjoint, and let <math>E_1\\le E_2\\le E_3\\le\\cdots</math> be the eigenvalues of ''A'' below the essential spectrum. Then\n\n<math>E_n=\\max_{\\psi_1,\\ldots,\\psi_{n-1}}\\min\\{\\langle\\psi,A\\psi\\rangle:\\psi\\perp\\psi_1,\\ldots,\\psi_{n-1}, \\, \\| \\psi \\| = 1\\}</math>.\n\nIf we only have ''N'' eigenvalues and hence run out of eigenvalues, then we let <math>E_n:=\\inf\\sigma_{ess}(A)</math> (the bottom of the essential spectrum) for ''n>N'', and the above statement holds after replacing max-min with sup-inf.\n\nThe proofs<ref name=\"teschl\"/><ref name=\"lieb-loss\"/> use the following results about self-adjoint operators:\n\n'''Theorem.''' Let ''A'' be self-adjoint. Then <math>(A-E)\\ge0</math> for <math>E\\in\\mathbb{R}</math> if and only if <math>\\sigma(A)\\subseteq[E,\\infty)</math>.\n\n'''Theorem.''' If ''A'' is self-adjoint, then\n\n<math>\\inf\\sigma(A)=\\inf_{\\psi\\in\\mathfrak{D}(A),\\|\\psi\\|=1}\\langle\\psi,A\\psi\\rangle</math>\n\nand\n\n<math>\\sup\\sigma(A)=\\sup_{\\psi\\in\\mathfrak{D}(A),\\|\\psi\\|=1}\\langle\\psi,A\\psi\\rangle</math>.\n\n== See also ==\n* [[Courant minimax principle]]\n* [[Max–min inequality]]\n\n== References ==\n{{Reflist}}\n* M. Reed and B. Simon, ''Methods of Modern Mathematical Physics IV: Analysis of Operators'', Academic Press, 1978.\n\n[[Category:Articles containing proofs]]\n[[Category:Theorems in functional analysis]]\n[[Category:Spectral theory]]\n[[Category:Operator theory]]"
    },
    {
      "title": "Multi-spectral phase coherence",
      "url": "https://en.wikipedia.org/wiki/Multi-spectral_phase_coherence",
      "text": "{{Multiple issues|\n{{technical|date=December 2016}}\n{{expert needed|mathematics|reason=expansion is needed as is a major edit to make the article more understandable to the average reader|date=December 2016}}\n{{COI|date=January 2017}}\n}}\n'''Multi-spectral phase coherence (MSPC)''' is a generalized cross-frequency [[Coupling (physics)|coupling]] metric introduced by Yang and colleagues in 2016.<ref>{{cite journal|last2=Solis-Escalante|first2=T|last3=Yao|first3=J|last4=Daffertshofer|first4=A|last5=Schouten|first5=AC|last6=van der Helm|first6=FC|date=February 2016|title=A General Approach for Quantifying Nonlinear Connectivity in the Nervous System Based on Phase Coupling.|journal=International Journal of Neural Systems|volume=26|issue=1|pages=1550031|pmid=26404514|last1=Yang|first1=Y|doi=10.1142/S0129065715500318}}</ref> MSPC can be used to quantify [[nonlinear]] phase coupling between a set of base frequencies and their [[harmonic]]/[[intermodulation]] frequencies. MSPC is a model-free method, which can provide a system description, including (i) the order of the nonlinearity, (ii) the direction of interaction, (iii) the time delay in the system, and both (iv) harmonic and (v) intermodulation coupling.\n\nThe MSPC is defined as:\n\n: <math>\\Psi(f_i,a_i) = \\left\\langle \\exp \\left( j\\left(\\sum_i a_i\\varphi(f_i) -\\varphi \\left(f_\\text{sum}\\right)\\right) \\right) \\right\\rangle </math>\n\nwhere <math>\\varphi(f_i) </math> is the phase at frequency <math>f_i </math>, <math>a_i </math> is the weight of <math>f_i </math> to a harmonic/intermodulation frequency <math>f_\\text{sum} = \\sum_i a_if_i </math>), and <math>\\langle \\cdot \\rangle</math> represents the average over [[Realization (systems)|realizations]].\n\nBi-phase locking value,<ref>{{cite journal|last2=Ojemann|first2=JG|last3=Sorensen|first3=LB|date=15 May 2009|title=Bi-phase locking – a tool for probing non-linear interaction in the human brain.|journal=NeuroImage|volume=46|issue=1|pages=123–32|pmid=19457390|last1=Darvas|first1=F|doi=10.1016/j.neuroimage.2009.01.034|pmc=2778057}}</ref> also called bi-phase coherence in the literature, is a special case of MSPC when <math>a_1=a_2=1 </math>, <math>i = 1, 2. </math>\n\nThe time-delay can be estimated from the [[Phase (waves)|phase lag]] when MSPC is computed between signals.\n\n== References ==\n\n<references />\n\n[[Category:Nonlinear functional analysis]]\n[[Category:Spectral theory]]"
    },
    {
      "title": "Numerical range",
      "url": "https://en.wikipedia.org/wiki/Numerical_range",
      "text": "In the [[mathematics|mathematical]] field of [[linear algebra]] and [[convex analysis]], the '''numerical range''' or '''field of values''' of a [[complex number|complex]] ''n''&nbsp;&times;&nbsp;''n'' [[square matrix|matrix]] ''A'' is the set\n\n:<math>W(A) = \\left\\{\\frac{\\mathbf{x}^*A\\mathbf{x}}{\\mathbf{x}^*\\mathbf{x}} \\mid \\mathbf{x}\\in\\mathbb{C}^n,\\ x\\not=0\\right\\} </math>\n\nwhere '''x'''* denotes the conjugate transpose of the [[vector (mathematics)|vector]] '''x'''.\n\nIn engineering, numerical ranges are used as a rough estimate of [[eigenvalue]]s of ''A''. Recently, generalizations of numerical range are used to study [[quantum computing]].\n\nA related concept is the '''numerical radius''', which is the largest absolute value of the numbers in the numerical range, i.e.\n\n:<math>r(A) = \\sup \\{ |\\lambda| : \\lambda \\in W(A) \\} = \\sup_{\\|x\\|=1} |\\langle Ax, x \\rangle|.</math>\n\n''r''(''A'') is a [[norm (mathematics)|norm]]. ''r''(''A'')&nbsp;≤&nbsp;||''A''||&nbsp;≤&nbsp;2''r''(''A'') where ||''A''|| is the [[operator norm]] of&nbsp;''A''.\n\n==Properties==\n\n# The numerical range is the [[range of a function|range]] of the [[Rayleigh quotient]]. \n# ('''Hausdorff–Toeplitz theorem''') The numerical range is convex and compact.\n# <math>W(\\alpha A+\\beta I)=\\alpha W(A)+\\{\\beta\\}</math> for all square matrix ''A'' and complex numbers &alpha; and &beta;.  Here ''I'' is the [[identity matrix]].\n# <math>W(A)</math> is a subset of the closed right half-plane if and only if <math>A+A^*</math> is positive semidefinite.\n# The numerical range <math>W(\\cdot)</math> is the only function on the set of square matrices that satisfies (2), (3) and (4).\n# (Sub-additive) <math>W(A+B)\\subseteq W(A)+W(B)</math>.\n# <math>W(A)</math> contains all the [[eigenvalue]]s of ''A''.\n# The numerical range of a 2&times;2 matrix is an [[elliptical disk]].\n# <math>W(A)</math> is a real line segment [&alpha;, &beta;] if and only if ''A'' is a [[Hermitian matrix]] with its smallest and the largest eigenvalues being &alpha; and &beta;\n# If ''A'' is a [[normal matrix]] then <math>W(A)</math> is the convex hull of its eigenvalues.\n# If &alpha; is a sharp point on the boundary of <math>W(A)</math>, then &alpha; is a normal eigenvalue of ''A''.\n# <math>r(\\cdot)</math> is a norm on the space of ''n''&times;''n'' matrices.\n# <math>r(A^n) \\le r(A)^n</math>\n\n== Generalisations ==\n*[[C-numerical range]]\n*[[Higher-rank numerical range]]\n*[[Joint numerical range]]\n*[[Product numerical range]]\n*[[Polynomial numerical hull]]\n\n==See also==\n* [[Spectral theory]]\n* [[Rayleigh quotient]]\n* [[Workshop on Numerical Ranges and Numerical Radii]]\n\n==References==\n{{reflist|2}}\n\n;Bibliography\n*{{Citation|last1=Choi|first1=M.D.|last2=Kribs|first2=D.W.|last3=Życzkowski|title=Quantum error correcting codes from the compression formalism |journal=Rep. Math. Phys. |volume=58 |pages=77| year=2006|bibcode=2006RpMP...58...77C|doi=10.1016/S0034-4877(06)80041-8|arxiv=quant-ph/0511101}}.\n*{{Citation|last1=Dirr|first1=G.|last2=Helmkel|first2=U.|last3=Kleinsteuber|first3=M.|last4=Schulte-Herbrüggen|first4=Th.|title=A new type of C-numerical range arising in quantum computing| journal=Proc. Appl. Math. Mech. |volume=6 |pages=711–712 | year=2006}}.\n*{{Citation | last1=Bonsall | first1=F.F. | last2=Duncan | first2=J. | title=Numerical Ranges of Operators on Normed Spaces and of Elements of Normed Algebras | publisher=[[Cambridge University Press]] | isbn=978-0-521-07988-4 | year=1971}}.\n*{{Citation | last1=Bonsall | first1=F.F. | last2=Duncan | first2=J. | title=Numerical Ranges II | publisher=[[Cambridge University Press]] | isbn=978-0-521-20227-5 | year=1971}}.\n*{{Citation | last1=Horn | first1=Roger A. | last2=Johnson | first2=Charles R. | title=Topics in Matrix Analysis | publisher=[[Cambridge University Press]] | isbn=978-0-521-46713-1 | year=1991}}.\n*{{Citation |last1=Li| first1=C.K.| title=A simple proof of the elliptical range theorem | journal=Proc. Am. Math. Soc. |volume=124 |page=1985  |  year=1996}}.\n*{{Citation |last1=Keeler| first1=Dennis S.|last2=Rodman| first2=Leiba|last3=Spitkovsky|first3=Ilya M.| title=The numerical range of 3 × 3 matrices | journal=Linear Algebra and Its Applications |volume=252 |page=115 |  year=1997}}.\n* Roger A. Horn and Charles R. Johnson, ''Topics in Matrix Analysis'', Chapter 1, Cambridge University Press, 1991. {{ISBN|0-521-30587-X}} (hardback), {{ISBN|0-521-46713-6}} (paperback).\n* \"Functional Characterizations of the Field of Values and the Convex Hull of the Spectrum\", Charles R. Johnson, ''Proceedings of the American Mathematical Society'', 61(2):201-204, Dec 1976.\n\n{{DEFAULTSORT:Numerical Range}}\n[[Category:Matrix theory]]\n[[Category:Spectral theory]]\n[[Category:Operator theory]]\n[[Category:Linear algebra]]"
    },
    {
      "title": "Polyakov formula",
      "url": "https://en.wikipedia.org/wiki/Polyakov_formula",
      "text": "In [[differential geometry]] and [[mathematical physics]] (especially [[string theory]]), the '''Polyakov formula''' expresses the [[conformal geometry|conformal]] [[calculus of variation|variation]] of the [[Minakshisundaram–Pleijel zeta function|zeta functional determinant]] of a [[Riemannian manifold]].  The corresponding density is local, and therefore is a Riemannian curvature invariant.  In particular, whereas the functional determinant itself is prohibitively difficult to work with in general, its conformal variation can be written down explicitly.\n\n==References==\n* {{citation|first=Thomas|last=Branson|title=''Q''-curvature, spectral invariants, and representation theory|journal=Symmetry, Integrability and Geometry (SIGMA)|volume=3|year=2007|url=http://www.emis.ams.org/journals/SIGMA/2007/090/sigma07-090.pdf}}\n\n[[Category:Conformal geometry]]\n[[Category:Spectral theory]]\n[[Category:String theory]]"
    },
    {
      "title": "Projection-valued measure",
      "url": "https://en.wikipedia.org/wiki/Projection-valued_measure",
      "text": "{{Short description|Mathematical operator-value measure of interest in quantum mechanics and functional analysis}}\nIn [[mathematics]], particularly in [[functional analysis]], a  '''projection-valued measure (PVM)''' is a function defined on certain subsets of a fixed set and whose values are [[self-adjoint]] [[projection (mathematics)|projection]]s on a fixed [[Hilbert space]]. Projection-valued measures are formally similar to real-valued [[Measure (mathematics)|measures]], except that their values are self-adjoint projections rather than real numbers. As in the case of ordinary measures, it is possible to integrate complex-valued functions with respect to a PVM; the result of such an integration is a linear operator on the given Hilbert space.\n\nProjection-valued measures are used to express results in [[spectral theory]], such as the important spectral theorem for [[self-adjoint operator]]s. The [[Borel functional calculus]] for self-adjoint operators is constructed using integrals with respect to PVMs.  In [[quantum mechanics]], PVMs are the mathematical description of [[Quantum measurement|projective measurements]].{{clarify|reason=Is this a novel term? It's not defined in the linked article.|date=May 2015}}  They are generalized by [[POVM|positive operator valued measures]] (POVMs) in the same sense that a [[mixed state (physics)|mixed state]] or [[density matrix]] generalizes the notion of a [[pure state]].\n\n== Formal definition ==\n\nA projection-valued measure on a [[measurable space]] \n<math>(X, M)</math>, where <math>M</math> is a [[σ-algebra]] of subsets of <math>X</math>, is a [[function (mathematics)|mapping]] <math>\\pi</math> from <math>M</math> to the set of [[self-adjoint]] [[projection operator|projections]] on a [[Hilbert space]] <math>H</math> (i.e. the orthogonal projections) such that\n\n: <math>\n\\pi(X) = \\operatorname{id}_H \\quad \n</math>\n\n(where <math>\\operatorname{id}_H</math> is the identity operator of <math>H</math>) and for every <math>\\xi,\\eta\\in H</math>, the set-function\n\n:<math> \nM \\to \\mathbb C : E \\mapsto \\langle \\pi(E)\\xi \\mid \\eta \\rangle \n</math>\n\nis a [[complex measure]] on ''<math>M</math>'' (that is, a complex-valued [[sigma additivity|countably additive]] function).\n\nWe denote this measure by \n<math>\\operatorname{S}_\\pi(\\xi, \\eta)</math>.\n\nNote that <math>\\operatorname{S}_\\pi(\\xi, \\xi)</math> is a real-valued measure, and a probability measure when <math>\\xi</math> has length one.\n\nIf π is a projection-valued measure and\n\n: <math>\nE \\cap F = \\emptyset,\n</math>\n\nthen the images <math>\\pi(E)</math>, <math>\\pi(F)</math> are [[orthogonal]] to each other.  From this follows that in general,\n\n: <math>\n \\pi(E) \\pi(F) = \\pi(E \\cap F) =  \\pi(F) \\pi(E), \n</math>\n\nand they commute.\n\n'''Example'''.  Suppose <math>(X, M, \\mu)</math> is a measure space.  Let, for every measurable subset <math>E</math> in <math>M</math>, \n:<math>\n\\pi(E) : L^2(\\mu) \\to L^2 (\\mu): \n\\psi \\mapsto \\chi_E \\psi\n</math>\nbe the operator of multiplication by the [[indicator function]] <math>1_E</math> on [[Lp space|''L''<sup>2</sup>(''X'')]]. Then <math>\\pi</math> is a projection-valued measure.\n\n== Extensions of projection-valued measures, integrals and the spectral theorem==\n\nIf π is a projection-valued measure on a measurable space (''X'', ''M''), then the map\n\n: <math>\n \\chi_E \\mapsto \\pi(E)\n</math>\n\nextends to a linear map on the vector space of [[step function]]s on ''X''.  In fact, it is easy to check that this map is a [[ring homomorphism]].  This map extends in a canonical way to all bounded complex-valued [[measurable function]]s on ''X'', and we have the following.\n\n'''Theorem'''. ''For any bounded'' ''M''-''measurable function f on X, there exists'' ''a unique bounded linear operator'' \n:<math>\n\\mathrm T_\\pi (f) : H \\to H\n</math>\nsuch that''\n: <math>\n \\langle \\operatorname{T}_\\pi(f) \\xi \\mid  \\eta \\rangle =\n \\int_X f \\ d \\operatorname{S}_\\pi (\\xi,\\eta) \n</math>\n\n''for all'' <math> \\xi,\\eta \\in H </math>.  ''Where,'' <math>\n\\operatorname{S}_\\pi (\\xi,\\eta)</math> ''denotes the complex measure'' \n\n:<math>E \\mapsto \\langle \\pi(E)\\xi \\mid \\eta \\rangle </math>\n\n''from the definition of'' <math>\\pi</math>.\n\nThe map\n\n<math> \\mathcal{BM}(X,M) \\to \\mathcal L(H): \nf \\mapsto \\operatorname{T}_\\pi(f)</math>\n\nis a [[Ring homomorphism|homomorphism of rings]]. \n\nAn integral notation is often used for <math>\\operatorname{T}_\\pi(f)</math>, as in\n\n: <math>\\operatorname{T}_\\pi(f)=\\int_X f(x) d \\pi(x) = \\int_X f d \\pi.</math>\n\nThe theorem is also correct for unbounded measurable functions ''f'', but then <math>\\operatorname{T}_\\pi(f)</math> will be an unbounded linear operator on the Hilbert space ''H''.\n\nThe [[spectral theorem]] says that every [[self-adjoint operator]] <math>A:H\\to H</math> has an associated projection-valued measure <math>\\pi_A</math> defined on the real axis, such that\n:<math>A =\\int_\\mathbb{R} x d \\pi_A(x).</math>\nThis allows to define the [[Borel functional calculus]] for such operators: if <math>g:\\mathbb{R}\\to\\mathbb{C}</math> is a measurable function, we set\n:<math>g(A) :=\\int_\\mathbb{R} g(x) d \\pi_A(x).</math>\n\n== Structure of projection-valued measures==\n\nFirst we provide a general example of projection-valued measure based on [[direct integral]]s.   Suppose (''X'', ''M'', μ) is a measure space and let {''H''<sub>''x''</sub>}<sub>''x'' ∈ ''X'' </sub> be a μ-measurable family of separable Hilbert spaces. For every  ''E'' ∈ ''M'', let π(''E'') be the operator of multiplication by 1<sub>''E''</sub> on the Hilbert space\n\n:<math> \\int_X^\\oplus H_x \\ d \\mu(x). </math>\n\nThen π is a projection-valued measure on (''X'', ''M'').\n\nSuppose π, ρ  are projection-valued measures on  (''X'', ''M'') with values in the projections of ''H'', ''K''.   π,  ρ  are '''unitarily equivalent''' [[if and only if]] there is a unitary operator ''U'':''H'' → ''K'' such that\n\n:<math> \\pi(E) = U^* \\rho(E) U \\quad </math>\n\nfor every ''E'' ∈ ''M''.\n\n'''Theorem'''. If (''X'', ''M'') is a [[Borel algebra#Standard Borel spaces and Kuratowski theorems|standard Borel space]], then for every projection-valued measure π on (''X'', ''M'') taking values in the projections of a ''separable'' Hilbert space, there is a Borel measure μ and a μ-measurable family of Hilbert spaces {''H''<sub>''x''</sub>}<sub>''x'' ∈ ''X'' </sub>, such that π is unitarily equivalent to multiplication by 1<sub>''E''</sub> on the Hilbert space\n\n:<math> \\int_X^\\oplus H_x \\ d \\mu(x). </math>\n\nThe measure class{{clarify|reason=What is a measure class? A measure up to measure-preserving equivalence? Should the measure be completed?|date=May 2015}} of μ and the measure equivalence class of the multiplicity function ''x'' → dim ''H''<sub>''x''</sub> completely characterize the projection-valued measure up to unitary equivalence.\n\nA projection-valued measure  π is ''homogeneous of multiplicity'' ''n'' if and only if the multiplicity function has constant value ''n''.  Clearly,\n\n'''Theorem'''.  Any projection-valued measure π taking values in the projections of a separable Hilbert space is an orthogonal direct sum of homogeneous projection-valued measures:\n\n:<math> \\pi = \\bigoplus_{1 \\leq n \\leq \\omega} (\\pi | H_n) </math>\n\nwhere\n\n:<math> H_n = \\int_{X_n}^\\oplus H_x \\ d (\\mu | X_n) (x) </math>\n\nand\n\n:<math> X_n = \\{x \\in X: \\operatorname{dim} H_x = n\\}. </math>\n\n==Application in quantum mechanics==\n\nIn quantum mechanics, given a projection valued measure of a measurable space X to the space of continuous endomorphisms upon a Hilbert space H, \n\n- the unit sphere of the Hilbert space ''H'' is interpreted as the set of possible states Φ of a quantum system,\n\n- the measurable space ''X'' is the value space for some quantum property of the system (an \"observable\"), \n\n- the projection-valued measure π  expresses the probability that the observable takes on various values.\n\nA common choice for ''X'' is the real line, but it may also be \n\n'''- R'''<sup>3</sup> (for position or momentum in three dimensions ), \n\n- a discrete set (for angular momentum, energy of a bound state, etc.), \n\n- the 2-point set \"true\" and \"false\" for the truth-value of an arbitrary proposition about Φ.\n\nLet ''E'' be a measurable subset of the measurable space ''X'' and Φ a normalized vector-state in ''H'', so that its Hilbert norm is unitary, ||Φ|| = 1. The probability that the observable takes its value in the subset ''E,'' given the system in state Φ, is\n\n:<math>\n P_\\pi(\\phi)(E) = \n\\langle \\phi|\\pi(E)(\\phi)\\rangle = \\langle \\phi|\\pi(E)|\\phi\\rangle,</math>\n\nwhere the latter notation is preferred in physics.\n\nWe can parse this in two ways. \n\nFirst, for each fixed ''E'', the projection π(''E'') is a self-adjoint operator on ''H'' whose 1-eigenspace is the states Φ for which the value of the observable always lies in ''E'', and whose 0-eigenspace is the states Φ for which the value of the observable never lies in ''E''.  \n\nSecond, for each fixed normalized vector state <math>\\psi</math>, the association \n\n:<math>\nP_\\pi(\\psi) :\nE \\mapsto  \\langle\\psi|\\pi(E)\\psi\\rangle\n</math>\nis a probability measure on ''X'' making the values of the observable into a random variable.\n\nA measurement that can be performed by a projection-valued measure π is called a '''projective measurement'''. \n\nIf ''X'' is the real number line, there exists, associated to π, a Hermitian operator ''A'' defined on ''H'' by\n\n:<math>A(\\phi) = \\int_{\\mathbf{R}} \\lambda \\,d\\pi(\\lambda)(\\phi),</math>\n\nwhich takes the more readable form\n\n:<math>A(\\phi) = \\sum_i \\lambda_i \\pi({\\lambda_i})(\\phi)</math>\n\nif the support of π is a discrete subset of '''R'''. \n\nThe above operator A is called the observable associated with the spectral measure.\n\nAny operator so obtained is called an [[observable]] , in quantum mechanics.\n\n==Generalizations==\nThe idea of a projection-valued measure is generalized by the [[positive operator-valued measure]] (POVM), where the need for the orthogonality implied by projection operators is replaced by the idea of a set of operators that are a non-orthogonal partition of unity{{clarify|reason=Partition of unity in the operator sense is not defined in the article \"partition of unity\".|date=May 2015}}. This generalization is motivated by applications to [[quantum information theory]].\n\n== References ==\n*{{citation | last = Moretti |first = V. |title =Spectral Theory and Quantum Mechanics Mathematical Foundations of Quantum Theories, Symmetries and Introduction to the Algebraic Formulation|volume=110 | year = 2018 |publisher = Springer|isbn=978-3-319-70705-1}}\n*{{citation | last = Hall |first = B.C. |title = Quantum Theory for Mathematicians|series=Graduate Texts in Mathematics|volume=267 | year = 2013 |publisher = Springer|isbn=978-1461471158}}\n* G. W. Mackey, ''The Theory of Unitary Group Representations'', The University of Chicago Press, 1976\n* [[Michael C. Reed|M. Reed]] and [[Barry Simon|B. Simon]], ''Methods of Mathematical Physics'', vols I–IV, Academic Press 1972.\n* [[Gerald Teschl|G. Teschl]], ''Mathematical Methods in Quantum Mechanics with Applications to Schrödinger Operators'', http://www.mat.univie.ac.at/~gerald/ftp/book-schroe/, American Mathematical Society, 2009.\n* V. S. Varadarajan, ''Geometry of Quantum Theory'' V2, Springer Verlag, 1970.\n\n{{Functional Analysis}}\n\n[[Category:Linear algebra]]\n[[Category:Spectral theory]]\n[[Category:Measures (measure theory)]]"
    },
    {
      "title": "Proto-value function",
      "url": "https://en.wikipedia.org/wiki/Proto-value_function",
      "text": "{{Orphan|date=November 2013}}\n\nIn [[applied mathematics]], '''proto-value functions (PVFs)''' are automatically learned [[basis function]]s that are useful in approximating task-specific value functions, providing a compact representation of the powers of transition matrices.  They provide a novel framework for solving the [[Assignment problem|credit assignment problem]].  The framework introduces a novel approach to solving [[Markov decision process]]es (MDP) and [[reinforcement learning]] problems, using multiscale spectral and [[manifold learning]] methods.  Proto-value functions are generated by [[Spectral graph theory|spectral analysis]] of a graph, using the [[Laplacian matrix|graph Laplacian]].\n\nProto-value functions were first introduced in the context of reinforcement learning by Sridhar Mahadevan in his paper, ''Proto-Value Functions: Developmental Reinforcement Learning'' at [[ICML]] 2005.<ref name=key1>Mahadevan, S. [http://www-anw.cs.umass.edu/pubs/2005/mahadevan_ICML05.pdf Proto-Value Functions: Developmental Reinforcement Learning]. Proceedings of the International Conference on Machine Learning [[ICML]] 2005</ref>\n\n== Motivation ==\nValue function [[function approximation|approximation]] is a critical component to solving [[Markov decision process]]es (MDPs) defined over a continuous state space.  A good function approximator allows a [[reinforcement learning]] (RL) agent to accurately represent the value of any state it has experienced, without explicitly storing its value.  Linear function approximation using [[basis function]]s is a common way of constructing a value function approximation, like [[radial basis functions]], polynomial state encodings, and [[Cerebellar Model Articulation Controller|CMAC]]s. However, parameters associated with these basis functions often require significant domain-specific hand-engineering.<ref name=key2>Johns, J. and Mahadevan, S., [http://wayback.archive-it.org/all/20070824014806/http://www.cs.umass.edu/~pvf/papers/johns_icml07.pdf Constructing Basis Functions from Directed Graphs for Value Function Approximation], International Conference on Machine Learning (ICML), 2007</ref> Proto-value functions attempts to solve this required hand-engineering by accounting for the underlying manifold structure of the problem domain.<ref name=key1 />\n\n== Overview ==\nProto-value functions are task-independent global basis functions that collectively span the entire space of possible value functions for a given state space.<ref name=key1 /> They incorporate geometric constraints intrinsic to the environment. For example, states close in Euclidean distance (such as states on opposite sides of a wall) may be far apart in manifold space. Previous approaches to this nonlinearity problem lacked a broad theoretical framework, and consequently have only been explored in the context of discrete [[Markov decision process|MDP]]s.\n\nProto-value functions arise from reformulating the problem of value function approximation as real-valued function approximation on a graph or manifold. This results in broader applicability of the learned bases and enables a new class of learning algorithms, which learn representations and policies at the same time.<ref name=key3>Mahadevan, S. and Maggiono, M., [http://www-anw.cs.umass.edu/pubs/2006/mahadevan_m_TECH06-35.pdf Proto-Value Functions: A Laplacian Framework for Learning Representation and Control in Markov Decision Processes], University of Massachusetts, Department of Computer Science Technical Report TR-2006-35, 2006</ref>\n\n== Basis functions from graph Laplacian ==\nIn this approach, we will construct the [[basis function]]s by spectral analysis of the graph Laplacian, a [[Self-adjoint operator|self-adjoint]] (or symmetric) operator on the space of functions on the graph, closely related to the [[random walk]] operator.\n\nFor the sake of simplicity, assume that the underlying state space can be represented as an undirected unweighted graph <math> G=(V,E) </math>  The [[Laplacian matrix|combinatorial Laplacian]] <math>L</math> is defined as the operator <math> L = D - A </math>, where <math>D</math> is a diagonal matrix called the [[degree matrix]] and <math>A</math> is the [[adjacency matrix]].<ref name=key1 />\n\nThe spectral analysis of the Laplace operator on a graph consists of finding the [[eigenvalue]]s and eigenfunctions which solve the equation\n:<math> L\\varphi_\\lambda = \\lambda\\varphi_\\lambda, </math>\nwhere <math>L</math> is the combinatorial Laplacian, <math>\\varphi_\\lambda</math> is an eigenfunction associated with the eigenvalue <math>\\lambda</math>.  Here the term \"eigenfunction\" is used to denote what is traditionally referred to as [[eigenvector]] in linear algebra, because the Laplacian [[eigenvector]]s can naturally be viewed as functions that map each vertex to a real number.<ref name=key3 />\n\nThe combinatorial Laplacian is not the only operator on graphs to select from.  Other possible graph operators include:\n*Normalized Laplacian <math> L_\\text{normalized} = I - D^{-1/2}AD^{-1/2} </math> <ref name=key4>Mahadevan, S. and Maggiono, M., [http://www.cs.umass.edu/~mahadeva/icml06-tutorial/icml2006-tutorial-pdf-final.pdf ICML 2006 tutorial].</ref>\n*Random Walk <math> P = D^{-1}A </math> <ref name=key4 />\n\n=== Graph construction on discrete state space ===\nFor a finite state space the graph <math>G</math> mentioned above can be simply constructed by examining the connections between states. Let <math> S_i</math> and <math>S_j </math> be any two states. Then\n\n:<math> G_{i,j}=\\begin{cases}\n1 & \\text{if } S_i\\leftrightarrow S_j \\\\\n0 & \\text{otherwise}\n\\end{cases} \n</math>\nIt is important to note that this can only be done when the state space is finite and of reasonable size.\n\n=== Graph construction on continuous or large state space ===\nFor a continuous state space or simply a very large discrete state space, it is necessary to sample from the manifold in state space.  Then constructing the Graph <math>G</math> based on the samples.  \nThere are a few issues to consider here:<ref name=key4 />\n* How to sample the manifold\n** Random walk or guided exploration\n* How to determine if two sample should be connected\n\n== Application ==\nOnce the PVFs are generated, they can be plugged into a traditional function approximation framework.  One such method is least-squares approximation.\n\n=== Least-squares approximation using proto-value functions ===\nLet <math>\\Phi_G=\\left\\{ V_1^G,\\dots,V_k^G\\right\\}</math> be the basis set of PVFs, where each <math> V_i^G</math> is the eigenfunction defined over all states in the graph <math>G</math>. \nLet <math>\\widehat{V}^\\pi</math> be the target value function that is only known for a subset of states <math> S_M^G =\\left\\{ s_1,\\dots,s_m\\right\\} </math>.\n\nDefine the [[Gramian matrix|gram matrix]]\n\n:<math> K_G =\\left(\\Phi_m^G \\right)^T \\Phi_m^G. </math>\n\nhere <math> S_m^G </math> is the component wise projection of the PVFs onto the states in <math> S_G^m</math>. Hence, each entry of the gram matrix is\n\n:<math>K_G(i,j) = \\sum_k V_i^G(k) V_j^G (k)</math>\n\nNow the we can solve for the coefficients that minimize the least squares error with the equation     \n:<math> \\alpha=K_G^{-1}\\left(\\Phi_M^G \\right)^T \\widehat{V}^\\pi. </math>\n\nA nonlinear least-squares approach is possible by using the ''k'' PVFs with the largest absolute coefficients to compute the approximation.<ref name=key1 />\n\n== See also ==\n* [[Reinforcement learning]]\n* [[Markov decision process]]\n* [[Basis function]]\n* [[Eigenfunction]]\n* [[Laplacian matrix]]\n\n== References ==\n{{Reflist}}\n\n[[Category:Spectral theory]]\n[[Category:Types of functions]]"
    },
    {
      "title": "Pseudospectrum",
      "url": "https://en.wikipedia.org/wiki/Pseudospectrum",
      "text": "In [[mathematics]], the '''pseudospectrum''' of an [[Operator (mathematics)|operator]] is a [[Set (mathematics)|set]] containing the [[spectrum of an operator|spectrum]] of the operator and the numbers that are \"almost\" [[eigenvalues]]. Knowledge of the pseudospectrum can be particularly useful for understanding [[normal operator|non-normal operator]]s and their eigenfunctions.\n\nThe &epsilon;-pseudospectrum of a matrix ''A'' consists of all eigenvalues of matrices which are &epsilon;-close to ''A'':<ref name=\"Hogben\">{{cite book|last1=Hogben|first1=Leslie|title=Handbook of Linear Algebra, Second Edition|date=2013|publisher=CRC Press|isbn=9781466507296|page=23-1|url=https://books.google.com/books?id=Er7MBQAAQBAJ&pg=SA23-PA18&dq=pseudospectrum&hl=en&sa=X&ved=0ahUKEwj11Ke34ZTWAhXJgFQKHbtZBbkQ6AEIQzAE#v=onepage&q=pseudospectrum&f=false|accessdate=8 September 2017|language=en}}</ref>\n:<math>\\Lambda_\\epsilon(A) = \\{\\lambda \\in \\mathbb{C} \\mid \\exists x \\in \\mathbb{C}^n \\setminus \\{0\\}, \\exists E \\in \\mathbb{C}^{n \\times n} \\colon (A+E)x = \\lambda x, \\|E\\| \\leq \\epsilon \\}.</math>\n\n[[Eigenvalue algorithm|Numerical algorithms which calculate the eigenvalues of a matrix]] give only approximate results due to rounding and other errors. These errors can be described with the matrix ''E''.\n\n== References ==\n{{reflist}}\n\n* Pseudospectra Gateway / Embree and Trefethen [http://web.comlab.ox.ac.uk/pseudospectra/]\n{{Numerical linear algebra}}\n\n[[Category:Numerical linear algebra]]\n[[Category:Spectral theory]]"
    },
    {
      "title": "Ramanujan graph",
      "url": "https://en.wikipedia.org/wiki/Ramanujan_graph",
      "text": "In [[spectral graph theory]], a '''Ramanujan graph''', named after [[Srinivasa Ramanujan]], is a [[regular graph|regular]] [[Graph (discrete mathematics)|graph]] whose [[spectral gap]] is almost as large as possible (see [[extremal graph theory]]). Such graphs are excellent [[expander graph|spectral expanders]].\n\nExamples of Ramanujan graphs include the [[clique (graph theory)|clique]], the [[biclique]] <math>K_{n,n}</math>, and the [[Petersen graph]].  As [http://www.mast.queensu.ca/~murty/ramanujan.pdf Murty's survey paper] notes, Ramanujan graphs \"fuse diverse branches of pure mathematics, namely, [[number theory]], [[representation theory]], and [[algebraic geometry]]\". As observed by [[Toshikazu Sunada]], a regular graph is Ramanujan if and only if its [[Ihara zeta function]] satisfies an analog of the [[Riemann hypothesis]].<ref>{{citation\n | last = Terras | first = Audrey | authorlink = Audrey Terras\n | isbn = 978-0-521-11367-0\n | mr = 2768284\n | publisher = Cambridge University Press\n | series = Cambridge Studies in Advanced Mathematics\n | title = Zeta functions of graphs: A stroll through the garden\n | volume = 128\n | year = 2011}}</ref>\n\n==Definition==\n\nLet <math>G</math> be a connected <math>d</math>-regular graph with <math>n</math> vertices, and let <math>\\lambda_0 \\geq \\lambda_1 \\geq \\cdots \\geq \\lambda_{n-1}</math> be the [[eigenvalues]] of the [[adjacency matrix]] of <math>G</math>.  Because <math>G</math> is connected and <math>d</math>-regular, its eigenvalues satisfy <math>d = \\lambda_0 > \\lambda_1 </math> <math> \\geq \\cdots \\geq \\lambda_{n-1} \\geq -d </math>.  Whenever there exists <math>\\lambda_i</math> with <math>|\\lambda_i| < d</math>, define\n\n: <math>\\lambda(G) = \\max_{|\\lambda_i| < d} |\\lambda_i|.\\,</math>\n\nA <math>d</math>-regular graph <math>G</math> is a Ramanujan graph if <math>\\lambda(G) \\leq 2\\sqrt{d-1}</math>.\n\nA Ramanujan graph is characterized as a regular graph whose [[Ihara zeta function]] satisfies an analogue of the [[Riemann Hypothesis]].\n\n==Extremality of Ramanujan graphs==\nFor a fixed <math>d</math> and large <math>n</math>, the <math>d</math>-regular, <math>n</math>-vertex Ramanujan graphs nearly minimize <math>\\lambda(G)</math>.  If <math>G</math> is a <math>d</math>-regular graph with [[Diameter (graph theory)|diameter]] <math>m</math>, a theorem due to [[Noga Alon]]<ref>{{citation\n | last = Nilli | first = A. | authorlink = Noga Alon\n | doi = 10.1016/0012-365X(91)90112-F\n | issue = 2\n | journal = [[Discrete Mathematics (journal)|Discrete Mathematics]]\n | mr = 1124768\n | pages = 207–210\n | title = On the second eigenvalue of a graph\n | volume = 91\n | year = 1991}}.</ref> states\n\n: <math>\\lambda_1 \\geq 2\\sqrt{d-1} - \\frac{2\\sqrt{d-1} - 1}{\\lfloor m/2\\rfloor}.</math>\n\nWhenever <math>G</math> is <math>d</math>-regular and connected on at least three vertices, <math>|\\lambda_1| < d</math>, and therefore <math>\\lambda(G) \\geq \\lambda_1</math>.  Let <math>\\mathcal{G}_n^d</math> be the set of all connected <math>d</math>-regular graphs <math>G</math> with at least <math>n</math> vertices.  Because the minimum diameter of graphs in <math>\\mathcal{G}_n^d</math> approaches infinity for fixed <math>d</math> and increasing <math>n</math>, this theorem implies an earlier theorem of Alon and Boppana which states\n\n: <math>\\lim_{n \\to \\infty} \\inf_{G \\in \\mathcal{G}_n^d} \\lambda(G) \\geq 2\\sqrt{d-1}.</math>\n\nA slightly stronger bound is\n\n: <math>\\lambda_1 \\geq 2\\sqrt{d-1} \\cdot \\left(1-\\frac{c}{m^2}\\right),</math>\n\nwhere <math>c\\approx 2\\pi^2</math>. The outline of Friedman's proof is the following. Take <math>k=\\left\\lfloor\\frac{m}{2}\\right\\rfloor-1</math>. Let <math>T_{d,k}</math> be the <math>d</math>-regular tree of height <math>k</math> and let <math>A_{T_k}</math> be its adjacency matrix. We want to prove that <math>\\lambda(G)\\geq \\lambda(T_{d,k})=2\\sqrt{d-1}\\cos\\theta</math>, for some <math>\\theta</math> depending only on <math>m</math>. Define a function <math>g:V(T_{d,k})\\rightarrow \\mathbb R</math> by <math>g(x)=(d-1)^{-\\delta/2}\\cdot \\sin((k+1-\\delta)\\theta)</math>, where <math>\\delta</math> is the distance from <math>x</math> to the root of <math>T_{d,k}</math>. Choosing a <math>\\theta</math> close to <math>2\\pi/m</math> it can be proved that <math>A_{t,k}g=\\lambda(T_{d,k})g</math>. Now let <math>s</math> and <math>t</math> be a pair of vertices at distance <math>m</math> and define\n\n: <math>f(v)=\\begin{cases} c_1 g(v_s) & \\text{for } v \\text{ at distance } \\leq k \\text{ from } s, \\\\\n-c_2 g(v_t) & \\text{for } v \\text{ at distance } \\leq k\\text{ from } t, \\\\\n0 & \\text{otherwise,}\\end{cases}</math>\n\nwhere <math>v_s</math> is a vertex in <math>T_{d,k}</math> which distance to the root is equal to the distance from <math>v</math> to <math>s</math> and the symmetric for <math>v_t</math>. By choosing properly <math>c_1,c_2</math> we get <math>f\\perp 1</math>, <math>(Af)_v\\geq \\lambda(T_{d,k})f_v</math> for <math>v</math> close to <math>s</math> and <math>(Af)_v\\leq \\lambda(T_{d,k})f_v</math> for <math>v</math> close to <math>t</math>. Then by the [[min-max theorem]] <math>\\lambda(G)\\geq fAf^T/\\|f\\|^2\\geq \\lambda(T_{d,k})</math>.\n\n==Constructions==\nConstructions of Ramanujan graphs are often algebraic.\n\n* [[Alexander Lubotzky|Lubotzky]], [[Ralph S. Phillips|Phillips]] and [[Peter Sarnak|Sarnak]]<ref name=lps88>{{cite journal | author=Alexander Lubotzky |author2=Ralph Phillips |author3=Peter Sarnak  | title=Ramanujan graphs | journal=Combinatorica | volume=8 | year=1988 | pages=261–277 | doi=10.1007/BF02126799 | issue=3 }}</ref> show how to construct an infinite family of <math>(p+1)</math>-regular Ramanujan graphs, whenever <math>p</math> is a [[prime number]] and <math>p\\equiv 1 \\pmod 4</math>. Their proof uses the [[Ramanujan conjecture]], which led to the name of Ramanujan graphs. Besides being Ramanujan graphs, their construction satisfies some other properties, for example, their [[girth (graph theory)|girth]] is <math>\\Omega(\\log_{p}(n))</math> where <math>n</math> is the number of nodes.\n* Morgenstern<ref name=m94>{{cite journal | author=Moshe Morgenstern | title=Existence and Explicit Constructions of q+1 Regular Ramanujan Graphs for Every Prime Power q | journal=Journal of Combinatorial Theory, Series B | volume=62 | year=1994 | pages=44–62 | doi=10.1006/jctb.1994.1054 }}</ref> extended the construction of Lubotzky, Phillips and Sarnak. His extended construction holds whenever <math>p</math> is a [[prime power]].\n* Arnold Pizer proved that the [[supersingular isogeny graph]]s are Ramanujan, although they tend to have lower girth than the graphs of Lubotzky, Phillips, and Sarnak.<ref>{{citation\n | last = Pizer | first = Arnold K.\n | doi = 10.1090/S0273-0979-1990-15918-X\n | issue = 1\n | journal = Bulletin of the American Mathematical Society\n | mr = 1027904\n | pages = 127–137\n | series = New Series\n | title = Ramanujan graphs and Hecke operators\n | volume = 23\n | year = 1990}}</ref> Like the graphs of Lubotzky, Phillips, and Sarnak, the degrees of these graphs are always a prime number plus one. These graphs have been proposed as the basis for [[post-quantum cryptography|post-quantum]] [[elliptic-curve cryptography]].<ref>{{citation\n | last1 = Eisenträger | first1 = Kirsten | author1-link = Kirsten Eisenträger\n | last2 = Hallgren | first2 = Sean\n | last3 = Lauter | first3 = Kristin | author3-link = Kristin Lauter\n | last4 = Morrison | first4 = Travis\n | last5 = Petit | first5 = Christophe\n | contribution = Supersingular isogeny graphs and endomorphism rings: Reductions and solutions\n | contribution-url = https://eprint.iacr.org/2018/371.pdf\n | doi = 10.1007/978-3-319-78372-7_11\n | editor1-first = Jesper Buus | editor1-last = Nielsen\n | editor2-first = Vincent | editor2-last = Rijmen | editor2-link = Vincent Rijmen\n | mr = 3794837\n | pages = 329–368\n | publisher = Springer | location = Cham\n | series = Lecture Notes in Computer Science\n | title = Advances in Cryptology – EUROCRYPT 2018: 37th Annual International Conference on the Theory and Applications of Cryptographic Techniques, Tel Aviv, Israel, April 29 - May 3, 2018, Proceedings, Part III\n | volume = 10822\n | year = 2018}}</ref>\n* Adam Marcus, Daniel Spielman and Nikhil Srivastava<ref name=mss13>{{cite conference | author=Adam Marcus |author2=Daniel Spielman |author3=Nikhil Srivastava | title=Interlacing families I: Bipartite Ramanujan graphs of all degrees | conference=Foundations of Computer Science (FOCS), 2013 IEEE 54th Annual Symposium |  year=2013}}</ref> proved the existence of <math>d</math>-regular bipartite Ramanujan graphs for any <math>d</math>. Later<ref name=mss15>{{cite conference | author=Adam Marcus |author2=Daniel Spielman |author3=Nikhil Srivastava | title=Interlacing families IV: Bipartite Ramanujan graphs of all sizes | conference=Foundations of Computer Science (FOCS), 2015 IEEE 56th Annual Symposium |  year=2015}}</ref> they proved that there exist bipartite Ramanujan graphs of every degree and every number of vertices. Michael B. Cohen<ref name=c16>{{cite conference | author=Michael B. Cohen | title=Ramanujan Graphs in Polynomial Time | conference=Foundations of Computer Science (FOCS), 2016 IEEE 57th Annual Symposium |  year=2016 | doi=10.1109/FOCS.2016.37| arxiv=1604.03544 }}</ref> showed how to construct these graphs in polynomial time.\n\n==References==\n{{Reflist}}\n* {{cite book | author=Guiliana Davidoff |author2=Peter Sarnak |author3=Alain Valette  | title=Elementary number theory, group theory and Ramanjuan graphs | publisher=[[Cambridge University Press]] | series=LMS student texts | volume=55 | year=2003 | isbn=0-521-53143-8 | oclc=50253269 }}\n* {{cite journal | author=T. Sunada| title=L-functions in geometry and some applications| journal= Lecture Notes in Math.| volume=1201 | year=1985 | pages=266–284 | doi=10.1007/BFb0075662 | series=Lecture Notes in Mathematics | isbn=978-3-540-16770-9 }}\n\n==External links==\n* [http://www.mast.queensu.ca/~murty/ramanujan.pdf Survey paper by M. Ram Murty]\n\n[[Category:Graph families]]\n[[Category:Algebraic graph theory]]\n[[Category:Spectral theory]]\n[[Category:Regular graphs]]\n[[Category:Srinivasa Ramanujan]]"
    },
    {
      "title": "Rayleigh–Faber–Krahn inequality",
      "url": "https://en.wikipedia.org/wiki/Rayleigh%E2%80%93Faber%E2%80%93Krahn_inequality",
      "text": "In [[spectral geometry]], the '''Rayleigh–Faber–Krahn inequality''', named after its conjecturer, [[Lord Rayleigh]], and two individuals who independently proved the conjecture, [[G. Faber]] and [[Edgar Krahn]], is an [[Inequality (mathematics)|inequality]] concerning the lowest [[Dirichlet eigenvalue]] of the [[Laplace operator]] on a bounded domain in <math>\\mathbb{R}^n</math>, <math>n \\ge 2</math>.<ref name=springer>{{cite web|last=Benguria|first=Rafael D.|title=Rayleigh–Faber–Krahn inequality|url=http://eom.springer.de/r/r130040.htm|work=Encyclopaedia of Mathematics|publisher=SpringerLink|accessdate=6 November 2011}}</ref>  It states that the first Dirichlet eigenvalue is no less than the corresponding Dirichlet eigenvalue of a Euclidean ball having the same volume.  Furthermore, the inequality is [[Rigidity (mathematics)|rigid]] in the sense that if the first Dirichlet eigenvalue is equal to that of the corresponding ball, then the domain must actually be a ball. In the case of <math>n=2</math>, the inequality essentially states that among all drums of equal area, the circular drum (uniquely) has the lowest voice.\n\nMore generally, the Faber–Krahn inequality holds in any [[Riemannian manifold]] in which the [[isoperimetric inequality]] holds.{{Citation needed|date=May 2019}}\n\n==See also==\n* [[Hearing the shape of a drum]]\n\n== References ==\n{{reflist}}\n\n\n{{Linear algebra}}\n{{Areas of mathematics |collapsed}}\n\n{{DEFAULTSORT:Rayleigh-Faber-Krahn inequality}}\n[[Category:Elliptic partial differential equations]]\n[[Category:Riemannian geometry]]\n[[Category:Spectral theory]]\n\n\n{{mathanalysis-stub}}"
    },
    {
      "title": "Rigged Hilbert space",
      "url": "https://en.wikipedia.org/wiki/Rigged_Hilbert_space",
      "text": "In [[mathematics]], a '''rigged Hilbert space''' ('''Gelfand triple''', '''nested Hilbert space''', '''equipped Hilbert space''') is a construction designed to link the [[distribution (mathematics)|distribution]] and [[square-integrable]] aspects of [[functional analysis]]. Such spaces were introduced to study [[spectral theory]] in the broad sense.{{vague|It does something that isn't everything|date=January 2012}} They bring together the '[[bound state]]' ([[eigenvector]]) and '[[Decomposition of spectrum (functional analysis)|continuous spectrum]]', in one place.\n\n==Motivation==\n\nA function such as the canonical [[homomorphism]] of the real line into the complex plane\n\n:<math> x \\mapsto e^{ix} , </math>\n\nis an [[eigenfunction]] of the [[differential operator]]\n\n:<math>-i\\frac{d}{dx}</math>\n\non the [[real line]] '''R''', but isn't [[square-integrable]] for the usual [[Borel measure]] on '''R'''. To properly consider this function as an eigenfunction requires some way of stepping outside the strict confines of the [[Hilbert space]] theory. This was supplied by the apparatus of [[Schwartz distribution]]s, and a ''generalized eigenfunction'' theory was developed in the years after 1950.\n\n==Functional analysis approach==\n\nThe concept of rigged Hilbert space places this idea in an abstract functional-analytic framework.  Formally, a rigged Hilbert space consists of a [[Hilbert space]] ''H'', together with a subspace Φ which carries a [[finer topology]], that is one for which the natural inclusion\n\n:<math> \\Phi \\subseteq H </math>\n\nis continuous.  It is [[Without loss of generality|no loss]] to assume that Φ is [[Dense set|dense]] in ''H'' for the Hilbert norm. We consider the inclusion of [[dual space]]s ''H''<sup>*</sup> in Φ<sup>*</sup>. The latter, dual to Φ in its 'test function' topology, is realised as a space of distributions or generalised functions of some sort, and the [[linear functional]]s on the subspace Φ of type\n\n:<math>\\phi\\mapsto\\langle v,\\phi\\rangle</math>\n\nfor ''v'' in ''H'' are faithfully represented as distributions (because we assume Φ dense).\n\nNow by applying the [[Riesz representation theorem]] we can identify ''H''<sup>*</sup> with ''H''. Therefore, the definition of ''rigged Hilbert space'' is in terms of a sandwich:\n\n:<math>\\Phi \\subseteq H \\subseteq \\Phi^*. </math>\n\nThe most significant examples are those for which Φ is a [[nuclear space]]; this comment is an abstract expression of the idea that Φ consists of test functions and Φ* of the corresponding [[distribution (mathematics)|distributions]]. Also, a simple example is given by [[Sobolev space]]s: Here (in the simplest case of Sobolev spaces on <math>\\mathbb R^n</math>) \n:<math>H=L^2(\\mathbb R^n),\\ \\Phi = H^s(\\mathbb R^n),\\ \\Phi^* = H^{-s}(\\mathbb R^n),</math>\nwhere <math>s>0</math>.\n\n==Formal definition (Gelfand triple)==\n\nA '''rigged Hilbert space''' is a pair (''H'',Φ) with ''H'' a Hilbert space, Φ a dense subspace, such that Φ is given a [[topological vector space]] structure for which the [[inclusion map]] ''i'' is continuous.\n\nIdentifying ''H'' with its dual space ''H<sup>*</sup>'', the adjoint to ''i'' is the map\n\n:<math>i^*:H=H^*\\to\\Phi^*.</math>\n\nThe duality pairing between Φ and Φ<sup>*</sup> is then compatible with the inner product on ''H'', in the sense that:\n\n:<math>\\langle u, v\\rangle_{\\Phi\\times\\Phi^*} = (u, v)_H</math>\n\nwhenever <math>u\\in\\Phi\\subset H</math> and <math>v \\in H=H^* \\subset \\Phi^*</math>. In the case of complex Hilbert spaces, we use a Hermitian inner product; it will be complex linear in ''u'' (math convention) or ''v'' (physics convention), and conjugate-linear (complex anti-linear) in the other variable.\n\nThe triple <math> (\\Phi,\\,\\,H,\\,\\,\\Phi^*)</math> is often named the \"Gelfand triple\"  (after the mathematician [[Israel Gelfand]]).\n\nNote that even though Φ is isomorphic to Φ<sup>*</sup> if it happens that Φ is a Hilbert space in its own right, this isomorphism is ''not'' the same as the composition of the inclusion ''i'' with its adjoint ''i''*\n\n:<math>i^* i:\\Phi\\subset H=H^*\\to\\Phi^*.</math>\n\n==References==\n\n* J.-P. Antoine, ''Quantum Mechanics Beyond Hilbert Space'' (1996), appearing in ''Irreversibility and Causality, Semigroups and Rigged Hilbert Spaces'', Arno Bohm, Heinz-Dietrich Doebner, Piotr Kielanowski, eds., Springer-Verlag, {{isbn|3-540-64305-2}}. ''(Provides a survey overview.)''\n* [[Jean Dieudonné]], ''Éléments d'analyse'' VII (1978). ''(See paragraphs 23.8 and 23.32)''\n* [[Israel Gelfand|I. M. Gelfand]] and N. J. Vilenkin. Generalized Functions, vol. 4: Some Applications of Harmonic Analysis. Rigged Hilbert Spaces. Academic Press, New York, 1964.\n* K. Maurin, ''Generalized Eigenfunction Expansions and Unitary Representations of Topological Groups'', Polish Scientific Publishers, Warsaw, 1968.\n* R. de la Madrid, \"Quantum Mechanics in Rigged Hilbert Space Language,\" [http://galaxy.cs.lamar.edu/~rafaelm/webdis.pdf PhD Thesis] (2001).\n* R. de la Madrid, \"The role of the rigged Hilbert space in Quantum Mechanics,\" Eur. J. Phys. 26, 287 (2005); [https://arxiv.org/abs/quant-ph/0502053 quant-ph/0502053].\n*{{eom|id=Rigged_Hilbert_space|first=R.A.|last= Minlos}}\n\n[[Category:Hilbert space]]\n[[Category:Spectral theory]]\n[[Category:Generalized functions]]"
    },
    {
      "title": "Selberg zeta function",
      "url": "https://en.wikipedia.org/wiki/Selberg_zeta_function",
      "text": "The '''Selberg zeta-function''' was introduced by {{harvs|txt|authorlink=Atle Selberg|first=Atle |last=Selberg|year=1956}}. It is analogous to the famous [[Riemann zeta function]] \n:<math> \\zeta(s) = \\prod_{p\\in\\mathbb{P}} \\frac{1}{1-p^{-s}} </math> \nwhere <math> \\mathbb{P} </math> is the set of prime numbers. The Selberg zeta-function uses the lengths of simple [[closed geodesic]]s instead of the primes numbers. If <math>\\Gamma</math> is a subgroup of [[SL2(R)|SL(2,'''R''')]], the associated Selberg zeta function is defined as follows,\n:<math>\\zeta_\\Gamma(s)=\\prod_p(1-N(p)^{-s})^{-1},</math>\nor\n:<math>Z_\\Gamma(s)=\\prod_p\\prod^\\infty_{n=0}(1-N(p)^{-s-n}),</math>\nwhere ''p'' runs over conjugacy classes of [[prime geodesic]]s (equivalently, conjugacy classes of primitive hyperbolic elements of <math>\\Gamma</math>), and ''N''(''p'') denotes the length of ''p'' (equivalently, the square of the bigger eigenvalue of ''p'').\n\nFor any [[hyperbolic manifold | hyperbolic surface]] of finite area there is an associated '''Selberg zeta-function'''; this function is a [[meromorphic function]] defined in the [[complex plane]]. The zeta function is defined in terms of the closed [[geodesic]]s of the surface.\n\nThe zeros and poles of the Selberg zeta-function, ''Z''(''s''), can be described in terms of spectral data of the surface.\n\nThe zeros are at the following points:\n# For every cusp form with eigenvalue <math>s_0(1-s_0)</math> there exists a zero at the point <math>s_0</math>. The order of the zero equals the dimension of the corresponding eigenspace. (A cusp form is an eigenfunction to the [[Laplace–Beltrami operator]] which has [[Fourier expansion]] with zero constant term.)\n# The zeta-function also has a zero at every pole of the determinant of the scattering matrix, <math> \\phi(s) </math>. The order of the zero equals the order of the corresponding pole of the scattering matrix.\n\nThe zeta-function also has poles at <math> 1/2 - \\mathbb{N} </math>, and can have zeros or poles at the points <math> - \\mathbb{N} </math>.\n\nThe [[Ihara zeta function]] is considered a p-adic (and a graph-theoretic) analogue of the Selberg zeta function.\n\n== Selberg zeta-function for the modular group ==\nFor the case where the surface is <math> \\Gamma \\backslash \\mathbb{H}^2 </math>, where <math> \\Gamma </math> is the [[modular group]], the Selberg zeta-function is of special interest. For this special case the Selberg zeta-function is intimately connected to the [[Riemann zeta function|Riemann zeta-function]].\n\nIn this case the determinant of the [[scattering matrix]] is given by:\n:<math> \\varphi(s) =  \\pi^{1/2} \\frac{ \\Gamma(s-1/2) \\zeta(2s-1) }{ \\Gamma(s) \\zeta(2s) }. </math>{{Citation needed|reason=unveriviable and unsufficient citation about the source|date=May 2017}}\n\nIn particular, we see that if the Riemann zeta-function has a zero at <math>s_0</math>, then the determinant of the scattering matrix has a pole at <math>s_0/2</math>, and hence the Selberg zeta-function has a zero at <math>s_0/2</math>.{{Citation needed|reason=unveriviable and unsufficient citation about the source|date=May 2017}}\n\n==References==\n*{{Citation | last1=Fischer | first1=Jürgen | title=An approach to the Selberg trace formula via the Selberg zeta-function | publisher=[[Springer-Verlag]] | location=Berlin, New York | series=Lecture Notes in Mathematics | isbn=978-3-540-15208-8 | doi=10.1007/BFb0077696 |mr=892317 | year=1987 | volume=1253}}\n*{{Citation | last1=Hejhal | first1=Dennis A. | title=The Selberg trace formula for PSL(2,R). Vol. I | publisher=[[Springer-Verlag]] | location=Berlin, New York | series=Lecture Notes in Mathematics, Vol. 548 | doi=10.1007/BFb0079608 |mr=0439755 | year=1976 | volume=548}}\n*{{Citation | last1=Hejhal | first1=Dennis A. | title=The Selberg trace formula for  PSL(2,R). Vol. 2 | publisher=[[Springer-Verlag]] | location=Berlin, New York | series=Lecture Notes in Mathematics | isbn=978-3-540-12323-1 | doi=10.1007/BFb0061302 |mr=711197 | year=1983 | volume=1001}}\n* [[Henryk Iwaniec|Iwaniec, H.]] Spectral methods of automorphic forms, American Mathematical Society, second edition, 2002.\n*{{Citation | last1=Selberg | first1=Atle | title=Harmonic analysis and discontinuous groups in weakly symmetric Riemannian spaces with applications to Dirichlet series |mr=0088511 | year=1956 | journal=J. Indian Math. Soc. (N.S.) | volume=20 | pages=47–87}}\n* Venkov, A. B. Spectral theory of automorphic functions. Proc. Steklov. Inst. Math, 1982.\n* [[Toshikazu Sunada|Sunada, T.]], L-functions in geometry and some applications, Proc. Taniguchi Symp. 1985, \"Curvature and Topology of Riemannian Manifolds\", Springer Lect. Note in Math. 1201(1986), 266-284. \n\n[[Category:Zeta and L-functions]]\n[[Category:Spectral theory]]"
    },
    {
      "title": "Spectral abscissa",
      "url": "https://en.wikipedia.org/wiki/Spectral_abscissa",
      "text": "{{Orphan|date=March 2017}}\n\nIn [[mathematics]], the '''spectral abscissa''' of a [[matrix (mathematics)|matrix]] or a [[bounded linear operator]] is the [[supremum]] among the real part of the elements in its [[spectrum of a matrix|spectrum]], sometimes denoted as <math>\\eta(A)</math>\n\n==Matrices==\nLet λ<sub>1</sub>, ..., λ<sub>''s''</sub> be the ([[real number|real]] or [[complex number|complex]]) eigenvalues of a matrix ''A'' ∈ '''C'''<sup>''n'' × ''n''</sup>. Then its spectral abscissa is defined as:\n\n:<math>\\eta(A) = \\max_i\\{ {\\rm Re}(\\lambda_i) \\} \\, </math>\n\nFor example, if the set of eigenvalues were = {1+3i,2+3i,4-2i}, then the Spectral abscissa in this case would be 4.\n\nIt is often used as a measure of stability in control theory, where a  continuous system is stable if all its eigenvalues are located in the left half plane, i.e. <math>\\eta(A)<0</math>\n\n==See also==\n[[Spectral radius]]\n\n{{DEFAULTSORT:Spectral Abscissa}}\n[[Category:Spectral theory]]\n[[Category:Matrix theory]]\n\n\n{{Linear-algebra-stub}}"
    },
    {
      "title": "Spectral asymmetry",
      "url": "https://en.wikipedia.org/wiki/Spectral_asymmetry",
      "text": "In [[mathematics]] and [[physics]], the '''spectral asymmetry''' is the asymmetry in the distribution of the [[spectrum]] of [[eigenvalue]]s of an [[Operator (mathematics)|operator]].  In mathematics, the spectral asymmetry arises in the study of [[elliptic operator]]s on [[compact manifold]]s, and is given a deep meaning by the [[Atiyah-Singer index theorem]]. In physics, it has numerous applications, typically resulting in a fractional [[charge (physics)|charge]] due to the asymmetry of the spectrum of a [[Dirac operator]]. For example, the [[vacuum expectation value]] of the [[baryon number]] is given by the spectral asymmetry of the [[Hamiltonian operator]]. The spectral asymmetry of the confined [[quark]] fields is an important property of the [[chiral bag model]]. For [[fermion]]s, it is known as the [[Witten index]], and can be understood as describing the [[Casimir effect]] for fermions.\n\n==Definition==\nGiven an operator with [[eigenvalue]]s <math>\\omega_n</math>, an equal number of which are positive and negative, the spectral asymmetry may be defined as the sum\n\n:<math>B=\\lim_{t\\to 0} \\frac{1}{2}\\sum_n \\sgn(\\omega_n) \\exp (-t|\\omega_n|) </math>\n\nwhere <math>\\sgn(x)</math> is the [[sign function]].  Other [[regularization (physics)|regulator]]s, such as the [[zeta function regulator]], may be used.\n\nThe need for both a positive and negative spectrum in the definition is why the spectral asymmetry usually occurs in the study of [[Dirac operator]]s.\n\n==Example==\nAs an example, consider an operator with a spectrum\n\n:<math>\\omega_n=n+\\theta</math>\n\nwhere ''n'' is an integer, ranging over all positive and negative values. One may show in a straightforward manner that the spectral asymmetry in this case is <math>B=\\theta</math>.\n\n==Discussion==\nRelated to the spectral asymmetry is the vacuum expectation value of the energy associated with the operator, the [[Casimir energy]], which is given by\n\n:<math>E=\\lim_{t\\to 0} \\frac{1}{2}\\sum_n |\\omega_n| \\exp (-t|\\omega_n|) </math>\n\nThis sum is formally divergent, and the divergences must be accounted for and removed using standard regularization techniques.\n\n==References==\n* MF Atiyah, VK Patodi and IM Singer, ''Spectral asymmetry and Riemannian geometry I'', Proc. Camb. Phil. Soc., '''77''' (1975), 43-69.\n* Linas Vepstas,  A.D. Jackson, A.S. Goldhaber, ''Two-phase models of baryons and the chiral Casimir effect'', Physics Letters '''B140''' (1984) p. 280-284.\n* Linas Vepstas, A.D. Jackson, ''Justifying the Chiral Bag'', Physics Reports, '''187''' (1990) p. 109-143.\n\n[[Category:Spectral theory]]\n[[Category:Asymmetry]]"
    },
    {
      "title": "Spectral gap",
      "url": "https://en.wikipedia.org/wiki/Spectral_gap",
      "text": "{{sources|date=December 2018}}\nIn mathematics, the '''spectral gap''' is the difference between the [[absolute value|moduli]] of the two largest [[eigenvalue]]s of a matrix or operator; alternately, it is sometimes taken as the smallest non-zero eigenvalue.  Various theorems relate this difference to other properties of the system.\n \nSee:\n\n* [[Expander graph]] (discrete case)\n* [[Poincaré inequality]] (continuous case)\n\n==See also==\n* [[Spectral radius]]\n* [[Eigengap]]\n* [[Spectral gap (physics)]]\n\n{{set index article}}\n\n==References==\n{{Reflist}}\n\n[[Category:Spectral theory]]"
    },
    {
      "title": "Spectral geometry",
      "url": "https://en.wikipedia.org/wiki/Spectral_geometry",
      "text": "'''Spectral geometry''' is a field in [[mathematics]] which concerns relationships between geometric structures of [[manifold]]s and [[Spectrum (functional analysis)|spectra]] of canonically defined [[differential operator]]s. The case of the [[Laplace–Beltrami operator]] on a [[Closed manifold|closed]] [[Riemannian manifold]] has been most intensively studied, although other [[Laplace operators in differential geometry]] have also been examined.  The field concerns itself with two kinds of questions: direct problems and inverse problems.\n\nInverse problems seek to identify features of the geometry from information about the [[eigenvalue]]s of the Laplacian.  One of the earliest results of this kind was due to [[Hermann Weyl]] who used [[David Hilbert]]'s theory of [[integral equation]] in 1911 to show that the volume of a bounded domain in [[Euclidean space]] can be determined from the [[asymptotic behavior]] of the eigenvalues for the [[Dirichlet boundary condition|Dirichlet boundary value problem]] of the [[Laplace operator]]. This question is usually expressed as \"[[Hearing the shape of a drum|Can one hear the shape of a drum?]]\", the popular phrase due to [[Mark Kac]]. A refinement of Weyl's asymptotic formula obtained by Pleijel and Minakshisundaram produces a series of local [[spectral invariants]] involving [[covariant differentiation]]s of the [[Riemann curvature tensor|curvature tensor]], which can be used to establish spectral rigidity for a special class of manifolds. However as the example given by [[John Milnor]] tells us, the information of eigenvalues is not enough to determine the [[isometry (Riemannian geometry)|isometry]] class of a manifold (see [[isospectral]]). A general and systematic method due to [[Toshikazu Sunada]] gave rise to a veritable cottage industry of such examples which clarifies the phenomenon of isospectral manifolds.\n\nDirect problems attempt to infer the behavior of the eigenvalues of a Riemannian manifold from knowledge of the geometry. The solutions to direct problems are typified by the [[Jeff Cheeger|Cheeger]] inequality which gives a relation between the first positive eigenvalue and an [[isoperimetric inequality|isoperimetric constant]] (the [[Cheeger constant]]). Many versions of the inequality have been established since Cheeger's work (by [[Robert W. Brooks|R. Brooks]] and P. Buser for instance).\n\n==See also==\n*[[Isospectral]]\n*[[Hearing the shape of a drum]]\n\n== References ==\n\n* {{citation|last1=Berger|first=Marcel|authorlink1=Marcel Berger|last2=Gauduchon|first2=Paul|last3=Mazet|first3=Edmond|title=Le spectre d'une variété riemannienne|series=Lecture Notes in Mathematics|volume=194|publisher=Springer-Verlag|publication-place=Berlin-New York|year=1971|language=fr}}.\n* {{citation|doi=10.2307/1971195|first=Toshikazu|last=Sunada|authorlink=Toshikazu Sunada|title=Riemannian coverings and isospectral manifolds|journal=Ann. of Math.|volume=121|issue=1|year=1985|pages=169–186|jstor=1971195}}.\n\n[[Category:Differential geometry]]\n[[Category:Spectral theory]]\n[[Category:Riemannian geometry]]"
    },
    {
      "title": "Spectral radius",
      "url": "https://en.wikipedia.org/wiki/Spectral_radius",
      "text": "{{Use Canadian English|date = March 2019}}\n{{Short description|Largest absolute value of an operator's eigenvalues}}\nIn [[mathematics]], the '''spectral radius''' of a [[matrix (mathematics)|square matrix]] or a [[bounded linear operator]] is the largest absolute value of its [[eigenvalues]] (i.e. [[supremum]] among the [[absolute value]]s of the elements in its [[spectrum of a matrix|spectrum]]). It is sometimes denoted by ρ(·).\n\n==Matrices==\nLet {{math|''λ''<sub>1</sub>, ..., ''λ<sub>n</sub>''}} be the ([[real number|real]] or [[complex number|complex]]) eigenvalues of a matrix {{math|''A'' ∈ '''C'''<sup>''n''×''n''</sup>}}. Then its spectral radius {{math|''ρ''(''A'')}} is defined as:\n\n:<math>\\rho(A) = \\max \\left \\{ |\\lambda_1|, \\dotsc, |\\lambda_n| \\right \\}.</math>\n\nThe [[condition number]] of <math>A</math> can be expressed using the spectral radius as <math> \\rho(A) \\rho(A^{-1}) </math>.\n\nThe spectral radius is a sort of infimum of all norms of a matrix. On the one hand, <math> \\rho(A) \\leqslant \\|A\\| </math> for every [[matrix norm#Matrix norms induced by vector norms|natural matrix norm]] <math>\\|\\cdot\\|</math>, and on the other hand, Gelfand's formula states that <math> \\rho(A) = \\lim_{k\\to\\infty} \\|A^k\\|^{1/k} </math>; both these results are shown below. However, the spectral radius does not necessarily satisfy <math> \\|A\\mathbf{v}\\| \\leqslant \\rho(A) \\|\\mathbf{v}\\| </math> for arbitrary vectors <math> \\mathbf{v} \\in \\mathbb{C}^n </math>. To see why, let <math> r>1 </math> be arbitrary and consider the matrix <math> C_r = \\begin{pmatrix} 0 & r^{-1} \\\\ r & 0 \\end{pmatrix} </math>. The [[characteristic polynomial]] of <math> C_r </math> is <math> \\lambda^2 - 1 </math>, hence its eigenvalues are <math> \\pm 1 </math>, and thus <math> \\rho(C_r) = 1 </math>. However <math> C_r \\mathbf{e}_1 = r \\mathbf{e}_2 </math>, so <math> \\| C_r \\mathbf{e}_1 \\| = r > 1 = \\rho(C_r) \\|\\mathbf{e}_1\\| </math> for <math> \\|\\cdot\\| </math> being any <math> \\ell^p </math> norm on <math> \\mathbb{C}^n </math>. What still allows <math> \\|C_r^k\\|^{1/k} \\to 1 </math> as <math> k \\to \\infty </math> is that <math> C_r^2 = I </math>, making <math> \\|C_r^k\\|^{1/k} \\leqslant \\|C_r\\|^{1/k} = r^{1/k} \\to 1 </math> as <math> k \\to \\infty </math>.\n: <math> \\|A\\mathbf{v}\\| \\leqslant \\rho(A) \\|\\mathbf{v}\\| </math> for all <math> \\mathbf{v} \\in \\mathbb{C}^n </math>\n''does'' hold when <math>A</math> is a [[Hermitian matrix]] and <math> \\|\\cdot\\| </math> is the [[Euclidean norm]].\n\n==Graphs==\nThe spectral radius of a finite [[Graph (discrete mathematics)|graph]] is defined to be the spectral radius of its [[adjacency matrix]].\n\nThis definition extends to the case of infinite graphs with bounded degrees of vertices (i.e. there exists some real number {{mvar|C}} such that the degree of every vertex of the graph is smaller than {{mvar|C}}). In this case, for the graph {{mvar|G}} define:\n\n:<math> \\ell^2(G) = \\left \\{ f : V(G) \\to \\mathbf{R} \\ : \\ \\sum\\nolimits_{v \\in V(G)} \\left \\|f(v)^2 \\right \\| < \\infty \\right \\}.</math>\n\nLet {{mvar|γ}} be the adjacency operator of {{mvar|G}}:\n\n:<math> \\begin{cases} \\gamma : \\ell^2(G) \\to \\ell^2(G) \\\\ (\\gamma f)(v) = \\sum_{(u,v) \\in E(G)} f(u) \\end{cases}</math>\n\nThe spectral radius of {{mvar|G}} is defined to be the spectral radius of the bounded linear operator {{mvar|γ}}.\n\n==Upper bound==\n\n===Proposition===\n\nThe following proposition shows a simple yet useful upper bound for the spectral radius of a matrix:\n:'''Proposition.''' Let {{math|''A'' ∈ '''C'''<sup>''n''×''n''</sup>}} with spectral radius {{math|''ρ''(''A'')}} and a [[matrix norm#Consistent norms|consistent matrix norm]] {{math|{{!!}}⋅{{!!}}}}. Then for each integer <math>k \\geqslant 1</math>:\n::<math>\\rho(A)\\leq \\|A^k\\|^{\\frac{1}{k}}.</math>\n\n===Proof of proposition===\nLet {{math|('''v''', ''λ'')}} be an [[eigenvector]]-[[eigenvalue]] pair for a matrix ''A''. By the sub-multiplicative property of the matrix norm, we get:\n\n:<math>|\\lambda|^k\\|\\mathbf{v}\\| = \\|\\lambda^k \\mathbf{v}\\| = \\|A^k \\mathbf{v}\\| \\leq \\|A^k\\|\\cdot\\|\\mathbf{v}\\|</math>\n\nand since {{math|'''v''' ≠ 0}} we have\n\n:<math>|\\lambda|^k \\leq \\|A^k\\|</math>\n\nand therefore\n\n:<math>\\rho(A)\\leq \\|A^k\\|^{\\frac{1}{k}}.</math>\n\n==Power sequence==\n\n===Theorem===\n\nThe spectral radius is closely related to the behaviour of the convergence of the power sequence of a matrix; namely, the following theorem holds:\n:'''Theorem.''' Let {{math|''A'' ∈ '''C'''<sup>''n''×''n''</sup>}} with spectral radius {{math|''ρ''(''A'')}}. Then {{math|''ρ''(''A'') < 1}} if and only if\n::<math>\\lim_{k \\to \\infty} A^k = 0.</math>\n:On the other hand, if {{math|''ρ''(''A'') > 1}}, <math>\\lim_{k \\to \\infty} \\|A^k\\| = \\infty</math>. The statement holds for any choice of matrix norm on {{math|'''C'''<sup>''n''×''n''</sup>}}.\n\n===Proof of theorem===\n\nAssume the limit in question is zero, we will show that {{math|''ρ''(''A'') < 1}}. Let {{math|('''v''', ''λ'')}} be an [[eigenvector]]-[[eigenvalue]] pair for ''A''. Since {{math|''A<sup>k</sup>'''''v''' {{=}} ''λ<sup>k</sup>'''''v'''}} we have:\n\n:<math>\\begin{align}\n  0 &= \\left(\\lim_{k \\to \\infty} A^k \\right) \\mathbf{v} \\\\\n    &= \\lim_{k \\to \\infty} \\left(A^k\\mathbf{v} \\right ) \\\\\n    &= \\lim_{k \\to \\infty} \\lambda^k\\mathbf{v} \\\\\n    &= \\mathbf{v} \\lim_{k \\to \\infty} \\lambda^k\n\\end{align}</math>\n\nand, since by hypothesis {{math|'''v''' ≠ 0}}, we must have\n\n:<math>\\lim_{k \\to \\infty}\\lambda^k = 0</math>\n\nwhich implies |λ| < 1. Since this must be true for any eigenvalue λ, we can conclude ρ(''A'') < 1.\n\nNow assume the radius of {{mvar|A}} is less than {{math|1}}. From the [[Jordan normal form]] theorem, we know that for all {{math|''A'' ∈ '''C'''<sup>''n''×''n''</sup>}}, there exist {{math|''V'', ''J'' ∈ '''C'''<sup>''n''×''n''</sup>}} with {{mvar|V}} non-singular and {{mvar|J}} block diagonal such that:\n\n:<math>A = VJV^{-1}</math>\n\nwith\n\n:<math>J=\\begin{bmatrix}\nJ_{m_1}(\\lambda_1) & 0 & 0 & \\cdots & 0 \\\\\n0 & J_{m_2}(\\lambda_2) & 0 & \\cdots & 0 \\\\\n\\vdots & \\cdots & \\ddots & \\cdots & \\vdots \\\\\n0 & \\cdots & 0 & J_{m_{s-1}}(\\lambda_{s-1}) & 0 \\\\\n0 & \\cdots & \\cdots & 0 & J_{m_s}(\\lambda_s)\n\\end{bmatrix}</math>\n\nwhere\n\n:<math>J_{m_i}(\\lambda_i)=\\begin{bmatrix}\n\\lambda_i & 1 & 0 & \\cdots & 0 \\\\\n0 & \\lambda_i & 1 & \\cdots & 0 \\\\\n\\vdots & \\vdots & \\ddots & \\ddots & \\vdots \\\\\n0 & 0 & \\cdots & \\lambda_i & 1 \\\\\n0 & 0 & \\cdots & 0 & \\lambda_i\n\\end{bmatrix}\\in \\mathbf{C}^{m_i \\times m_i}, 1\\leq i\\leq s.</math>\n\nIt is easy to see that\n\n:<math>A^k=VJ^kV^{-1}</math>\n\nand, since {{mvar|J}} is block-diagonal,\n\n:<math>J^k=\\begin{bmatrix}\nJ_{m_1}^k(\\lambda_1) & 0 & 0 & \\cdots & 0 \\\\\n0 & J_{m_2}^k(\\lambda_2) & 0 & \\cdots & 0 \\\\\n\\vdots & \\cdots & \\ddots & \\cdots & \\vdots \\\\\n0 & \\cdots & 0 & J_{m_{s-1}}^k(\\lambda_{s-1}) & 0 \\\\\n0 & \\cdots & \\cdots & 0 & J_{m_s}^k(\\lambda_s)\n\\end{bmatrix}</math>\n\nNow, a standard result on the {{mvar|k}}-power of an <math>m_i \\times m_i</math> Jordan block states that, for <math>k \\geq m_i-1</math>:\n\n:<math>J_{m_i}^k(\\lambda_i)=\\begin{bmatrix}\n\\lambda_i^k & {k \\choose 1}\\lambda_i^{k-1} & {k \\choose 2}\\lambda_i^{k-2} & \\cdots & {k \\choose m_i-1}\\lambda_i^{k-m_i+1} \\\\\n0 & \\lambda_i^k & {k \\choose 1}\\lambda_i^{k-1} & \\cdots & {k \\choose m_i-2}\\lambda_i^{k-m_i+2} \\\\\n\\vdots & \\vdots & \\ddots & \\ddots & \\vdots \\\\\n0 & 0 & \\cdots & \\lambda_i^k & {k \\choose 1}\\lambda_i^{k-1} \\\\\n0 & 0 & \\cdots & 0 & \\lambda_i^k\n\\end{bmatrix}</math>\n\nThus, if <math>\\rho(A) < 1</math> then for all {{mvar|i}} <math>|\\lambda_i| < 1</math>. Hence for all {{mvar|i}} we have:\n\n:<math>\\lim_{k \\to \\infty}J_{m_i}^k=0</math>\n\nwhich implies\n\n:<math>\\lim_{k \\to \\infty} J^k = 0.</math>\n\nTherefore,\n\n:<math>\\lim_{k \\to \\infty}A^k=\\lim_{k \\to \\infty}VJ^kV^{-1}=V \\left (\\lim_{k \\to \\infty}J^k \\right )V^{-1}=0</math>\n\nOn the other side, if <math>\\rho(A)>1</math>, there is at least one element in {{mvar|J}} which doesn't remain bounded as k increases, so proving the second part of the statement.\n\n==Gelfand's formula==\n\n=== Theorem ===\nThe next theorem gives the spectral radius as a limit of matrix norms.\n:'''Theorem (Gelfand's Formula; 1941).''' For any [[matrix norm]] {{math|{{!!}}⋅{{!!}},}} we have\n::<math>\\rho(A)=\\lim_{k \\to \\infty} \\left \\|A^k \\right \\|^{\\frac{1}{k}}.</math><ref>The formula holds for any [[Banach algebra]]; see {{harvnb|Lax|2002|pp=195–197}}</ref>\n\n===Proof===\nFor any {{math|''ε'' > 0}}, first we construct the following two matrices:\n\n:<math>A_{\\pm}= \\frac{1}{\\rho(A) \\pm\\varepsilon}A.</math>\n\nThen:\n\n:<math>\\rho \\left (A_{\\pm} \\right ) = \\frac{\\rho(A)}{\\rho(A) \\pm \\varepsilon}, \\qquad \\rho (A_+) < 1 < \\rho (A_-).</math>\n\nFirst we apply the previous theorem to {{math|''A''<sub>+</sub>}}:\n\n:<math>\\lim_{k \\to \\infty} A_+^k=0.</math>\n\nThat means, by the sequence limit definition, there exists {{math|''N''<sub>+</sub> ∈ '''N'''}} such that for all ''k'' ≥ N<sub>+</sub>,\n\n:<math>\\begin{align}\n\\left \\|A_+^k \\right \\| < 1 \\end{align}</math>\nso\n:<math>\\begin{align}\n\\left \\|A^k \\right \\|^{\\frac{1}{k}} < \\rho(A)+\\varepsilon.\n\\end{align}</math>\n\nApplying the previous theorem to {{math|''A''<sub>−</sub>}} implies <math>\\|A_-^k\\|</math> is not bounded and there exists {{math|''N''<sub>−</sub> ∈ '''N'''}} such that  for all ''k'' ≥ N<sub>−</sub>,\n\n:<math>\\begin{align}\n\\left\\|A_-^k \\right \\| > 1 \n\\end{align}</math>\nso\n:<math>\\begin{align}\n\\left\\|A^k \\right\\|^{\\frac{1}{k}} > \\rho(A)-\\varepsilon. \n\\end{align}</math>\n\nLet {{math|''N'' {{=}} max{''N''<sub>+</sub>, ''N''<sub>−</sub>},}} then we have:\n\n:<math>\\forall \\varepsilon>0\\quad \\exists N\\in\\mathbf{N} \\quad \\forall k\\geq N \\quad \\rho(A)-\\varepsilon < \\left \\|A^k \\right \\|^{\\frac{1}{k}} < \\rho(A)+\\varepsilon</math>\n\nwhich, by definition, is\n\n:<math>\\lim_{k \\to \\infty} \\left \\|A^k \\right \\|^{\\frac{1}{k}} = \\rho(A).</math>\n\n==Gelfand corollaries==\nGelfand's formula leads directly to a bound on the spectral radius of a product of finitely many matrices, namely assuming that they all commute we obtain\n\n:<math>\\rho(A_1 \\cdots A_n) \\leq \\rho(A_1) \\cdots \\rho(A_n).</math>\n\nActually, in case the norm is [[matrix norm|consistent]], the proof shows more than the thesis; in fact, using the previous lemma, we can replace in the limit definition the left lower bound with the spectral radius itself and write more precisely:\n\n:<math>\\forall \\varepsilon>0, \\exists N\\in\\mathbf{N}, \\forall k\\geq N \\quad \\rho(A) \\leq \\|A^k\\|^{\\frac{1}{k}} < \\rho(A)+\\varepsilon</math>\n\nwhich, by definition, is\n\n:<math>\\lim_{k \\to \\infty} \\left \\|A^k \\right \\|^{\\frac{1}{k}} = \\rho(A)^+,</math>\n\nwhere the + means that the limit is approached from above.\n\n==Example==\nConsider the matrix\n\n:<math>A=\\begin{bmatrix}\n9 & -1 & 2\\\\\n-2 & 8 & 4\\\\\n1 & 1 & 8\n\\end{bmatrix}</math>\n\nwhose eigenvalues are {{math|5, 10, 10}}; by definition, {{math|''ρ''(''A'') {{=}} 10}}. In the following table, the values of <math>\\|A^k\\|^{\\frac{1}{k}}</math> for the four most used norms are listed versus several increasing values of k (note that, due to the particular form of this matrix,<math>\\|.\\|_1=\\|.\\|_\\infty</math>):\n\n{| class=wikitable\n! ''k''\n! <math>\\|.\\|_1=\\|.\\|_\\infty</math>\n! <math>\\|.\\|_F</math>\n! <math>\\|.\\|_2</math>\n|-\n| 1\n| 14\n| 15.362291496\n| 10.681145748\n|-\n| 2\n| 12.649110641\n| 12.328294348\n| 10.595665162\n|-\n| 3\n| 11.934831919\n| 11.532450664\n| 10.500980846\n|-\n| 4\n| 11.501633169\n| 11.151002986\n| 10.418165779\n|-\n| 5\n| 11.216043151\n| 10.921242235\n| 10.351918183\n|-\n| <math>\\vdots</math>\n| <math>\\vdots</math>\n| <math>\\vdots</math>\n| <math>\\vdots</math>\n|-\n| 10\n| 10.604944422\n| 10.455910430\n| 10.183690042\n|-\n| 11\n| 10.548677680\n| 10.413702213\n| 10.166990229\n|-\n| 12\n| 10.501921835\n| 10.378620930\n| 10.153031596\n|-\n| <math>\\vdots</math>\n| <math>\\vdots</math>\n| <math>\\vdots</math>\n| <math>\\vdots</math>\n|-\n| 20\n| 10.298254399\n| 10.225504447\n| 10.091577411\n|-\n| 30\n| 10.197860892\n| 10.149776921\n| 10.060958900\n|-\n| 40\n| 10.148031640\n| 10.112123681\n| 10.045684426\n|-\n| 50\n| 10.118251035\n| 10.089598820\n| 10.036530875\n|-\n| <math>\\vdots</math>\n| <math>\\vdots</math>\n| <math>\\vdots</math>\n| <math>\\vdots</math>\n|-\n| 100\n| 10.058951752\n| 10.044699508\n| 10.018248786\n|-\n| 200\n| 10.029432562\n| 10.022324834\n| 10.009120234\n|-\n| 300\n| 10.019612095\n| 10.014877690\n| 10.006079232\n|-\n| 400\n| 10.014705469\n| 10.011156194\n| 10.004559078\n|-\n| <math>\\vdots</math>\n| <math>\\vdots</math>\n| <math>\\vdots</math>\n| <math>\\vdots</math>\n|-\n| 1000\n| 10.005879594\n| 10.004460985\n| 10.001823382\n|-\n| 2000\n| 10.002939365\n| 10.002230244\n| 10.000911649\n|-\n| 3000\n| 10.001959481\n| 10.001486774\n| 10.000607757\n|-\n| <math>\\vdots</math>\n| <math>\\vdots</math>\n| <math>\\vdots</math>\n| <math>\\vdots</math>\n|-\n| 10000\n| 10.000587804\n| 10.000446009\n| 10.000182323\n|-\n| 20000\n| 10.000293898\n| 10.000223002\n| 10.000091161\n|-\n| 30000\n| 10.000195931\n| 10.000148667\n| 10.000060774\n|-\n| <math>\\vdots</math>\n| <math>\\vdots</math>\n| <math>\\vdots</math>\n| <math>\\vdots</math>\n|-\n| 100000\n| 10.000058779\n| 10.000044600\n| 10.000018232\n|}\n\n==Bounded linear operators==\nFor a [[bounded linear operator]] {{mvar|A}} and the [[operator norm]] ||·||, again we have\n\n:<math>\\rho(A) = \\lim_{k \\to \\infty}\\|A^k\\|^{\\frac{1}{k}}.</math>\n\nA bounded operator (on a complex Hilbert space) is called a '''spectraloid operator''' if its spectral radius coincides with its [[numerical radius]]. An example of such an operator is a [[normal operator]].\n\n==Notes and references==\n{{reflist}}\n* {{citation | last=Lax| first = Peter D. |authorlink=Peter Lax \n| title = Functional Analysis | publisher = Wiley-Interscience | year = 2002 \n| isbn = 0-471-55604-1}}\n\n==See also==\n* [[Spectral gap]]\n* The [[Joint spectral radius]] is a generalization of the spectral radius to sets of matrices.\n* [[Spectrum of a matrix]]\n* [[Spectral abscissa]]\n\n{{Functional Analysis}}\n\n[[Category:Spectral theory]]\n[[Category:Articles containing proofs]]"
    },
    {
      "title": "Spectral theory of compact operators",
      "url": "https://en.wikipedia.org/wiki/Spectral_theory_of_compact_operators",
      "text": "{{Cleanup rewrite|it is written like a maths textbook, not an encyclopedia article|article|date=September 2017}}\n\nIn [[functional analysis]], [[compact operator]]s are linear operators on Banach spaces that map bounded sets to [[relatively compact set]]s. In the case of a Hilbert space ''H'', the compact operators are the closure of the finite rank operators in the uniform operator topology. In general, operators on infinite-dimensional spaces feature properties that do not appear in the finite-dimensional case, i.e. for matrices. The compact operators are notable in that they share as much similarity with matrices as one can expect from a general operator. In particular, the spectral properties of compact operators resemble those of square matrices.\n\nThis article first summarizes the corresponding results from the matrix case before discussing the spectral properties of compact operators. The reader will see that most statements transfer verbatim from the matrix case.\n\nThe spectral theory of compact operators was first developed by [[F. Riesz]].\n\n== Spectral theory of matrices ==\n{{further|Jordan canonical form}}\n\nThe classical result for square matrices is the Jordan canonical form, which states the following:\n\n'''Theorem.''' Let ''A'' be an ''n'' × ''n'' complex matrix, i.e. ''A'' a linear operator acting on '''C'''<sup>''n''</sup>. If ''λ''<sub>1</sub>...''λ<sub>k</sub>'' are the distinct eigenvalues of ''A'', then '''C'''<sup>''n''</sup> can be decomposed into the invariant subspaces of ''A''\n\n:<math>\\mathbf{C}^n = \\bigoplus _{i = 1}^k Y_i.</math>\n\nThe subspace ''Y<sub>i</sub>'' = ''Ker''(''λ<sub>i</sub>'' − ''A'')<sup>''m''</sup> where ''Ker''(''λ<sub>i</sub>'' − ''A'')<sup>''m''</sup> = ''Ker''(''λ<sub>i</sub>'' − ''A'')<sup>''m''+1</sup>. Furthermore,  the poles of the resolvent function ''ζ'' → (''ζ'' − ''A'')<sup>−1</sup> coincide with the set of eigenvalues of ''A''.\n\n== Compact operators ==\n\n=== Statement ===\nLet ''X'' be a Banach space, ''C'' be a compact operator acting on ''X'', and ''σ''(''C'') be the [[spectrum (functional analysis)|spectrum]] of ''C''. The spectral properties of ''C'' are:\n\n<blockquote>'''Theorem.'''<br>\n\n'''i''') Every nonzero ''λ'' ∈ ''σ''(''C'') is an eigenvalue of ''C''.<br>\n\n'''ii''') For all nonzero ''λ'' ∈ ''σ''(''C''), there exist ''m'' such that ''Ker''((''λ'' − ''C'')<sup>''m''</sup>) = ''Ker''((''λ'' − ''C'')<sup>''m''+1</sup>), and this subspace is finite-dimensional.<br>\n\n'''iii''') The eigenvalues can only accumulate at 0. If the dimension of ''X'' is not finite, then ''σ''(''C'') must contain 0.<br>\n\n'''iv''') ''σ''(''C'') is at most countably infinite.<br>\n\n'''v''') Every nonzero ''λ'' ∈ ''σ''(''C'') is a pole of the resolvent function ''ζ'' → (''ζ'' − ''C'')<sup>−1</sup>.</blockquote>\n\n=== Proof ===\n\n==== Preliminary Lemmas====\nThe theorem claims several properties of the operator ''λ'' − ''C'' where ''λ'' ≠ 0. Without loss of generality, it can be assumed that ''λ'' = 1. Therefore we consider ''I'' − ''C'', ''I'' being the identity operator. The proof will require two lemmas.\n\n<blockquote>'''Lemma 1 ([[Riesz's lemma]]).''' Let ''X'' be a Banach space and ''Y'' ⊂ ''X'', ''Y'' ≠ ''X'', be a closed subspace. For all ''ε'' > 0, there exists ''x'' ∈ ''X'' such that ||''x''|| = 1 and\n\n:<math>1 - \\varepsilon \\le d(x, Y) \\le 1</math>\n\nwhere ''d''(''x'', ''Y'') is the distance from ''x'' to ''Y''. </blockquote>\n\nThis fact will be used repeatedly in the argument leading to the theorem. Notice that when ''X'' is a Hilbert space, the lemma is trivial.\n\n<blockquote>'''Lemma 2.''' If ''C'' is compact, then ''Ran''(''I'' − ''C'') is closed.</blockquote>\n\n'''Proof:''' Let (''I'' − ''C'')''x<sub>n</sub>'' → ''y'' in norm. If {''x<sub>n</sub>''} is bounded, then compactness of ''C'' implies that there exists a subsequence ''x<sub>nk</sub>'' such that ''C x<sub>nk</sub>'' is norm convergent. So ''x<sub>nk</sub>'' = (''I'' - ''C'')''x<sub>nk</sub>'' + ''C x<sub>nk</sub>'' is norm convergent, to some ''x''. This gives (''I'' − ''C'')''x<sub>nk</sub>'' → (''I'' − ''C'')''x'' = ''y''. The same argument goes through if the distances ''d''(''x<sub>n</sub>'', ''Ker''(''I'' − ''C'')) is bounded.\n\nBut ''d''(''x<sub>n</sub>'', ''Ker''(''I'' − ''C'')) must be bounded. Suppose this is not the case. Pass now to the quotient map of (''I'' − ''C''), still denoted by (''I'' − ''C''), on ''X''/''Ker''(''I'' − ''C''). The quotient norm on ''X''/''Ker''(''I'' − ''C'') is still denoted by ||·||, and {''x<sub>n</sub>''} are now viewed as representatives of their equivalence classes in the quotient space. Take a subsequence {''x<sub>nk</sub>''} such that ||''x<sub>n</sub>''|| > ''k'' and define a sequence of unit vectors by ''z<sub>nk</sub>'' = ''x<sub>nk</sub>''/||''x<sub>nk</sub>''||. Again we would have (''I'' − ''C'')''z<sub>nk</sub>'' → (''I'' − ''C'')''z'' for some ''z''. Since ||(''I'' − ''C'')''z<sub>nk</sub>''|| = ||(''I'' − ''C'')''x<sub>nk</sub>''||/ ||''x<sub>nk</sub>''|| → 0, we have (''I'' − ''C'')''z'' = 0 i.e. ''z'' ∈ ''Ker''(''I'' − ''C''). Since we passed to the quotient map, ''z'' = 0. This is impossible because ''z'' is the norm limit of a sequence of unit vectors. Thus the lemma is proven.\n\n====Concluding the Proof====\n'''i''') Without loss of generality, assume ''λ'' = 1. ''λ'' ∈ ''σ''(''C'') not being an eigenvalue means (''I'' − ''C'') is injective but not surjective. By Lemma 2, ''Y''<sub>1</sub> = ''Ran''(''I'' − ''C'') is a closed proper subspace of ''X''. Since (''I'' − ''C'') is injective, ''Y''<sub>2</sub> = (''I'' − ''C'')''Y''<sub>1</sub> is again a closed proper subspace of ''Y''<sub>1</sub>. Define ''Y''<sub>n</sub> = ''Ran''(''I'' − ''C'')<sup>''n''</sup>. Consider the decreasing sequence of subspaces\n\n:<math>Y_1 \\supset \\cdots \\supset Y_n \\cdots \\supset Y_m \\cdots </math>\n\nwhere all inclusions are proper. By lemma 1, we can choose unit vectors ''y<sub>n</sub>'' ∈ ''Y<sub>n</sub>'' such that ''d''(''y<sub>n</sub>'', ''Y''<sub>''n''+1</sub>) > ½. Compactness of ''C'' means {''C y<sub>n</sub>''} must contain a norm convergent subsequence. But for ''n'' < ''m''\n\n:<math> \\left \\| C y_n - C y_m \\right \\| = \\left \\| (C-I) y_n + y_n - (C-I) y_m - y_m \\right \\|</math>\n\nand notice that\n\n:<math>(C-I) y_n - (C-I) y_m - y_m  \\in Y_{n+1},</math>\n\nwhich implies ||''Cy<sub>n</sub> − Cy<sub>m</sub>''|| > ½. This is a contradiction, and so ''λ'' must be an eigenvalue.\n\n'''ii''') The sequence { ''Y<sub>n</sub>'' = ''Ker''(''λ<sub>i</sub>'' − ''A'')<sup>''n''</sup>} is an increasing sequence of closed subspaces. The theorem claims it stops. Suppose it does not stop, i.e. the inclusion ''Ker''(''λ<sub>i</sub>'' − ''A'')<sup>''n''</sup> ⊂ ''Ker''(''λ<sub>i</sub>'' − ''A'')<sup>''n''+1</sup> is proper for all ''n''. By lemma 1, there exists a sequence {''y<sub>n</sub>''}<sub>''n'' ≥ 2</sub> of unit vectors such that ''y<sub>n</sub>'' ∈ ''Y''<sub>''n''</sub> and ''d''(''y<sub>n</sub>'', ''Y''<sub>''n'' − 1</sub>) > ½. As before, compactness of ''C'' means {''C y<sub>n</sub>''} must contain a norm convergent subsequence. But for ''n'' < ''m''\n\n:<math>\\| C y_n - C y_m \\| = \\| (C-I) y_n + y_n - (C-I) y_m - y_m \\|</math>\n\nand notice that\n\n:<math>(C-I) y_n + y_n - (C-I) y_m  \\in Y_{m-1},</math>\n\nwhich implies ||''Cy<sub>n</sub> − Cy<sub>m</sub>''|| > ½. This is a contradiction, and so the sequence { ''Y<sub>n</sub>'' = ''Ker''(''λ<sub>i</sub>'' − ''A'')<sup>''n''</sup>}  must terminate at some finite ''m''.\n\nUsing the definition of the Kernel, we can show that the unit sphere of ''Ker''(''λ<sub>i</sub>'' − ''C'') is compact, so that ''Ker''(''λ<sub>i</sub>'' − ''C'') is finite-dimensional. ''Ker''(''λ<sub>i</sub>'' − ''C'')<sup>''n''</sup> is finite-dimensional for the same reason.\n\n'''iii''') Suppose there exist infinite (at least countable) distinct eigenvalues {''λ<sub>n</sub>''}, with corresponding eigenvectors {''x<sub>n</sub>''}, such that |''λ<sub>n</sub>''| > ''ε'' for all ''n''. Define ''Y<sub>n</sub>'' = ''span''{''x''<sub>1</sub>...''x<sub>n</sub>''}. The sequence {''Y<sub>n</sub>''} is a strictly increasing sequence. Choose unit vectors such that ''y<sub>n</sub>'' ∈ ''Y''<sup>''n''</sup> and ''d''(''y<sub>n</sub>'', ''Y''<sup>''n'' − 1</sup>) > ½. Then for ''n'' < ''m''\n\n:<math> \\left \\| C y_n - C y_m \\right \\| = \\left \\| (C- \\lambda_n) y_n + \\lambda_n y_n - (C- \\lambda_m) y_m - \\lambda_m y_m \\right \\|. </math>\n\nBut\n\n:<math>(C- \\lambda_n) y_n + \\lambda_n y_n - (C- \\lambda_m) y_m \\in Y_{m-1},</math>\n\ntherefore ||''Cy<sub>n</sub> − Cy<sub>m</sub>''|| > ''ε''/2, a contradiction.\n\nSo we have that there are only finite distinct eigenvalues outside any ball centered at zero. This immediately gives us that zero is the only possible limit point of eigenvalues and there are at most countable distinct eigenvalues (see iv).\n\n'''iv''') This is an immediate consequence of iii). The set of eigenvalues {''λ''} is the union\n\n:<math>\\bigcup_n \\left \\{ |\\lambda| > \\tfrac{1}{n} \\right \\} = \\bigcup_n S_n .</math>\n\nBecause ''σ''(''C'') is a bounded set and the eigenvalues can only accumulate at 0, each ''S<sub>n</sub>'' is finite, which gives the desired result.\n\n'''v''') As in the matrix case, this is a direct application of the [[holomorphic functional calculus]].\n\n=== Invariant subspaces ===\nAs in the matrix case, the above spectral properties lead to a decomposition of ''X'' into invariant subspaces of a compact operator ''C''. Let ''λ'' ≠ 0 be an eigenvalue of ''C''; so ''λ'' is an isolated point of ''σ''(''C''). Using the holomorphic functional calculus, define the '''Riesz projection''' ''E''(''λ'') by\n\n:<math>E(\\lambda) = {1\\over 2\\pi i}\\int _{\\gamma} (\\xi - C)^{-1} d \\xi</math>\n\nwhere ''γ'' is a Jordan contour that encloses only ''λ'' from ''σ''(''C''). Let ''Y'' be the subspace ''Y'' = ''E''(''λ'')''X''. ''C'' restricted to ''Y'' is a compact invertible operator with spectrum {''λ''}, therefore ''Y'' is finite-dimensional. Let ''&nu;'' be such that ''Ker''(''λ'' − ''C'')<sup>''&nu;''</sup> = ''Ker''(''λ'' − ''C'')<sup>''&nu;'' + 1</sup>. By inspecting the Jordan form, we see that (''λ'' − ''C'')<sup>''&nu;''</sup> = 0 while (''λ'' − ''C'')<sup>''&nu;'' − 1</sup> ≠ 0. The Laurent series of the resolvent mapping centered at ''λ'' shows that\n\n:<math>E(\\lambda) (\\lambda - C)^{\\nu} = (\\lambda - C)^{\\nu}E(\\lambda) = 0.</math>\n\nSo ''Y'' = ''Ker''(''λ'' − ''C'')<sup>''&nu;''</sup>.\n\nThe ''E''(''λ'') satisfy ''E''(''λ'')<sup>2</sup> = ''E''(''λ''), so that they are indeed [[projection operator]]s or '''spectral projections'''. By definition they commute with ''C''. Moreover ''E''(''λ'')''E''(''μ'') = 0 if λ ≠ μ.\n\n* Let ''X''(''λ'') = ''E''(''λ'')''X'' if λ is a non-zero eigenvalue. Thus ''X''(''λ'') is a finite-dimensional invariant subspace, the generalised eigenspace of λ.\n* Let ''X''(0) be the intersection of the kernels of the ''E''(''λ''). Thus ''X''(0) is a closed subspace invariant under ''C'' and the restriction of ''C'' to ''X''(0) is a compact operator with spectrum {0}.\n\n=== Operators with compact power ===\nIf ''B'' is an operator on a Banach space ''X'' such that ''B<sup>n</sup>'' is compact for some ''n'', then the theorem proven above also holds for ''B''.\n\n==References==\n* John B. Conway, A course in functional analysis, Graduate Texts in Mathematics ''96'', Springer 1990. {{ISBN|0-387-97245-5}}\n\n[[Category:Functional analysis]]\n[[Category:Spectral theory]]"
    },
    {
      "title": "Spectral theory of ordinary differential equations",
      "url": "https://en.wikipedia.org/wiki/Spectral_theory_of_ordinary_differential_equations",
      "text": "In [[mathematics]], the '''spectral theory of ordinary differential equations''' is the part of [[spectral theory]] concerned with the determination of the [[Spectrum of an operator#Spectrum of unbounded operators|spectrum]] and [[eigenfunction|eigenfunction expansion]] associated with a linear [[ordinary differential equation]]. In his dissertation [[Hermann Weyl]] generalized the classical [[Sturm–Liouville theory]] on a finite [[closed interval]] to second order [[differential operator]]s with singularities at the endpoints of the interval, possibly semi-infinite or infinite. Unlike the classical case, the spectrum may no longer consist of just a countable set of eigenvalues, but may also contain a continuous part. In this case the eigenfunction expansion involves an integral over the continuous part with respect to a [[spectral theory|spectral measure]], given by the [[E. C. Titchmarsh|Titchmarsh]]–[[Kunihiko Kodaira|Kodaira]] [[Titchmarsh-Kodaira formula|formula]]. The theory was put in its final simplified form for singular differential equations of even degree by Kodaira and others, using [[John von Neumann|von Neumann]]'s [[spectral theorem]]. It has had important applications in [[quantum mechanics]], [[operator theory]] and [[harmonic analysis]] on [[semisimple Lie group]]s.\n\n==Introduction==\n[[Spectral theory]] for second order ordinary differential equations on a compact interval was developed by [[Jacques Charles François Sturm]] and [[Joseph Liouville]] in the nineteenth century and is now known as [[Sturm–Liouville theory]]. In modern language it is an application of the [[spectral theorem]] for [[compact operator]]s due to [[David Hilbert]]. In his dissertation, published in 1910, [[Hermann Weyl]] extended this theory to second order ordinary differential equations with\n[[singularity (mathematics)|singularities]] at the endpoints of the interval, now allowed to be infinite or semi-infinite. He simultaneously developed a spectral theory adapted to these special operators and introduced [[boundary condition]]s in terms of his celebrated dichotomy between ''limit points'' and ''limit circles''.\n\nIn the 1920s [[John von Neumann]] established a general spectral theorem for [[unbounded operator|unbounded]] [[self-adjoint operator]]s, which [[Kunihiko Kodaira]] used to streamline Weyl's method. Kodaira also generalised Weyl's method to singular ordinary differential equations of even order and obtained a simple formula for the [[spectral theorem|spectral measure]]. The same formula had also been obtained independently by [[E. C. Titchmarsh]] in 1946 (scientific communication between [[Japan]] and the [[United Kingdom]] had been interrupted by [[World War II]]). Titchmarsh had followed the method of the German mathematician [[Emil Hilb]], who derived the eigenfunction expansions using [[complex function theory]] instead of [[operator theory]]. Other methods avoiding the spectral theorem were later developed independently by Levitan, Levinson and Yoshida, who used the fact that the [[spectral theorem|resolvent]] of the singular differential operator could be approximated by [[compact operator|compact]] resolvents corresponding to [[Sturm–Liouville problem]]s for proper subintervals. Another method was found by [[Mark Grigoryevich Krein]]; his use of ''direction functionals'' was subsequently generalised by [[Izrail Glazman]] to arbitrary ordinary differential equations of even order.\n\nWeyl applied his theory to [[Carl Friedrich Gauss]]'s [[hypergeometric differential equation]], thus obtaining a far-reaching generalisation of the transform formula of [[Gustav Ferdinand Mehler]] (1881) for the [[Legendre function|Legendre differential equation]], rediscovered by the Russian physicist [[Vladimir Fock]] in 1943, and usually called the [[Mehler–Fock transform]]. The corresponding ordinary differential operator is the radial part of the [[Laplacian operator]] on 2-dimensional [[hyperbolic space]]. More generally, the [[Plancherel theorem]] for [[SL(2,R)]] of [[Harish Chandra]] and [[I. M. Gelfand|Gelfand]]–[[M. A. Naimark|Naimark]] can be deduced from Weyl's theory for the hypergeometric equation, as can the theory of [[Zonal spherical function|spherical function]]s for the [[isometry group]]s of higher dimensional hyperbolic spaces. Harish Chandra's later development of the Plancherel theorem for general real [[semisimple Lie group]]s was strongly influenced by the methods Weyl developed for eigenfunction expansions associated with singular ordinary differential equations. Equally importantly the theory also laid the mathematical foundations for the analysis of the [[Schrödinger equation]] and [[scattering matrix]] in [[quantum mechanics]].\n\n== Solutions of ordinary differential equations ==\n{{Main|Ordinary differential equations}}\n\n=== Reduction to standard form ===\nLet ''D'' be the second order differential operator on ''(a,b)'' given by\n\n:<math> Df(x) = -p(x) f^{\\prime\\prime}(x) +r(x) f^\\prime(x) + q(x) f(x),</math>\n\nwhere ''p'' is a strictly positive continuously differentiable function and ''q'' and ''r'' are continuous\nreal-valued functions.\n\nFor ''x''<sub>0</sub> in (''a'', ''b''), define the [[Sturm–Liouville theory|Liouville transformation]] ψ by\n\n:<math> \\psi(x)= \\int_{x_0}^x p(t)^{-1/2}\\, dt</math>\n\nIf\n\n:<math>U: L^2(a, b) \\mapsto L^2(\\psi(a), \\psi(b))</math>\n\nis the [[unitary operator]] defined by\n\n:<math>(Uf)(\\psi(x))  = f(x) \\times \\left(\\psi'(x)\\right)^{-1/2},\\ \\ \\forall x \\in (a, b) </math>\n\nthen\n\n:<math> U \\frac{\\mathrm{d}}{\\mathrm{d}x} U^{-1} g = g' \\psi' + \\frac 12 g \\frac{\\psi''}{\\psi'} </math>\n\nand\n\n:<math>\n\\begin{align}\nU \\frac{\\mathrm{d}^2}{\\mathrm{d}x^2} U^{-1} g & =  \\left( U \\frac{\\mathrm{d}}{\\mathrm{d}x} U^{-1} \\right) \\times \\left( U \\frac{\\mathrm{d}}{\\mathrm{d}x} U^{-1} \\right) g \\\\ & = \\frac{\\mathrm{d}}{\\mathrm{d}\\psi} \\left[ g' \\psi' + \\frac 12 g \\frac{\\psi''}{\\psi'}  \\right] \\cdot \\psi' + \\frac 12 \\left[ g' \\psi' + \\frac 12 g \\frac{\\psi''}{\\psi'}  \\right] \\times \\frac{\\psi''}{\\psi'} \\\\ & = g'' \\psi'^2 + 2 g' \\psi'' + \\frac 12 g \\times \\left[ \\frac{\\psi'''}{\\psi'} + \\frac {\\psi''^2}{\\psi'^2} \\right]\n\\end{align}   </math>\n\nHence,\n\n:<math> UDU^{-1} g= -g^{\\prime\\prime} + R g^{\\prime} +  Q g,</math>\n\nwhere\n\n:<math> R = \\frac { p' + r}{p^{1/2}} </math>\n\nand\n\n:<math> Q = q - \\frac {r p'}{4p} + \\frac {p''}4 - \\frac {p'^2}{8p} </math>\n\nThe term in ''g' '' can be removed using an [[Euler]] [[integrating factor]]. If ''S' ''/''S'' = &minus;''R''/2, then ''h'' = ''Sg''\nsatisfies \n \n:<math> (S UDU^{-1} S^{-1}) h = -h^{\\prime \\prime} + V h,</math>\n\nwhere the [[potential]] ''V'' is given by\n\n:<math> V = Q + \\frac{S''}{S} </math>\n\nThe differential operator can thus always be reduced to one of the form <ref>{{harvnb|Titchmarsh|1962|p= 22}}</ref>\n\n:<math>Df = - f^{\\prime\\prime} + qf.</math>\n\n===Existence theorem===\nThe following is a version of the classical [[Picard–Lindelöf theorem|Picard existence theorem]] for second order differential equations with values in a \n[[Banach space]] '''E'''.<ref>{{harvnb|Dieudonné |1969}}, Chapter X.</ref>\n\nLet α, β be arbitrary elements of '''E''', ''A'' a [[bounded operator]] on ''E'' and ''q'' a continuous function on [''a'',''b''].\n\nThen, for ''c'' = ''a'' or ''b'',\nthe differential equation\n\n:''Df'' = ''Af''\n\nhas a unique solution ''f'' in ''C''<sup>2</sup>([''a'',''b''],'''E''') satisfying the initial conditions\n\n:''f''(''c'') = β, ''f'' '(''c'') = α.\n\nIn fact a solution of the differential equation with these initial conditions is equivalent to a solution\nof the [[integral equation]]\n\n:''f'' = ''h'' + ''T'' ''f''\n\nwith ''T'' the bounded linear map on ''C''([''a'',''b''], '''E''') defined by\n\n:<math> Tf(x) = \\int_c^x K(x,y)f(y) \\, dy,</math>\n\nwhere ''K'' is the [[Volterra kernel]]\n\n:''K''(''x'',''t'')= (''x'' &minus; ''t'')(''q''(''t'') &minus; ''A'')\n\nand\n\n:''h''(''x'') = α(''x'' &minus; ''c'') + β.\n\nSince ||''T''<sup>k</sup>|| tends to 0, this integral equation has a unique solution given by the [[Neumann series]]\n\n:''f'' = (''I'' &minus; ''T'')<sup>&minus;1</sup> ''h'' = ''h''  + ''T'' ''h'' + ''T''<sup>2</sup> ''h'' + ''T''<sup>3</sup> ''h'' + ···\n\nThis iterative scheme is often called ''Picard iteration'' after the French mathematician [[Charles Émile Picard]].\n\n===Fundamental eigenfunctions===\nIf ''f'' is twice continuously differentiable (i.e. ''C''<sup>2</sup>) on (''a'', ''b'') satisfying ''Df'' = λ''f'', then ''f'' is called an [[eigenfunction]] of ''L'' with [[eigenvalue]] λ.\n\n* In the case of a compact interval [''a'', ''b''] and ''q'' continuous on [''a'', ''b''], the existence theorem implies that for ''c'' = ''a'' or ''b'' and every complex number λ there a unique ''C''<sup>2</sup> eigenfunction ''f''<sub>λ</sub>  on [''a'', ''b''] with ''f''<sub>λ</sub>(c) and ''f'' '<sub>λ</sub>(c) prescribed. Moreover, for each ''x'' in [''a'', ''b''], ''f''<sub>λ</sub>(x) and ''f'' '<sub>λ</sub>(x) are [[holomorphic function]]s of λ.\n* For an arbitrary interval (''a'',''b'') and ''q'' continuous on (''a'', ''b''), the existence theorem implies that for ''c'' in (''a'', ''b'')  and every complex number λ there a unique ''C''<sup>2</sup> eigenfunction ''f''<sub>λ</sub>  on (''a'', ''b'') with ''f''<sub>λ</sub>(c) and ''f'' '<sub>λ</sub>(c) prescribed. Moreover, for each ''x'' in (''a'', ''b''), ''f''<sub>λ</sub>(x) and ''f'' '<sub>λ</sub>(x) are [[holomorphic function]]s of λ.\n\n===Green's formula===\nIf ''f'' and ''g'' are ''C''<sup>2</sup> functions on (''a'', ''b''),  the [[Wronskian]] ''W''(''f'', ''g'') is defined by\n\n:''W''(''f'', ''g'') (x) = ''f''(''x'') ''g'' '(''x'') &minus; ''f'' '(''x'') ''g''(''x'').\n\n[[Green's identities|Green's formula]] - which in this one-dimensional case is a simple integration by parts - states that for ''x'', ''y'' in (''a'', ''b'')\n\n:<math> \\int_x^y (Df) g - f (Dg) \\, dt =  W(f,g)(y) - W(f,g)(x).</math>\n\nWhen ''q'' is continuous and ''f'', ''g'' ''C''<sup>2</sup> on the compact interval [''a'', ''b''], this formula also holds for ''x'' = ''a'' or ''y'' = ''b''.\n\nWhen ''f'' and ''g'' are eigenfunctions for the same eigenvalue, then\n\n:<math> {d\\over dx} W(f,g) =0, </math>\n\nso that ''W''(''f'', ''g'') is independent of ''x''.\n\n== Classical Sturm–Liouville theory ==\n{{Main|Sturm–Liouville theory}}\nLet [''a'', ''b''] be a finite closed interval, ''q'' a real-valued continuous function on [''a'', ''b''] and let ''H''<sub>0</sub> be the\nspace of C<sup>2</sup> functions ''f'' on [''a'', ''b''] satisfying the [[Robin boundary condition]]s\n\n:<math> \\cos \\alpha \\,f(a) - \\sin \\alpha \\,f^\\prime(a)=0, \\qquad \\cos\\beta \\,f(b) - \\sin \\beta\\, f^\\prime(b)=0,</math>\n\nwith [[inner product]]\n\n:<math> (f,g) = \\int_a^b f(x) \\overline{g(x)} \\, dx.</math>\n\nIn practise usually one of the two standard boundary conditions:\n\n*[[Dirichlet boundary condition]] ''f''(''c'') = 0\n*[[Neumann boundary condition]] ''f'' '(''c'') = 0\n\nis imposed at each endpoint ''c'' = ''a'', ''b''.\n\nThe differential operator ''D'' given by\n\n:<math> Df=-f^{\\prime\\prime} + qf </math>\n\nacts on ''H''<sub>0</sub>. A function ''f'' in ''H''<sub>0</sub> is called an [[eigenfunction]] of ''D'' (for the above choice of boundary values) if ''Df'' = λ ''f'' for some complex number λ, the corresponding [[eigenvalue]].\nBy Green's formula, ''D'' is formally [[self-adjoint]] on ''H''<sub>0</sub>, since the Wronskian ''W(f,g)'' vanishes if both ''f,g'' satisfy the  boundary conditions:\n\n:(''Df'', ''g'') = (''f'', ''Dg'') for ''f'', ''g'' in ''H''<sub>0</sub>.\n\nAs a consequence, exactly as for a [[hermitian matrix|self-adjoint matrix]] in finite dimensions,\n\n*the eigenvalues of ''D'' are real;\n*the [[eigenspace]]s for distinct eigenvalues are [[orthogonal]].\n\nIt turns out that the eigenvalues can be described by the [[Courant minimax principle|maximum-minimum]] principle of [[John Strutt, 3rd Baron Rayleigh|Rayleigh]]–[[Walter Ritz|Ritz]] <ref>{{harvnb|Courant | Hilbert |1989}}</ref> (see below). In fact it is easy to see ''a priori'' that the eigenvalues are bounded below because the operator ''D'' is itself ''bounded below'' on ''H''<sub>0</sub>:\n\n:*<math>(Df, f) \\ge M (f, f)</math> for some finite (possibly negative) constant <math>M</math>.\n\nIn fact integrating by parts\n\n::<math> (Df,f)= [-f^\\prime \\overline{f}]_a^b + \\int |f^\\prime|^2 + \\int q |f|^2.</math>\n\nFor Dirichlet or Neumann boundary conditions, the first term vanishes and the inequality holds with ''M'' = inf ''q''.\n\nFor general Robin boundary conditions the first term can be estimated using an elementary ''Peter-Paul'' version of [[Sobolev inequality|Sobolev's inequality]]:\n\n:: \"''Given ε > 0, there is constant R >0 such that |f(x)|''<sup>2</sup> ≤ ε ''(f', f') + R (f, f) for all f in C<sup>1</sup>[a, b].''\"\n\nIn fact, since\n\n::|''f''(''b'') &minus; ''f''(''x'')| ≤ (''b'' &minus; ''a'')<sup>½</sup>·||''f'' '||<sub>2</sub>,\n \nonly an estimate for ''f''(''b'') is needed and this follows by replacing ''f''(''x'') in the above inequality by (''x'' &minus; ''a'')<sup>''n''</sup>·(''b'' &minus; ''a'')<sup>&minus;''n''</sup>·''f''(''x'') for ''n'' sufficiently large.\n\n=== Green's function (regular case) ===\nFrom the theory of ordinary differential equations, there are unique fundamental eigenfunctions φ<sub>λ</sub>(x), χ<sub>λ</sub>(x) such that\n\n* ''D'' φ<sub>λ</sub> = λ φ<sub>λ</sub>,  φ<sub>λ</sub>(''a'') = sin α,  φ<sub>λ</sub>'(''a'') =  cos α\n* ''D'' χ<sub>λ</sub> = λ χ<sub>λ</sub>,   χ<sub>λ</sub>(''b'') = sin β,   χ<sub>λ</sub>'(''b'') =  cos β\n\nwhich at each point, together with their first derivatives, depend holomorphically on λ. Let\n\n:ω(λ) = W(φ<sub>λ</sub>, χ<sub>λ</sub>),\n\nan [[entire function|entire holomorphic function]].\n\nThis function ω(λ) plays the rôle of the [[characteristic polynomial]] of ''D''. Indeed, the uniqueness of the fundamental eigenfunctions implies that its zeros are precisely the eigenvalues of ''D'' and that each non-zero eigenspace is one-dimensional. In particular there are at most countably many eigenvalues of ''D'' and, if there are infinitely many, they must tend to infinity. It turns out that the zeros of ω(λ) also have mutilplicity one (see below).\n\nIf λ is not an eigenvalue of ''D'' on ''H''<sub>0</sub>, define the [[Green's function]] by\n\n:''G''<sub>λ</sub>(''x'',''y'') = φ<sub>λ</sub> (''x'')  χ<sub>λ</sub>(''y'') / ω(λ) for ''x'' ≥ ''y'' and χ<sub>λ</sub>(''x'') φ<sub>λ</sub> (''y'') / ω(λ) for ''y'' ≥ ''x''.\n\nThis kernel defines an operator on the inner product space C[''a'',''b''] via\n\n:<math> (G_\\lambda f)(x) =\\int_a^b G_\\lambda(x,y) f(y)\\, dy.</math>\n\nSince ''G''<sub>λ</sub>(''x'',''y'') is continuous on [''a'', ''b''] x [''a'', ''b''], it defines a [[Hilbert–Schmidt operator]] on the Hilbert space completion\n''H'' of C[''a'', ''b''] = ''H''<sub>1</sub> (or equivalently of the dense subspace ''H''<sub>0</sub>), taking values in ''H''<sub>1</sub>. This operator carries ''H''<sub>1</sub> into ''H''<sub>0</sub>. When λ is real, ''G''<sub>λ</sub>(''x'',''y'') = ''G''<sub>λ</sub>(''y'',''x'') is also real, so defines a self-adjoint operator on ''H''. Moreover,\n\n* ''G''<sub>λ</sub> (''D'' &minus; λ) =I on ''H''<sub>0</sub>\n* ''G''<sub>λ</sub> carries ''H''<sub>1</sub> into ''H''<sub>0</sub>, and  (''D'' &minus; λ) ''G''<sub>λ</sub> = I on ''H''<sub>1</sub>.\n\nThus the operator ''G''<sub>λ</sub> can be identified with the [[Resolvent formalism|resolvent]] (''D'' &minus; λ)<sup>−1</sup>.\n\n=== Spectral theorem ===\n\n'''Theorem.''' ''The eigenvalues of D are real of multiplicity one and form an increasing sequence λ<sub>1</sub> < λ<sub>2</sub> < ··· tending to infinity.''\n\n''The corresponding normalised eigenfunctions form an orthonormal basis of'' ''H''<sub>0</sub>.\n\n''The kth eigenvalue of D is given by the [[Courant minimax principle|minimax principle]]''\n\n:<math> \\lambda_k = \\max_{{\\rm dim} \\, G = k-1} \\, \\min_{f\\perp G} {(Df,f)\\over (f,f)}. </math>\n\n''In particular if q<sub>1</sub> ≤ q<sub>2</sub>, then''\n\n:<math> \\lambda_k(D_1) \\le \\lambda_k(D_2).</math>\n\nIn fact let ''T'' = ''G''<sub>λ</sub> for λ large and negative. Then ''T'' defines a [[compact operator|compact self-adjoint operator]] on the Hilbert space ''H''.\nBy the [[spectral theorem]] for compact self-adjoint operators, ''H'' has an orthonormal basis consisting of eigenvectors ψ<sub>''n''</sub> of ''T'' with\n''T''ψ<sub>''n''</sub> =  μ<sub>''n''</sub> ψ<sub>''n''</sub>, where μ<sub>''n''</sub> tends to zero. The range of ''T'' contains ''H''<sub>0</sub> so is dense. Hence 0 is not an eigenvalue of ''T''. The resolvent properties of ''T'' imply that ψ<sub>''n''</sub> lies in ''H''<sub>0</sub> and that\n\n:''D'' ψ<sub>''n''</sub> = (λ + 1/μ<sub>''n''</sub>) ψ<sub>''n''</sub>\n\nThe minimax principle follows because if\n\n:<math>\\lambda(G) = \\min_{f\\perp G} {(Df,f)\\over (f,f)},</math>\n\nthen λ(''G'')= λ<sub>k</sub> for the [[linear span]] of the first ''k''&nbsp;&minus;&nbsp;1 eigenfunctions. For any other (''k''&nbsp;&minus;&nbsp;1)-dimensional subspace ''G'', some ''f'' in the linear span of the first ''k'' eigenvectors must be orthogonal to ''G''. Hence λ(''G'') ≤ (''Df'',''f'')/(''f'',''f'') ≤ λ<sub>k</sub>.\n\n=== Wronskian as a Fredholm determinant ===\nFor simplicity, suppose that ''m'' ≤ ''q''(''x'') ≤ ''M'' on [0,π] with Dirichlet boundary conditions.\nThe minimax principle shows that\n\n:<math>   n^2 + m \\le \\lambda_n(D) \\le n^2 + M. </math>\n\nIt follows that the resolvent (''D'' &minus; λ)<sup>−1</sup> is a [[trace-class operator]] \nwhenever λ is not an eigenvalue of ''D'' and hence that the [[Fredholm determinant]]\ndet I &minus; μ(''D'' &minus; λ)<sup>−1</sup> is defined.\n\nThe Dirichlet boundary conditions imply that\n\n:ω(λ)= φ<sub>λ</sub>(''b'').\n \nUsing Picard iteration, Titchmarsh showed that φ<sub>λ</sub>(''b''), and hence ω(λ), \nis an [[entire function|entire function of finite order]] 1/2:\n\n:ω(λ) = O(e<sup>{{radic|{{mabs|λ}}}}</sup>)\nAt a zero μ of ω(λ), \nφ<sub>μ</sub>(''b'') = 0. Moreover,\n\n:<math>\\psi(x)=\\partial_\\lambda \\varphi_\\lambda(x)|_{\\lambda=\\mu}</math>\n\nsatisfies (''D''&nbsp;&minus;&nbsp;μ)ψ = φ<sub>μ</sub>. Thus\n\n:ω(λ) = (λ &minus; μ)ψ(''b'') + O( (λ &minus; μ)<sup>2</sup>).\n\nThis implies that<ref>{{harvnb|Titchmarsh|1962}}</ref>\n\n* μ is a simple zero of ω(λ).\n\nFor otherwise ψ(''b'') = 0, so that ψ would have to lie in ''H''<sub>0</sub>.\nBut then\n\n:(φ<sub>μ</sub>, φ<sub>μ</sub>) = ((''D'' &minus; μ)ψ, φ<sub>μ</sub>) = (ψ, (''D'' &minus; μ)φ<sub>μ</sub>) = 0,\n\na contradiction.\n\nOn the other hand, the distribution of the zeros of the entire function\nω(λ) is already known from the minimax principle.\n\nBy the [[Hadamard factorization theorem]], it follows\nthat<ref>{{citation|last=Titchmarsh|first= E.C.| year=1939| title=Theory of Functions|publisher= Oxford University Press}}, §8.2.</ref>\n\n*<math> \\omega(\\lambda) = C \\prod (1 -\\lambda/\\lambda_n),</math>\n\nfor some non-zero constant ''C''.\n\nHence\n\n:<math> {\\rm det} \\,( I - \\mu(D - \\lambda)^{-1}) = \\prod \\left( 1 - {\\mu \\over \\lambda_n -\\lambda}\\right) = \\prod {1 - (\\lambda+\\mu)/\\lambda_n   \\over 1-\\lambda/\\lambda_n} = {\\omega(\\lambda+\\mu)\\over \\omega(\\lambda)} .</math>\n\nIn particular if 0 is not an eigenvalue of ''D''\n\n:<math>\\omega(\\mu) = \\omega(0) \\cdot {\\rm det} \\,( I - \\mu D^{-1}) . </math>\n\n== Tools from abstract spectral theory ==\n\n=== Functions of bounded variation ===\n{{See also|Bounded variation|Lebesgue–Stieltjes integration|Riesz representation theorem}}\nA function ρ(''x'') of [[bounded variation]]<ref>{{citation|first=J.C.|last=Burkill|year=1951|title=The Lebesgue Integral|series=Cambridge Tracts in Mathematics and Mathematical Physics|volume=40|publisher=Cambridge University Press|\nisbn=978-0-521-04382-3|pages= 50–52}}</ref> on a closed interval [''a'', ''b''] is a complex-valued function such that  \nits [[total variation]] ''V''(ρ), the [[supremum]]\nof the variations\n\n:<math> \\sum_{r=0}^{k-1} |\\rho(x_{r+1}) - \\rho(x_r)|</math>\n\nover all [[partition of an interval|dissection]]s\n\n:<math> a= x_0 < x_1 < \\dots < x_k =b </math>\n\nis finite. The real and imaginary parts of ρ are real-valued functions of bounded variation. If ρ is real-valued and normalised so that ρ(a)=0, \nit has a canonical decomposition as the difference of two bounded non-decreasing functions:\n\n:<math> \\rho(x) = \\rho_+(x) - \\rho_-(x),</math>\n\nwhere ρ<sub>+</sub>(''x'') and ρ<sub>–</sub>(''x'') are the total positive and negative variation of ρ over [''a'', ''x''].\n\nIf ''f'' is a continuous function on [''a'', ''b''] its [[Riemann–Stieltjes integral]] with respect to ρ\n\n:<math>\\int_a^b f(x)\\, d\\rho(x)</math>\n\nis defined to be the limit of approximating sums\n\n:<math>\\sum_{r=0}^{k-1} f(x_r)(\\rho(x_{r+1})-\\rho(x_r))</math>\n\nas the [[partition of an interval|mesh]] of the dissection, given by sup |''x''<sub>''r''+1</sub> - ''x''<sub>''r''</sub>|, tends to zero.\n\nThis integral satisfies\n\n:<math>\\left|\\int_a^b f(x)\\, d\\rho(x)\\right|\\le V(\\rho)\\cdot \\|f\\|_\\infty</math>\n\nand thus defines a [[bounded linear functional]] ''d''ρ on ''C''[''a'', ''b''] with [[norm (mathematics)|norm]]  ||d''ρ||=''V''(ρ).\n\nEvery bounded linear functional μ on ''C''[''a'', ''b''] has an [[absolute value]] |μ| defined for non-negative ''f'' by<ref>{{citation|first=Lynn H.|last=Loomis|title=An Introduction to Abstract Harmonic Analysis| publisher=van Nostrand|year=1953}}, [https://archive.org/details/introductiontoab031610mbp page 40].</ref>\n \n:<math> |\\mu|(f) = \\sup_{0\\le |g|\\le f} |\\mu(g)|.</math>\n\nThe form |μ| extends linearly to a bounded linear form on C[''a'', ''b''] with norm ||μ|| and satisfies the characterizing inequality\n\n:|μ(''f'')| ≤ |μ|(|''f''|)\n\nfor ''f'' in C[''a'', ''b'']. If μ is ''real'', i.e. is real-valued on real-valued functions, then\n\n:<math> \\mu = |\\mu| -(|\\mu| -\\mu)\\equiv \\mu_+-\\mu_-</math>\n\ngives a canonical decomposition as a difference of ''positive'' forms, i.e. forms that are non-negative on non-negative functions.\n\nEvery positive form μ extends uniquely to the linear span of non-negative bounded lower [[semicontinuous function]]s ''g'' by the formula<ref>{{harvnb|Loomis|1953|pp=30–31}}</ref>\n\n:<math> \\mu(g) = \\lim \\mu(f_n),</math>\n\nwhere the non-negative continuous functions ''f''<sub>''n''</sub> increase pointwise to ''g''.\n\nThe same therefore applies to an arbitrary bounded linear form μ, so that a function ρ of bounded variation may be defined by<ref>{{citation|first=A.N.|last=Kolmogorov|first2=S.V.|last2=Fomin|title=Introductory Real Analysis|isbn=978-0-486-61226-3|publisher=Dover|year=1975|pages= 374–376}}</ref>\n\n:<math>\\rho(x)=\\mu(\\chi_{[a,x]}),</math>\n\nwhere χ<sub>''A''</sub> denotes the [[Indicator function|characteristic function]] of a subset ''A'' of [''a'', ''b'']. Thus μ = ''d''ρ and ||μ|| = ||''d''ρ||.\nMoreover μ<sub>+</sub> = ''d''ρ<sub>+</sub> and μ<sub>–</sub> = ''d''ρ<sub>–</sub>.\n\nThis correspondence between functions of bounded variation and bounded linear forms is a special case of the '''[[Riesz representation theorem]]'''.\n\nThe [[support (measure theory)|support]] of μ = ''d''ρ is the complement of all points ''x'' in [''a'',''b''] where ρ is constant on some neighborhood of ''x''; by definition it is a closed subset ''A'' of [''a'',''b'']. Moreover, μ((1-χ<sub>''A''</sub>)''f'') =0, so that μ(''f'') = 0 if ''f'' vanishes on ''A''.\n\n===Spectral measure===\n{{See also|Spectral theorem|Projection-valued measure}}\nLet ''H'' be a Hilbert space and <math>T</math> a self-adjoint [[bounded operator]] on ''H'' with <math> 0 \\leq T \\leq I </math>, so that the [[spectrum (functional analysis)|spectrum]] <math> \\sigma(T) </math> of <math> T </math> is contained in <math>[0,1]</math>. If <math>p(t)</math> is a complex polynomial, then by the ''spectral mapping theorem''\n\n:<math> \\sigma (p(T)) = p (\\sigma(T)) </math>\n\nand hence\n\n:<math> \\|p(T)\\| \\leq \\|p\\|_\\infty </math>\n\nwhere <math> \\| \\, \\|_\\infty </math> denotes the [[uniform norm]] on <math>C[0,1]</math>.  By the [[Weierstrass approximation theorem]], polynomials are uniformly dense in <math>C[0,1]</math>. It follows that <math>f(T)</math> can be defined <math>\\forall f \\in C[0,1]</math>, with\n\n:<math> \\sigma (f(T)) = f(\\sigma(T))</math> and <math> \\| f(T) \\| \\leq \\|f\\|_\\infty</math>.\n\nIf  <math>0 \\leq g \\leq 1 </math>  is a lower semicontinuous function on <math> [0,1]</math>, for example the characteristic function <math> \\chi_{[0,\\alpha]}</math> of a subinterval of <math>[0,1]</math>, then\n<math>g</math> is a pointwise increasing limit of non-negative <math>f_n \\in C[0,1]</math>.\n\nAccording to [[Béla Szőkefalvi-Nagy|Szőkefalvi-Nagy]],<ref>{{harvnb|Riesz|Nagy|1990|p=263}}</ref> if <math>\\xi</math> is a vector in ''H'', then the vectors\n\n:<math> \\eta_n=f_n(T)\\xi</math>\n\nform a [[Cauchy sequence]] in ''H'', since, for <math>n \\geq m</math>,\n\n:<math> \\|\\eta_n-\\eta_m\\|^2 \\le (\\eta_n,\\xi) - (\\eta_m,\\xi),</math>\n\nand <math>( \\eta_n, \\xi) = (f_n(T)\\xi, \\xi)</math> is bounded and increasing, so has a limit.\n\nIt follows that <math>g(T)</math> can be defined by<ref>This is a limit in the [[strong operator topology]].</ref>\n\n:<math>g(T)\\xi= \\lim f_n(T)\\xi</math>.\n\nIf <math>\\xi</math> and <math>\\eta</math> are vectors in ''H'', then\n\n:<math>\\mu_{\\xi,\\eta}(f) = (f(T) \\xi,\\eta)</math>\n\ndefines a bounded linear form <math>\\mu_{\\xi, \\eta}</math> on ''H''. By the Riesz representation theorem\n\n:<math>\\mu_{\\xi,\\eta}=d\\rho_{\\xi,\\eta}</math>\n\nfor a unique normalised function <math>\\rho_{\\xi, \\eta}</math> of bounded variation on <math>[0,1]</math>.\n\n<math>d\\rho_{\\xi, \\eta}</math> (or sometimes slightly incorrectly <math>\\rho_{\\xi, \\eta}</math> itself) is called the '''spectral measure'''\ndetermined by <math>\\xi</math> and <math>\\eta</math>.\n \nThe operator <math>g(T)</math> is accordingly uniquely characterised by the equation\n\n:<math> (g(T)\\xi,\\eta) = \\mu_{\\xi,\\eta}(g) = \\int_0^1 g(\\lambda) \\, d\\rho_{\\xi,\\eta}(\\lambda).</math>\n\nThe [[spectral theorem|spectral projection]] <math>E(\\lambda)</math> is defined by\n\n:<math>E(\\lambda)=\\chi_{[0,\\lambda]}(T),</math>\n\nso that\n\n:<math>\\rho_{\\xi,\\eta}(\\lambda)=(E(\\lambda)\\xi,\\eta).</math>\n\nIt follows that\n\n:<math> g(T) = \\int_0^1 g(\\lambda) \\,dE(\\lambda),</math>\n\nwhich is understood in the sense that for any vectors <math>\\xi</math> and <math>\\eta</math>,\n\n: <math> (g(T)\\xi,\\eta) = \\int_0^1 g(\\lambda)\\, d(E(\\lambda)\\xi,\\eta) = \\int_0^1 g(\\lambda)\\, d\\rho_{\\xi,\\eta}(\\lambda). </math>\n\nFor a single vector <math>\\xi, \\, \\mu_{\\xi} = \\mu_{\\xi, \\xi}</math> is a positive form on <math>[0,1]</math> \n(in other words proportional to a [[probability measure]] on <math>[0,1]</math>) and <math>\\rho_{\\xi} = \\rho_{\\xi, \\xi}</math> is non-negative and non-decreasing.\nPolarisation shows that all the forms <math>\\mu_{\\xi, \\eta}</math> can naturally be expressed in terms of such positive forms, since\n\n:<math>\\mu_{\\xi, \\eta} = \\frac{1}{4}\\bigg(\\mu_{\\xi+\\eta}+i\\mu_{\\xi+i\\eta}-\\mu_{\\xi-\\eta}-i\\mu_{\\xi-i\\eta}\\bigg)</math>\n\nIf the vector <math>\\xi</math> is such that the [[linear span]] of the vectors <math>(T^n\\xi)</math> is dense in ''H'', i.e. <math>\\xi</math> is a ''cyclic vector'' for\n<math>T</math>, then the map <math>U</math> defined by\n\n:<math> U(f) = f(T)\\xi, \\, C[0,1] \\rightarrow H</math>\n\nsatisfies\n\n:<math> (Uf_1,Uf_2)= \\int_0^1 f_1(\\lambda) \\overline{f_2(\\lambda)} \\, d\\rho_\\xi(\\lambda).</math>\n\nLet <math>L_2([0,1], d\\rho_\\xi)</math> denote the Hilbert space completion of <math>C[0,1]</math> associated\nwith the possibly [[inner product#Degenerate inner products|degenerate inner product]] on the right hand side.<ref>A ''bona fide'' inner product is defined on the quotient by the subspace of null functions <math>f</math>, i.e. those with <math>\\mu_\\xi(|f|_2)=0</math>. Alternatively in this case the support of the measure is <math>\\sigma(T)</math>, so the right hand side defines a (non-degenerate) inner product on <math>C(\\sigma(T))</math>.</ref> \nThus <math>U</math> extends to a [[unitary transformation]] of <math>L_2([0,1], \\rho_\\xi)</math> onto ''H''. <math>UTU^\\ast</math> is then just multiplication by <math>\\lambda</math> on <math>L_2([0,1], d\\rho_\\xi)</math>; and more generally <math>Uf(T)U^\\ast</math> is multiplication by <math>f(\\lambda)</math>. In this case, the support of <math>d\\rho_\\xi</math>\nis exactly <math>\\sigma(T)</math>, so that\n\n* ''the self-adjoint operator becomes a multiplication operator on the space of functions on its spectrum with inner product given by the spectral measure''.\n\n== Weyl–Titchmarsh–Kodaira theory ==\n\nThe eigenfunction expansion associated with singular differential operators of the form\n\n:<math> Df = -(pf^\\prime)^\\prime + qf</math>\n\non an open interval (''a'', ''b'') requires an initial analysis of the behaviour of the fundamental\neigenfunctions near the endpoints ''a'' and ''b'' to determine possible [[boundary condition]]s there. Unlike the regular Sturm–Liouville case, in some circumstances [[spectral theory|spectral values]] of ''D'' can have [[Multiplicity (mathematics)|multiplicity]] 2. In the development outlined below standard assumptions will be imposed on ''p'' and ''q'' that guarantee that the spectrum of\n''D'' has multiplicity one everywhere and is bounded below. This includes almost all important applications; modifications required for the more general case will be discussed later.\n\nHaving chosen the boundary conditions, as in the classical theory the resolvent of ''D'', (''D'' + ''R'' )<sup>−1</sup> for ''R '' large and positive, is given by an operator ''T'' corresponding to a Green's function constructed from two fundamental eigenfunctions. In the classical case ''T'' was a compact self-adjoint operator; in this case ''T'' is just a self-adjoint bounded operator with 0 ≤ ''T'' ≤ I. The abstract theory of spectral measure can therefore be applied to ''T'' to give the eigenfunction expansion for ''D''.\n\nThe central idea in the proof of Weyl and Kodaira can be explained informally as follows. Assume that the spectrum of ''D'' lies in [1,∞) and that ''T'' =''D''<sup>−1</sup> and let\n\n:<math> E(\\lambda) =\\chi_{[\\lambda^{-1},1]}(T)</math>\n\nbe the spectral projection of ''D'' corresponding to the interval [1,λ]. For an arbitrary function ''f'' define\n\n:<math> f(x,\\lambda)= (E(\\lambda)f)(x). </math>\n\n''f''(''x'',λ)  may be regarded as a differentiable map into the space of functions of bounded variation ρ; or equivalently as a differentiable map\n\n:<math> x\\mapsto (d_\\lambda f)(x)</math>\n\ninto the Banach space '''E''' of  bounded linear functionals ''d''ρ on C[α,β] whenever [α,β] is a compact subinterval of [1, ∞).\n\nWeyl's fundamental observation was that ''d''<sub>λ</sub> ''f''  satisfies a second order ordinary differential equation taking values in '''E''':\n\n:<math> D (d_\\lambda f) = \\lambda \\cdot d_\\lambda f.</math>\n\nAfter imposing initial conditions on the first two derivatives at a fixed point ''c'', this equation can be solved explicitly\nin terms of the two fundamental eigenfunctions and the \"initial value\" functionals\n\n:<math> (d_\\lambda f)(c)= d_\\lambda f(c,\\cdot), \\quad (d_\\lambda f)^\\prime(c)= d_\\lambda f_x(c,\\cdot).</math>\n\nThis point of view may now be turned on its head: ''f''(''c'',λ) and ''f''<sub>''x''</sub>(''c'',λ) may be written as\n\n:<math> f(c,\\lambda)=(f,\\xi_1(\\lambda)), \\quad  f_x(c,\\lambda)=(f,\\xi_2(\\lambda)),</math>\n\nwhere ξ<sub>1</sub>(λ) and ξ<sub>2</sub>(λ) are given purely in terms of the fundamental eigenfunctions.\nThe functions of bounded variation\n\n:<math> \\sigma_{ij}(\\lambda) = (\\xi_i(\\lambda),\\xi_j(\\lambda))</math>\n\ndetermine a spectral measure on the spectrum of ''D'' and can be computed explicitly from the behaviour\nof the fundamental eigenfunctions (the Titchmarsh–Kodaira formula).\n\n=== Limit circle and limit point for singular equations ===\nLet  ''q''(''x'') be a continuous real-valued function on (0,∞)\nand let ''D'' be the second order differential operator\n\n:<math> Df= -f^{\\prime\\prime} + qf</math>\n\non (0,∞). Fix a point ''c'' in (0,∞) and, for λ complex, let <math>\\varphi_\\lambda, \\theta_\\lambda</math> be the unique '''fundamental eigenfunctions''' of ''D'' on (0,∞) satisfying\n\n:<math> (D-\\lambda)\\varphi_\\lambda = 0, \\quad (D-\\lambda)\\theta_\\lambda =0 </math>\n\ntogether with the initial conditions at ''c''\n\n:<math> \\varphi_\\lambda(c)=1,\\, \\varphi_\\lambda^\\prime(c)=0, \\, \\theta_\\lambda(c)=0, \\, \\theta_\\lambda^\\prime(c)=1.</math>\n\nThen their Wronskian satisfies\n\n:<math> W(\\varphi_\\lambda,\\theta_\\lambda) = \\varphi_\\lambda\\theta_\\lambda^\\prime- \\theta_\\lambda \\varphi_\\lambda^\\prime\\equiv 1,</math>\n\nsince it is constant and equal to 1 at ''c''.\n\nLet λ be non-real and 0 < ''x'' < ∞. If the complex number <math>\\mu</math> is such that <math>f=\\varphi +\\mu \\theta</math> satisfies the boundary condition <math>\\cos\\beta\\, f(x) - \\sin\\beta\\, f'(x) = 0</math> for some <math>\\beta</math> (or, equivalently, <math>f'(x) / f(x)</math> is real) then, using integration by parts, one obtains\n\n:<math> {\\rm Im}(\\lambda) \\int_c^x |\\varphi +\\mu \\theta|^2 ={\\rm Im}(\\mu).</math>\n\nTherefore, the set of <math>\\mu</math> satisfying this equation is not empty. This set is a [[circle]] in the complex <math>\\mu</math>-plane. Points <math>\\mu</math> in its interior are characterized by\n\n:<math> \\int_c^x | \\varphi +\\mu \\theta|^2 <{{\\rm Im}(\\mu)\\over  {\\rm Im}(\\lambda)}</math>\n\nif ''x'' > ''c'' and by\n\n:<math> \\int_x^c | \\varphi +\\mu \\theta|^2 <{{\\rm Im}(\\mu)\\over   {\\rm Im}(\\lambda)}</math>\n\nif ''x'' < ''c''.\n\nLet ''D''<sub>''x''</sub> be the closed disc enclosed by the circle. By definition\nthese closed discs are nested and decrease as ''x'' approaches 0 or ∞. So in the limit, the circles\ntend either to a '''limit circle''' or a '''limit point''' at each end. If <math>\\mu</math> is a \nlimit point or a point on the limit circle at 0 or ∞, then <math>f=\\varphi + \\mu\\theta</math> is \n[[square integrable]] (L<sup>2</sup>) near 0 or ∞, since <math>\\mu</math> lies in ''D''<sub>''x''</sub> for all ''x>c'' (in the ∞ case) and so <math> \\int_c^x | \\varphi +\\mu \\theta|^2 <{{\\rm Im}(\\mu)\\over  {\\rm Im}(\\lambda)}</math> is bounded independent of ''x''. In particular:<ref name=\"Weyl 1910\">{{harvnb|Weyl|1910}}</ref>\n\n* ''there are always non-zero solutions of  Df = λf  which are square integrable near 0 resp. ∞'';\n* ''in the limit circle case all solutions of Df = λf are square integrable near 0 resp. ∞''.\n\nThe radius of the disc ''D''<sub>''x''</sub> can be calculated to be \n:<math> \\left|{1 \\over {2 {\\rm Im}(\\lambda) \\int_c^x |\\theta|^2}}\\right|</math>\nand this implies that in the limit point case <math>\\theta</math> cannot be square integrable near 0 resp. ∞. Therefore, we have a converse to the second statement above:\n\n* ''in the limit point case there is exactly one non-zero solution (up to scalar multiples) of Df = λf which is square integrable near 0 resp. ∞''.\n\nOn the other hand, if ''Dg'' = λ' ''g'' for another value λ', then\n\n:<math> h(x) = g(x) -(\\lambda^\\prime-\\lambda) \\int_c^x (\\varphi_\\lambda(x) \\theta_\\lambda(y) - \\theta_\\lambda(x)\\varphi_\\lambda(y))g(y)\\, dy</math>\n\nsatisfies ''Dh'' = λ''h'', so that\n\n:<math>g(x)=c_1 \\varphi_\\lambda + c_2 \\theta_\\lambda + (\\lambda^\\prime-\\lambda) \\int_c^x (\\varphi_\\lambda(x) \\theta_\\lambda(y) - \\theta_\\lambda(x)\\varphi_\\lambda(y))g(y)\\, dy.</math>\n\nThis formula may also be obtained directly by the variation of constant method from (D-λ)g = (λ'-λ)g.\nUsing this to estimate ''g'', it follows that<ref name=\"Weyl 1910\"/>\n\n* ''the limit point/limit circle behaviour at 0 or ∞ is independent of the choice of λ''.\n\nMore generally if ''Dg''= (λ – ''r'') ''g'' for some function ''r''(''x''), then<ref name=\"Bellman 1969 116\">{{harvnb|Bellman|1969|p=116}}</ref>\n\n:<math>g(x)=c_1 \\varphi_\\lambda + c_2 \\theta_\\lambda - \\int_c^x (\\varphi_\\lambda(x) \\theta_\\lambda(y) - \\theta_\\lambda(x)\\varphi_\\lambda(y))r(y)g(y)\\, dy.</math>\n\nFrom this it follows that<ref name=\"Bellman 1969 116\"/>\n\n* ''if r is continuous at 0, then D + r is limit point or limit circle at 0 precisely when D is'',\n\nso that in particular<ref>{{harvnb|Reed|Simon|1975|p=159}}</ref>\n\n* ''if q(x)- a/x<sup>2</sup> is continuous at 0, then D is limit point at 0 if and only if a ≥ ¾''.\n\nSimilarly\n\n* ''if r has a finite limit at ∞, then D + r is limit point or limit circle at ∞ precisely when D is'',\n\nso that in particular<ref>{{harvnb|Reed|Simon|1975|p=154}}</ref>\n\n* ''if q has a finite limit at ∞, then D is limit point at ∞''.\n\nMany more elaborate criteria to be limit point or limit circle can be found in the mathematical literature.\n\n=== Green's function (singular case) ===\nConsider the differential operator\n\n:<math> D_0 f = -(p_0f^\\prime)^\\prime + q_0f</math>\n\non (0,∞) with ''q''<sub>0</sub> positive and continuous on (0,∞) and ''p''<sub>0</sub> continuously differentiable in [0,∞), positive in (0,∞) and ''p''<sub>0</sub>(0)=0.\n\nMoreover, assume that after reduction to standard form\n''D''<sub>0</sub> becomes the equivalent operator\n\n:<math> Df= -f^{\\prime\\prime} + qf</math>\n\non (0,∞) where ''q'' has a finite limit at ∞. Thus\n\n*''D is limit point at ∞''.\n\nAt 0, ''D'' may be either limit circle or limit point. In either case there is an eigenfunction Φ<sub>0</sub> with ''D''Φ<sub>0</sub>=0 and  Φ<sub>0</sub> square integrable near 0. In the limit circle case, Φ<sub>0</sub> determines a '''[[boundary condition]]''' at 0:\n\n:<math> W(f,\\Phi_0)(0)=0.</math>\n\nFor λ complex, let Φ<sub>λ</sub> and Χ<sub>λ</sub> satisfy\n\n* (''D'' – λ)Φ<sub>λ</sub> = 0, (''D'' – λ)Χ<sub>λ</sub> = 0\n* Χ<sub>λ</sub> square integrable near infinity\n* Φ<sub>λ</sub> square integrable at 0 if 0 is ''limit point''\n* Φ<sub>λ</sub> satisfies the boundary condition above if 0 is ''limit circle''.\n\nLet\n\n:<math>\\omega(\\lambda) = W(\\Phi_\\lambda,\\Chi_\\lambda),</math>\n\na constant which vanishes precisely when Φ<sub>λ</sub> and Χ<sub>λ</sub> are proportional, i.e. λ is an [[eigenvalue]] of ''D'' for these boundary conditions.\n\nOn the other hand, this cannot occur if Im λ ≠ 0 or if λ is negative.<ref name=\"Weyl 1910\"/>\n\nIndeed, if ''D f''= λ''f'' with ''q''<sub>0</sub> – λ ≥ δ >0, then by Green's formula (''Df'',''f'') = (''f'',''Df''),  since ''W''(''f'',''f''<sup>*</sup>) is constant. So  λ must be real. If ''f'' is taken to be real-valued in the ''D''<sub>0</sub> realization, then for 0 < ''x'' < ''y''\n\n:<math> [p_0 ff^\\prime]_x^y = \\int_x^y (q_0 -\\lambda)|f|^2 + p_0 (f^\\prime)^2 .</math>\n\nSince ''p''<sub>0</sub>(0) = 0 and ''f'' is integrable near 0, ''p''<sub>0</sub>''f'' ''f'' ' must vanish at 0. Setting ''x'' = 0, it follows that ''f''(''y'') ''f'' '(''y'')  >0, so that ''f''<sup>2</sup> is increasing, contradicting the square integrability of ''f'' near ∞.\n\nThus, adding a positive scalar to ''q'', it may be assumed that\n\n:''ω(λ) ≠ 0 when λ is not in [1,∞)''.\n\nIf ω(λ) ≠ 0, the '''[[Green's function]]''' ''G''<sub>λ</sub>(''x'',''y'') at λ is defined by\n\n:<math>G_\\lambda(x,y) = \\Phi_\\lambda(x)\\Chi_\\lambda(y)/\\omega(\\lambda) \\,\\, (x\\le y), \\,\\,\\,\\, \n\\Chi_\\lambda(x)\\Phi_\\lambda(y)/\\omega(\\lambda) \\,\\, (x\\ge y).</math>\n\nand is independent of the choice of <sub>λ</sub> and Χ<sub>λ</sub>.\n\nIn the examples there will be a third \"bad\" eigenfunction Ψ<sub>λ</sub> defined and holomorphic for λ not in [1, ∞) such that \nΨ<sub>λ</sub> satisfies the boundary conditions at neither 0 nor ∞. This means that for λ not in [1, ∞)\n\n* ''W''(Φ<sub>λ</sub>,Ψ<sub>λ</sub>) is nowhere vanishing;\n* ''W''(Χ<sub>λ</sub>,Ψ<sub>λ</sub>) is nowhere vanishing.\n\nIn this case Χ<sub>λ</sub> is proportional to Φ<sub>λ</sub> + ''m''(λ) Ψ<sub>λ</sub>, where\n\n* ''m''(λ) = – ''W''(Φ<sub>λ</sub>,Χ<sub>λ</sub>) / ''W''(Ψ<sub>λ</sub>,Χ<sub>λ</sub>).\n\nLet ''H''<sub>1</sub> be the space of square integrable continuous functions on (0,∞) and let ''H''<sub>0</sub> be\n\n* the space of C<sup>2</sup> functions ''f'' on (0,∞) of [[compact support]] if ''D'' is limit point at 0\n* the space of C<sup>2</sup> functions ''f'' on (0,∞) with ''W''(''f'',Φ<sub>0</sub>)=0 at 0 and with ''f'' = 0 near ∞ if ''D'' is limit circle at 0.\n\nDefine ''T'' = ''G''<sub>0</sub> by\n\n:<math>(Tf)(x) =\\int_0^\\infty G_0(x,y)f(y) \\, dy. </math>\n\nThen ''T'' ''D'' = ''I'' on ''H''<sub>0</sub>, ''D'' ''T'' = ''I'' on ''H''<sub>1</sub> and the operator ''D'' is bounded below on ''H''<sub>0</sub>:\n\n:<math>(Df,f) \\ge (f,f).</math>\n\nThus ''T'' is a self-adjoint bounded operator with 0 ≤ ''T'' ≤ ''I''.\n\nFormally ''T'' = ''D''<sup>−1</sup>. The corresponding operators ''G''<sub>λ</sub> defined for λ not in [1,∞) can be formally identified with\n\n:<math>(D-\\lambda)^{-1}=T(I-\\lambda T)^{-1}</math>\n\nand satisfy ''G''<sub>λ</sub> (''D'' – λ) = ''I'' on ''H''<sub>0</sub>, (''D'' – λ)''G''<sub>λ</sub> = ''I'' on ''H''<sub>1</sub>.\n\n=== Spectral theorem and Titchmarsh–Kodaira formula ===\n\n'''Theorem'''.<ref name=\"Weyl 1910\"/><ref>{{harvnb|Titchmarsh |1946}}, Chapter III.</ref><ref>{{harvnb|Kodaira|1949|pp=935–936}}</ref> ''For every real number λ let ρ(λ) be defined by the'' '''Titchmarsh–Kodaira formula''':\n\n:<math> \\rho(\\lambda) = \\lim_{\\delta \\downarrow 0} \\lim_{\\varepsilon \\downarrow 0} {1\\over \\pi} \\int_\\delta^{\\lambda+\\delta} {\\rm Im}\\, m(t + i\\varepsilon) \\, dt.</math>\n\n''Then ρ(λ) is a lower semicontinuous non-decreasing function of λ and if''\n\n:<math> (Uf)(\\lambda) = \\int_0^\\infty f(x) \\Phi(x,\\lambda) \\, dx,</math>\n\n''then U defines a unitary transformation of L<sup>2</sup>(0,∞) onto L<sup>2</sup>([1,∞), dρ) such that''\nUDU<sup>−1</sup> ''corresponds to multiplication by λ. ''\n\n''The inverse transformation U<sup>−1</sup> is given by''\n\n:<math> (U^{-1}g)(x) = \\int_1^\\infty g(\\lambda) \\Phi(x,\\lambda) \\, d\\rho(\\lambda).</math>\n\n''The spectrum of D equals the support of dρ.''\n\nKodaira gave a streamlined version<ref>{{harvnb|Kodaira|1949|pp=929–932}}; for omitted details, see {{harvnb|Kodaira|1950|pp=529–536}}</ref><ref>{{harvnb|Dieudonné|1988}}</ref> of Weyl's original proof.<ref name=\"Weyl 1910\"/> ([[Marshall Harvey Stone|M.H. Stone]] had previously shown<ref>{{harvnb|Stone|1932}}, Chapter X.</ref> how part of Weyl's work could be simplified using von Neumann's spectral theorem.)\n\nIn fact for ''T'' =''D''<sup>−1</sup> with 0 ≤ ''T'' ≤ ''I'', the spectral projection ''E''(λ) of ''T'' is defined by\n\n:<math> E(\\lambda) =\\chi_{[\\lambda^{-1},1]}(T)</math>\n\nIt is also the spectral projection of ''D'' corresponding to the interval [1,λ].\n\nFor ''f'' in ''H''<sub>1</sub> define\n\n:<math> f(x,\\lambda)= (E(\\lambda)f)(x). </math>\n\n''f''(''x'',λ)  may be regarded as a differentiable map into the space of functions ρ of bounded variation; or equivalently as a differentiable map\n\n:<math> x\\mapsto (d_\\lambda f)(x)</math>\n\ninto the Banach space '''E''' of  bounded linear functionals ''d''ρ on C[α,β] for any compact subinterval [α,β] of [1, ∞).\n\nThe functionals (or measures) ''d''<sub>λ</sub> ''f''(''x'')  satisfies the following '''E'''-valued second order ordinary differential equation:\n\n:<math> D (d_\\lambda f) = \\lambda \\cdot d_\\lambda f,</math>\n\nwith initial conditions at ''c'' in (0,∞)\n\n<math> (d_\\lambda f)(c)= d_\\lambda f(c,\\cdot)=\\mu^{(0)}, \\quad (d_\\lambda f)^\\prime(c)= d_\\lambda f_x(c,\\cdot)=\\mu^{(1)}.</math>\n\nIf φ<sub>λ</sub> and χ<sub>λ</sub> are the special eigenfunctions adapted to ''c'', then\n\n:<math> d_\\lambda f (x) = \\varphi_\\lambda(x) \\mu^{(0)} + \\chi_\\lambda(x) \\mu^{(1)}.</math>\n\nMoreover,\n\n:<math> \\mu^{(k)}= d_\\lambda (f,\\xi^{(k)}_\\lambda),</math>\n\nwhere\n\n:<math> \\xi^{(k)}_\\lambda = D E(\\lambda) \\eta^{(k)},</math>\n\nwith\n\n:<math> \\eta_z^{(0)}(y) = G_z(c,y), \\,\\,\\,\\, \\eta_z^{(1)}(x)=\\partial_x G_z(c,y), \\,\\,\\,\\, (z \\notin [1,\\infty)).</math>\n\n(As the notation suggests, ξ<sub>λ</sub><sup>(0)</sup> and ξ<sub>λ</sub><sup>(1)</sup> do not depend on the choice of ''z''.)\n\nSetting\n\n:<math>\\sigma_{ij}(\\lambda) = (\\xi^{(i)}_\\lambda, \\xi^{(j)}_\\lambda),</math>\n\nit follows that\n\n:<math> d_\\lambda (E(\\lambda)\\eta_z^{(i)},\\eta_z^{(j)}) = |\\lambda - z|^{-2} \\cdot d_\\lambda \\sigma_{ij}(\\lambda).</math>\n\nOn the other hand, there are holomorphic functions\n''a''(λ), ''b''(λ) such that\n\n* φ<sub>λ</sub> + ''a''(λ) χ<sub>λ</sub> is proportional to Φ<sub>λ</sub>;\n* φ<sub>λ</sub> + ''b''(λ) χ<sub>λ</sub> is proportional to Χ<sub>λ</sub>.\n\nSince ''W''(φ<sub>λ</sub>,χ<sub>λ</sub>) = 1, the Green's function is given by\n\n:<math> G_\\lambda(x,y) = {(\\varphi_\\lambda(x) + a(\\lambda)\\chi_\\lambda(x))(\\varphi_\\lambda(y) + b(\\lambda)\\chi_\\lambda(y))\\over b(\\lambda)-a(\\lambda)} \\,\\, (x\\le y), \\,\\,\\,\\, {(\\varphi_\\lambda(x) + b(\\lambda)\\chi_\\lambda(x))(\\varphi_\\lambda(y) + a(\\lambda)\\chi_\\lambda(y))\\over b(\\lambda)-a(\\lambda)} \\,\\, (y\\le x). </math>\n\nDirect calculation<ref>{{harvnb|Kodaira|1950|pp=534–535}}</ref> shows that\n\n:<math>(\\eta_z^{(i)},\\eta_z^{(j)}) = {\\rm Im}\\, M_{ij}(z)/ {\\rm Im}\\, z, </math>\n\nwhere the so-called ''' ''characteristic matrix'' ''' ''M''<sub>''ij''</sub>(''z'') is given by\n\n:<math> M_{00}(z)= {a(z)b(z)\\over a(z)-b(z)},\\,\\, M_{01}(z)=M_{10}(z)={a(z)+b(z)\\over 2(a(z) -b(z))}, \\,\\, M_{11}(z)= {1\\over a(z)-b(z)}.</math>\n\nHence\n\n:<math> \\int_{-\\infty}^\\infty ({\\rm Im}\\, z)\\cdot|\\lambda-z|^{-2}\\, d\\sigma_{ij}(\\lambda) = {\\rm Im} M_{ij}(z),</math>\n\nwhich immediately implies\n\n:<math> \\sigma_{ij}(\\lambda) = \\lim_{\\delta\\downarrow 0} \\lim_{\\varepsilon \\downarrow 0} \\int_\\delta^{\\lambda +\\delta}{\\rm Im}\\, M_{ij}(t +i\\varepsilon)\\, dt.</math>\n\n(This is a special case of the [[Stieltjes transformation|\"Stietljes inversion formula\"]].)\n\nSetting ψ<sub>λ</sub><sup>(0)</sup>=φ<sub>λ</sub> and ψ<sub>λ</sub><sup>(1)</sup>=χ<sub>λ</sub>, it follows that\n\n:<math> (E(\\mu)f)(x)= \\sum_{i.j}\\int_0^\\mu \\int_0^\\infty\\psi^{(i)}_\\lambda(x)\\psi^{(j)}_\\lambda(y) f(y)\\, dy \\,d\\sigma_{ij}(\\lambda) = \\int_0^\\mu \\int_0^\\infty\\Phi_\\lambda(x) \\Phi_\\lambda(y) f(y)\\, dy \\, d\\rho(\\lambda).</math>\n\nThis identity is equivalent to the spectral theorem and Titchmarsh–Kodaira formula.\n\n== Application to the hypergeometric equation ==\n{{See also|Legendre equation|Hypergeometric equation}}\nThe '''Mehler–Fock transform'''<ref>{{citation|last=Mehler|first=F.G.|title=Ueber mit der Kugel- und Cylinderfunctionen verwandte Function und ihre Anwendung in der Theorie der Elektricitätsverteilung|journal=[[Mathematische Annalen]]|year=1881|volume=18|issue=2|pages=161–194|doi=10.1007/BF01445847|url=http://gdz.sub.uni-goettingen.de/index.php?id=11&PPN=PPN235181684_0018&DMDID=DMDLOG_0021&L=1}}</ref><ref>{{citation|last=Fock|first=V.A.|title=On the representation of an arbitrary function by an integral involving Legendre's functions with a complex index|journal=C. R. Acad. Sci. URSS |year=1943|volume=39|pages=253–256}}</ref><ref>{{harvnb|Vilenkin|1968}}</ref> concerns the eigenfunction expansion associated with the [[Legendre function|Legendre differential operator]] ''D''\n\n:<math> Df = -((x^2-1) f^\\prime)^\\prime =-(x^2-1)f^{\\prime\\prime} -2x f^\\prime </math>\n\non (1,∞). The eigenfunctions are the [[Legendre function]]s<ref>{{citation|first=Audrey|last=Terras|authorlink=Audrey Terras|title=Non-Euclidean harmonic analysis, the central limit theorem, and long transmission lines with random inhomogeneities|journal=J. Multivariate Anal.|volume= 15 |issue=2|year=1984|pages=261–276|doi=10.1016/0047-259X(84)90031-9}}</ref>\n\n:<math> P_{-1/2+i\\sqrt{\\lambda}}(\\cosh r) = {1\\over 2\\pi} \\int_0^{2\\pi} \\left({\\sin \\theta + i e^{-r} \\cos\\theta\\over \\cos \\theta - i e^{-r}\\sin\\theta} \\right)^{{1\\over 2}+i\\sqrt{\\lambda}}\\, d\\theta</math>\n\nwith eigenvalue λ ≥ 0. The two Mehler–Fock transformations are<ref>{{citation|first=N.N.|last=Lebedev|title=Special Functions and Their Applications|year=1972|\npublisher=Dover|isbn=978-0-486-60624-8}}</ref>\n\n:<math>Uf(\\lambda)=\\int_1^\\infty f(x)\\, P_{-1/2 +i\\sqrt{\\lambda}}(x) \\, dx</math>\n\nand\n\n:<math>U^{-1}g(x)=\\int_0^\\infty g(\\lambda) \\, {1\\over2}\\tanh \\pi \\sqrt{\\lambda}\\,d\\lambda.</math>\n\n(Often this is written in terms of the variable τ = {{radic|λ}}.)\n\nMehler and Fock studied this differential operator because it arose as the radial component of the Laplacian on 2-dimensional hyperbolic space. \nMore generally,<ref>{{harvnb|Vilenkin|1968}}, Chapter VI.</ref> consider the group ''G'' = [[SL(2,R)|SU(1,1)]] consisting of complex matrices of the form\n\n:<math> \\left(\\begin{matrix}\\alpha & \\beta\\\\\n                   \\overline{\\beta} & \\overline{\\alpha}\\end{matrix}\\right)</math>\n\nwith determinant |α|<sup>2</sup> &minus; |β|<sup>2</sup> = 1.\n\n== Application to the hydrogen atom ==\n{{See also|Hydrogen atom}}\n\n== Generalisations and alternative approaches ==\nA Weyl function can be defined at a singular endpoint <math>a</math> giving rise to a singular version of Weyl–Titchmarsh–Kodaira theory.<ref>{{citation|first=Aleksey|last=Kostenko|first2=Alexander|last2=Sakhnovich|first3=Gerald|last3=Teschl|authorlink3=Gerald Teschl|title=Weyl–Titchmarsh Theory for Schrödinger Operators with Strongly Singular Potentials|journal=Int Math Res Notices|volume= 2012 |year=2012|pages=1699–1747|doi=10.1093/imrn/rnr065|arxiv=1007.0136}}</ref> this applies for example to the case of radial Schrödinger operators\n\n:<math> Df = -f^{\\prime\\prime} + \\frac{l(l+1)}{x^2} f+ V(x) f, \\qquad x\\in(0,\\infty) </math>\n\nThe whole theory can also be extended to the case where the coefficients are allowed to be measures.<ref>{{citation|first=Jonathan|last=Eckhardt|first2=Gerald|last2=Teschl|authorlink2=Gerald Teschl|title=Sturm–Liouville operators with measure-valued coefficients|journal=J. d'Analyse Math.|volume=120|year=2013|pages=151–224|doi=10.1007/s11854-013-0018-x|arxiv=1105.3755}}</ref>\n\n== Gelfand–Levitan theory ==\n{{See also|Inverse scattering theory}}\n\n==Notes==\n{{Reflist|30em}}\n\n==References==\n*{{citation|first=Naum Ilich|last=[[Naum Akhiezer|Akhiezer]]|first2=Izrael Markovich|last2=Glazman|title=Theory of Linear Operators in Hilbert Space|publisher=Dover|year=1993|isbn=978-0-486-67748-4}}\n*{{citation|first=Richard|last= Bellman|title=Stability Theory of Differential Equations|publisher=Dover|year=1969|isbn=978-0-486-62210-1}}\n*{{citation|first=Earl A.|last= Coddington|first2=Norman|last2=Levinson|year= 1955|publisher= McGraw-Hill|title=Theory of Ordinary Differential equations|isbn=978-0-07-011542-2}}\n*{{citation|last=[[Richard Courant|Courant]]|first=Richard|first2=David|last2=Hilbert|title=Method of Mathematical Physics, Vol. I|publisher=Wiley-Interscience|year=1989|isbn=978-0-471-50447-4}}\n*{{citation|first=Jean|last=[[Jean Dieudonné|Dieudonné]]|title=Treatise on Analysis, Vol. I [Foundations of Modern Analysis]|publisher=Academic Press|year=1969|\nisbn=978-1-4067-2791-3}}\n\n*{{citation|first=Jean|last=Dieudonné|title=Treatise on Analysis, Vol. VIII|publisher=Academic Press|year=1988|isbn= 978-0-12-215507-9}}\n*{{citation|first=Nelson|last=[[Nelson Dunford|Dunford]]|first2=Jacob T.| last2=Schwartz|title=Linear Operators, Part II Spectral Theory. Self Adjoint Operators in Hilbert space|year=1963|publisher=Wiley Interscience|isbn=978-0-471-60847-9}}\n*{{citation|first=Einar|last=[[Einar Hille|Hille]]|title=Lectures on Ordinary Differential Equations|year=1969|publisher=Addison-Wesley|isbn= 978-0-201-53083-4}}\n*{{citation|first=Kunihiko|last=[[Kunihiko Kodaira|Kodaira]]|title= The eigenvalue problem for ordinary differential equations of the second order and Heisenberg's theory of S-matrices|journal=American Journal of Mathematics|year=1949|volume=71|pages=921–945|doi=10.2307/2372377|issue=4|jstor=2372377}}\n*{{citation|first=Kunihiko|last=Kodaira|title=On ordinary differential equations of any even order and the corresponding eigenfunction expansions|journal= American Journal of Mathematics|year=1950|volume=72|pages=502–544|doi=10.2307/2372051|issue=3|jstor=2372051}}\n*{{citation|first=Michael|last=[[Michael C. Reed|Reed]]|first2=Barry|last2=[[Barry Simon|Simon]]|title=Methods of Modern Mathematical Physics II, Fourier Analysis, Self-Adjointness|publisher=Academic Press|year=1975|isbn= 978-0-12-585002-5}}\n*{{citation|first=Marshall Harvey|last=[[Marshall Harvey Stone|Stone]]|title=Linear transformations in Hilbert space and Their Applications to Analysis|series=AMS Colloquium Publications|volume=16|year=1932|isbn=978-0-8218-1015-6}}\n*{{cite book| last = Teschl| given = Gerald|authorlink=Gerald Teschl| title=Mathematical Methods in Quantum Mechanics; With Applications to Schrödinger Operators|url=http://www.mat.univie.ac.at/~gerald/ftp/book-schroe/|series=AMS Graduate Studies in Mathematics|volume=99|year=2009|isbn=978-0-8218-4660-5}}\n*{{cite book| last = Teschl| given = Gerald|authorlink=Gerald Teschl| title = Ordinary Differential Equations and Dynamical Systems| series=AMS Graduate Studies in Mathematics|volume=140| year = 2012| isbn= 978-0-8218-8328-0| url = http://www.mat.univie.ac.at/~gerald/ftp/book-ode/}}\n*{{citation|first=Edward Charles|last=[[Edward Charles Titchmarsh|Titchmarsh]]| title=Eigenfunction expansions associated with second order differential equations, Vol. I, first edition|year=1946|publisher=Oxford University Press}}\n*{{citation|first=Edward Charles|last=Titchmarsh| title=Eigenfunction expansions associated with second order differential equations, Vol. I, second edition|year=1962|publisher=Oxford University Press|isbn=978-0-608-08254-7}}\n*{{citation|first=Naoum Iakovlevitch|last=Vilenkin|title=Special Functions and the Theory of Group Representations|series=Translations of Mathematical Monographs|volume=22|year=1968|publisher=American Mathematical Society|\nisbn=978-0-8218-1572-4}}\n\n*{{citation|first=Joachim|last=Weidmann|title=Spectral Theory of Ordinary Differential Operators|series=Lecture Notes in Mathematics|volume=1258| publisher=Springer-Verlag|year=1987|isbn=978-0-387-17902-5}}\n*{{citation|first=Hermann|last=[[Hermann Weyl|Weyl]]|title=Über gewöhnliche Differentialgleichungen mit Singularitäten und die zugehörigen Entwicklungen willkürlicher Functionen|journal=[[Mathematische Annalen]]|volume=68|issue=2|year=1910|pages=220–269|doi=10.1007/BF01474161|url=http://gdz.sub.uni-goettingen.de/index.php?id=11&PPN=PPN235181684_0068&DMDID=DMDLOG_0023&L=1}}\n*{{citation|first=Hermann|last=Weyl|title=Über gewöhnliche Differentialgleichungen mit Singulären Stellen und ihre Eigenfunktionen|\njournal=Nachr. Akad. Wiss. Göttingen. Math.-Phys.|year=1910|pages=442–446}}\n\n*{{citation|first=Hermann|last=Weyl|title=Über das Pick-Nevanlinnasche Interpolationsproblem und sein infinitesimales Analogen|journal=Annals of Mathematics|year=1935|pages=230–254|doi=10.2307/1968677|volume=36|issue=1|jstor=1968677}}\n\n{{Functional Analysis}}\n\n[[Category:Ordinary differential equations]]\n[[Category:Operator theory]]\n[[Category:Spectral theory]]"
    },
    {
      "title": "Spectrum (functional analysis)",
      "url": "https://en.wikipedia.org/wiki/Spectrum_%28functional_analysis%29",
      "text": "In [[mathematics]], particularly in [[functional analysis]], the '''spectrum''' of a [[bounded operator]] is a generalisation of the set of [[eigenvalue]]s of a [[matrix (mathematics)|matrix]].  Specifically, a [[complex number]] λ is said to be in the spectrum of a bounded linear operator ''T'' if λ''I''&nbsp;&minus;&nbsp;''T'' is not [[inverse function|invertible]], where ''I'' is the [[identity operator]]. The study of spectra and related properties is known as [[spectral theory]], which has numerous applications, most notably the [[mathematical formulation of quantum mechanics|mathematical formulation]] of [[quantum mechanics]].\n\nThe spectrum of an operator on a [[Dimension (vector space)|finite-dimensional]] [[vector space]] is precisely the set of eigenvalues.  However an operator on an infinite-dimensional space may have additional elements in its spectrum, and may have no eigenvalues.  For example, consider the [[unilateral shift|right shift]] operator ''R'' on the [[Hilbert space]] [[Lp space|ℓ<sup>2</sup>]],\n:<math>(x_1, x_2, \\dots) \\mapsto (0, x_1, x_2, \\dots).</math>\nThis has no eigenvalues, since if ''Rx''=λ''x'' then by expanding this expression we see that ''x''<sub>1</sub>=0, ''x''<sub>2</sub>=0, etc.  On the other hand, 0 is in the spectrum because the operator ''R''&nbsp;&minus;&nbsp;0 (i.e. ''R'' itself) is not invertible: it is not surjective since any vector with non-zero first component is not in its range.  In fact ''every'' bounded linear operator on a [[complex number|complex]] [[Banach space]] must have a non-empty spectrum.\n\nThe notion of spectrum extends to [[densely defined operator|densely defined]] [[unbounded operator]]s. In this case a [[complex number]] λ is said to be in the spectrum of such an operator ''T'':''D''→''X'' (where ''D'' is dense in ''X'') if there is no bounded inverse (λ''I''&nbsp;&minus;&nbsp;''T'')<sup>−1</sup>:''X''→''D''.  If ''T'' is a [[closed operator]] (which includes the case that ''T'' is a bounded operator), boundedness of such inverses follows automatically if the inverse exists at all.\n\nThe space of bounded linear operators ''B''(''X'') on a Banach space ''X'' is an example of a [[unital algebra|unital]] [[Banach algebra]].  Since the definition of the spectrum does not mention any properties of ''B''(''X'') except those that any such algebra has, the notion of a spectrum may be generalised to this context by using the same definition verbatim.\n\n==Spectrum of a bounded operator==\n===Definition===\nLet <math>T</math> be a [[bounded linear operator]] acting on a Banach space <math>X</math> over the scalar field <math>\\mathbb{K}</math>, and <math>I</math> be the [[identity operator]] on <math>X</math>.  The '''spectrum''' of <math>T</math> is the set of all <math>\\lambda \\in \\mathbb{K}</math> for which the operator <math>\\lambda I - T</math> does not have an inverse that is a bounded linear operator.\n\nSince <math>\\lambda I - T</math> is a linear operator, the inverse is linear if it exists; and, by the [[bounded inverse theorem]], it is bounded.  Therefore, the spectrum consists precisely of those scalars <math>\\lambda</math> for which <math>\\lambda I - T</math> is not [[bijective]].\n\nThe spectrum of a given operator <math>T</math> is often denoted <math>\\sigma(T)</math>, and its complement, the [[resolvent set]], is denoted <math>\\rho(T) = \\mathbb{K} \\setminus \\sigma(T)</math>. (<math>\\rho(T)</math> is sometimes used to denote the spectral radius of <math>T</math>)\n\n===Spectrum and eigenvalues===\nIf <math>\\lambda</math> is an eigenvalue of <math>T</math>, then the operator <math>T-\\lambda I</math> is not one-to-one, and therefore its inverse <math>(T-\\lambda I)^{-1}</math> is not defined.  However, the inverse statement is not true: the operator <math>T - \\lambda I</math> may not have an inverse, even if <math>\\lambda</math> is not an eigenvalue. Thus the spectrum of an operator always contains all its eigenvalues, but is not limited to them.\n\nFor example, consider the Hilbert space <math>\\ell^2(\\mathbb{Z})</math>, that consists of all [[Sequence#Finite and infinite|bi-infinite sequences]] of real numbers\n:<math>v = (\\ldots, v_{-2},v_{-1},v_0,v_1,v_2,\\ldots)</math>\nthat have a finite sum of squares <math>\\sum_{i=-\\infty}^{+\\infty} v_i^2</math>.  The [[bilateral shift]] operator <math>T</math> simply displaces every element of the sequence by one position; namely if <math>u = T(v)</math> then <math>u_i = v_{i-1}</math> for every integer <math>i</math>.  The eigenvalue equation <math>T(v) = \\lambda v</math> has no solution in this space, since it implies that all the values <math>v_i</math> have the same absolute value (if <math>\\lambda = 1</math>) or are a geometric progression (if <math>\\lambda \\neq 1</math>); either way, the sum of their squares would not be finite.  However, the operator <math>T-\\lambda I</math> is not invertible if <math>|\\lambda| = 1</math>. For example, the sequence <math>u</math> such that <math>u_i = 1/(|i|+1)</math> is in <math>\\ell^2(\\mathbb{Z})</math>; but there is no sequence <math>v</math> in <math>\\ell^2(\\mathbb{Z})</math> such that <math>(T-I)v = u</math> (that is, <math>v_{i-1} = u_i + v_i</math> for all <math>i</math>).\n\n=== Basic properties ===\n\nThe spectrum of a bounded operator ''T'' is always a [[closed set|closed]], [[bounded set|bounded]] and [[empty set|non-empty]] subset of the [[complex plane]].\n\nIf the spectrum were empty, then the [[Resolvent formalism|''resolvent function'']]\n\n:<math>R(\\lambda) = (\\lambda I - T)^{-1} \\,</math>\n\nwould be defined everywhere on the complex plane and bounded. But it can be shown that the resolvent function ''R'' is [[Holomorphic function|holomorphic]] on its domain. By the vector-valued version of [[Liouville's theorem (complex analysis)|Liouville's theorem]], this function is constant, thus everywhere zero as it is zero at infinity. This would be a contradiction.\n\nThe boundedness of the spectrum follows from the [[Neumann series|Neumann series expansion]] in ''λ''; the spectrum ''σ''(''T'') is bounded by ||''T''||. A similar result shows the closedness of the spectrum.\n\nThe bound ||''T''|| on the spectrum can be refined somewhat. The ''[[spectral radius]]'', ''r''(''T''), of ''T'' is the radius of the smallest circle in the complex plane which is centered at the origin and contains the spectrum σ(''T'') inside of it, i.e.\n\n:<math>r(T) = \\sup \\{|\\lambda| : \\lambda \\in \\sigma(T)\\}.</math>\n \nThe '''spectral radius formula''' says<ref>Theorem 3.3.3 of Kadison & Ringrose, 1983, ''Fundamentals of the Theory of Operator Algebras, Vol. I: Elementary Theory'', New York: Academic Press, Inc.</ref> that  for any element <math>T</math> of a [[Banach algebra]],\n:<math>r(T) = \\lim_{n \\to \\infty} \\|T^n\\|^{1/n}.</math>\n\n== Classification of points in the spectrum of an operator ==\n{{further|Decomposition of spectrum (functional analysis)}}\nA bounded operator ''T'' on a Banach space is invertible, i.e. has a bounded inverse, if and only if ''T'' is bounded below and has dense range. Accordingly, the spectrum of ''T'' can be divided into the following parts:\n\n# &lambda;&nbsp;∈&nbsp;&sigma;(''T''), if &lambda;''I''&nbsp;-&nbsp;''T'' is not bounded below. In particular, this is the case if &lambda;''I''&nbsp;-&nbsp;''T'' is not injective, that is, &lambda; is an eigenvalue. The set of eigenvalues is called the '''point spectrum''' of ''T'' and denoted by &sigma;<sub>p</sub>(''T''). Alternatively, &lambda;''I''&nbsp;-&nbsp;''T'' could be one-to-one but still not be bounded below. Such &lambda; is not an eigenvalue but still an ''approximate eigenvalue'' of ''T'' (eigenvalues themselves are also approximate eigenvalues). The set of approximate eigenvalues (which includes the point spectrum) is called the '''approximate point spectrum''' of ''T'', denoted by &sigma;<sub>ap</sub>(''T'').\n# &lambda;&nbsp;∈&nbsp;&sigma;(''T''), if &lambda;''I''&nbsp;-&nbsp;''T'' does not have dense range.  The set of such &lambda; is called the '''compression spectrum''' of ''T'', denoted by &sigma;<sub>cp</sub>(''T''). For a subset: If &lambda;''I''&nbsp;-&nbsp;''T'' does not have dense range but is injective, &lambda; is said to be in the '''residual spectrum''' of ''T'', denoted by &sigma;<sub>r</sub>(''T'').\n\nNote that the approximate point spectrum and residual spectrum are not necessarily disjoint (however, the point spectrum and the residual spectrum are).\n\nThe following subsections provide more details on the three parts of &sigma;(''T'') sketched above.\n\n===Point spectrum===\n\nIf an operator is not injective (so there is some nonzero ''x'' with ''T''(''x'')&nbsp;=&nbsp;0), then it is clearly not invertible. So if &lambda; is an [[eigenvalue]] of ''T'', one necessarily has &lambda;&nbsp;∈&nbsp;&sigma;(''T''). The set of eigenvalues of ''T'' is also called the '''point spectrum''' of ''T'', denoted by &sigma;<sub>p</sub>(''T'').\n\n===Approximate point spectrum===\n\nMore generally, by the [[bounded inverse theorem]], ''T'' is not invertible if it is not bounded below; that is, if there is no ''c''&nbsp;>&nbsp;0 such that ||''Tx''||&nbsp;≥&nbsp;''c''||''x''|| for all {{nowrap|''x'' ∈ ''X''}}.  So the spectrum includes the set of '''approximate eigenvalues''', which are those λ such that {{nowrap|''T'' -λ''I''}} is not bounded below; equivalently, it is the set of λ for which there is a sequence of unit vectors ''x''<sub>1</sub>, ''x''<sub>2</sub>, ... for which\n\n:<math>\\lim_{n \\to \\infty} \\|Tx_n - \\lambda x_n\\| = 0</math>.\n\nThe set of approximate eigenvalues is known as the '''approximate point spectrum''', denoted by '''σ<sub>ap</sub>(''T'')'''.\n\nIt is easy to see that the eigenvalues lie in the approximate point spectrum.\n\n'''Example''' Consider the [[bilateral shift]] ''T'' on ''l''<sup>2</sup>('''Z''') defined by\n\n:<math>\nT(\\cdots, a_{-1}, \\hat{a}_0, a_1, \\cdots) = (\\cdots, \\hat{a}_{-1}, a_0, a_1, \\cdots)\n</math>\n\nwhere the ˆ denotes the zero-th position. Direct calculation shows ''T'' has no eigenvalues, but every λ with |λ| = 1 is an approximate eigenvalue; letting ''x''<sub>''n''</sub> be the vector\n\n:<math>\\frac{1}{\\sqrt{n}}(\\dots, 0, 1, \\lambda^{-1}, \\lambda^{-2}, \\dots, \\lambda^{1 - n}, 0, \\dots)</math>\n\nthen ||''x''<sub>''n''</sub>|| = 1 for all ''n'', but\n\n:<math>\\|Tx_n - \\lambda x_n\\| = \\sqrt{\\frac{2}{n}} \\to 0.</math>\n\nSince ''T'' is a unitary operator, its spectrum lies on the unit circle. Therefore, the approximate point spectrum of T is its entire spectrum. This is true for a more general class of operators.\n\nA unitary operator is [[normal operator|normal]]. By [[spectral theorem]], a bounded operator on a Hilbert space H is normal if and only if it is equivalent (after identification of H with an L^2 space) to a [[multiplication operator]]. It can be shown that the approximate point spectrum of a bounded multiplication operator equals its spectrum.\n\n===Residual spectrum===\n\nAn operator may be injective, even bounded below, but not invertible. The [[unilateral shift]] on <math>l^2(\\mathbb{N})</math> is such an example. This shift operator is an [[isometry]], therefore bounded below by 1. But it is not invertible as it is not surjective. The set of λ for which λ''I''&nbsp;-&nbsp;''T'' is injective but does not have dense range is known as the '''residual spectrum''' or '''compression spectrum''' of ''T'' and is denoted by  '''σ<sub>r</sub>(''T'')'''.\n\n===Continuous spectrum===\n\nThe set of all λ for which λ''I''&nbsp;-&nbsp;''T'' is injective and has dense range, but is not surjective, is called the '''continuous spectrum''' of ''T'', denoted by  '''σ<sub>c</sub>(''T'')''' . The continuous spectrum therefore consists of those approximate eigenvalues which are not eigenvalues and do not lie in the residual spectrum. That is,\n\n:<math>\\sigma_c(T) = \\sigma_{ap}(T) \\setminus (\\sigma_r(T) \\cup  \\sigma_p(T)) </math>.\n\n===Peripheral spectrum===\n\nThe peripheral spectrum of an operator is defined as the set of points in its spectrum which have modulus equal to its spectral radius.<ref name=\"Zaanen\">{{cite book|last1=Zaanen|first1=Adriaan C.|title=Introduction to Operator Theory in Riesz Spaces|date=2012|publisher=Springer Science & Business Media|isbn=9783642606373|page=304|url=https://books.google.com/books?id=cgvpCAAAQBAJ&pg=PA304&dq=Peripheral+spectrum&hl=en&sa=X&ved=0ahUKEwjVxPCw35TWAhWQ-lQKHS5WBdQQ6AEIKDAA#v=onepage&q=Peripheral%20spectrum&f=false|accessdate=8 September 2017|language=en}}</ref>\n\n===Example===\nThe [[hydrogen atom]] provides an example of this decomposition.  The eigenfunctions of the [[molecular Hamiltonian|hydrogen atom Hamiltonian]] are called '''eigenstates''' and are grouped into two categories. The [[bound state]]s of the hydrogen atom correspond to the discrete part of the spectrum (they have a discrete set of eigenvalues that can be computed by the [[Rydberg formula]]), whereas the end result of the [[ionization]] process is described by the continuous part (the energy of the collision/ionization is not \"quantized\").\n\n== Further results ==\n\nIf ''T'' is a [[compact operator]], then it can be shown that any nonzero λ in the spectrum is an eigenvalue. In other words, the spectrum of such an operator, which was defined as a generalization of the concept of eigenvalues, consists in this case only of the usual eigenvalues, plus possibly 0.\n\nIf ''X'' is a [[Hilbert space]] and ''T'' is a [[normal operator]], then a remarkable result known as the [[spectral theorem]] gives an analogue of the diagonalisation theorem for normal finite-dimensional operators (Hermitian matrices, for example).\n\n== Spectrum of an unbounded operator ==\n\nOne can extend the definition of spectrum for [[unbounded operator]]s on a [[Banach space]] ''X'', operators which are no longer elements in the Banach algebra ''B''(''X''). One proceeds in a manner similar to the bounded case. A complex number λ is said to be in the '''resolvent set''', that is, the [[complement (set theory)|complement]] of the spectrum of a linear operator\n\n:<math>T: D \\subset X \\to X</math>\n\nif the operator\n\n:<math>T-\\lambda I: D \\to X</math>\n\nhas a bounded inverse, i.e. if there exists a bounded operator\n\n:<math>S : X \\rightarrow D</math>\n\nsuch that\n\n:<math>S (T - I \\lambda) = I_D, \\,  (T - I \\lambda) S  = I_X.</math>\n\nA complex number λ is then in the '''spectrum''' if this property fails to hold. One can classify the spectrum in exactly the same way as in the bounded case.\n\nThe spectrum of an unbounded operator is in general a closed, possibly empty, subset of the complex plane.\n\nFor ''λ'' to be in the resolvent (i.e. not in the spectrum), as in the bounded case λ''I''&nbsp;&minus;&nbsp;''T'' must be bijective, since it must have a two-sided inverse. As before if an inverse exists then its linearity is immediate, but in general it may not be bounded, so this condition must be checked separately.\n\nHowever, boundedness of the inverse ''does'' follow directly from its existence if one introduces the additional assumption that ''T'' is [[closed operator|closed]]; this follows from the [[closed graph theorem]].  Therefore, as in the bounded case, a complex number ''λ'' lies in the spectrum of a closed operator ''T'' if and only if λ''I''&nbsp;&minus;&nbsp;''T'' is not bijective.  Note that the class of closed operators includes all bounded operators.\n\nVia its [[spectral measure]]s, one can define a [[decomposition of spectrum (functional analysis)|decomposition of the spectrum]] of any self adjoint operator, bounded or otherwise into absolutely continuous, pure point, and singular parts.\n\n== Spectrum of a unital Banach algebra ==\n{{Expand section|date=June 2009}}\nLet ''B'' be a complex [[Banach algebra]] containing a [[unit (ring theory)|unit]] ''e''. Then we define the spectrum σ(''x'') (or more explicitly σ<sub>''B''</sub>(''x'')) of an element ''x'' of ''B'' to be the set of those [[complex number]]s λ for which λ''e''&nbsp;−&nbsp;''x'' is not invertible in  ''B''.  This extends the definition for bounded linear operators ''B''(''X'') on a Banach space ''X'', since ''B''(''X'') is a Banach algebra.\n\n==See also==\n*[[Essential spectrum]]\n*[[Self-adjoint operator]]\n*[[Pseudospectrum]]\n*[[Resolvent set]]\n\n== References ==\n{{Reflist}}\n*Dales et al., ''Introduction to Banach Algebras, Operators, and Harmonic Analysis'', {{ISBN|0-521-53584-0}}\n*{{springer|title=Spectrum of an operator|id=p/s086610}}\n\n{{Functional Analysis}}\n\n{{DEFAULTSORT:Spectrum (Functional Analysis)}}\n[[Category:Spectral theory]]"
    },
    {
      "title": "Starlike tree",
      "url": "https://en.wikipedia.org/wiki/Starlike_tree",
      "text": "{{unreferenced|date=April 2017}}\nIn the area of mathematics known as [[graph theory]], a [[tree (graph theory)|tree]] is said to be '''starlike''' if it has exactly one vertex of [[degree (graph theory)|degree]] greater than&nbsp;2. This high-degree vertex is the '''root''' and a starlike tree is obtained by attaching at least three [[path graph|linear graphs]] to this central vertex.\n\n== Properties ==\n\nTwo finite starlike trees are [[isospectral]], i.e. their [[discrete Laplace operator|graph Laplacians]] have the same spectra, if and only if they are [[graph isomorphism|isomorphic]].  \n\n[[Category:Graph theory]]\n[[Category:Spectral theory]]\n\n\n{{combin-stub}}"
    },
    {
      "title": "Sturm–Liouville theory",
      "url": "https://en.wikipedia.org/wiki/Sturm%E2%80%93Liouville_theory",
      "text": "In [[mathematics]] and its applications, a classical '''Sturm–Liouville theory''', named after [[Jacques Charles François Sturm]] (1803&ndash;1855) and [[Joseph Liouville]] (1809&ndash;1882), is the theory of a real second-order linear [[differential equation]] of the form\n\n{{NumBlk|:|<math> \\frac{\\mathrm{d}}{\\mathrm{d}x}\\left[p(x)\\frac{\\mathrm{d}y}{\\mathrm{d}x}\\right]+q(x)y=-\\lambda w(x)y, </math>|{{EquationRef|1}}}}\n\nwhere {{mvar|y}} is a function of the free variable {{mvar|x}}. Here the functions {{math|''p''(''x'')}}, {{math|''q''(''x'')}}, and {{math|''w''(''x'') > 0}} are specified at the outset. In the simplest of cases all coefficients are continuous on the finite closed interval {{math|[''a'',''b'']}}, and {{mvar|p}} has ''continuous derivative''. In this case, this function {{mvar|y}} is called a ''solution'' if it is continuously differentiable on {{math|(''a'',''b'')}} and satisfies the equation '''({{EquationNote|'''1'''}})''' at every point in {{math|(''a'',''b'')}}. In addition, the unknown function {{mvar|y}} is typically required to satisfy some [[boundary condition]]s at {{mvar|a}} and {{mvar|b}}.  The function {{math|''w''(''x'')}}, which is sometimes also called {{math|''r''(''x'')}}, is called the \"weight\" or \"density\" function.\n\nThe value of {{mvar|λ}} is not specified in the equation; finding the values of {{mvar|λ}} for which there exists a [[non-trivial]] solution of '''({{EquationNote|'''1'''}})''' satisfying the boundary conditions is part of the '''Sturm–Liouville (S–L) problem'''.\n\nSuch values of {{mvar|λ}}, when they exist, are called the [[eigenvalues]] of the boundary value problem defined by '''({{EquationNote|'''1'''}})''' and the prescribed set of boundary conditions. The corresponding solutions (for each such {{mvar|λ}}) are the [[eigenfunction]]s of this problem. Under normal assumptions on the coefficient functions {{math|''p''(''x'')}}, {{math|''q''(''x'')}}, and {{math|''w''(''x'')}} above, they induce a [[hermitian operator|Hermitian]] [[differential operator]] in some [[function space]] defined by [[boundary value problem|boundary conditions]]. The resulting theory of the existence and asymptotic behavior of the eigenvalues, the corresponding qualitative theory of the eigenfunctions and their [[Complete metric space|completeness]] in a suitable [[function space]] became known as '''Sturm–Liouville theory'''. This theory is important in applied mathematics, where S–L problems  occur very commonly, particularly when dealing with linear [[partial differential equation]]s that are [[separation of variables|separable]].\n\nA Sturm–Liouville (S–L) problem is said to be ''regular'' if {{math|''p''(''x'')}}, {{math|''w''(''x'') > 0}}, and {{math|''p''(''x'')}}, {{math|''p''′(''x'')}}, {{math|''q''(''x'')}}, and {{math|''w''(''x'')}} are continuous functions over the finite interval {{math|[''a'',''b'']}}, and has ''separated boundary conditions'' of the form\n\n{{NumBlk|:|<math> \\alpha_1 y(a)+\\alpha_2 y'(a)=0 \\qquad\\qquad\\alpha_1^2+\\alpha_2^2>0,</math>|{{EquationRef|2}}}}\n\n{{NumBlk|:|<math> \\beta_1y(b)+\\beta_2 y'(b)=0 \\qquad\\qquad\\beta_{1}^{2}+\\beta_2^2>0,</math>|{{EquationRef|3}}}}\n\nUnder the assumption that the S–L problem is regular, the main tenet of '''Sturm–Liouville theory''' states that:\n\n* The eigenvalues {{math|''λ''<sub>1</sub>, ''λ''<sub>2</sub>, ''λ''<sub>3</sub>, ...}} of the regular Sturm–Liouville problem '''({{EquationNote|'''1'''}})'''–'''({{EquationNote|'''2'''}})'''–'''({{EquationNote|'''3'''}})''' are real and can be ordered such that\n\n::<math>\\lambda_1 < \\lambda_2 < \\lambda_3 < \\cdots < \\lambda_n < \\cdots \\to \\infty;</math>\n\n* Corresponding to each eigenvalue {{math|''λ''<sub>''n''</sub>}} is a unique (up to a normalization constant) eigenfunction {{math|''y<sub>n</sub>''(''x'')}} which has exactly {{math|''n'' − 1}} zeros in {{math|(''a'',''b'')}}. The eigenfunction {{math|''y<sub>n</sub>''(''x'')}} is called the {{mvar|n}}th ''fundamental solution'' satisfying the regular Sturm–Liouville problem '''({{EquationNote|'''1'''}})'''–'''({{EquationNote|'''2'''}})'''–'''({{EquationNote|'''3'''}})'''.\n* The normalized eigenfunctions form an [[orthonormal basis]]\n\n::<math> \\int_a^b y_n(x)y_m(x)w(x)\\,\\mathrm{d}x = \\delta_{mn},</math>\n   \n:in the [[Hilbert space]] [[Lp space#Weighted Lp spaces|{{math|''L''<sup>2</sup>([''a'',''b''],&nbsp;''w''(''x'')&nbsp;d''x'')}}]]. Here {{math|''δ''<sub>''mn''</sub>}} is the [[Kronecker delta]].\n\nNote that unless {{math|''p''(''x'')}} is continuously differentiable, and {{math|''q''(''x'')}} and {{math|''w''(''x'')}} are continuous, the equation has to be understood in a [[weak solution|weak sense]].\n\n== Sturm–Liouville form ==\nThe differential equation '''({{EquationNote|'''1'''}})''' is said to be in '''Sturm–Liouville form''' or '''self-adjoint form'''. All second-order linear [[ordinary differential equation]]s can be recast in the form on the left-hand side of '''({{EquationNote|'''1'''}})''' by multiplying both sides of the equation by an appropriate [[integrating factor]] (although the same is not true of second-order [[partial differential equation]]s, or if {{mvar|y}} is a [[vector (mathematics)|vector]]).\n\n=== Examples ===\n\n====The [[Bessel equation]]====\n\n: <math>x^2y''+xy'+\\left(x^2-\\nu^2\\right)y=0</math>\n\nwhich can be written in Sturm–Liouville form (first by dividing through by x, then by collapsing the two terms on the left into one term) as\n\n: <math>\\left(xy'\\right)'+ \\left (x-\\frac{\\nu^2} x \\right )y=0.</math>\n\n====The [[Legendre polynomials|Legendre equation]]====\n\n: <math>\\left(1-x^2\\right)y''-2xy'+\\nu(\\nu+1)y=0</math>\n\nwhich can easily be put into Sturm–Liouville form, since {{math|{{sfrac|d|d''x''}}(1 − ''x''<sup>2</sup>) {{=}} −2''x''}}, so the Legendre equation is equivalent to\n\n: <math>\\left (\\left(1-x^2\\right)y' \\right )'+\\nu(\\nu+1)y=0</math>\n\n====An example using an integrating factor====\n\n: <math>x^3y''-xy'+2y=0.</math>\n\nDivide throughout by {{math|''x''<sup>3</sup>}}:\n\n: <math>y''-\\frac{1}{x^2}y'+\\frac{2}{x^3}y=0</math>\n\nMultiplying throughout by an [[integrating factor]] of\n\n: <math>\\mu(x) =\\exp\\left(\\int -\\frac{1}{x^2} \\,\\mathrm{d}x\\right)=e^{\\frac{1}{x}},</math>\n\ngives\n\n: <math>e^{\\frac{1}{x}}y''-\\frac{e^{\\frac{1}{x}}}{x^2} y'+ \\frac{2 e^{\\frac{1}{x}}}{x^3} y = 0</math>\n\nwhich can be easily put into Sturm–Liouville form since\n\n: <math>\\frac{\\mathrm{d}}{\\mathrm{d}x} e^{\\frac{1}{x}} = -\\frac{e^{\\frac{1}{x}}}{x^2} </math>\n\nso the differential equation is equivalent to\n\n: <math>\\left (e^{\\frac{1}{x}}y' \\right )'+\\frac{2 e^{\\frac{1}{x}}}{x^3} y =0.</math>\n\n====The integrating factor for a general second-order differential equation====\n\n: <math>P(x)y''+Q(x)y'+R(x)y=0</math>\n\nmultiplying through by the integrating factor\n\n: <math>\\mu(x) = \\frac 1 {P(x)} \\exp \\left(\\int \\frac{Q(x)}{P(x)} \\,\\mathrm{d}x\\right),</math>\n\nand then collecting gives the Sturm–Liouville form:\n\n: <math>\\frac{\\mathrm{d}}{\\mathrm{d}x} \\bigl(\\mu(x)P(x)y'\\bigr)+\\mu(x)R(x)y=0</math>\n\nor, explicitly,\n\n: <math>\\frac{\\mathrm{d}}{\\mathrm{d}x} \\left(\\exp\\left (\\int \\frac{Q(x)}{P(x)} \\,\\mathrm{d}x\\right)y' \\right )+\\frac{R(x)}{P(x)} \\exp \\left(\\int \\frac{Q(x)}{P(x)}\\,\\mathrm{d}x\\right) y = 0</math>\n\n== Sturm–Liouville equations as self-adjoint differential operators ==\nThe map\n\n: <math>Lu = -\\frac{1}{w(x)} \\left(\\frac{\\mathrm{d}}{\\mathrm{d}x}\\left[p(x)\\,\\frac{\\mathrm{d}u}{\\mathrm{d}x}\\right]+q(x)u \\right)</math>\n\ncan be viewed as a [[linear operator]] {{mvar|L}} mapping a function {{mvar|u}} to another function {{mvar|Lu}}. One may study this linear operator in the context of [[functional analysis]]. In fact, equation '''({{EquationNote|'''1'''}})''' can be written as\n\n: <math>Lu  = \\lambda u.</math>\n\nThis is precisely the [[eigenvalue]] problem; that is, one is trying to find the eigenvalues {{math|''λ''<sub>1</sub>, ''λ''<sub>2</sub>, ''λ''<sub>3</sub>,...}} and the corresponding eigenvectors {{math|''u''<sub>1</sub>, ''u''<sub>2</sub>, ''u''<sub>3</sub>,...}} of the {{mvar|L}} operator. The proper setting for this problem is the [[Hilbert space]] [[Lp space#Weighted Lp spaces|{{math|''L''<sup>2</sup>([''a'',''b''], ''w''(''x'') d''x'')}}]] with scalar product\n\n: <math> \\langle f, g\\rangle = \\int_a^b \\overline{f(x)} g(x)w(x)\\,\\mathrm{d}x.</math>\n\nIn this space {{mvar|L}} is defined on sufficiently smooth functions which satisfy the above [[boundary value problem|boundary condition]]s. Moreover, ''L'' gives rise to a [[self-adjoint]] operator:\n\n:<math> \\langle L f, g \\rangle = \\langle f, L g \\rangle .</math>\n\nThis can be seen formally by using [[integration by parts]] twice, where the boundary terms vanish by virtue of the boundary conditions. It then follows that the eigenvalues of a Sturm–Liouville operator are real and that eigenfunctions of {{mvar|L}} corresponding to different eigenvalues are orthogonal. However, this operator is [[Bounded operator|unbounded]] and hence existence of an orthonormal basis of eigenfunctions is not evident. To overcome this problem, one looks at the [[Resolvent formalism|resolvent]]\n\n:<math>\\left (L - z\\right)^{-1}, \\qquad z \\in\\mathbb{C},</math>\n\nwhere {{mvar|z}} is chosen to be some real number which is not an eigenvalue. Then, computing the resolvent amounts to solving the inhomogeneous equation, which can be done using the [[variation of parameters]] formula. This shows that the resolvent is an [[integral operator]] with a continuous symmetric kernel (the [[Green's function]] of the problem). As a consequence of the [[Arzelà–Ascoli theorem]], this integral operator is compact and existence of a sequence of eigenvalues {{mvar|α<sub>n</sub>}} which converge to 0 and eigenfunctions which form an orthonormal basis follows from the [[compact operator on Hilbert space|spectral theorem for compact operators]]. Finally, note that\n\n:<math>\\left(L-z\\right)^{-1} u = \\alpha u, \\qquad L u = \\left(z+\\alpha^{-1}\\right) u,</math>\n\nare equivalent.\n\nIf the interval is unbounded, or if the coefficients have singularities at the boundary points, one calls {{mvar|L}} singular. In this case, the spectrum no longer consists of eigenvalues alone and can contain a continuous component. There is still an associated eigenfunction expansion (similar to Fourier series versus Fourier transform). This is important in [[quantum mechanics]], since the one-dimensional time-independent [[Schrödinger equation]] is a special case of a S–L equation.\n\n==Second order differential equation with boundary conditions==\n\nThe operator {{mvar|L}} in the previous section can be written\n:<math>Lu = \\frac{p}{w(x)}u'' + \\frac{p'}{w(x)}u' + \\frac{q}{w(x)}u.</math>\nIf {{math|''Ay''″ + ''By''′ + ''Cy'' {{=}} ''f''&thinsp;(''x'')}} is an ordinary second order differential equation, and assuming for the sake of simplicity that {{math|''A''(''x'') ≠ 0}}, the first member can be transformed into a Sturm-Liouville operator {{mvar|L}} by solving the following system of equations:\n:<math>p = Aw,\\quad p' = Bw,\\quad q = Cw.</math>\nIt suffices to solve the first two equations, which in turn amounts to solve {{math|(''Aw'')′ {{=}} ''Bw''}}, or\n:<math> w' = \\frac{B-A'}{A}w:= \\alpha w.</math>\nA solution is \n:<math>w = \\exp\\left(\\int\\alpha \\,\\mathrm{d}x\\right), \\quad p = A \\exp\\left(\\int\\alpha \\,\\mathrm{d}x\\right), \\quad q = C \\exp\\left(\\int\\alpha \\,\\mathrm{d}x\\right).</math>\nThus, the first member of the proposed equation can be transformed in a Sturm-Liouville operator {{mvar|L}} as in the previous section,\nand the equation can now be written as\n:<math>Ly = f.</math>\n\nIn general, if initial conditions at some point are specified, for example {{math|''y''(''a'') {{=}} 0}} and {{math|''y''′(''a'') {{=}} 0}}, a second order differential equation can be solved using ordinary methods and the [[Picard-Lindelöf theorem]] ensures that the differential equation has a unique solution in a neighbourhood of the point where the initial conditions have been specified.\n\nBut if in place of specifying initial values at a ''single point'', it is desired to specify values at ''two'' different points (so-called boundary values), e.g. {{math|''y''(''a'') {{=}} 0}}  and {{math|''y''(''b'') {{=}} 1}}, the problem turns out to be much more difficult. Notice that by adding a suitable known differentiable function to {{mvar|y}}, whose values at {{mvar|a}} and {{mvar|b}} satisfy the desired boundary conditions, and injecting inside the proposed differential equation, it can be assumed without loss of generality that the boundary conditions are of the form {{math|''y''(''a'') {{=}} 0}} and {{math|''y''(''b'') {{=}} 0}}.\n\nFrom this point, the Sturm–Liouville theory comes in play; indeed, for a large class of functions {{mvar|f}}, {{mvar|f}} can be reconstructed from a set of orthonormal eigenfunction {{mvar|u<sub>i</sub>}} of the associated Liouville problem (it may be helpful to think about Fourier decomposition), with corresponding eigenvalue {{mvar|λ<sub>i</sub>}}:\n:<math>f(x) = \\sum_i \\alpha_i u_i(x), \\quad \\alpha_i \\in {\\mathbb R}.</math>\nThen a solution to the proposed equation is simply:\n:<math> y = \\sum_i \\frac{\\alpha_i}{\\lambda_i} u_i,</math>\nas can be checked immediately. Note, however, that the solution will be valid in the open interval {{math|(''a'',''b'') {{=}} {''x'' {{!}} ''a'' < ''x'' < ''b''<nowiki>}</nowiki>}} since it may fail in the boundaries. An example of this procedure is given in the next section.\n\n== Example ==\nWe wish to find a function {{math|''u''(''x'')}} which solves the following Sturm–Liouville problem:\n\n{{NumBlk|:|<math> L  u  = -\\frac{\\mathrm{d}^2u}{\\mathrm{d}x^2} = \\lambda u</math>|{{EquationRef|4}}}}\n\nwhere the unknowns are {{mvar|λ}} and {{math|''u''(''x'')}}. As above, we must add boundary conditions, we take for example\n\n:<math> u(0) = u(\\pi) = 0.</math>\n\nObserve that if {{mvar|k}} is any integer, then the function\n\n:<math> u(x) = \\sin kx</math>\n\nis a solution with eigenvalue {{math|''λ'' {{=}} ''k''<sup>2</sup>}}. We know that the solutions of a S–L problem form an [[orthogonal basis]], and we know from [[Fourier series]] that this set of sinusoidal functions is an orthogonal basis. Since orthogonal bases are always maximal (by definition) we conclude that the S–L problem in this case has no other eigenvectors.\n\nGiven the preceding, let us now solve the inhomogeneous problem\n\n:<math>L  u  =x, \\qquad x\\in(0,\\pi)</math>\n\nwith the same boundary conditions. In this case, we must write {{math|''f''&thinsp;(''x'') {{=}} ''x''}} in a Fourier series. The reader may check, either by integrating {{math|∫ ''e''<sup>''ikx''</sup>''x'' d''x''}} or by consulting a table of Fourier transforms, that we thus obtain\n\n:<math>L  u  =\\sum_{k=1}^\\infty -2\\frac{\\left(-1\\right)^k} k \\sin kx.</math>\n\nThis particular Fourier series is troublesome because of its poor convergence properties. It is not clear ''a priori'' whether the series converges pointwise. Because of Fourier analysis, since the Fourier coefficients are \"[[Lp space|square-summable]]\", the Fourier series converges in {{math|''L''<sup>2</sup>}} which is all we need for this particular theory to function. We mention for the interested reader that in this case we may rely on a result which says that Fourier series converge at every point of differentiability, and at jump points (the function ''x'', considered as a periodic function, has a jump at&nbsp;{{pi}}) converges to the average of the left and right limits (see [[convergence of Fourier series]]).\n\nTherefore, by using formula '''({{EquationNote|'''4'''}})''', we obtain that the solution is\n\n:<math>u=\\sum_{k=1}^{\\infty}2\\frac{\\left(-1\\right)^k}{k^3}\\sin kx.</math>\n\nIn this case, we could have found the answer using [[antidifferentiation]]. This technique yields\n\n:<math>u= \\tfrac 1 6 \\left(x^3 -\\pi^2 x\\right),</math>\n\nwhose Fourier series agrees with the solution we found. The antidifferentiation technique is no longer useful in most cases when the differential equation is in many variables.\n\n== Application to normal modes ==\nCertain [[partial differential equation]]s can be solved with the help of S–L theory. Suppose we are interested in the [[vibrational mode]]s of a thin membrane, held in a rectangular frame, {{math|0 ≤ ''x'' ≤ ''L''<sub>1</sub>}}, {{math|0 ≤ ''y'' ≤ ''L''<sub>2</sub>}}. The equation of motion for the vertical membrane's displacement, {{math|''W''(''x'',''y'',''t'')}} is given by the [[wave equation]]:\n\n:<math>\\frac{\\partial^2W}{\\partial x^2}+\\frac{\\partial^2W}{\\partial y^2} = \\frac 1 {c^2} \\frac{\\partial^2W}{\\partial t^2}.</math>\n\nThe method of  [[separation of variables]]  suggests looking first for solutions of the simple form {{math|''W'' {{=}} ''X''(''x'') × ''Y''(''y'') × ''T''(''t'')}}.  For such a function {{mvar|W}} the partial differential equation becomes {{math|{{sfrac|''X''″|''X''}} + {{sfrac|''Y''″|''Y''}} {{=}} {{sfrac|1|''c''<sup>2</sup>}} {{sfrac|''T''″|''T''}}}}.  Since the three terms of this equation are functions of {{math|''x'', ''y'', ''t''}} separately, they must be constants. For example, the first term gives {{math|''X''″ {{=}} ''λX''}} for a constant&nbsp;{{mvar|λ}}. The boundary conditions (\"held in a rectangular frame\") are {{math|''W'' {{=}} 0}} when {{math|''x'' {{=}} 0}}, {{math|''L''<sub>1</sub>}} or {{math|''y'' {{=}} 0}}, {{math|''L''<sub>2</sub>}} and define the simplest possible S–L eigenvalue problems as in the example, yielding the \"normal mode solutions\" for {{mvar|W}} with harmonic time dependence,\n\n:<math>W_{mn}(x,y,t) = A_{mn}\\sin\\left(\\frac{m\\pi x}{L_1}\\right)\\sin\\left(\\frac{n\\pi y}{L_2}\\right)\\cos\\left(\\omega_{mn}t\\right)</math>\n\nwhere {{mvar|m}} and {{mvar|n}} are non-zero [[integer]]s, {{mvar|A<sub>mn</sub>}} are arbitrary constants, and\n\n: <math>\\omega^2_{mn} = c^2 \\left(\\frac{m^2\\pi^2}{L_1^2}+\\frac{n^2\\pi^2}{L_2^2}\\right).</math>\n\nThe functions {{mvar|W<sub>mn</sub>}} form a basis for the [[Hilbert space]] of (generalized) solutions of the wave equation; that is, an arbitrary solution {{mvar|W}} can be decomposed into a sum of these modes, which vibrate at their individual frequencies {{mvar|ω<sub>mn</sub>}}. This representation may require a [[Convergent series|convergent]] infinite sum.\n\n==Representation of solutions and numerical calculation==\nThe Sturm–Liouville differential equation '''({{EquationNote|'''1'''}})''' with boundary conditions may be solved analytically, which can be exact or provide an approximation, by the [[Rayleigh–Ritz method]], or by the [[Matrix-Variational Method]] of Gerck et.al.<ref>Ed  Gerck,  A.  B.  d’Oliveira,  H.  F.  de  Carvalho.   Heavy baryons as bound states of three quarks. Lettere al Nuovo Cimento  38(1):27-32,  Sep  1983.</ref><ref>Augusto B. d’Oliveira, Ed Gerck, Jason A. C. Gallas. Solution    of    the    Schrödinger  equation   for   bound   states   in   closed   form. Physical Review  A,   26:1(1), June   1982.</ref><ref>Robert F. O’Connell, Jason A. C. Gallas, Ed Gerck. Scaling Laws  for  Rydberg  Atoms  in  Magnetic  Fields.   Physical Review  Letters  50(5):324-327,  Jan  1983.</ref>\n\nNumerically, a variety of methods are also available. In difficult cases, one may need to carry out the intermediate calculations to several hundred decimal places of accuracy in order to obtain the eigenvalues correctly to a few decimal places.\n\n# Shooting methods.<ref>{{cite book |first=J. D. |last=Pryce |title=Numerical Solution of Sturm–Liouville Problems |publisher=Clarendon Press |location=Oxford |year=1993 |isbn=0-19-853415-9 |url=https://books.google.com/books?id=bTDvAAAAMAAJ }}</ref><ref>{{cite journal |first=V. |last=Ledoux |first2=M. |last2=Van Daele |first3=G. Vanden |last3=Berghe |title=Efficient computation of high index Sturm–Liouville eigenvalues for problems in physics |journal=Comput. Phys. Commun. |volume=180 |year=2009 |pages=532–554 |doi=10.1016/j.cpc.2008.10.001 |arxiv=0804.2605 |bibcode=2009CoPhC.180..241L }}</ref>  These methods proceed by guessing a value of {{mvar|λ}}, solving an initial value problem defined by the boundary conditions at one endpoint, say, {{mvar|a}},  of the interval {{math|[''a'',''b'']}}, comparing the value this solution takes at the other endpoint {{mvar|b}} with the other desired boundary condition, and finally increasing or decreasing {{mvar|λ}} as necessary to correct the original value. This strategy is not applicable for locating complex eigenvalues.{{clarify|date=June 2017|reason=The operator is self-adjoint by design; all its eigenvalues are real. So what is the point of this remark? Is this about the improper use of 'eigenvalue' as frequency, or more generally 'that constant in the argument that is different from eigenfunction to eigenfunction'?}}\n# [[Finite difference method]].\n#  The spectral parameter power series (SPPS) method<ref name=\"KP\">{{cite journal |first=V. V. |last=Kravchenko |first2=R. M. |last2=Porter |title=Spectral parameter power series for Sturm–Liouville problems |journal=Mathematical Methods in the Applied Sciences |volume=33 |issue=4 |year=2010 |pages=459–468 |doi=10.1002/mma.1205 |arxiv=0811.4488 }}</ref> makes use of a generalization of the following fact about second-order ordinary differential equations:  if {{mvar|y}} is a solution which does not vanish at any point of {{math|[''a'',''b'']}}, then the function\n\n::<math> y(x) \\int_a^x \\frac{\\mathrm{d}t}{p(t)y(t)^2} </math>\n\n:is a solution of the same equation and is linearly independent from {{mvar|y}}.  Further, all solutions are linear combinations of these two solutions.  In the SPPS algorithm, one must begin with an arbitrary value {{math|''λ''{{su|b=0|p=∗}}}} (often {{math|''λ''{{su|b=0|p=∗}} {{=}} 0}}; it does not need to be an eigenvalue) and any solution {{math|''y''<sub>0</sub>}} of '''({{EquationNote|'''1'''}})''' with {{math|''λ'' {{=}} ''λ''{{su|b=0|p=∗}}}} which does not vanish on {{math|[''a'',''b'']}}. (Discussion [[#Construction of a nonvanishing solution|below]] of ways to find appropriate {{math|''y''<sub>0</sub>}} and {{math|''λ''{{su|b=0|p=∗}}}}.) Two sequences of functions {{math|''X''{{isup|(''n'')}}(''t'')}}, {{math|''X̃''{{isup|(''n'')}}(''t'')}} on {{math|[''a'',''b'']}}, referred to as ''iterated integrals'', are defined recursively as follows. First when {{math|''n'' {{=}} 0}}, they are taken to be identically equal to 1 on {{math|[''a'',''b'']}}.  To obtain the next functions they are multiplied alternately by {{math|{{sfrac|1|''py''{{su|b=0|p=2}}}}}} and {{math|''wy''{{su|b=0|p=2}}}} and integrated, specifically\n\n{{NumBlk|::| <math> X^{(n)}(t) = \\begin{cases} \\displaystyle - \\int_a^x  X^{(n-1)}(t) p(t)^{-1}  y_0(t)^{-2}\\,\\mathrm{d}t & n \\text{ odd}, \\\\[6pt]\n\\displaystyle \\quad \\int_a^x  X^{(n-1)}(t)y_0(t)^2 w(t) \\,\\mathrm{d}t & n \\text{ even} \\end{cases}</math> |{{EquationRef|5}}}}\n\n{{NumBlk|::| <math> \\tilde X^{(n)}(t) = \\begin{cases} \\displaystyle \\quad \\int_a^x \\tilde X^{(n-1)}(t)y_0(t)^2 w(t)\\,\\mathrm{d}t & n \\text{ odd}, \\\\[6pt]\n\\displaystyle -\\int_a^x \\tilde X^{(n-1)}(t) p(t)^{-1}  y_0(t)^{-2} \\,\\mathrm{d}t & n \\text{ even}\\end{cases}</math>  |{{EquationRef|6}}}}\n\n:when {{math|''n''&nbsp;>&nbsp;0}}.  The resulting iterated integrals are now applied as coefficients in the following two power series in&nbsp;''λ'':\n\n::<math> u_0 = y_0 \\sum_{k=0}^\\infty \\left (\\lambda-\\lambda_0^* \\right )^k \\tilde X^{(2k)},</math>\n::<math> u_1 = y_0 \\sum_{k=0}^\\infty \\left (\\lambda-\\lambda_0^* \\right )^k X^{(2k+1)}.</math>\n \n:Then for any {{mvar|λ}} (real or complex), {{math|''u''<sub>0</sub>}} and {{math|''u''<sub>1</sub>}}  are linearly independent solutions of the corresponding equation '''({{EquationNote|'''1'''}})'''. (The functions {{math|''p''(''x'')}} and {{math|''q''(''x'')}} take part in this construction through their influence on the choice of {{math|''y''<sub>0</sub>}}.)\n\n:Next one chooses coefficients {{math|''c''<sub>0</sub>}} and {{math|''c''<sub>1</sub>}} so that the combination {{math|''y'' {{=}} ''c''<sub>0</sub>''u''<sub>0</sub> + ''c''<sub>1</sub>''u''<sub>1</sub>}} satisfies the first boundary condition '''({{EquationNote|'''2'''}})'''. This is simple to do since {{math|''X''{{isup|(''n'')}}(''a'') {{=}} 0}} and {{math|''X̃''{{isup|(''n'')}}(''a'') {{=}} 0}}, for {{math|''n'' > 0}}.  The values of {{math|''X''{{isup|(''n'')}}(''b'')}} and {{math|''X̃''{{isup|(''n'')}}(''b'')}} provide the values of {{math|''u''<sub>0</sub>(''b'')}} and {{math|''u''<sub>1</sub>(''b'')}} and the derivatives {{math|''u''′<sub>0</sub>(''b'')}} and {{math|''u''′<sub>0</sub>(''b'')}}, so the second boundary condition '''({{EquationNote|'''3'''}})''' becomes an equation in a power series in&nbsp;{{mvar|λ}}.  For numerical work one may truncate this series to a finite number of terms, producing a calculable polynomial in {{mvar|λ}} whose roots are approximations of the sought-after eigenvalues.\n\n:When {{math|''λ'' {{=}} ''λ''<sub>0</sub>}}, this reduces to the original construction described above for a  solution linearly independent to a given one. The representations '''('''{{EquationNote|5}}''')''' and '''('''{{EquationNote|6}}''')''' also have theoretical applications in Sturm–Liouville theory.<ref name=\"KP\"/>\n\n===Construction of a nonvanishing solution===\nThe SPPS method can, itself, be used to find a starting solution {{math|''y''<sub>0</sub>}}. Consider the equation {{math|(''py''′)′ {{=}} ''μqy''}}; i.e., {{mvar|q}}, {{mvar|w}}, and {{mvar|λ}} are replaced in '''({{EquationNote|'''1'''}})''' by 0, {{math|−''q''}}, and {{mvar|μ}} respectively. Then the constant function 1 is a nonvanishing solution corresponding to the eigenvalue {{math|''μ''<sub>0</sub> {{=}} 0}}.  While there is no guarantee that {{math|''u''<sub>0</sub>}} or {{math|''u''<sub>1</sub>}} will not vanish, the complex function {{math|''y''<sub>0</sub> {{=}} ''u''<sub>0</sub> + ''iu''<sub>1</sub>}} will never vanish because two linearly-independent solutions of a regular S–L equation cannot vanish simultaneously as a consequence of the [[Sturm separation theorem]]. This trick gives a solution {{math|''y''<sub>0</sub>}} of '''({{EquationNote|'''1'''}})''' for the value {{math|''λ''<sub>0</sub> {{=}} 0}}.  In practice if '''({{EquationNote|'''1'''}})''' has real coefficients, the solutions based on {{math|''y''<sub>0</sub>}} will have very small imaginary parts which must be discarded.\n\n==Application to [[partial differential equation]]s==\nFor a linear second-order in one spatial dimension and first-order in time of the form:\n\n: <math> f(x) \\frac{\\partial^2 u}{\\partial x^2} + g(x) \\frac{\\partial u}{\\partial x} + h(x) u= \\frac{\\partial u}{\\partial t} + k(t) u</math>\n\n: <math> u(a,t)=u(b,t)=0 </math>\n\n: <math>u(x,0)=s(x) </math>\n\nLet us apply separation of variables, which in doing we must impose that:\n\n: <math>u(x,t) =X(x) T(t) </math>\n\nThen our above partial differential equation may be written as:\n\n: <math>\\frac{\\hat{L} X(x)}{X(x)} = \\frac{\\hat{M} T(t)}{T(t)}</math>\n\nwhere\n\n:<math> \\hat{L}=f(x) \\frac{\\mathrm{d}^2}{\\mathrm{d} x^2}+g(x) \\frac{\\mathrm{d}}{\\mathrm{d}x}+h(x), \\qquad \\hat{M}=\\frac{\\mathrm{d}}{\\mathrm{d}t} +k(t)</math>\n\nSince, by definition, {{mvar|L̂}} and {{math|''X''(''x'')}} are independent of time {{mvar|t}} and {{mvar|M̂}} and {{math|''T''(''t'')}} are independent of position {{mvar|x}}, then both sides of the above equation must be equal to a constant:\n\n: <math> \\hat{L} X(x) =\\lambda X(x)</math>\n\n: <math> X(a)=X(b)=0 \\, </math>\n\n: <math> \\hat{M} T(t) =\\lambda T(t) \\, </math>\n\nThe first of these equations must be solved as a Sturm–Liouville problem.  Since there is no general analytic (exact) solution to Sturm–Liouville problems, we can assume we already have the solution to this problem, that is, we have the eigenfunctions {{math|''X<sub>n</sub>''(''x'')}} and eigenvalues {{math|''λ<sub>n</sub>''}}. The second of these equations can be analytically solved once the eigenvalues are known.\n\n: <math> \\frac{\\mathrm{d}}{\\mathrm{d}t} T_n (t)= \\bigl(\\lambda_n -k(t)\\bigr) T_n (t) </math>\n\n: <math> T_n (t) = a_n \\exp \\left(\\lambda_n t -\\int_0^t k(\\tau) \\,\\mathrm{d}\\tau\\right) </math>\n\n: <math> u(x,t) =\\sum_n a_n X_n (x) \\exp \\left(\\lambda_n t -\\int_0^t k(\\tau) \\,\\mathrm{d}\\tau\\right) </math>\n\n: <math> a_n =\\frac{\\bigl\\langle X_n (x), s(x)\\bigr\\rangle}{\\bigl\\langle X_n(x),X_n (x)\\bigr\\rangle}</math>\n\nwhere\n\n: <math> \\bigl\\langle y(x),z(x)\\bigr\\rangle = \\int_a^b y(x) z(x) w(x) \\,\\mathrm{d}x, </math>\n\n: <math> w(x)= \\frac{\\exp \\left(\\int \\frac{g(x)}{f(x)} \\,\\mathrm{d}x\\right)}{f(x)}. </math>\n\n==See also==\n* [[Normal mode]]\n* [[Oscillation theory]]\n* [[Self-adjoint]]\n* [[Variation of parameters]]\n* [[Spectral theory of ordinary differential equations]]\n* [[Atkinson–Mingarelli theorem]]\n\n== References ==\n{{Reflist}}\n\n== Further reading ==\n* {{springer|title=Sturm–Liouville theory|id=p/s130620}}\n* {{cite book| last = Hartman| given = Philip| title = Ordinary Differential Equations| edition = 2 | publisher=[[Society for Industrial and Applied Mathematics|SIAM]]| place = Philadelphia| year = 2002| isbn= 978-0-89871-510-1}}\n*  {{cite book|author1=Polyanin, A. D.  |author2=Zaitsev, V. F. |lastauthoramp=yes | title = Handbook of Exact Solutions for Ordinary Differential Equations | edition= 2 | publisher=Chapman & Hall/CRC Press | place = Boca Raton | year = 2003| isbn= 1-58488-297-2}}\n* {{cite book| last = Teschl| given = Gerald|authorlink=Gerald Teschl| title = Ordinary Differential Equations and Dynamical Systems| publisher=[[American Mathematical Society]]| place = [[Providence, Rhode Island|Providence]]| year = 2012| isbn= 978-0-8218-8328-0| url = http://www.mat.univie.ac.at/~gerald/ftp/book-ode/}} (Chapter 5)\n* {{cite book| last = Teschl| given = Gerald|authorlink=Gerald Teschl| title=Mathematical Methods in Quantum Mechanics; With Applications to Schrödinger Operators| publisher=[[American Mathematical Society]]| place = [[Providence, Rhode Island|Providence]]| year=2009 |url=http://www.mat.univie.ac.at/~gerald/ftp/book-schroe/ |isbn=978-0-8218-4660-5 }} (see Chapter 9 for singular S–L operators and connections with quantum mechanics)\n* {{cite book| last = Zettl| given = Anton| title = Sturm–Liouville Theory| publisher=[[American Mathematical Society]]| place = [[Providence, Rhode Island|Providence]]| year = 2005| isbn= 0-8218-3905-5}}\n* {{cite book| last = Birkhoff| given = Garrett| title = A source book in classical analysis| publisher=[[Harvard University Press]]| place = [[Cambridge, Massachusetts]]| year = 1973| isbn= 0-674-82245-5}} (See Chapter 8, part B, for excerpts from the works of Sturm and Liouville and commentary on them.)\n\n{{DEFAULTSORT:Sturm-Liouville theory}}\n[[Category:Ordinary differential equations]]\n[[Category:Operator theory]]\n[[Category:Spectral theory]]"
    },
    {
      "title": "Superstrong approximation",
      "url": "https://en.wikipedia.org/wiki/Superstrong_approximation",
      "text": "'''Superstrong approximation''' is a generalisation of [[strong approximation in algebraic groups]] ''G'', to provide \"spectral gap\" results. The spectrum in question is that of the [[Laplacian matrix]] associated to a family of quotients of a discrete group Γ; and the gap is that between the first and second eigenvalues (normalisation so that the first eigenvalue corresponds to constant functions as eigenvectors). Here Γ is a subgroup of the rational points of ''G'', but need not be a [[lattice (discrete subgroup)|lattice]]: it may be a so-called [[thin group (algebraic group theory)|thin group]]. The \"gap\" in question is a lower bound (absolute constant) for the difference of those eigenvalues.\n\nA consequence and equivalent of this property, potentially holding for [[Zariski dense]] subgroups Γ of the [[special linear group]] over the integers, and in more general classes of algebraic groups ''G'', is that the sequence of [[Cayley graph]]s for reductions Γ<sub>''p''</sub> modulo prime numbers ''p'', with respect to any fixed set ''S'' in Γ that is a [[symmetric set]] and [[generating set]], is an [[expander family]].<ref>{{harv|Breuillard|Oh|2014|loc=pages x, 343}}</ref>\n\nIn this context \"strong approximation\" is the statement that ''S'' when reduced generates the full group of points of ''G'' over the prime fields with ''p'' elements, when ''p'' is large enough. It is equivalent to the Cayley graphs being connected (when ''p'' is large enough), or that the locally constant functions on these graphs are constant, so that the eigenspace for the first eigenvalue is one-dimensional. Superstrong approximation therefore is a concrete quantitative improvement on these statements.\n\n==Background==\n'''Property (τ)''' is an analogue in discrete group theory of [[Kazhdan's property (T)]], and was introduced by [[Alexander Lubotzky]].<ref>http://www.ams.org/notices/200506/what-is.pdf</ref> For a given family of normal subgroups ''N'' of finite index in Γ, one equivalent formulation is that the Cayley graphs of the groups Γ/''N'', all with respect to a fixed symmetric set of generators ''S'', form an expander family.<ref name=\"Lubotzky1994\">{{cite book|author=[[Alexander Lubotzky]]|title=Discrete Groups, Expanding Graphs and Invariant Measures|url=https://books.google.com/books?id=aNURlzNuotEC&pg=PA49|date=1 January 1994|publisher=Springer|isbn=978-3-7643-5075-8|page=49}}</ref> Therefore superstrong approximation is a formulation of property (τ), where the subgroups ''N'' are the kernels of reduction modulo large enough primes ''p''.\n\nThe '''Lubotzky–Weiss conjecture''' states (for special linear groups and reduction modulo primes) that an expansion result of this kind holds independent of the choice of ''S''. For applications, it is also relevant to have results where the modulus is not restricted to being a prime.<ref>{{harv|Breuillard|Oh|2014|loc=pages 3-4}}</ref>\n\n==Proofs of superstrong approximation==\nResults on superstrong approximation have been found using techniques on [[approximate subgroup]]s, and [[growth rate (group theory)|growth rate]] in finite simple groups.<ref>{{harv|Breuillard|Oh|2014|loc=page xi}}</ref>\n\n==Notes==\n{{reflist}}\n\n==References==\n\n*{{citation|editor2-first=Hee|editor2-last= Oh|editor1-first=Emmanuel |editor1-last=Breuillard|title=Thin Groups and Superstrong Approximation|year= 2014|publisher=Cambridge University Press|isbn=978-1-107-03685-7|url=http://library.msri.org/books/Book61/index.html}}\n*{{citation|MR=0735226 \n|last1=Matthews|first1= C. R.|last2= Vaserstein|first2= L. N.|last3= Weisfeiler|first3= B.\n|title=Congruence properties of Zariski-dense subgroups. I. \n|journal=Proc. London Math. Soc. |series=Series 3|volume= 48 |year=1984|issue= 3|pages= 514–532|doi=10.1112/plms/s3-48.3.514}}\n\n[[Category:Algebraic groups]]\n[[Category:Cayley graphs]]\n[[Category:Spectral theory]]"
    },
    {
      "title": "Transfer operator",
      "url": "https://en.wikipedia.org/wiki/Transfer_operator",
      "text": ": ''The transfer operator is different from the [[Transfer (group theory)|transfer homomorphism]].''\n\nIn [[mathematics]], the '''transfer operator''' encodes information about an [[iterated map]] and is frequently used to study the behavior of [[dynamical systems]], [[statistical mechanics]], [[quantum chaos]] and [[fractals]].   In all usual cases, the largest eigenvalue is 1, and the corresponding eigenvector is the [[invariant measure]] of the system.\n\n==Definition==\nThe iterated function to be studied is a map <math>f\\colon X\\rightarrow X</math> for an arbitrary set <math>X</math>. \n\nThe transfer operator is defined as an operator <math>\\mathcal{L}</math> acting on the space of functions <math>\\{\\Phi\\colon X\\rightarrow \\mathbb{C}\\}</math> as\n\n:<math>(\\mathcal{L}\\Phi)(x) = \\sum_{y\\in f^{-1}(x)} g(y) \\Phi(y)</math>\n\nwhere <math>g\\colon X\\rightarrow\\mathbb{C}</math> is an auxiliary valuation function. When <math>f</math> has a [[Jacobian matrix and determinant|Jacobian]] determinant <math>|J|</math>, then <math>g</math> is usually taken to be <math>g=1/|J|</math>.\n\nThe above definition of the transfer operator can be shown to be the point-set limit of the measure-theoretic [[Pushforward measure|pushforward]] of ''g'': in essence, the transfer operator is the [[direct image functor]] in the category of [[measurable space]]s.  The left-adjoint of the Frobenius&ndash;Perron operator is the [[Koopman operator]] or [[composition operator]]. The general setting is provided by the [[Borel functional calculus]].\n\nAs a general rule, the transfer operator can usually be interpreted as a (left-)[[shift operator]] acting on a [[shift space]]. The most commonly studied shifts are the [[subshifts of finite type]]. The adjoint to the transfer operator can likewise usually be interpreted as a right-shift. Particularly well studied right-shifts include the [[Jacobi operator]] and the [[Hessenberg matrix]], both of which generate systems of [[orthogonal polynomials]] via a right-shift.\n\n==Name ==\nThe transfer operator is sometimes called:\n* the '''Ruelle operator''', after [[David Ruelle]]\n* the '''Ruelle&ndash;Perron&ndash;Frobenius operator''' in reference to the applicability of the [[Frobenius&ndash;Perron theorem]] to the determination of the [[eigenvalue]]s of the operator\n==Applications==\nWhereas the iteration of a function <math>f</math> naturally leads to a study of the orbits of points of X under iteration (the study of [[Chaos theory|point dynamics]]), the transfer operator defines how (smooth) maps evolve under iteration.  Thus, transfer operators typically appear in  [[physics]] problems, such as [[quantum chaos]] and [[statistical mechanics]], where attention is focused on the time evolution of smooth functions. In turn, this has medical applications to [[rational drug design]], through the field of [[molecular dynamics]].\n\nIt is often the case that the transfer operator is positive, has discrete positive real-valued [[eigenvalue]]s, with the largest eigenvalue being equal to one.  For this reason, the transfer operator is sometimes called the  Frobenius&ndash;Perron operator.\n\nThe [[eigenfunction]]s of the transfer operator are usually fractals. When the logarithm of the transfer operator corresponds to a quantum [[Hamiltonian (quantum theory)|Hamiltonian]], the eigenvalues will typically be very closely spaced, and thus even a very narrow and carefully selected [[quantum ensemble|ensemble]] of quantum states will encompass a large number of very different fractal eigenstates with non-zero [[support (mathematics)|support]] over the entire volume.  This can be used to explain many results from classical statistical mechanics, including the irreversibility of time and the increase of [[entropy]].\n\nThe transfer operator of the [[Bernoulli map]] <math>b(x)=2x-\\lfloor 2x\\rfloor</math> is exactly solvable and is a classic example of [[chaos theory|deterministic chaos]]; the discrete eigenvalues correspond to the [[Bernoulli polynomials]].  This operator also has a continuous spectrum consisting of the [[Hurwitz zeta function]].\n\nThe transfer operator of the Gauss map <math>h(x)=1/x-\\lfloor 1/x \\rfloor</math> is called the [[Gauss&ndash;Kuzmin&ndash;Wirsing operator|Gauss&ndash;Kuzmin&ndash;Wirsing (GKW) operator]] and due to its extraordinary difficulty, has not been fully solved. The theory of the GKW dates back to a hypothesis by Gauss on [[continued fraction]]s and is closely related to the [[Riemann zeta function]].\n\n==See also==\n* [[Bernoulli scheme]]\n* [[Shift of finite type]]\n* [[Krein–Rutman theorem]]\n\n==References==\n* {{cite book | author=Pierre Gaspard | title=Chaos, scattering and statistical mechanics | publisher=[[Cambridge University Press]] | year=1998 }}\n* {{cite book | author=David Ruelle | title=Thermodynamic formalism: the mathematical structures of classical equilibrium statistical mechanics | publisher=Addison&ndash;Wesley, Reading | year=1978 | isbn=0-201-13504-3}}\n* {{cite book | author=Dieter H. Mayer | title=The Ruelle-Araki transfer operator in classical statistical mechanics | publisher=Springer-Verlag | year=1978 | isbn=0-387-09990-5}}\n* David Ruelle, ''[http://www.ihes.fr/~ruelle/PUBLICATIONS/137zeta.pdf Dynamical Zeta Functions and Transfer Operators]'', (2002) Institut des Hautes Etudes Scientifiques preprint IHES/M/02/66. ''(Provides an introductory survey).''\n* Michael C. Mackey, ''Time's Arrow, The origins of thermodynamic behaviour'', Springer-Verlag, 1992\n\n[[Category:Chaos theory]]\n[[Category:Dynamical systems]]\n[[Category:Operator theory]]\n[[Category:Spectral theory]]"
    },
    {
      "title": "Weyl law",
      "url": "https://en.wikipedia.org/wiki/Weyl_law",
      "text": "In [[mathematics]], especially [[spectral theory]], '''Weyl's law''' describes the asymptotic behavior of eigenvalues of the [[Laplace–Beltrami operator]]. This description was discovered in 1911 by [[Hermann Weyl]] for eigenvalues for the Laplace–Beltrami operator acting on functions that vanish at the boundary of a bounded domain <math> \\Omega \\subset \\mathbb{R}^d</math>. In particular, he proved that the number, <math> N(\\lambda)</math>, of [[Dirichlet eigenvalue]]s (counting their multiplicities) less than or equal to <math>\\lambda</math> satisfies\n:<math>\n\\lim_{\\lambda \\rightarrow \\infty} \\frac{N(\\lambda)}{\\lambda^{d/2}} = (2\\pi)^{-d} \\omega_d \\mathrm{vol}(\\Omega)\n</math>\nwhere  <math>\\omega_d</math> is a [[Volume of an n-ball|volume of the unit ball]] in <math>\\mathbb{R}^d</math>.<ref>{{cite journal |last=Weyl |first=Hermann |url=http://gdz.sub.uni-goettingen.de/dms/load/img/?IDDOC=63048 |title=Über die asymptotische Verteilung der Eigenwerte |journal=Nachrichten der Königlichen Gesellschaft der Wissenschaften zu Göttingen |pages=110–117 |year=1911 }}</ref> In 1912 he provided a new proof based on [[variational methods]].<ref>{{cite journal |title=Das asymptotische Verteilungsgesetz linearen partiellen Differentialgleichungen |journal=[[Mathematische Annalen|Math. Ann.]] |volume=71 |issue= |pages=441–479 |year=1912 }}</ref><ref>For a proof in English, see {{cite book |title=Partial Differential Equations |first=Walter A. |last=Strauss |publisher=John Wiley & Sons |year=2008 |isbn= }} See chapter 11.</ref>\n\n==Generalizations==\nThe Weyl law has been extended to more general domains and operators.  For the Schrödinger operator\n:<math>\nH=-h^2 \\Delta + V(x)\n</math>\nit was extended to\n:<math>\nN(E,h)\\sim (2\\pi h)^{-d}  \\int _{\\{ |\\xi|^2 + V(x)<E \\}} dx d\\xi\n</math>\nas <math>E </math> tending to <math>+\\infty</math> or to a bottom of essential spectrum and/or <math>h\\to +0</math>.\n\nHere <math>N(E,h)</math> is the number of eigenvalues of <math>H</math> below <math>E</math> unless there is essential spectrum below <math>E</math> in which case <math>N(E,h)=+\\infty</math>.\n\nIn the development of [[spectral asymptotics]], the crucial role was played by [[variational methods]] and [[microlocal analysis]].\n\n==Counter-examples==\nThe extended Weyl law fails in certain situations. In particular, the extended Weyl law \"claims\" that there is no [[essential spectrum]]  if and only if  the right-hand expression is finite for all <math>E</math>.\n\nIf one considers domains with cusps (i.e. \"shrinking exits to infinity\") then the (extended) Weyl law claims that there is no essential spectrum if and only if the volume is finite. However for the Dirichlet Laplacian there is no essential spectrum even if the volume is infinite as long as cusps shrinks at infinity (so the finiteness of the volume is not necessary).\n\nOn the other hand, for the Neumann Laplacian there is an essential spectrum unless cusps shrinks at infinity faster than the negative exponent (so the finiteness of the volume is not sufficient).\n\n==Weyl conjecture==\nWeyl conjectured that\n:<math>\nN(\\lambda)= (2\\pi)^{-d}\\lambda ^{d/2} \\omega_d \\mathrm{vol} (\\Omega)\\mp \\frac{1}{4} (2\\pi)^{1-d}\\lambda ^{(d-1)/2}\\mathrm{area} (\\partial \\Omega) +o (\\lambda ^{(d-1)/2})\n</math>\n\nwhere the remainder term is negative for Dirichlet boundary conditions and positive for Neumann.\nThe remainder estimate was improved upon by many mathematicians.\n\nIn 1922, [[Richard Courant]] proved a bound of <math>O(\\lambda^{(d-1)/2}\\log \\lambda)</math>.\nIn 1952, [[Boris Levitan]] proved the tighter bound of <math>O(\\lambda^{(d-1)/2})</math> for compact closed manifolds.  [[Robert Thomas Seeley|Robert Seeley]] extended this to include certain Euclidean domains in 1978.<ref>A sharp asymptotic estimate for the eigenvalues of the Laplacian in a domain of <math>\\mathbf{R}^3</math>. Advances in Mathematics, 102(3):244–264 (1978).</ref>\nIn 1975, [[Hans Duistermaat]] and [[Victor Guillemin]] proved the bound of\n<math>o(\\lambda ^{(d-1)/2})</math> when the set of periodic bicharacteristics has measure 0.<ref>The spectrum of positive elliptic operators and periodic bicharacteristics. Invent. Math. , 29(1):37–79 (1975).</ref>  This was finally generalized by [[Victor Ivrii]] in 1980.<ref>Second term of the spectral asymptotic expansion for the Laplace–Beltrami operator on manifold with boundary. Funct. Anal. Appl. 14(2):98–106 (1980).</ref>  This generalization assumes that the set of periodic trajectories of a billiard in <math>\\Omega</math> has measure 0, which Ivrii conjectured is fulfilled for all bounded Euclidean domains with smooth boundaries.  Since then, similar results have been obtained for wider classes of operators.\n\n==References==\n{{Reflist}}\n\n{{DEFAULTSORT:Weyl law}}\n[[Category:Partial differential equations]]\n[[Category:Spectral theory]]"
    },
    {
      "title": "Associative bialgebroid",
      "url": "https://en.wikipedia.org/wiki/Associative_bialgebroid",
      "text": "{{no footnotes|date=September 2017}}\n\nIn [[mathematics]], an '''associative ''L''-bialgebroid''' where ''L'' is an [[associative algebra]] over some [[ground field]] ''k'' is another associative ''k''-algebra ''H'' together with a number of additional structure maps involving ''H'', ''L'' and various [[tensor product]]s of those. Associative bialgebroids are a generalization of a ''k''-[[bialgebra]] where a ground [[Ring (mathematics)|ring]] ''k'' is replaced by a possibly noncommutative ''k''-algebra ''L''. [[Hopf algebroid]]s are associative bialgebroids with an additional antipode map which is an antiautomorphism of ''H'' satisfying additional axioms. \n\nThe term bialgebroid for this notion has been first proposed by J-H. Lu. The modifier associative is often dropped from the name, and retained mainly only when we wants to distinguish it from the notion of a [[Lie bialgebroid]], often also referred just as a bialgebroid. Associative bialgebroids come in two chiral versions, left and right. A dual notion is the notion of a cobialgebroid. \n\nThere is a generalization, an [[internal bialgebroid]] which abstracts the structure of an associative bialgebroid to the setup where the category of vector spaces is replaced by an abstract symmetric monoidal category admitting coequalizers commuting with the tensor product. \n\n==References==\n<references />\n* T. Brzeziński, G. Militaru, \"Bialgebroids\", <math>\\times_A</math>-bialgebras and duality_,  J. Algebra 251: 279-294, 2002 https://arxiv.org/abs/math.QA/0012164\n* Gabriella Böhm, \"Hopf algebroids\", (a chapter of) Handbook of algebra, Vol. 6, ed. by M. Hazewinkel, Elsevier 2009, 173–236, https://arxiv.org/abs/0805.3806\n* Jiang-Hua Lu, \"Hopf algebroids and quantum groupoids\", Int. J. Math. 7, n. 1 (1996) pp. 47-70, https://arxiv.org/abs/q-alg/9505024, http://www.ams.org/mathscinet-getitem?mr=95e:16037, https://dx.doi.org/10.1142/S0129167X96000050\n\n[[Category:Bialgebras]]"
    },
    {
      "title": "Bialgebra",
      "url": "https://en.wikipedia.org/wiki/Bialgebra",
      "text": "{{Refimprove|date=December 2009}}\n\nIn [[mathematics]], a '''bialgebra''' over a [[Field (mathematics)|field]] ''K'' is a [[vector space]] over ''K'' which is both a [[unital algebra|unital]] [[associative algebra]] and a [[coalgebra|counital coassociative coalgebra]]. The algebraic and coalgebraic structures are made compatible with a few more axioms. Specifically, the [[comultiplication]] and the [[counit]] are both unital algebra [[homomorphisms]], or equivalently, the multiplication and the unit of the algebra both are [[Coalgebra#Further concepts and facts|coalgebra morphisms]]. (These statements are equivalent since they are expressed by the same [[commutative diagram]]s.)\n\nSimilar bialgebras are related by bialgebra homomorphisms. A bialgebra homomorphism is a [[linear map]] that is both an algebra and a coalgebra homomorphism.\n\nAs reflected in the symmetry of the commutative diagrams, the definition of bialgebra is [[Dual (category theory)|self-dual]], so if one can define a [[Dual space|dual]] of ''B'' (which is always possible if ''B'' is finite-dimensional), then it is automatically a bialgebra.\n\n{{Algebraic structures |Algebra}}\n\n== Formal definition ==\n\n'''(''B'', ∇, η, Δ, ε)''' is a '''bialgebra''' over ''K'' if it has the following properties: \n* ''B'' is a vector space over ''K'';\n* there are ''K''-[[linear map]]s (multiplication) ∇: ''B'' ⊗ ''B'' → ''B'' (equivalent to ''K''-[[multilinear map]] ∇: ''B'' × ''B'' → ''B'') and (unit) η: ''K'' → ''B'', such that (''B'', ∇, η) is a unital associative [[Algebra over a field|algebra]];\n* there are ''K''-linear maps (comultiplication) Δ: ''B'' → ''B'' ⊗ ''B'' and (counit) ε: ''B'' → ''K'', such that (''B'', Δ, ε) is a (counital coassociative) [[coalgebra]];\n* compatibility conditions expressed by the following [[commutative diagram]]s:\n\n# Multiplication ∇ and comultiplication Δ<ref>{{cite book|author=Dăscălescu, Năstăsescu & Raianu|year=2001|title=Hopf Algebras: An introduction|url={{Google books|plainurl=y|id=pBJ6sbPHA0IC|page=147|text=is a morphism of coalgebras}}|pages=147 & 148}}</ref> \n#::[[File:Bialgebra2.svg|500px|Bialgebra commutative diagrams]]\n#: where τ: ''B'' ⊗ ''B'' → ''B'' ⊗ ''B'' is the [[linear map]] defined by τ(''x'' ⊗ ''y'') = ''y'' ⊗ ''x'' for all ''x'' and ''y'' in ''B'',\n# Multiplication ∇ and counit ε\n#::[[File:Bialgebra3.svg|310px|Bialgebra commutative diagrams]]\n# Comultiplication Δ and unit η<ref>{{cite book|author=Dăscălescu, Năstăsescu & Raianu |title=Hopf Algebras: An introduction|year=2001|url={{Google books|plainurl=y|id=pBJ6sbPHA0IC|page=148|text=is a morphism of coalgebras}}|page=148}}</ref> \n#::[[File:Bialgebra4a.svg|310px|Bialgebra commutative diagrams]]\n# Unit η and counit ε\n#::[[File:Bialgebra1.svg|125px|Bialgebra commutative diagrams]]\n\n==Coassociativity and counit==\nThe [[multilinear map|''K''-linear map]] Δ: ''B'' → ''B'' ⊗ ''B'' is [[coalgebra|coassociative]] if <math>(\\mathrm{id}_B \\otimes \\Delta) \\circ \\Delta = (\\Delta \\otimes \\mathrm{id}_B) \\circ \\Delta</math>.\n\nThe ''K''-linear map ε: ''B'' → ''K'' is a counit if <math>(\\mathrm{id}_B \\otimes \\epsilon) \\circ \\Delta = \\mathrm{id}_B = (\\epsilon \\otimes \\mathrm{id}_B) \\circ \\Delta</math>.\n\nCoassociativity and counit are expressed by the [[commutative diagram|commutativity]] of the following two diagrams (they are the duals of the diagrams expressing associativity and unit of an algebra):\n\n[[File:Bialgebra Diagram.svg|center|800px]]\n\n== Compatibility conditions ==\nThe four commutative diagrams can be read either as \"comultiplication and counit are [[homomorphism]]s of algebras\" or,  equivalently, \"multiplication and unit are [[homomorphism]]s of coalgebras\".\n\nThese statements are meaningful once we explain the natural structures of algebra and coalgebra in all the vector spaces involved besides ''B'': (''K'', ∇<sub>0</sub>, η<sub>0</sub>) is a unital associative algebra in an obvious way and (''B'' ⊗ ''B'', ∇<sub>2</sub>, η<sub>2</sub>) is a unital associative algebra with unit and  multiplication\n\n:<math>\\eta_2 := (\\eta \\otimes \\eta) : K \\otimes K \\equiv K \\to (B \\otimes B) </math>\n:<math>\\nabla_2 := (\\nabla \\otimes \\nabla) \\circ (id \\otimes \\tau \\otimes id) : (B \\otimes B) \\otimes (B \\otimes B) \\to (B \\otimes B) </math>,\n\nso that <math>\\nabla_2 ( (x_1 \\otimes x_2) \\otimes (y_1 \\otimes y_2) ) = \\nabla(x_1 \\otimes y_1) \\otimes \\nabla(x_2 \\otimes y_2) </math> or, omitting ∇ and writing [[multiplication as juxtaposition]], <math>(x_1 \\otimes x_2)(y_1 \\otimes y_2) = x_1 y_1 \\otimes x_2 y_2 </math>;\n\nsimilarly, (''K'', Δ<sub>0</sub>, ε<sub>0</sub>) is a coalgebra in an obvious way and ''B'' ⊗ ''B'' is a coalgebra with counit and comultiplication\n\n:<math>\\epsilon_2 := (\\epsilon \\otimes \\epsilon) : (B \\otimes B) \\to K \\otimes K \\equiv K</math>\n:<math>\\Delta_2 :=  (id \\otimes \\tau \\otimes id) \\circ (\\Delta \\otimes \\Delta)  : (B \\otimes B) \\to (B \\otimes B) \\otimes (B \\otimes B)</math>.\n\nThen, diagrams 1 and 3 say that Δ: ''B'' → ''B'' ⊗ ''B'' is a homomorphism of unital (associative) algebras  (''B'', ∇, η) and (''B'' ⊗ ''B'', ∇<sub>2</sub>, η<sub>2</sub>)\n\n:<math>\\Delta \\circ \\nabla = \\nabla_2 \\circ (\\Delta \\otimes \\Delta) : (B \\otimes B) \\to (B \\otimes B)</math>, or simply Δ(''xy'') = Δ(''x'') Δ(''y''),\n:<math>\\Delta \\circ \\eta = \\eta_2 : K \\to (B \\otimes B)</math>, or simply  Δ(1<sub>''B''</sub>) = 1<sub>''B'' ⊗ ''B''</sub>;\n\ndiagrams 2 and 4 say that ε: ''B'' → ''K'' is a homomorphism of unital (associative) algebras  (''B'', ∇, η) and (''K'', ∇<sub>0</sub>, η<sub>0</sub>):\n\n:<math>\\epsilon \\circ \\nabla = \\nabla_0 \\circ (\\epsilon \\otimes \\epsilon) : (B \\otimes B) \\to K</math>, or simply ε(''xy'') = ε(''x'') ε(''y'')\n:<math>\\epsilon \\circ \\eta = \\eta_0 : K \\to K</math>, or simply  ε(1<sub>''B''</sub>) = 1<sub>''K''</sub>.\n\nEquivalently, diagrams 1 and 2 say that ∇: ''B'' ⊗ ''B'' → ''B'' is a homomorphism of (counital coassociative) coalgebras (''B'' ⊗ ''B'', Δ<sub>2</sub>, ε<sub>2</sub>) and (''B'', Δ, ε):\n\n:<math> \\nabla \\otimes \\nabla \\circ \\Delta_2 = \\Delta \\circ \\nabla : (B \\otimes B) \\to (B \\otimes B),</math>\n:<math> \\nabla_0 \\circ \\epsilon_2 = \\epsilon \\circ \\nabla : (B \\otimes B) \\to K</math>;\n\ndiagrams 3 and 4 say that η: ''K'' → ''B'' is a homomorphism of (counital coassociative) coalgebras (''K'', Δ<sub>0</sub>, ε<sub>0</sub>) and (''B'', Δ, ε):\n\n:<math>\\eta_2 \\circ \\Delta_0 = \\Delta \\circ \\eta : K \\to (B \\otimes B),</math>\n:<math>\\eta_0 \\circ \\epsilon_0 = \\epsilon \\circ \\eta : K \\to K</math>.\n\n==Examples==\n===Group bialgebra===\nAn example of a bialgebra is the set of functions from a [[group (mathematics)|group]] ''G'' (or more generally, any [[monoid]]) to <math>\\mathbb R</math>, which we may represent as a vector space <math>\\mathbb R^G</math> consisting of linear combinations of standard basis vectors '''e'''<sub>''g''</sub> for each ''g''&nbsp;&isin;&nbsp;''G'', which may represent a [[probability distribution]] over ''G'' in the case of vectors whose coefficients are all non-negative and sum to 1. An example of suitable comultiplication operators and counits which yield a counital coalgebra are\n:<math>\\Delta(\\mathbf e_g) = \\mathbf e_g \\otimes \\mathbf e_g \\,,</math>\nwhich represents making a copy of a [[random variable]] (which we extend to all <math>\\mathbb R^G</math> by linearity), and\n:<math>\\varepsilon(\\mathbf e_g) = 1 \\,,</math>\n(again extended linearly to all of <math> \\mathbb R^G</math>) which represents \"tracing out\" a random variable &mdash; ''i.e.,''&nbsp;forgetting the value of a random variable (represented by a single tensor factor) to obtain a [[marginal distribution]] on the remaining variables (the remaining tensor factors). \nGiven the interpretation of (Δ,ε) in terms of probability distributions as above, the bialgebra consistency conditions amount to constraints on (∇,η) as follows:\n\n# η is an operator preparing a normalized probability distribution which is independent of all other random variables;\n# The product ∇ maps a probability distribution on two variables to a probability distribution on one variable;\n# Copying a random variable in the distribution given by η is equivalent to having two independent random variables in the distribution η;\n# Taking the product of two random variables, and preparing a copy of the resulting random variable, has the same distribution as preparing copies of each random variable independently of one another, and multiplying them together in pairs.\n\nA pair (∇,η) which satisfy these constraints are the [[convolution]] operator\n:<math>\\nabla\\bigl(\\mathbf e_g \\otimes \\mathbf e_h\\bigr) = \\mathbf e_{gh} \\,,</math>\nagain extended to all <math>\\mathbb R^G \\otimes \\mathbb R^G</math> by linearity; this produces a normalized probability distribution from a distribution on two random variables, and has as a unit the delta-distribution <math> \\eta = \\mathbf e_{i} \\;,</math> where ''i''&nbsp;&isin;&nbsp;''G'' denotes the identity element of the group ''G''.\n\n=== Other examples ===\nOther examples of bialgebras include the [[tensor algebra]], which can be made into a bialgebra by adding the appropriate comultiplication and counit; these are worked out in detail in that article.\n\nBialgebras can often be extended to [[Hopf algebra]]s, if an appropriate antipode can be found. Thus, all Hopf algebras are examples of bialgebras.<ref>{{cite book|author=Dăscălescu, Năstăsescu & Raianu |title=Hopf Algebras: An introduction|year=2001|url={{Google books|plainurl=y|id=pBJ6sbPHA0IC|page=151|text=Hopf}}|page=151}}</ref>  Similar structures with different compatibility between the product and comultiplication, or different types of multiplication and comultiplication, include [[Lie bialgebra]]s and [[Frobenius algebra]]s.  Additional examples are given in the article on [[coalgebra]]s.\n\n==See also==\n*[[Quasi-bialgebra]]\n*[[Frobenius algebra]]\n*[[Hopf algebra]]\n\n== Notes ==\n<references/>\n\n== References ==\n* {{Citation| last1=Dăscălescu| first1=Sorin| last2=Năstăsescu| first2=Constantin| last3=Raianu| first3=Șerban| year=2001| title=Hopf Algebras: An introduction| edition=1st| volume = 235| series=Pure and Applied Mathematics | publisher=Marcel Dekker| isbn = 0-8247-0481-9}}.\n\n[[Category:Bialgebras]]\n[[Category:Coalgebras]]\n[[Category:Monoidal categories]]"
    },
    {
      "title": "Internal bialgebroid",
      "url": "https://en.wikipedia.org/wiki/Internal_bialgebroid",
      "text": "In [[mathematics]], an '''internal bialgebroid''' is a structure which abstracts the [[associative bialgebroid]] to the setup where the category of [[vector spaces]] is replaced by an abstract [[symmetric monoidal category]] admitting [[coequalizer]]s commuting with the monoidal product.\n\n==See also==\n*[[Bialgebra]]\n\n==External links==\n* Gabriella Böhm, Internal bialgebroids, entwining structures and corings,  in: Algebraic structures and their representations, 207–226, Contemp. Math. 376, Amer. Math. Soc. 2005. [https://arxiv.org/abs/math/0311244 Cornell University Library, retrieved 11 September, 2017]\n\n[[Category:Bialgebras]]\n{{context|date=September 2017}}"
    },
    {
      "title": "Hopf algebra",
      "url": "https://en.wikipedia.org/wiki/Hopf_algebra",
      "text": "{{Use American English|date=January 2019}}{{Short description|Construction in algebra\n}}\nIn [[mathematics]], a '''Hopf algebra''', named after [[Heinz Hopf]], is a structure that is simultaneously an ([[unital algebra|unital]] associative) [[Associative algebra|algebra]] and a (counital coassociative) [[coalgebra]], with these structures' compatibility making it a [[bialgebra]], and that moreover is equipped with an [[antiautomorphism]] satisfying a certain property. The [[representation theory]] of a Hopf algebra is particularly nice, since the existence of compatible comultiplication, counit, and antipode allows for the construction of tensor products of representations, trivial representations, and dual representations.\n\nHopf algebras occur naturally in [[algebraic topology]], where they originated and are related to the [[H-space]] concept, in [[group scheme]] theory, in [[group theory]] (via the concept of a [[group ring]]), and in numerous other places, making them probably the most familiar type of [[bialgebra]]. Hopf algebras are also studied in their own right, with much work on specific classes of examples on the one hand and classification problems on the other. They have diverse applications ranging from [[Condensed-matter physics]] and [[quantum field theory]]<ref>{{cite journal | last1 = Haldane | first1 = F. D. M. | last2 = Ha | first2 = Z. N. C. | last3 = Talstra | first3 = J. C. | last4 = Bernard | first4 = D. | last5 = Pasquier | first5 = V. | year = 1992 | title = Yangian symmetry of integrable quantum chains with long-range interactions and a new description of states in conformal field theory | url = | journal = Physical Review Letters | volume = 69 | issue = 14| pages = 2021–2025 | doi=10.1103/physrevlett.69.2021 | pmid=10046379| bibcode = 1992PhRvL..69.2021H }}</ref> to [[string theory]]<ref>{{cite journal | last1 = Plefka | first1 = J. | last2 = Spill | first2 = F. | last3 = Torrielli | first3 = A. | year = 2006 | title = Hopf algebra structure of the AdS/CFT S-matrix | url = | journal = Physical Review D | volume = 74 | issue = 6| page = 066008 | doi = 10.1103/PhysRevD.74.066008 | arxiv = hep-th/0608038 | bibcode = 2006PhRvD..74f6008P }}</ref> and [[Large Hadron Collider|LHC phenomenology]]<ref>{{Cite journal|last=Abreu|first=Samuel|last2=Britto|first2=Ruth|last3=Duhr|first3=Claude|last4=Gardi|first4=Einan|date=2017-12-01|title=Diagrammatic Hopf algebra of cut Feynman integrals: the one-loop case|journal=Journal of High Energy Physics|language=en|volume=2017|issue=12|pages=90|doi=10.1007/jhep12(2017)090|issn=1029-8479|arxiv=1704.07931|bibcode=2017JHEP...12..090A}}</ref> .\n\n'''Theorem (Hopf)'''<ref name=\"Hopf, 1941\">{{cite journal|last1=Hopf|first1=Heinz|title=Über die Topologie der Gruppen–Mannigfaltigkeiten und ihre Verallgemeinerungen|journal=Ann. of Math. |series= 2|date=1941|volume=42|issue=1|pages=22–52|doi=10.2307/1968985|language=German|jstor=1968985}}<!--|accessdate=7 March 2016--></ref> Let ''A'' be a finite-dimensional, [[Graded-commutative|graded commutative]], graded cocommutative Hopf algebra over a field of characteristic 0. Then ''A'' (as an algebra) is a free exterior algebra with generators of odd degree.\n\n==Formal definition==\nFormally, a Hopf algebra is a (associative and coassociative) [[bialgebra]] ''H'' over a [[field (mathematics)|field]] ''K'' together with a [[linear transformation|''K''-linear]] map ''S'': ''H'' → ''H'' (called the '''antipode''') such that the following diagram [[commutative diagram|commutes]]:\n<div style=\"text-align: center;\">\n[[File:Hopf algebra.svg|250px|antipode commutative diagram]]\n</div>\nHere Δ is the comultiplication of the bialgebra, ∇ its multiplication, η its unit and ε its counit. In the sumless [[Sweedler notation]], this property can also be expressed as\n:<math>S(c_{(1)})c_{(2)}=c_{(1)}S(c_{(2)})=\\varepsilon(c)1\\qquad\\mbox{ for all }c\\in H.</math>\n\nAs for [[associative algebra|algebra]]s, one can replace the underlying field ''K'' with a [[commutative ring]] ''R'' in the above definition.<ref name=Und55>Underwood (2011) p.55</ref>\n\nThe definition of Hopf algebra is [[Dual (category theory)|self-dual]] (as reflected in the symmetry of the above diagram), so if one can define a [[Dual space|dual]] of ''H'' (which is always possible if ''H'' is finite-dimensional), then it is automatically a Hopf algebra.<ref name=Und62>Underwood (2011) p.62</ref>\n\n=== Structure constants ===\nFixing a basis <math>\\{e_k\\}</math> for the underlying vector space, one may define the algebra in terms of [[structure constant]]s for multiplication:\n:<math>e_i\\nabla e_j = \\sum_k \\mu^k_{\\;ij} e_k</math>\nfor co-multiplication:\n:<math>\\Delta e_i = \\sum_{j,k} \\nu^{\\;jk}_i e_j\\otimes e_k</math>\nand the antipode:\n:<math>S e_i = \\sum_j \\tau_i^{\\;j} e_j</math>\nAssociativity then requires that\n:<math>\\mu^k_{\\;ij}\\mu^m_{\\;kn}=\\mu^k_{\\;jn}\\mu^m_{\\;ik}</math>\nwhile co-associativity requires that\n:<math>\\nu_k^{\\;ij}\\nu_i^{\\;mn}=\\nu_k^{\\;mi}\\nu_i^{\\;nj}</math>\nThe connecting axiom requires that\n:<math>\\nu_k^{\\;ij}\\tau_j^{\\;m}\\mu^n_{\\;pm}=\\nu_k^{\\;jm}\\tau_j^{\\,\\;i}\\mu^n_{\\;pm}</math>\n\n===Properties of the antipode===\nThe antipode ''S'' is sometimes required to have a ''K''-linear inverse, which is automatic in the finite-dimensional case{{clarify|date=May 2018|reason=Either provide a reference or briefly sketch an explanation}}, or if ''H'' is [[commutative]] or [[cocommutative]] (or more generally [[Quasitriangular Hopf algebra|quasitriangular]]).\n\nIn general, ''S'' is an [[antihomomorphism]],<ref>{{cite book|author=Dăscălescu, Năstăsescu & Raianu |title=Prop. 4.2.6|booktitle=Hopf Algebra: An Introduction |year=2001|url={{Google books|plainurl=y|id=pBJ6sbPHA0IC|page=153|text=is an antimorphism of algebras}}|page=153}}</ref> so ''S''<sup>2</sup> is a [[homomorphism]], which is therefore an automorphism if ''S'' was invertible (as may be required).\n\nIf ''S''<sup>2</sup> = id<sub>''H''</sub>, then the Hopf algebra is said to be '''involutive''' (and the underlying algebra with involution is a [[*-algebra]]). If ''H'' is finite-dimensional semisimple over a field of characteristic zero, commutative, or cocommutative, then it is involutive.\n\nIf a bialgebra ''B'' admits an antipode ''S'', then ''S'' is unique (\"a bialgebra admits at most 1 Hopf algebra structure\").<ref>{{cite book|author=Dăscălescu, Năstăsescu & Raianu |title=Remarks 4.2.3|booktitle=Hopf Algebra: An Introduction |year=2001|url={{Google books|plainurl=y|id=pBJ6sbPHA0IC|page=151|text=the antipode is unique}}|page=151}}</ref> Thus, the antipode does not pose any extra structure which we can choose: Being a Hopf algebra is a property of a bialgebra.\n\nThe antipode is an analog to the inversion map on a group that sends ''g'' to ''g''<sup>−1</sup>.<ref>[http://www.mathematik.uni-muenchen.de/~pareigis/Vorlesungen/98SS/Quantum_Groups/LN2_1.PDF Quantum groups lecture notes]</ref>\n\n===Hopf subalgebras===\nA subalgebra ''A'' of a Hopf algebra ''H'' is a Hopf subalgebra if it is a subcoalgebra of ''H'' and the antipode ''S'' maps ''A'' into ''A''. In other words, a Hopf subalgebra A is a Hopf algebra in its own right when the multiplication, comultiplication, counit and antipode of ''H'' is restricted to ''A'' (and additionally the identity 1 of ''H'' is  required to be in A). The Nichols–Zoeller freeness theorem  established (in 1989) that the natural ''A''-module ''H'' is free of finite rank if ''H'' is finite-dimensional: a generalization of [[Lagrange's theorem (group theory)|Lagrange's theorem for subgroups]]. As a corollary of this and integral theory, a Hopf subalgebra of a semisimple finite-dimensional Hopf algebra is automatically semisimple.\n\nA Hopf subalgebra ''A'' is said to be right normal in a Hopf algebra ''H'' if it satisfies the condition of stability, ''ad<sub>r</sub>''(''h'')(''A'') ⊆ ''A'' for all ''h'' in ''H'', where the right adjoint mapping ''ad<sub>r</sub>'' is defined by ''ad<sub>r</sub>''(''h'')(''a'') = ''S''(''h''<sub>(1)</sub>)''ah''<sub>(2)</sub> for all ''a'' in ''A'', ''h'' in ''H''. Similarly, a Hopf subalgebra ''A'' is left normal in ''H'' if it is stable under the left adjoint mapping defined by ''ad<sub>l</sub>''(''h'')(''a'') = ''h''<sub>(1)</sub>''aS''(''h''<sub>(2)</sub>). The two conditions of normality are equivalent if the antipode ''S'' is bijective, in which case ''A'' is said to be a normal Hopf subalgebra.\n\nA normal Hopf subalgebra ''A'' in ''H'' satisfies the condition (of equality of subsets of H): ''HA''<sup>+</sup> = ''A''<sup>+</sup>''H'' where ''A''<sup>+</sup> denotes the kernel of the counit on ''K''. This normality condition implies that ''HA''<sup>+</sup> is a Hopf ideal of ''H'' (i.e. an algebra ideal in the kernel of the counit, a coalgebra coideal and stable under the antipode). As a consequence one has a quotient Hopf algebra ''H''/''HA''<sup>+</sup> and epimorphism ''H'' → ''H''/''A''<sup>+</sup>''H'', a theory analogous to that of normal subgroups and quotient groups in [[group theory]].<ref>Montgomery (1993) p.36</ref>\n\n===Hopf orders===\nA '''Hopf order''' ''O'' over an [[integral domain]] ''R'' with [[field of fractions]] ''K'' is an [[Order (ring theory)|order]] in a Hopf algebra ''H'' over ''K'' which is closed under the algebra and coalgebra operations: in particular, the comultiplication Δ maps ''O'' to ''O''⊗''O''.<ref name=Und82>Underwood (2011) p.82</ref>\n\n===Group-like elements===\nA '''group-like element''' is a nonzero element ''x'' such that Δ(''x'') = ''x''⊗''x''. The group-like elements form a group with inverse given by the antipode.<ref>{{cite book | page=149 | title=Algebras, Rings, and Modules: Lie Algebras and Hopf Algebras | volume=168 | series=Mathematical surveys and monographs | first1=Michiel | last1=Hazewinkel | first2=Nadezhda Mikhaĭlovna | last2=Gubareni | first3=Vladimir V. | last3=Kirichenko | publisher=[[American Mathematical Society]] | year=2010 | isbn=978-0-8218-7549-0 }}</ref> A '''[[primitive element (co-algebra)|primitive element]]''' ''x'' satisfies Δ(''x'') = ''x''⊗1 + 1⊗''x''.<ref>{{cite book | at=p. 307, C.42  | title=The Concise Handbook of Algebra | editor1-first=Aleksandr Vasilʹevich | editor1-last=Mikhalev | editor2-first=Günter | editor2-last=Pilz | publisher=[[Springer-Verlag]] | year=2002 | isbn=978-0792370727 }}</ref><ref>{{cite book | title=Hopf Algebras | volume=74 | series=Cambridge Tracts in Mathematics | first=Eiichi | last=Abe | publisher=[[Cambridge University Press]] | year=2004 | isbn=978-0-521-60489-5 | page=59 }}</ref>\n\n==Representation theory==\nLet ''A'' be a Hopf algebra, and let ''M'' and ''N'' be ''A''-modules. Then, ''M'' ⊗ ''N'' is also an ''A''-module, with\n:<math>a(m\\otimes n):=\\Delta(a)(m \\otimes n)=(a_1\\otimes a_2)(m\\otimes n)=(a_1 m \\otimes a_2 n)</math>\nfor ''m'' ∈ ''M'', ''n'' ∈ ''N'' and Δ(''a'') = (''a''<sub>1</sub>, ''a''<sub>2</sub>). Furthermore, we can define the trivial representation as the base field ''K'' with\n:<math>a(m):=\\epsilon(a)m</math>\nfor ''m'' ∈ ''K''. Finally, the dual representation of ''A'' can be defined: if ''M'' is an ''A''-module and ''M*'' is its dual space, then\n:<math>(af)(m):=f(S(a)m)</math>\nwhere ''f'' ∈ ''M*'' and ''m'' ∈ ''M''.\n\nThe relationship between Δ, ε, and ''S'' ensure that certain natural homomorphisms of vector spaces are indeed homomorphisms of ''A''-modules. For instance, the natural isomorphisms of vector spaces ''M'' → ''M'' ⊗ ''K'' and ''M'' → ''K'' ⊗ ''M'' are also isomorphisms of ''A''-modules. Also, the map of vector spaces ''M*'' ⊗ ''M'' → ''K'' with ''f'' ⊗ ''m'' → ''f''(''m'') is also a homomorphism of ''A''-modules. However, the map ''M'' ⊗ ''M*'' → ''K'' is not necessarily a homomorphism of ''A''-modules.\n\n== Examples ==\n{| class=\"wikitable\"\n|-\n!  !! Depending on !! Comultiplication !! Counit !! Antipode !! Commutative !! Cocommutative !! Remarks\n|-\n| [[group ring|group algebra]] ''KG'' || [[group (mathematics)|group]] ''G'' || Δ(''g'') = ''g'' ⊗ ''g'' for all ''g'' in ''G'' || ''ε''(''g'') = 1 for all ''g'' in ''G'' || ''S''(''g'') = ''g''<sup>−1</sup> for all ''g'' in ''G'' || if and only if ''G'' is abelian || yes ||\n|-\n| functions ''f'' from a finite<ref>The finiteness of ''G'' implies that ''K<sup>G</sup>'' ⊗ ''K<sup>G</sup>'' is naturally isomorphic to ''K''<sup>''G''x''G''</sup>. This is used in the above formula for the comultiplication. For infinite groups ''G'', ''K<sup>G</sup>'' ⊗ ''K<sup>G</sup>'' is a proper subset of ''K''<sup>''G''x''G''</sup>. In this case the space of functions with finite [[support (mathematics)|support]] can be endowed with a Hopf algebra structure.</ref> group to ''K'', ''K<sup>G</sup>'' (with pointwise addition and multiplication) || finite group ''G'' || Δ(''f'')(''x'',''y'') = ''f''(''xy'') || ''ε''(''f'') = ''f''(1<sub>''G''</sub>)|| ''S''(''f'')(''x'') = ''f''(''x''<sup>−1</sup>)  || yes || if and only if ''G'' is commutative ||\n|- \n|[[Representative function]]s on a compact group||[[compact group]] ''G'' || Δ(''f'')(''x'',''y'') = ''f''(''xy'') || ''ε''(''f'') = ''f''(1<sub>''G''</sub>)|| ''S''(''f'')(''x'') = ''f''(''x''<sup>−1</sup>)  || yes || if and only if ''G'' is commutative || Conversely, every commutative involutive [[reduced algebra|reduced]] Hopf algebra over '''C''' with a finite Haar integral arises in this way, giving one formulation of [[Tannaka–Krein duality]].<ref>{{citation|last=Hochschild|first=G|title=Structure of Lie groups|year=1965|pages=14–32|publisher=Holden-Day}}</ref>\n|-\n| [[Regular function]]s on an [[algebraic group]] || || Δ(''f'')(''x'',''y'') = ''f''(''xy'') || ''ε''(''f'') = ''f''(1<sub>''G''</sub>)|| ''S''(''f'')(''x'') = ''f''(''x''<sup>−1</sup>)  || yes || if and only if ''G'' is commutative || Conversely, every commutative Hopf algebra over a field arises from a [[group scheme]] in this way, giving an [[equivalence (category theory)|antiequivalence]] of categories.<ref>{{Citation | last1=Jantzen | first1=Jens Carsten | author1-link=Jens Carsten Jantzen | title=Representations of algebraic groups | publisher=[[American Mathematical Society]] | location=Providence, R.I. | edition=2nd | series=Mathematical Surveys and Monographs | isbn=978-0-8218-3527-2 | year=2003 | volume=107}}, section 2.3</ref>\n|-\n| [[Tensor algebra]] T(''V'') || [[vector space]] ''V'' || Δ(''x'') = ''x'' ⊗ 1 + 1 ⊗ ''x'', ''x'' in ''V'',  Δ(1) = 1 ⊗ 1 || ''ε''(''x'') = 0  || ''S''(''x'') = −''x'' for all ''x'' in 'T<sup>1</sup>(''V'') (and extended to higher tensor powers) || If and only if dim(''V'')=0,1 || yes || [[symmetric algebra]] and [[exterior algebra]] (which are quotients of the tensor algebra) are also Hopf algebras with this definition of the comultiplication, counit and antipode\n|-\n| [[Universal enveloping algebra]] U(g) || [[Lie algebra]] ''g'' || Δ(''x'') = ''x'' ⊗ 1 + 1 ⊗ ''x'' for every ''x'' in ''g'' (this rule is compatible with [[commutator]]s and can therefore be uniquely extended to all of ''U'') || ''ε''(''x'') = 0 for all ''x'' in ''g'' (again, extended to ''U'') || ''S''(''x'') = −''x''  || if and only if ''g'' is abelian || yes ||\n|-\n| [[Sweedler's Hopf algebra]] ''H''=''K''[''c'', ''x'']/''c<sup>2</sup>'' = 1, ''x''<sup>2</sup> = 0 and ''xc'' = −''cx''.|| ''K'' is a field with [[Field characteristic|characteristic]] different from 2 || Δ(''c'') = ''c'' ⊗ ''c'',  Δ(''x'') = ''c'' ⊗ ''x'' + ''x'' ⊗ 1, Δ(1) = 1 ⊗ 1 || ''ε''(''c'') = 1 and ''ε''(''x'') = 0 || ''S''(''c'') = ''c''<sup>−1</sup> = ''c'' and ''S''(''x'') = −''cx'' || no || no || The underlying [[vector space]] is generated by {1, ''c'', ''x'', ''cx''} and thus has dimension 4. This is the smallest example of a Hopf algebra that is both non-commutative and non-cocommutative.\n|-\n| [[ring of symmetric functions]]<ref>See\n    Michiel Hazewinkel, ''Symmetric Functions, Noncommutative Symmetric Functions, and Quasisymmetric Functions'', Acta Applicandae Mathematica, January 2003, Volume 75, Issue 1-3, pp 55–83</ref> ||   \n|| in terms of complete homogeneous symmetric functions ''h''<sub>''k''</sub> (''k'' &ge; 1):\n\nΔ(''h<sub>k</sub>'') = 1 ⊗ ''h<sub>k</sub>'' + ''h''<sub>1</sub> ⊗ ''h''<sub>''k''−1</sub> + ... +  ''h''<sub>''k''−1</sub> ⊗ ''h''<sub>1</sub> + ''h<sub>k</sub>'' ⊗ 1.\n|| ''ε''(''h<sub>k</sub>'') = 0\n||  ''S''(''h<sub>k</sub>'') = (−1)<sup>''k''</sup> ''e<sub>k</sub>''\n|| yes || yes ||\n|}\n\nNote that functions on a finite group can be identified with the group ring, though these are more naturally thought of as dual – the group ring consists of ''finite'' sums of elements, and thus pairs with functions on the group by evaluating the function on the summed elements.\n\n== Cohomology of Lie groups ==\nThe cohomology algebra (over a field <math>K</math>) of a Lie group <math>G</math> is a Hopf algebra: the multiplication is provided by the [[cup product]], and the comultiplication \n:<math>H^*(G,K) \\rightarrow H^*(G\\times G,K) \\cong H^*(G,K)\\otimes H^*(G,K)</math>\nby the group multiplication <math>G\\times G\\to G</math>. This observation was actually a source of the notion of Hopf algebra. Using this structure, Hopf proved a structure theorem for the cohomology algebra of Lie groups.\n\n'''Theorem (Hopf)'''<ref name=\"Hopf, 1941\"/> Let <math>A</math> be a finite-dimensional, [[Graded-commutative|graded commutative]], graded cocommutative Hopf algebra over a field of characteristic 0. Then <math>A</math> (as an algebra) is a free exterior algebra with generators of odd degree.\n\n==Quantum groups and non-commutative geometry==\n{{Main|quantum group}}\n\nAll examples above are either commutative (i.e. the multiplication is [[commutative]]) or co-commutative (i.e.<ref name=Und57>Underwood (2011) p.57</ref> Δ = ''T'' ∘ Δ where the ''twist map''<ref name=Und36>Underwood (2011) p.36</ref> ''T'': ''H'' ⊗ ''H'' → ''H'' ⊗ ''H'' is defined by ''T''(''x'' ⊗ ''y'') = ''y'' ⊗ ''x''). Other interesting Hopf algebras are certain \"deformations\" or \"[[quantization (physics)|quantization]]s\" of those from example 3 which are neither commutative nor co-commutative. These Hopf algebras are often called ''[[quantum groups]]'', a term that is so far only loosely defined. They are important in [[noncommutative geometry]], the idea being the following: a standard algebraic group is well described by its standard Hopf algebra of regular functions; we can then think of the deformed version of this Hopf algebra as describing a certain \"non-standard\" or \"quantized\" algebraic group (which is not an algebraic group at all). While there does not seem to be a direct way to define or manipulate these non-standard objects, one can still work with their Hopf algebras, and indeed one ''identifies'' them with their Hopf algebras. Hence the name \"quantum group\".\n\n== Related concepts ==\n[[Graded algebra|Graded]] Hopf algebras are often used in [[algebraic topology]]: they are the natural algebraic structure on the direct sum of all [[homology (mathematics)|homology]] or [[cohomology]] groups of an [[H-space]].\n\n[[Locally compact quantum group]]s generalize Hopf algebras and carry a [[topological space|topology]]. The algebra of all [[continuous function]]s on a [[Lie group]] is a locally compact quantum group.\n\n[[Quasi-Hopf algebra]]s are generalizations of Hopf algebras, where coassociativity only holds up to a twist. They have been used in the study of the [[Knizhnik–Zamolodchikov equations]].<ref name=Mon203>Montgomery (1993) p.&nbsp;203</ref>\n\n[[Multiplier Hopf algebra]]s introduced by Alfons Van Daele in 1994<ref>{{cite journal | last1 = Van Daele | first1 = Alfons | year = 1994 | title = Multiplier Hopf algebras | url = http://www.ams.org/tran/1994-342-02/S0002-9947-1994-1220906-5/S0002-9947-1994-1220906-5.pdf| journal = Transactions of the American Mathematical Society | volume = 342 | issue = 2| pages = 917–932 | doi=10.1090/S0002-9947-1994-1220906-5}}</ref> are generalizations of [[Hopf algebras]] where comultiplication from an algebra (with or without unit) to the [[multiplier algebra]] of tensor product algebra of the algebra with itself.\n\n[[Hopf group-(co)algebra]]s introduced by V. G. Turaev in 2000 are also generalizations of Hopf algebras.\n\n===Weak Hopf algebras===\n[[Weak Hopf algebra]]s, or quantum groupoids, are  generalizations of Hopf algebras. Like Hopf algebras, weak Hopf algebras form a self-dual class of algebras; i.e., if ''H'' is a (weak) Hopf algebra, so is ''H''*, the dual space of linear forms on ''H'' (with respect to the algebra-coalgebra structure obtained from  the natural pairing with ''H'' and its coalgebra-algebra structure). A weak Hopf algebra ''H'' is usually taken to be a\n*finite-dimensional algebra and coalgebra with coproduct Δ: ''H'' → ''H'' ⊗ ''H''  and counit ε: ''H'' → ''k'' satisfying all the axioms of Hopf algebra except possibly Δ(1) ≠ 1 ⊗ 1 or ε(''ab'') ≠ ε(''a'')ε(''b'') for some ''a,b'' in ''H''. Instead one requires the following:\n\n::<math> (\\Delta(1) \\otimes 1)(1 \\otimes \\Delta(1)) = (1 \\otimes \\Delta(1))(\\Delta(1) \\otimes 1) = (\\Delta \\otimes \\mbox{Id})\\Delta(1)</math>\n::<math> \\epsilon(abc) = \\sum \\epsilon(ab_{(1)})\\epsilon(b_{(2)}c) = \\sum \\epsilon(ab_{(2)})\\epsilon(b_{(1)}c)</math>\n\n:for all ''a'', ''b'', and ''c'' in ''H''.\n* ''H'' has a weakened antipode ''S'': ''H'' → ''H'' satisfying the axioms:\n\n#<math>S(a_{(1)})a_{(2)} = 1_{(1)} \\epsilon(a 1_{(2)})</math> for all ''a'' in ''H'' (the right-hand side is the interesting projection usually denoted by Π<sup>''R''</sup>(''a'') or ε<sub>''s''</sub>(''a'') with image a separable subalgebra denoted by ''H<sup>R</sup>'' or ''H<sub>s</sub>''); \n#<math>a_{(1)}S(a_{(2)}) =  \\epsilon(1_{(1)}a)1_{(2)}</math> for all ''a'' in ''H'' (another interesting projection usually denoted by Π<sup>''R''</sup>(''a'') or ε<sub>''t''</sub>(''a'') with image a separable algebra ''H<sup>L</sup>'' or ''H<sub>t</sub>'', anti-isomorphic to ''H<sup>L</sup>'' via ''S'');\n#<math>S(a_{(1)})a_{(2)}S(a_{(3)}) = S(a) </math> for all ''a'' in ''H''.\n\n:Note that if Δ(1) = 1 ⊗ 1, these conditions reduce to the two usual conditions on the antipode of a Hopf algebra.\n\nThe axioms are partly chosen so that the category of ''H''-modules is a [[rigid category|rigid monoidal category]]. The unit ''H''-module is the separable algebra ''H<sup>L</sup>'' mentioned above. \n \nFor example, a finite [[groupoid]] algebra is a weak Hopf algebra. In particular, the groupoid algebra on [n] with one pair of invertible arrows ''e<sub>ij</sub>'' and ''e<sub>ji</sub>''  between ''i'' and ''j'' in [''n''] is isomorphic to the algebra ''H'' of ''n'' x ''n'' matrices. The weak Hopf algebra structure on this particular ''H'' is given by coproduct Δ(''e<sub>ij</sub>'') = ''e<sub>ij</sub>'' ⊗ ''e<sub>ij</sub>'', counit ε(''e<sub>ij</sub>'') = 1 and antipode ''S''(''e<sub>ij</sub>'') = ''e<sub>ji</sub>''. The separable subalgebras ''H<sup>L</sup>'' and ''H<sup>R</sup>'' coincide and are non-central commutative algebras in this particular case (the subalgebra of diagonal matrices).\n\nEarly theoretical contributions to weak Hopf algebras are to be found in<ref>{{cite journal | last1 = Böhm | first1 = Gabriella | last2 = Nill | first2 = Florian | last3 = Szlachanyi | first3 = Kornel | year = 1999 | title =  Weak Hopf Algebras| url = | journal = J. Algebra | volume = 221 | issue = 2| pages = 385–438 | doi=10.1006/jabr.1999.7984| arxiv = math/9805116 }}</ref> as well as<ref>Dmitri Nikshych, Leonid Vainerman, in: New direction in Hopf algebras, S. Montgomery and H.-J. Schneider, eds., M.S.R.I. Publications, vol. 43, Cambridge, 2002, 211–262.</ref>\n\n===Hopf algebroids===\nSee [[Hopf algebroid]]\n\n==Analogy with groups==\nGroups can be axiomatized by the same diagrams (equivalently, operations) as a Hopf algebra, where ''G'' is taken to be a set instead of a module. In this case:\n* the field ''K'' is replaced by the 1-point set\n* there is a natural counit (map to 1 point)\n* there is a natural comultiplication (the diagonal map)\n* the unit is the identity element of the group\n* the multiplication is the multiplication in the group\n* the antipode is the inverse\nIn this philosophy, a group can be thought of as a Hopf algebra over the \"[[field with one element]]\".<ref>[http://sbseminar.wordpress.com/2007/10/07/group-hopf-algebra/ Group = Hopf algebra « Secret Blogging Seminar<!-- Bot generated title -->], [https://www.youtube.com/watch?v=p3kkm5dYH-w Group objects and Hopf algebras], video of Simon Willerton.</ref>\n\n== Hopf algebras in symmetric monoidal categories ==\nThe definition of Hopf algebra is naturally extended to  arbitrary [[symmetric monoidal category|symmetric monoidal categories]]{{sfn|Akbarov|2009|p=482}}. A Hopf algebra in such a category <math>(C,\\otimes,s,I)</math> is a sextuple <math>(H,\\nabla,\\eta,\\Delta,\\varepsilon,S)</math> where \n\n* <math>H</math> is an object in <math>C</math>;\n\n* <math>\\nabla:H\\otimes H\\to H</math> is a morphism with the properties of multiplication; \n\n* <math>\\eta:I\\to H</math> is a morphism with the properties of unit; \n\n* <math>\\Delta:H\\to H\\otimes H</math> is a morphism with the properties of comultiplication; \n\n* <math>\\varepsilon:H\\to I</math> is a morphism with the properties of counit; \n\n* <math>S:H\\to H</math> is a morphism with the properties of antipode. \n\nThe typical examples are the following.\n\n* The standard [[Stereotype algebra#Examples|functional algebras]] <math>{\\mathcal C}(G)</math>, <math>{\\mathcal E}(G)</math>, <math>{\\mathcal O}(G)</math>, <math>{\\mathcal P}(G)</math> (of contionuous, smooth, holomorphic, regular functions) on groups are Hopf algebras in the category ('''Ste''',<math>\\odot</math>) of [[stereotype space]]s,\n\n* The [[Group algebra#Stereotype group algebras|stereotype group algebras]] <math>{\\mathcal C}^\\star(G)</math>, <math>{\\mathcal E}^\\star(G)</math>, <math>{\\mathcal O}^\\star(G)</math>, <math>{\\mathcal P}^\\star(G)</math> (of measures, distributions, analytic functionals and currents) on groups are Hopf algebras in the category ('''Ste''',<math>\\circledast</math>) of [[stereotype space]]s.\n\nThese Hopf algebras play an important role in the [[Pontryagin duality#Dualities for non-commutative topological groups|duality theories for non-commutative groups]]{{sfn|Akbarov|2009}}.\n\n== See also ==\n* [[Quasitriangular Hopf algebra]]\n* [[Algebra/set analogy]]\n* [[Representation theory of Hopf algebras]]\n* [[Ribbon Hopf algebra]]\n* [[Superalgebra]]\n* [[Supergroup (physics)|Supergroup]]\n* [[Anyonic Lie algebra]]\n* [[Sweedler's Hopf algebra]]\n* [[Hopf algebra of permutations]]\n* [[Milnor–Moore theorem]]\n\n==Notes and references==\n\n=== Notes ===\n{{Reflist}}\n\n=== References ===\n* {{Citation| last1=Dăscălescu| first1=Sorin| last2=Năstăsescu| first2=Constantin| last3=Raianu| first3=Șerban| year=2001| title=Hopf Algebras. An introduction| edition=1st| volume = 235| series=Pure and Applied Mathematics | publisher=Marcel Dekker| isbn = 978-0-8247-0481-0 | zbl=0962.16026 }}.\n* {{citation |authorlink=Pierre Cartier (mathematician) |first=Pierre |last=Cartier |chapter=A Primer of Hopf Algebras |editor-last=Cartier |editor-first=P. |editor2-last=Moussa |editor2-first=P. |editor3-last=Julia |editor3-first=B. |editor4-last=Vanhove |editor4-first=P. |title=Frontiers in Number Theory, Physics, and Geometry |volume=II |pages=537–615 |publisher=Springer |location=Berlin |year=2007 |doi=10.1007/978-3-540-30308-4_12 }}\n* {{citation | last=Fuchs | first=Jürgen | title=Affine Lie algebras and quantum groups. An introduction with applications in conformal field theory | series=Cambridge Monographs on Mathematical Physics | location=Cambridge | publisher=Cambridge University Press | year=1992 | isbn=978-0-521-48412-1 | zbl=0925.17031 }}\n* [[Heinz Hopf]], Uber die Topologie der Gruppen-Mannigfaltigkeiten und ihrer Verallgemeinerungen, [[Annals of Mathematics]] 42 (1941), 22–52. Reprinted in Selecta Heinz Hopf, pp.&nbsp;119–151, Springer, Berlin (1964). {{MR|4784}}, {{zbl|0025.09303}}\n* {{citation | last=Montgomery | first=Susan | authorlink=Susan Montgomery|title=Hopf algebras and their actions on rings | series=Regional Conference Series in Mathematics | volume=82 | location=Providence, Rhode Island | publisher=[[American Mathematical Society]] | year=1993 | isbn=978-0-8218-0738-5 | zbl=0793.16029 }}\n* {{Citation | last1=Street | first1=Ross | author1-link=Ross Street | title=Quantum groups: A Path To Current Algebra | publisher=Cambridge University Press | series=Australian Mathematical Society Lecture Series | volume=19 | year=2007 | isbn=978-0-521-69524-4 | mr=2294803 | zbl=1117.16031 }}.\n*{{Citation | last1=Sweedler | first1=Moss E. | title=Hopf algebras | url=https://books.google.com/books?id=8FnvAAAAMAAJ | publisher=W. A. Benjamin, Inc., New York | series=Mathematics Lecture Note Series | year=1969 | mr=0252485 | zbl=0194.32901  }}\n* {{citation | last=Underwood | first=Robert G. | title=An introduction to Hopf algebras | location=Berlin | publisher=Springer-Verlag | year=2011 | isbn=978-0-387-72765-3 | zbl=1234.16022 }}\n*{{cite journal|last=Akbarov|first=S.S.|title=Holomorphic functions of exponential type and duality for Stein groups with algebraic connected component of identity|journal=Journal of Mathematical Sciences|year=2009|volume=162|issue=4|pages=459–586|arxiv=0806.3205|doi=10.1007/s10958-009-9646-1| ref = harv}}\n\n{{DEFAULTSORT:Hopf Algebra}}\n[[Category:Hopf algebras| ]]\n[[Category:Monoidal categories]]\n[[Category:Representation theory]]"
    },
    {
      "title": "Augmentation ideal",
      "url": "https://en.wikipedia.org/wiki/Augmentation_ideal",
      "text": "In [[Abstract algebra|algebra]], an '''augmentation ideal''' is an [[ideal (ring theory)|ideal]] that can be defined in any [[group ring]]. \n\nIf ''G'' is a [[group (mathematics)|group]] and ''R'' a [[commutative ring]], there is a [[ring homomorphism]] <math>\\varepsilon</math>, called the '''[[augmentation map]]''', from the group ring <math>R[G]</math> to ''R'', defined by taking a (finite<ref group=\"Note\">When constructing {{math|''R''[''G'']}}, we restrict {{math|''R''[''G'']}} to only finite (formal) sums</ref>) sum <math>\\sum r_i g_i</math> to <math>\\sum r_i.</math>  (Here <math>r_i\\in R</math> and <math>g_i\\in G</math>.)  In less formal terms, <math>\\varepsilon(g)=1_R</math> for any element <math>g\\in G</math>, <math>\\varepsilon(r) = r</math> for any element <math>r\\in R</math>, and <math>\\varepsilon</math> is then extended to a homomorphism of ''R''-[[module (mathematics)|module]]s in the obvious way. \n\nThe '''augmentation ideal''' {{mvar|A}} is the [[kernel (algebra)|kernel]] of <math>\\varepsilon</math> and is therefore a [[two-sided ideal]] in ''R''[''G''].  \n\n{{mvar|A}} is generated by the differences <math> g - g'</math> of group elements.  Equivalently, it is also generated by <math>\\{g - 1 : g\\in G\\}</math>, which is a basis as a free ''R''-module.\n\nFor ''R'' and ''G'' as above, the group ring ''R''[''G''] is an example of an [[augmented algebra|''augmented'' ''R''-algebra]]. Such an algebra comes equipped with a ring homomorphism to ''R''.  The kernel of this homomorphism is the augmentation ideal of the algebra.\n\nThe augmentation ideal plays a basic role in [[group cohomology]], amongst other applications.\n\n==Examples of Quotients by the Augmentation Ideal==\n* Let ''G'' a group and <math>\\mathbb{Z}[G]</math> the group ring over the integers. Let ''I'' denote the augmentation ideal of <math>\\mathbb{Z}[G]</math>. Then the quotient {{math|''I''/''I''{{sup|2}} }} is isomorphic to the abelianization of ''G'', defined as the quotient of ''G'' by its commutator subgroup. \n* A complex representation ''V'' of a group ''G'' is a <math>\\mathbb{C}[G]</math> - module. The coinvariants of ''V'' can then be described as the quotient of ''V'' by ''IV'', where ''I'' is the augmentation ideal in <math>\\mathbb{C}[G]</math>. \n* Another class of examples of augmentation ideal can be the [[kernel (algebra)|kernel]] of the [[counit]] <math>\\varepsilon</math> of any [[Hopf algebra]].\n\n==Notes==\n{{reflist|group=Note}}\n\n==References==\n* {{cite book | author=D. L. Johnson | title=Presentations of groups | series=London Mathematical Society Student Texts | volume=15 | publisher=[[Cambridge University Press]] | year=1990 | isbn=0-521-37203-8 | pages=149–150 }}\n*Dummit and Foote, Abstract Algebra\n\n[[Category:Ideals]]\n[[Category:Hopf algebras]]"
    },
    {
      "title": "Braided Hopf algebra",
      "url": "https://en.wikipedia.org/wiki/Braided_Hopf_algebra",
      "text": "In [[mathematics]], a '''braided Hopf algebra''' is a [[Hopf algebra]] in a [[braided monoidal category]]. The most common braided Hopf algebras are objects in a [[Yetter–Drinfeld category]] of a Hopf algebra ''H'', particularly the [[Nichols algebra]] of a braided vectorspace in that category.\n\n''The notion should not be confused with [[quasitriangular Hopf algebra]].''\n\n== Definition ==\n\nLet ''H'' be a Hopf algebra over a field ''k'', and assume that the antipode of ''H'' is bijective. A [[Yetter–Drinfeld module]] ''R'' over ''H'' is called a '''braided bialgebra''' in the Yetter–Drinfeld category <math> {}^H_H\\mathcal{YD}</math> if\n* <math> (R,\\cdot ,\\eta ) </math> is a unital [[associative algebra]], where the multiplication map <math>\\cdot :R\\times R\\to R</math> and the unit <math> \\eta :k\\to R </math> are maps of Yetter–Drinfeld modules,\n* <math> (R,\\Delta ,\\varepsilon )</math> is a coassociative [[coalgebra]] with counit <math>\\varepsilon </math>, and both <math> \\Delta </math> and <math>\\varepsilon </math> are maps of Yetter–Drinfeld modules,\n* the maps <math>\\Delta :R\\to R\\otimes R </math> and <math> \\varepsilon :R\\to k </math> are algebra maps in the category <math> {}^H_H\\mathcal{YD}</math>, where the algebra structure of <math> R\\otimes R </math> is determined by the unit <math> \\eta \\otimes \\eta(1) : k\\to R\\otimes R</math> and the multiplication map\n:: <math> (R\\otimes R)\\times (R\\otimes R)\\to R\\otimes R,\\quad (r\\otimes s,t\\otimes u) \\mapsto \\sum _i rt_i\\otimes s_i u, \\quad \\text{and}\\quad c(s\\otimes t)=\\sum _i t_i\\otimes s_i. </math>\n:Here ''c'' is the canonical braiding in the Yetter–Drinfeld category <math> {}^H_H\\mathcal{YD}</math>.\n\nA braided bialgebra in <math> {}^H_H\\mathcal{YD}</math> is called a '''braided Hopf algebra''', if there is a morphism <math> S:R\\to R </math> of Yetter–Drinfeld modules such that\n:: <math> S(r^{(1)})r^{(2)}=r^{(1)}S(r^{(2)})=\\eta(\\varepsilon (r)) </math> for all <math> r\\in R,</math>\n\nwhere <math>\\Delta _R(r)=r^{(1)}\\otimes r^{(2)}</math> in slightly modified [[Coalgebra|Sweedler notation]] – a change of notation is performed in order to avoid confusion in Radford's biproduct below.\n\n== Examples ==\n\n* Any Hopf algebra is also a braided Hopf algebra over <math> H=k </math>\n* A '''super Hopf algebra''' is nothing but a braided Hopf algebra over the [[group ring|group algebra]] <math> H=k[\\mathbb{Z}/2\\mathbb{Z}] </math>.\n* The [[tensor algebra]] <math> TV </math> of a Yetter–Drinfeld module <math> V\\in {}^H_H\\mathcal{YD}</math> is always a braided Hopf algebra. The coproduct <math> \\Delta </math> of <math> TV </math> is defined in such a way that the elements of ''V'' are primitive, that is\n::<math> \\Delta (v)=1\\otimes v+v\\otimes 1 \\quad \\text{for all}\\quad v\\in V.</math>                                                                              \n:The counit <math>\\varepsilon :TV\\to k</math> then satisfies the equation <math> \\varepsilon (v)=0</math> for all <math> v\\in V .</math>\n* The universal quotient of <math> TV </math>, that is still a braided Hopf algebra containing <math> V </math> as primitive elements is called the [[Nichols algebra]]. They take the role of quantum Borel algebras in the classification of pointed Hopf algebras, analogously to the classical Lie algebra case.\n\n== Radford's biproduct ==\n\nFor any braided Hopf algebra ''R'' in <math> {}^H_H\\mathcal{YD}</math> there exists a natural Hopf algebra <math> R\\# H </math> which contains ''R'' as a subalgebra and ''H'' as a Hopf subalgebra. It is called  '''Radford's biproduct''', named after its discoverer, the Hopf algebraist David Radford. It was rediscovered by [[Shahn Majid]], who called it '''bosonization'''.\n\nAs a vector space, <math> R\\# H </math> is just <math> R\\otimes H </math>. The algebra structure of <math> R\\# H </math> is given by\n:: <math> (r\\# h)(r'\\#h')=r(h_{(1)}\\boldsymbol{.}r')\\#h_{(2)}h', </math>\n\nwhere <math> r,r'\\in R,\\quad h,h'\\in H</math>, <math> \\Delta (h)=h_{(1)}\\otimes h_{(2)} </math> ([[coproduct|Sweedler notation]]) is the coproduct of <math> h\\in H </math>, and <math> \\boldsymbol{.}:H\\otimes R\\to R </math> is the left action of ''H'' on ''R''. Further, the coproduct of <math> R\\# H </math> is determined by the formula\n:: <math> \\Delta (r\\#h)=(r^{(1)}\\#r^{(2)}{}_{(-1)}h_{(1)})\\otimes (r^{(2)}{}_{(0)}\\#h_{(2)}), \\quad r\\in R,h\\in H.</math>\n\nHere <math>\\Delta _R(r)=r^{(1)}\\otimes r^{(2)}</math> denotes the coproduct of ''r'' in ''R'', and <math> \\delta (r^{(2)})=r^{(2)}{}_{(-1)}\\otimes r^{(2)}{}_{(0)} </math> is the left coaction of ''H'' on <math> r^{(2)}\\in R. </math>\n\n== References ==\n\n* Andruskiewitsch, Nicolás and Schneider, Hans-Jürgen, ''Pointed Hopf algebras'',  New directions in Hopf algebras,  1–68, Math. Sci. Res. Inst. Publ., 43, Cambridge Univ. Press, Cambridge, 2002.\n\n[[Category:Hopf algebras]]"
    },
    {
      "title": "Braided vector space",
      "url": "https://en.wikipedia.org/wiki/Braided_vector_space",
      "text": "In mathematics, a '''braided''' vectorspace <math>\\;V</math> is a [[vector space]] together with an additional structure map <math>\\tau</math> symbolizing '''interchanging''' of two vector [[tensor product|tensor copies]]:\n\n::<math>\\tau:\\; V\\otimes V\\longrightarrow V\\otimes V </math>\n\nsuch that the [[Yang–Baxter equation]] is fulfilled. Hence drawing [[Penrose graphical notation|tensor diagram]]s with <math>\\tau</math> an '''overcrossing''' the corresponding composed morphism is unchanged when a [[Reidemeister move]] is applied to the tensor diagram and thus they present a representation of the [[braid group]].\n \nAs first example, every vector space is braided via the trivial braiding (simply flipping). A [[superspace]] has a braiding with negative sign in braiding two '''odd''' vectors. More generally, a '''diagonal braiding''' means that for a <math>\\;V</math>-base <math>x_i</math> we have\n\n::<math>\\tau(x_i\\otimes x_j)=q_{ij}(x_j\\otimes x_i) </math>\n\nA good source for braided vector spaces entire [[braided monoidal category|braided monoidal categories]] with braidings  between any objects <math>\\tau_{V,W}</math>, most importantly the modules over [[quasitriangular Hopf algebra]]s and [[Yetter–Drinfeld category|Yetter–Drinfeld modules]] over finite groups (such as <math>\\mathbb{Z}_2</math> above)\n\nIf <math>V</math> additionally possesses an [[braided Hopf algebra|algebra structure inside the braided category]] (\"braided algebra\") one has a '''braided commutator''' (e.g. for a [[superspace]] the [[Commutator|anticommutator]]): \n\n::<math>\\;[x,y]_\\tau:=\\mu((x\\otimes y)-\\tau(x\\otimes y))\\qquad \\mu(x\\otimes y):=xy</math>\n\nExamples of such braided algebras (and even [[braided Hopf algebra|Hopf algebras]]) are the [[Nichols algebra]]s, that are by definition generated by a given braided vectorspace. They appear as quantum Borel part of [[quantum group]]s and often (e.g. when finite or over an abelian group) possess an [[Root system|arithmetic root system]], multiple [[Dynkin diagram]]s and a [[Poincaré–Birkhoff–Witt theorem|PBW-basis]] made up of braided commutators just like the ones in [[semisimple Lie algebra]]s.\n\n<ref name=AS02>Andruskiewitsch, Schneider: ''Pointed Hopf algebras'',  New directions in Hopf algebras,  1–68, Math. Sci. Res. Inst. Publ., 43, Cambridge Univ. Press, Cambridge, 2002.</ref>\n<references/>\n\n[[Category:Hopf algebras]]\n[[Category:Quantum groups]]\n\n\n{{algebra-stub}}"
    },
    {
      "title": "Butcher group",
      "url": "https://en.wikipedia.org/wiki/Butcher_group",
      "text": "In [[mathematics]],  the '''Butcher group''', named after the New Zealand mathematician [[John C. Butcher]] by {{harvtxt|Hairer|Wanner|1974}}, is an infinite-dimensional  [[Lie group]]<ref name=\":0\">{{harvnb|Bogfjellmo|Schmeding|2015}}</ref> first introduced in [[numerical analysis]] to study solutions of non-linear [[ordinary differential equation]]s by the [[Runge&ndash;Kutta method]]. It arose from an algebraic formalism involving [[rooted tree]]s that provides [[formal power series]] solutions of the differential equation modeling the flow of a [[vector field]]. It was {{harvtxt|Cayley|1857}}, prompted by the work of [[James Joseph Sylvester|Sylvester]] on change of variables in [[differential calculus]], who first noted that the [[Faà di Bruno's formula|derivatives of a composition of functions]] can be conveniently expressed in terms of rooted trees and their combinatorics.\n\n{{harvtxt|Connes|Kreimer|1999}} pointed out that the Butcher group is the group of characters of the [[Hopf algebra]] of rooted trees that had arisen independently in their own work on [[renormalization]] in [[quantum field theory]] and [[Alain Connes|Connes]]' work with [[Henri Moscovici|Moscovici]] on local [[index theorem]]s. This Hopf algebra, often called the ''Connes-Kreimer algebra'', is essentially equivalent to the Butcher group, since its dual can be identified with the [[universal enveloping algebra]] of the [[Lie algebra]] of the Butcher group.<ref>{{harvnb|Brouder|2004}}</ref> As they commented:\n{{cquote|We regard Butcher’s work on the classification of numerical integration methods as an impressive example that concrete problem-oriented work can lead to far-reaching conceptual results.}}\n\n==Differentials and rooted trees==\n[[File:Caylrich-first-trees.png|thumb|250px|right|Rooted trees with two, three and four nodes, from Cayley's original article]]\nA rooted tree is a [[graph theory|graph]] with a distinguished node, called the ''root'', in which every other node is connected to the root by a unique path.  If the root of a tree '''t''' is removed and the nodes connected to the original node by a single bond are taken as new roots, the tree '''t''' breaks up into rooted trees '''t'''<sub>1</sub>, '''t'''<sub>2</sub>, ... Reversing this process a new tree '''t''' = ['''t'''<sub>1</sub>, '''t'''<sub>2</sub>, ...] can be constructed by joining the roots of the trees to a new common root. The number of nodes in a tree is denoted by |'''t'''|. A ''heap-ordering'' of a rooted tree '''t''' is an allocation of the numbers 1 through |'''t'''| to the nodes so that the numbers increase on any path going away from the root. Two heap orderings are ''equivalent'', if there is an [[automorphism]] of rooted trees mapping one of them on the other. The number of [[equivalence class]]es of heap-orderings on a particular tree is denoted by α('''t''') and can be computed using the Butcher's formula:<ref name=\"Butcher2008\">{{harvnb|Butcher|2008}}</ref><ref>{{harvnb|Brouder|2000}}</ref>\n\n:<math>\\displaystyle \\alpha(t)= {|t|!\\over t! |S_t|},</math>\n\nwhere ''S''<sub>'''t'''</sub> denotes the [[symmetry group]] of '''t''' and the tree factorial is defined recursively by\n \n:<math>[t_1,\\dots,t_n]! = |[t_1,\\dots,t_n]| \\cdot t_1! \\cdots t_n!</math>\n\nwith the tree factorial of an isolated root defined to be 1\n\n:<math>\\bullet ! =1.</math>\n\nThe ordinary differential equation for the flow of a [[vector field]] on an open subset ''U'' of '''R'''<sup>N</sup> can be written\n\n:<math>\\displaystyle {dx(s)\\over ds} = f(x(s)),\\,\\, x(0)=x_0, </math>\n\nwhere ''x''(''s'') takes values in ''U'', ''f'' is a smooth function from ''U'' to  '''R'''<sup>N</sup> and ''x''<sub>0</sub> is the starting point of the flow at time ''s'' = 0.\n\n{{harvtxt|Cayley|1857}} gave a method to compute the higher order derivatives ''x''<sup>(''m'')</sup>(''s'') in terms of rooted trees. His formula can be conveniently expressed using the ''elementary differentials'' introduced by Butcher. These are defined inductively by\n\n:<math> \\delta_\\bullet^i= f^i, \\,\\,\\, \\delta^i_{[t_1,\\dots,t_n]} = \\sum_{j_1,\\dots,j_n=1}^N (\\delta^{j_1}_{t_1} \\cdots \\delta^{j_n}_{t_n})\\partial_{j_1} \\cdots \\partial_{j_n} f^i.</math>\n\nWith this notation\n\n:<math> {d^m x\\over ds^m} = \\sum_{|t|=m} \\alpha(t) \\delta_t,</math>\n\ngiving the power series expansion\n\n:<math>\\displaystyle x(s) = x_0 + \\sum_{t}  {s^{|t|}\\over |t|!} \\alpha(t) \\delta_t(0).</math>\n\nAs an example when ''N'' = 1, so that ''x'' and ''f'' are real-valued functions of a single real variable, the formula yields\n\n:<math> x^{(4)} = f^{\\prime\\prime\\prime}f^3  + 3 f^{\\prime\\prime}f^{\\prime} f^2 + f^{\\prime}f^{\\prime\\prime} f^2 +(f^\\prime)^3 f,</math>\n\nwhere the four terms correspond to the four rooted trees from left to right in Figure 3 above.\n\nIn a single variable this formula is the same as [[Faà di Bruno's formula]] of 1855; however in several variables it has to be written more carefully in the form\n\n:<math> x^{(4)} = f^{\\prime\\prime\\prime}(f,f,f)  + 3f^{\\prime\\prime}(f,f^\\prime(f))   +   f^\\prime(f^{\\prime\\prime}(f,f))            +f^\\prime(f^\\prime(f^\\prime(f))),</math>\n\nwhere the tree structure is crucial.\n\n==Definition using Hopf algebra of rooted trees==\nThe [[Hopf algebra]] '''H''' of rooted trees was defined by {{harvtxt|Connes|Kreimer|1998}} in connection with [[Dirk Kreimer|Kreimer]]'s previous work on [[renormalization]] in [[quantum field theory]]. It was later discovered that the Hopf algebra was the dual of a Hopf algebra defined earlier by {{harvtxt|Grossman|Larsen|1989}} in a different context. The characters of '''H''', i.e. the homomorphisms of the underlying commutative algebra into '''R''', form a group, called the '''Butcher group'''. It corresponds to the [[formal group]] structure discovered in [[numerical analysis]] by {{harvtxt|Butcher|1972}}.\n\nThe '''Hopf algebra of rooted trees''' '''H''' is defined to be the [[polynomial ring]] in the variables '''t''', where '''t''' runs through rooted trees.\n\n*Its [[comultiplication]] <math> \\Delta:H\\rightarrow H \\otimes H</math> is defined by\n\n:<math>\\Delta(t) = t\\otimes I + I \\otimes t +\\sum_{s\\subset t} s\\otimes [t\\backslash s],</math>\n\nwhere the sum is over all proper rooted subtrees '''s''' of '''t'''; <math>[t\\backslash s]</math> is the monomial given by the product the variables '''t'''<sub>i</sub> formed by the rooted trees that arise on erasing all the nodes of '''s''' and connected links from '''t'''. The number of such trees is denoted by ''n''('''t'''\\'''s''').\n\n*Its [[counit]] is the homomorphism ε of '''H''' into '''R''' sending each variable '''t''' to zero.\n*Its [[antipode (algebra)|antipode]] ''S'' can be defined recursively by the formula\n\n:<math> S(t) = -t - \\sum_{s \\subset t}(-1)^{n(t\\backslash s)}S([t\\backslash s])s, \\,\\,\\, S(\\bullet)= -\\bullet.</math>\n\nThe '''Butcher group''' is defined to be the set of algebra homomorphisms φ of '''H''' into '''R''' with group structure\n\n:<math>\\varphi_1 \\star \\varphi_2 (t)= (\\varphi_1\\otimes \\varphi_2)\\Delta(t).</math>\n\nThe inverse in the Butcher group is given by\n\n:<math>\\varphi^{-1}(t)=\\varphi(St)</math>\n\nand the identity by the counit ε.\n\nUsing complex coefficients in the construction of the Hopf algebra of rooted trees one obtains the complex Hopf algebra of rooted trees.\nIts '''C'''-valued characters form a group, called the '''complex Butcher group G<sub>C</sub>'''. The complex Butcher group '''G'''<sub>'''C'''</sub> is an infinite-dimensional complex Lie group<ref name=\":0\" /> which appears as a toy model in the {{section link||Renormalization}} of quantum field theories.\n\n==Butcher series and Runge&ndash;Kutta method==\nThe non-linear ordinary differential equation\n\n:<math> {dx(s)\\over ds} = f(x(s)),\\,\\,\\, x(0)=x_0,</math>\n\ncan be solved approximately by the [[Runge-Kutta method]]. This iterative scheme requires an ''m'' x ''m'' matrix\n\n:<math>A=(a_{ij})</math>\n\nand a vector\n\n:<math>b=(b_i)</math>\n\nwith ''m'' components.\n\nThe scheme defines vectors ''x''<sub>''n''</sub> by first finding a solution ''X''<sub>1</sub>, ... , ''X''<sub>''m''</sub> of\n\n:<math> X_i= x_{n-1} + h \\sum_{j=1}^m a_{ij} f(X_j)</math>\n\nand then setting\n\n:<math>x_n=x_{n-1} +h \\sum_{j=1}^m b_j f(x_j).</math>\n\n{{harvtxt|Butcher|1963}} showed that the solution of the corresponding ordinary differential equations\n\n:<math> X_i(s)=x_0 + s\\sum_{j=1}^m a_{ij} f(X_j(s)),\\,\\,\\, x(s)=x_0 + s \\sum_{j=1}^m b_jf(X_j(s))</math>\n\nhas the power series expansion\n\n:<math> X_i(s) = x_0 +\\sum_t {s^{|t|}\\over |t|!} \\alpha(t) t! \\sum_{j=1}^m a_{ij} \\varphi_j(t)\\delta_t(0),\\,\\,\\,\\,x(s) = x_0 +\n\\sum_t {s^{|t|}\\over |t|!} \\alpha(t) t! \\varphi(t)\\delta_t(0), </math>\n\nwhere φ<sub>''j''</sub> and φ are determined recursively by\n\n:<math>\\varphi_j(\\bullet)=1.\\,\\,\\, \\varphi_i([t_1,\\cdots,t_k])=\\sum_{j_1,\\dots,j_k} a_{ij_1}\\dots a_{ij_k} \\varphi_{j_1}(t_1)\\dots \\varphi_{j_k}(t_k)</math>\n\nand\n\n:<math>\\varphi(t) = \\sum_{j=1}^m b_j \\varphi_j(t).</math>\n\nThe power series above are called '''B-series''' or '''Butcher series'''.<ref name=\"Butcher2008\" /><ref>{{citation|title=The use of Butcher series in the analysis of Newton-like iterations in Runge-Kutta formulas|journal=Applied Numerical Mathematics|volume=15 |year=1994|pages=341–356| first=K. R.|last= Jackson|first2=A. |last2=Kværnø|first3=S.P.|last3=Nørsett|doi=10.1016/0168-9274(94)00031-X|issue=3|citeseerx=10.1.1.42.8612}} (Special issue to honor professor J. C. Butcher on his sixtieth birthday)</ref> The corresponding assignment φ is an element of the Butcher group. The homomorphism corresponding to the actual flow has\n\n:<math> \\Phi(t)={1\\over t!}.</math>\n\nButcher showed that the Runge-Kutta method gives an ''n''th order approximation of the actual flow provided that φ and Φ agree on all trees with ''n'' nodes or less. Moreover, {{harvtxt|Butcher|1972}} showed that the homomorphisms defined by the Runge-Kutta method form a dense subgroup of the Butcher group: in fact he showed that, given a homomorphism  φ', there is a Runge-Kutta homomorphism φ agreeing with φ' to order ''n''; and that if given homomorphims φ and φ' corresponding to Runge-Kutta data (''A'', ''b'') and (''A' '', ''b' ''), the product homomorphism <math>\\varphi\\star \\varphi^\\prime</math> corresponds to the data\n\n:<math> \\begin{pmatrix} A & 0\\\\ 0 & A^\\prime\\\\ \\end{pmatrix},\\,\\, (b,b^\\prime).</math>\n\n{{harvtxt|Hairer|Wanner|1974}} proved that the Butcher group acts naturally on the functions ''f''. Indeed, setting\n\n:<math>\\varphi\\circ f= 1 +\\sum_t {s^{|t|}\\over |t|!} \\alpha(t) t! \\varphi(t)\\delta_t(0),</math>\n\nthey proved that\n\n:<math> \\varphi_1\\circ (\\varphi_2\\circ f) = (\\varphi_1\\star \\varphi_2)\\circ f.</math>\n\n==Lie algebra==\n{{harvtxt|Connes|Kreimer|1998}} showed that associated with the Butcher group '''G''' is an infinite-dimensional Lie algebra. The existence of this Lie algebra is predicted by a [[Milnor–Moore theorem|theorem]] of {{harvtxt|Milnor|Moore|1965}}: the commutativity and natural grading on '''H''' implies that the graded dual '''H'''* can be identified with the [[universal enveloping algebra]] of a Lie algebra <math>\\mathfrak{g}</math>. Connes and Kreimer explicitly identify <math>\\mathfrak{g}</math> with a space of [[derivation (abstract algebra)|derivation]]s  θ of '''H''' into '''R''', i.e. linear maps such that\n\n:<math>\\theta(ab)=\\varepsilon(a)\\theta(b) + \\theta(a)\\varepsilon(b),</math>\n\nthe formal tangent space of '''G''' at the identity ε. This forms a Lie algebra with Lie bracket\n\n:<math>[\\theta_1,\\theta_2](t)=(\\theta_1 \\otimes \\theta_2 -\\theta_2\\otimes\\theta_1)\\Delta(t).</math>\n\n<math>\\mathfrak{g}</math> is generated by the derivations θ<sub>'''t'''</sub> defined by\n\n:<math>\\theta_t(t^\\prime)=\\delta_{tt^\\prime}, </math>\n\nfor each rooted tree '''t'''.\n\nThe infinite-dimensional Lie algebra <math>\\mathfrak{g}</math> from {{harvtxt|Connes|Kreimer|1998}} and the Lie algebra '''L(G)''' of the Butcher group as an infinite-dimensional Lie group are not the same. The Lie algebra '''L(G)''' can be identified with the Lie algebra of all derivations in the dual of '''H''' (i.e. the space of all linear maps from  '''H''' to '''R'''), whereas <math>\\mathfrak{g}</math> is obtained from the graded dual. Hence <math>\\mathfrak{g}</math> turns out to be a (strictly smaller) Lie subalgebra of '''L(G)'''.<ref name=\":0\" />\n\n==Renormalization==\n{{harvtxt|Connes|Kreimer|1998}} provided a general context for using [[Hopf algebra]]ic methods to give a simple mathematical formulation of [[renormalization]] in [[quantum field theory]]. Renormalization was interpreted as [[Riemann–Hilbert problem|Birkhoff factorization]] of loops in the character group of the associated Hopf algebra.  The models considered by {{harvtxt|Kreimer|1999}} had Hopf algebra '''H''' and character group '''G''', the Butcher group. {{harvtxt|Brouder|2000}} has given an account of this renormalization process in terms of Runge-Kutta data.\n\nIn this simplified setting, a ''renormalizable model'' has two pieces of input data:<ref>{{harvnb|Kreimer|2007}}</ref>\n \n* a set of ''Feynman rules'' given by an algebra homomorphism Φ of '''H''' into the algebra ''V'' of [[Laurent series]] in ''z'' with poles of finite order;\n* a ''renormalization scheme'' given by a linear operator ''R''  on ''V'' such that ''R'' satisfies the [[Rota-Baxter algebra|Rota-Baxter identity]]\n::<math>R(fg) + R(f)R(g) = R(fR(g)) + R(R(f)g)</math>\n:and the image of ''R'' – ''id'' lies in the algebra ''V''<sub>+</sub> of [[power series]] in ''z''.\n\nNote that ''R'' satisfies the Rota-Baxter identity if and only if ''id'' –  ''R'' does. An important example is the ''[[minimal subtraction scheme]]''\n\n:<math>\\displaystyle R(\\sum_{n} a_n z^n )= \\sum_{n< 0} a_n z^n.</math>\n\nIn addition there is a projection ''P'' of '''H''' onto the [[augmentation ideal]] ker ε given by\n\n:<math>\\displaystyle P(x) = x -\\varepsilon(x)1.</math>\n\nTo define the renormalized Feynman rules, note that the antipode ''S'' satisfies\n\n:<math> m\\circ (S\\otimes {\\rm id}) \\Delta (x) =\\varepsilon(x)1</math>\n\nso that\n\n:<math>S = - m\\circ (S\\otimes P)\\Delta,</math>\n\nThe ''renormalized Feynman rules'' are given by a homomorphism <math>\\Phi_S^R</math> of '''H''' into ''V'' obtained by twisting the homomorphism Φ • S. The homomorphism <math>\\Phi_S^R</math> is uniquely specified by\n\n:<math>\\Phi_S^R = -m(S\\otimes \\Phi_S^R\\circ P)\\Delta.</math>\n\nBecause of the precise form of Δ, this gives a recursive formula for <math>\\Phi_S^R</math>.\n\nFor the minimal subtraction scheme, this process can be interpreted in terms of Birkhoff factorization in the complex Butcher group. Φ can be regarded as a map γ of the unit circle into the complexification '''G'''<sub>'''C'''</sub> of '''G''' (maps into '''C''' instead of '''R'''). As such it has a Birkhoff factorization\n\n:<math> \\displaystyle \\gamma(z)=\\gamma_-(z)^{-1} \\gamma_+(z),</math>\n\nwhere  γ<sub>+</sub> is [[Holomorphic function|holomorphic]] on the interior of the closed unit disk and γ<sub>–</sub> is holomorphic on its complement in the [[Riemann sphere]] '''C''' <math>\\cup\\{\\infty\\}</math> with γ<sub>–</sub>(∞) = 1. The loop γ<sub>+</sub> corresponds to the renormalized homomorphism. The evaluation at ''z'' =  0 of γ<sub>+</sub> or the renormalized homomorphism gives the ''dimensionally regularized'' values for each rooted tree.\n\nIn example, the Feynman rules depend on additional parameter μ, a \"unit of mass\". {{harvtxt|Connes|Kreimer|2001}} showed that\n\n:<math>\\partial_\\mu \\gamma_{\\mu-} =0,</math>\n\nso that γ<sub>μ–</sub> is independent of μ.\n\nThe complex Butcher group comes with a natural one-parameter group λ<sub>''w''</sub> of automorphisms, dual to that on '''H'''\n\n:<math>\\lambda_{w}(t)= w^{|t|}t</math>\n\nfor ''w'' ≠ 0 in '''C'''.\n\nThe loops γ<sub>μ</sub> and λ<sub>''w''</sub> · γ<sub>μ</sub> have the same negative part and, for ''t'' real,\n\n:<math>\\displaystyle F_t=\\lim_{z=0} \\gamma_-(z) \\lambda_{tz}(\\gamma_-(z)^{-1})</math>\n\ndefines a one-parameter subgroup of the complex Butcher group '''G'''<sub>'''C'''</sub> called the [[renormalization group| renormalization group flow]] (RG).\n\nIts infinitesimal generator β is an element of the Lie algebra of '''G'''<sub>'''C'''</sub> and is defined by\n\n:<math>\\beta=\\partial_t F_t|_{t=0}.</math>\n\nIt is called the [[beta-function]] of the model.\n\nIn any given model, there is usually a finite-dimensional space of complex coupling constants. The complex Butcher group acts by diffeomorphims on this space. In particular the renormalization group defines a flow on the space of coupling constants, with the beta function giving the corresponding vector field.\n\nMore general models in quantum field theory require rooted trees to be replaced by [[Feynman diagram]]s with vertices decorated by symbols from a finite index set. Connes and Kreimer have also defined Hopf algebras in this setting and have shown how they can be used to systematize standard computations in renormalization theory.\n\n==Example==\n{{harvtxt|Kreimer|2007}} has given a \"toy model\" involving [[dimensional regularization]] for '''H''' and the algebra ''V''. If ''c'' is a positive integer and ''q''<sub>μ</sub> = ''q'' / μ is a dimensionless constant, Feynman rules can be defined recursively by\n\n:<math>\\displaystyle \\Phi([t_1,\\dots, t_n])=\\int {\\Phi(t_1)\\cdots \\Phi(t_n) \\over |y|^2 + q_\\mu^2} (|y|^2)^{-z({c\\over 2} -1)} \\, d^D y,</math>\n\nwhere ''z'' = 1 – ''D''/2 is the regularization parameter. These integrals can be computed explicitly in terms of the [[Gamma function]] using the formula\n\n:<math>\\displaystyle \\int  {(|y|^2)^{-u}\\over |y|^2 +q_\\mu^2} \\, d^Dy =  \\pi^{D/2} (q_\\mu^2)^{-z-u} {\\Gamma(-u +D/2)\\Gamma(1+u-D/2)\\over \\Gamma(D/2)}.</math>\n\nIn particular\n\n:<math>\\displaystyle \\Phi(\\bullet)=\\pi^{D/2}(q_\\mu^2)^{-zc/2}{\\Gamma(1+cz)\\over cz}.</math>\n\nTaking the renormalization scheme ''R'' of minimal subtraction, the renormalized quantities <math>\\Phi_S^R(t)</math> are [[polynomial]]s in <math>\\log q_\\mu^2</math> when evaluated at ''z'' = 0.\n\n==Notes==\n{{reflist|2}}\n\n==References==\n*{{citation|journal=Annales Henri Poincaré|volume= 6 |year=2005|pages=343–367|title=The Hopf Algebra of Rooted Trees in Epstein-Glaser Renormalization|first=Christoph|last= Bergbauer|first2=Dirk|last2= Kreimer|authorlink2=Dirk Kreimer|arxiv=hep-th/0403207|doi=10.1007/s00023-005-0210-3|issue=2|bibcode = 2005AnHP....6..343B }}\n*{{citation|last=Boutet de Monvel|first= Louis|title=Algèbre de Hopf des diagrammes de Feynman, renormalisation et factorisation de Wiener-Hopf (d'après A. Connes et D. Kreimer). [Hopf algebra of Feynman diagrams, renormalization and Wiener-Hopf factorization (following A. Connes and D. Kreimer)]|series=[[Séminaire Bourbaki]]|journal= Astérisque|volume= 290|year=2003|pages= 149–165|url=http://people.math.jussieu.fr/~boutet/renormalisation.pdf}}\n*{{citation|title=Runge&ndash;Kutta methods and renormalization|first=Christian |last=Brouder|journal=Eur. Phys. J. C|volume= 12 |issue=3 |year=2000|pages= 521&ndash;534|arxiv=hep-th/9904014|bibcode = 2000EPJC...12..521B |doi = 10.1007/s100529900235 }}\n*{{citation|first=G. |last=Bogfjellmo|first2=A. |last2=Schmeding|title= The Lie group structure of the Butcher group|journal= Foundations of Computational Mathematics|volume=17|issue=1|pages=127–159|year= 2015|doi=10.1007/s10208-015-9285-5|arxiv=1410.4761}}\n*{{citation|first=Christian |last=Brouder|title= Trees, Renormalization and Differential Equations|journal=BIT Numerical Mathematics|volume= 44|year= 2004|pages=425–438|doi=10.1023/B:BITN.0000046809.66837.cc|issue=3|citeseerx=10.1.1.180.7535}}\n*{{citation|first=J.C|last=Butcher|authorlink=John C. Butcher|title=Coefficients for the study of Runge-Kutta integration processes|journal=J. Austral. Math. Soc. |volume=3 |year=1963 |pages=185–201|doi=10.1017/S1446788700027932|issue=2}}\n*{{citation|first=J.C|last=Butcher|authorlink=John C. Butcher|title=An algebraic theory of integration methods|journal=Math. Comput.|volume=26|issue=117|year=1972|pages=79&ndash;106|jstor=2004720|doi=10.2307/2004720}}\n*{{Citation | last1=Butcher | first1=John C. | author1-link=John C. Butcher | title=Numerical methods for ordinary differential equations | publisher=John Wiley & Sons Ltd. | edition=2nd | isbn=978-0-470-72335-7 | mr=2401398 | year=2008}}\n*{{citation|first=J.C|last=Butcher|authorlink=John C. Butcher|title=Trees and numerical methods for ordinary differential equations|journal=Numerical Algorithms|volume=53|issue=2–3|pages=153–170|year=2009|doi=10.1007/s11075-009-9285-0}}\n*{{citation|first=Arthur|last=Cayley|authorlink=Arthur Cayley|title=On the theory of analytic forms called trees|url= https://archive.org/stream/collectedmathema03cayluoft#page/242/mode/1up|journal=[[Philosophical Magazine]]|volume=XIII|year=1857|pages=172&ndash;176}} (also in Volume 3 of the Collected Works of Cayley, pages 242&ndash;246)\n*{{citation|first=Alain|last=Connes|authorlink=Alain Connes|first2=Dirk|last2=Kreimer|authorlink2=Dirk Kreimer|title=Hopf Algebras, Renormalization and Noncommutative Geometry|journal=Communications in Mathematical Physics|volume= 199|issue=1|year= 1998|pages=203&ndash;242|url=http://www.alainconnes.org/docs/ncgk.pdf|doi=10.1007/s002200050499|arxiv = hep-th/9808042 |bibcode = 1998CMaPh.199..203C }}\n*{{citation|first=Alain|last=Connes|authorlink=Alain Connes|first2=Dirk|last2=Kreimer|authorlink2=Dirk Kreimer|title=Lessons from quantum field theory: Hopf algebras and spacetime geometries|journal=[[Letters in Mathematical Physics]]|volume= 48 |year=1999|pages= 85–96|doi=10.1023/A:1007523409317}}\n*{{citation|first=Alain|last=Connes|authorlink=Alain Connes|first2=Dirk|last2=Kreimer|authorlink2=Dirk Kreimer|title=Renormalization in quantum field theory and the Riemann-Hilbert problem. I. The Hopf algebra structure of graphs and the main theorem|journal=Commun. Math. Phys.|volume= 210|issue=1|year=2000|pages=249–273\n|url=http://www.alainconnes.org/docs/RH1.pdf|doi=10.1007/s002200050779|arxiv = hep-th/9912092 |bibcode = 2000CMaPh.210..249C }}\n*{{citation|first=Alain|last=Connes|authorlink=Alain Connes|first2=Dirk|last2=Kreimer|authorlink2=Dirk Kreimer|title= Renormalization in quantum field theory and the Riemann-Hilbert problem. II. The β-function, diffeomorphisms and the renormalization group|journal= Commun. Math. Phys.|volume= 216|issue=1|pages= 215–241|year=2001|\nurl=http://www.alainconnes.org/docs/RH2.pdf|doi=10.1007/PL00005547|arxiv = hep-th/0003188 |bibcode = 2001CMaPh.216..215C }}\n*{{citation|title=Elements of noncommutative geometry|first=José |last=Gracia-Bondía|first2= Joseph C.|last2= Várilly|first3= Héctor|last3= Figueroa|publisher=Birkhäuser|year=2000|isbn=978-0-8176-4124-5}}, Chapter 14.\n*{{citation|first=R. |last=Grossman |first2=R. |last2=Larson |title=Hopf algebraic structures of families of trees |journal=Journal of Algebra |volume=26 |year=1989 |pages=184&ndash;210 |url=http://users.lac.uic.edu/~grossman/papers/journal-03.pdf |deadurl=yes |archiveurl=https://web.archive.org/web/20080820054732/http://users.lac.uic.edu/~grossman/papers/journal-03.pdf |archivedate=2008-08-20 |df= |doi=10.1016/0021-8693(89)90328-1 }}\n*{{citation|title=On the Butcher group and general multi-value methods|journal=Computing|volume= 13|year= 1974|pages=1&ndash;15|first=E. |last=Hairer|first2=G.|last2= Wanner|doi=10.1007/BF02268387}}\n*{{citation|last=Kreimer|first= Dirk|authorlink=Dirk Kreimer|title=On the Hopf algebra structure of perturbative quantum field theories|journal=Adv. Theor. Math. Phys.|volume=2|issue= 2|year=1998|pages= 303–334|arxiv=q-alg/9707029|bibcode = 1997q.alg.....7029K |doi= 10.4310/ATMP.1998.v2.n2.a4}}\n*{{citation|arxiv=hep-th/9901099|last=Kreimer|first= Dirk|authorlink=Dirk Kreimer|title=Chen's iterated integral represents the operator product expansion|journal=Adv. Theor. Math. Phys.|volume= 3 |issue=3|year=1999|pages=627–670|bibcode = 1999hep.th....1099K |doi=10.4310/ATMP.1999.v3.n3.a7}}\n*{{citation|last=Kreimer|first= Dirk|authorlink=Dirk Kreimer|title= Factorization in Quantum Field Theory: An Exercise in Hopf Algebras and Local Singularities|\nseries=Frontiers in Number Theory, Physics, and Geometry II|publisher=Springer|year=2007|pages=715–736|arxiv=hep-th/0306020|bibcode = 2003hep.th....6020K }}\n*{{Citation | last1=Milnor | first1=John Willard | author1-link=John Milnor | last2=Moore | first2=John C. | title=On the structure of Hopf algebras | jstor=1970615 | mr=0174052 | year=1965 | journal=[[Annals of Mathematics]] | series = Second Series | volume=81 | issue=2 | pages=211–264 | doi=10.2307/1970615| url=https://polipapers.upv.es/index.php/AGT/article/view/2250 }}\n\n[[Category:Combinatorics]]\n[[Category:Numerical analysis]]\n[[Category:Quantum field theory]]\n[[Category:Renormalization group]]\n[[Category:Hopf algebras]]"
    },
    {
      "title": "Exp algebra",
      "url": "https://en.wikipedia.org/wiki/Exp_algebra",
      "text": "In mathematics, an '''exp algebra''' is a [[Hopf algebra]] Exp(''G'') constructed from an abelian group ''G'', and is the [[universal property|universal]] [[ring (mathematics)|ring]] ''R'' such that there is an exponential map from ''G'' to the group of the power series in ''R''<nowiki>[[</nowiki>''t''<nowiki>]]</nowiki> with constant term&nbsp;1. In other words the functor Exp from abelian groups to commutative rings is adjoint to the functor from commutative rings to abelian groups taking a ring to the group of formal power series with constant term&nbsp;1.\n\nThe definition of the exp ring of ''G'' is similar to that of the [[group ring]] '''Z'''[''G''] of ''G'', which is the universal ring such that there is an exponential homomorphism from the group to its units. In particular there is a natural homomorphism from the group ring to a completion of the exp ring. However in general the Exp ring can be much larger than the group ring: for example, the group ring of the integers is the ring of [[Laurent polynomial]]s in 1 variable, while the exp ring is a polynomial ring in countably many generators.\n\n==Construction==\n\nFor each element ''g'' of ''G'' introduce a countable set of variables ''g''<sub>''i''</sub> for ''i''>0. Define exp(''gt'') to be the formal power series in ''t''\n\n:<math>\\exp(gt) = 1+g_1t+g_2t^2+g_3t^3+\\cdots.</math>\n\nThe exp ring of ''G'' is the commutative ring generated by all the elements ''g''<sub>''i''</sub> with the relations\n\n:<math>\\exp((g+h)t) = \\exp(gt)\\exp(ht)</math>\n\nfor all ''g'', ''h'' in ''G''; in other words the coefficients of any power of ''t'' on both sides are identified.\n\nThe ring Exp(''G'') can be made into a commutative and cocommutative [[Hopf algebra]] as follows.  The [[coproduct]] of Exp(''G'') is defined so that all the elements exp(''gt'') are group-like. The antipode is defined by making exp(–''gt'') the antipode of exp(''gt''). The counit takes all the generators ''g''<sub>''i''</sub> to 0.\n\n{{harvtxt|Hoffman|1983}} showed that Exp(''G'') has the structure of a [[λ-ring]].\n\n==Examples==\n\n*The exp ring of an infinite cyclic group such as the integers is a polynomial ring in a countable number of generators ''g''<sub>''i''</sub> where ''g'' is a generator of the cyclic group. This ring (or Hopf algebra) is naturally isomorphic to the [[ring of symmetric functions]] (or the [[Hopf algebra of symmetric functions]]).\n*{{harvs|txt | MR=2724822 | zbl=1211.16023\n|last=Hazewinkel|first= Michiel|last2= Gubareni|first2= Nadiya|last3= Kirichenko|first3= V. V.\n|title=Algebras, rings and modules. \nLie algebras and Hopf algebras|series= Mathematical Surveys and Monographs|volume= 168|publisher= American Mathematical Society|place= Providence, RI|year= 2010|ISBN= 978-0-8218-5262-0 }} suggest that it might be interesting to extend the theory to non-commutative groups ''G''.\n\n==References==\n\n*{{citation | MR=2724822 | zbl=1211.16023\n|last=Hazewinkel|first= Michiel|last2= Gubareni|first2= Nadiya|last3= Kirichenko|first3= V. V.\n|title=Algebras, rings and modules.  Lie algebras and Hopf algebras|series= Mathematical Surveys and Monographs|volume= 168|publisher= American Mathematical Society|place= Providence, RI|year= 2010|ISBN= 978-0-8218-5262-0 }}\n*{{citation|mr=0687747 \n|last=Hoffman|first= P.\n|title=Exponential maps and λ-rings \n|journal=J. Pure Appl. Algebra|volume= 27 |year=1983|issue= 2|pages= 131–162|doi=10.1016/0022-4049(83)90011-7}}\n\n[[Category:Hopf algebras]]"
    },
    {
      "title": "Group Hopf algebra",
      "url": "https://en.wikipedia.org/wiki/Group_Hopf_algebra",
      "text": "{{Refimprove|date=March 2011}}\nIn mathematics, the '''group Hopf algebra''' of a given [[group (mathematics)|group]] is a certain construct related to the symmetries of [[Group action (mathematics)|group actions]]. Deformations of group Hopf algebras are foundational in the theory of [[quantum groups]].\n\n==Definition==\n\nLet ''G'' be a [[group (mathematics)|group]] and ''k'' a [[field (mathematics)|field]]. The ''group Hopf algebra'' of ''G'' over ''k'', denoted ''kG'' (or ''k''[''G'']), is as a set (and vector space) the [[free vector space]] on ''G'' over ''k''. As an [[algebra over a field|algebra]], its product is defined by linear extension of the group composition in ''G'', with multiplicative unit the identity in ''G''; this product is also known as [[convolution]].\n\nNote that while the group algebra of a ''finite'' group can be identified with the space of functions on the group, for an infinite group these are different. The group algebra, consisting of ''finite'' sums, corresponds to functions on the group that vanish for [[cofinitely]] many points; topologically (using the [[discrete topology]]), these correspond to functions with [[compact support]].\n\nHowever, the group algebra ''k''[''G''] and the space of functions ''k''<sup>''G''</sup> := Hom(''G'',''k'') are dual: given an element of the group algebra <math>x = \\sum_{g\\in G} a_g g</math> and a function on the group <math>f\\colon G \\to k,</math> these pair to give an element of ''k'' via <math>(x,f) = \\sum_{g\\in G} a_g f(g),</math> which is a well-defined sum because it is finite.\n\n==Hopf algebra structure==\n\nWe give ''kG'' the structure of a cocommutative [[Hopf algebra]] by defining the coproduct, counit, and antipode to be the linear extensions of the following maps defined on ''G'':<ref>{{cite book | last=Montgomery | first=Susan | authorlink=Susan Montgomery | title=Hopf algebras and their actions on rings. Expanded version of ten lectures given at the CBMS Conference on Hopf algebras and their actions on rings, which took place at DePaul University in Chicago, USA, August 10-14, 1992 | zbl=0793.16029 | series=Regional Conference Series in Mathematics | volume=82 | location=Providence, RI | publisher=American Mathematical Society | year=1993 | isbn=978-0-8218-0738-5 | page=8 }}</ref>\n\n:<math>\\Delta(x) = x \\otimes x;</math>\n:<math>\\epsilon(x) = 1_{k};</math>\n:<math>S(x) = x^{-1}. </math>\n\nThe required Hopf algebra compatibility axioms are easily checked. Notice that <math>\\mathcal{G}(kG)</math>, the set of group-like elements of ''kG'' (i.e. elements <math>a \\in kG</math> such that <math>\\Delta(a) = a \\otimes a</math> and <math>\\epsilon(a)=1</math>), is precisely ''G''.\n\n==Symmetries of group actions==\n\nLet ''G'' be a group and ''X'' a [[topological space]]. Any action <math>\\alpha\\colon G \\times X \\to X</math> of ''G'' on ''X'' gives a homomorphism <math>\\phi_\\alpha\\colon G \\to \\mathrm{Aut}(F(X))</math>, where ''F(X)'' is an appropriate algebra of ''k''-valued functions, such as the Gelfand-Naimark algebra <math>C_0(X)</math> of [[continuous function]]s [[vanish at infinity|vanishing at infinity]]. <math>\\phi_{\\alpha}</math> is defined by  <math>\\phi_\\alpha(g)= \\alpha^*_g</math> with the adjoint <math>\\alpha^*_{g}</math> defined by\n\n:<math>\\alpha^*_g(f)x = f(\\alpha(g,x))</math>\n\nfor <math>g \\in G, f \\in F(X)</math>, and <math>x \\in X</math>.\n\nThis may be described by a linear mapping\n\n:<math>\\lambda\\colon kG \\otimes F(X) \\to F(X) </math>\n\n:<math>\\lambda((c_1 g_1 + c_2 g_2 + \\cdots ) \\otimes f)(x) = c_1 f(g_1 \\cdot x) + c_2 f(g_2 \\cdot x) + \\cdots</math>\n\nwhere <math>c_1,c_2,\\ldots \\in k</math>, <math>g_1, g_2,\\ldots</math> are the elements of ''G'', and <math>g_i \\cdot x := \\alpha(g_i,x)</math>, which has the property that group-like elements in ''kG'' give rise to automorphisms of ''F(X)''.\n\n<math>\\lambda</math> endows ''F(X)'' with an important extra structure, described below.\n\n==Hopf module algebras and the Hopf smash product==\n\nLet ''H'' be a Hopf algebra. A (left) ''Hopf ''H''-module algebra'' ''A'' is an algebra which is a (left) [[module (mathematics)|module]] over the algebra ''H'' such that <math>h \\cdot 1_A = \\epsilon(h)1_A</math> and\n\n:<math>h \\cdot (ab) = (h_{(1)} \\cdot a)(h_{(2)} \\cdot b)</math>\n\nwhenever <math>a,b \\in A</math>, <math>h \\in H</math> and <math>\\Delta(h) = h_{(1)} \\otimes h_{(2)}</math> in sumless [[Sweedler notation]]. When <math>\\lambda</math> has been defined as in the previous section, this turns <math>F(X)</math> into a left Hopf ''kG''-module algebra, which allows the following construction.\n\nLet ''H'' be a Hopf algebra and ''A'' a left Hopf ''H''-module algebra. The ''smash product'' algebra <math>A\\mathop{\\#} H</math> is the vector space <math>A \\otimes H</math> with the product\n\n:<math>(a \\otimes h)(b \\otimes k) := a(h_{(1)} \\cdot b) \\otimes h_{(2)}k</math>,\n\nand we write <math>a\\mathop{\\#} h</math> for <math>a \\otimes h</math> in this context.<ref>{{cite book | last1=Dăscălescu | first1=S. | last2=Raianu | first2=Ş. | last3=Van Oystaeyen | first3=F. | authorlink3=Fred Van Oystaeyen | chapter=Smash (co)products from adjunctions | zbl=0905.16017 | editor1-last=Caenepeel | editor1-first=Stefaan | editor2-last=Verschoren | editor2-first=A. | title=Rings, Hopf algebras, and Brauer groups. Proceedings of the fourth week on algebra and algebraic geometry, SAGA-4, Antwerp and Brussels, Belgium, September 12–17, 1996 | location=New York, NY | publisher=Marcel Dekker | series=Lect. Notes Pure Appl. Math. | volume=197 | pages=103–110 | year=1998 | isbn=0824701534 }}</ref>\n\nIn our case, ''A = F(X)'' and ''H = kG'', and we have\n\n:<math>(a\\mathop{\\#} g_1)(b\\mathop{\\#} g_2) = a(g_1 \\cdot b)\\mathop{\\#} g_1 g_2</math>.\n\nIn this case the smash product algebra <math>A\\mathop{\\#} kG</math> is also denoted by <math>A\\mathop{\\#} G</math>.\n\nThe cyclic homology of Hopf smash products has been computed.<ref>R. Akbarpour and M. Khalkhali (2003) [https://arxiv.org/abs/math.KT/0011248v6 ''Hopf Algebra Equivariant Cyclic Homology and Cyclic Homology of Crossed Product Algebras'']. arXiv:math/0011248v6 [math.KT]. J. reine angew. Math.\n559 137–152.</ref> However, there the smash product is called a crossed product and denoted <math>A \\rtimes H</math>- not to be confused with the [[crossed product]] derived from <math>C^{*}</math>-dynamical systems.<ref>Gracia-Bondia, J. ''et al.'' ''Elements of Noncommutative Geometry''. Birkhäuser: Boston, 2001. {{ISBN|0-8176-4124-6}}.</ref>\n\n==References==\n{{reflist}}\n\n{{DEFAULTSORT:Group Hopf Algebra}}\n[[Category:Hopf algebras]]\n[[Category:Quantum groups]]"
    },
    {
      "title": "Group scheme",
      "url": "https://en.wikipedia.org/wiki/Group_scheme",
      "text": "{{Group theory sidebar |Basics}}\n\nIn [[mathematics]], a '''group scheme''' is a type of [[Algebraic geometry|algebro-geometric]] object equipped with a composition law.  Group schemes arise naturally as symmetries of [[Scheme (mathematics)|scheme]]s, and they generalize [[algebraic group]]s, in the sense that all algebraic groups have group scheme structure, but group schemes are not necessarily connected, smooth, or defined over a field.  This extra generality allows one to study richer infinitesimal structures, and this can help one to understand and answer questions of arithmetic significance.  The [[Category (mathematics)|category]] of group schemes is somewhat better behaved than that of [[Group variety|group varieties]], since all homomorphisms have [[Kernel (category theory)|kernel]]s, and there is a well-behaved [[deformation theory]].  Group schemes that are not algebraic groups play a significant role in [[arithmetic geometry]] and algebraic topology, since they come up in contexts of [[Galois representation]]s and [[moduli problem]]s.  The initial development of the theory of group schemes was due to [[Alexander Grothendieck]], [[Michel Raynaud]] and [[Michel Demazure]] in the early 1960s.\n\n== Definition ==\n\nA group scheme is a [[group object]] in a [[category of schemes]] that has fiber products and some final object ''S''. That is, it is an ''S''-scheme ''G'' equipped with one of the equivalent sets of data\n\n* a triple of morphisms μ: ''G'' &times;<sub>S</sub> ''G'' → ''G'', e: ''S'' → ''G'', and ι: ''G'' → ''G'', satisfying the usual compatibilities of groups (namely associativity of μ, identity, and inverse axioms)\n* a functor from schemes over ''S'' to the [[category of groups]], such that composition with the forgetful functor to [[Set (mathematics)|sets]] is equivalent to the presheaf corresponding to ''G'' under the [[Yoneda lemma|Yoneda embedding]]. (See also: [[group functor]].)\n\nA homomorphism of group schemes is a map of schemes that respects multiplication.  This can be precisely phrased either by saying that a map ''f'' satisfies the equation ''f''μ = μ(''f'' &times; ''f''), or by saying that ''f'' is a [[natural transformation]] of functors from schemes to groups (rather than just sets).\n\nA [[group-scheme action|left action of a group scheme]] ''G'' on a scheme ''X'' is a morphism ''G'' &times;<sub>S</sub> ''X''→ ''X'' that induces a left [[Group action (mathematics)|action]] of the group ''G''(''T'') on the set ''X''(''T'') for any ''S''-scheme ''T''.  Right actions are defined similarly.  Any group scheme admits natural left and right actions on its underlying scheme by multiplication and [[inner automorphism|conjugation]].  Conjugation is an action by automorphisms, i.e., it commutes with the group structure, and this induces linear actions on naturally derived objects, such as its [[Lie algebra]], and the algebra of left-invariant differential operators.\n\nAn ''S''-group scheme ''G'' is commutative if the group ''G''(''T'') is an abelian group for all ''S''-schemes ''T''.    There are several other equivalent conditions, such as conjugation inducing a trivial action, or inversion map ι being a group scheme automorphism.\n\n== Constructions ==\n\n* Given a group ''G'', one can form the constant group scheme ''G''<sub>''S''</sub>.  As a scheme, it is a disjoint union of copies of ''S'', and by choosing an identification of these copies with elements of ''G'', one can define the multiplication, unit, and inverse maps by transport of structure.  As a functor, it takes any ''S''-scheme ''T'' to a product of copies of the group ''G'', where the number of copies is equal to the number of connected components of ''T''.  ''G''<sub>''S''</sub> is affine over ''S'' if and only if ''G'' is a finite group.  However, one can take a projective limit of finite constant group schemes to get profinite group schemes, which appear in the study of fundamental groups and Galois representations or in the theory of the [[fundamental group scheme]], and these are affine of infinite type.  More generally, by taking a locally constant sheaf of groups on ''S'', one obtains a locally constant group scheme, for which [[monodromy]] on the base can induce non-trivial automorphisms on the fibers.\n* The existence of [[fiber product of schemes|fiber products of schemes]] allows one to make several constructions.  Finite direct products of group schemes have a canonical group scheme structure.  Given an action of one group scheme on another by automorphisms, one can form semidirect products by following the usual set-theoretic construction.  Kernels of group scheme homomorphisms are group schemes, by taking a fiber product over the unit map from the base.  Base change sends group schemes to group schemes.\n* Group schemes can be formed from smaller group schemes by taking [[restriction of scalars]] with respect to some morphism of base schemes, although one needs finiteness conditions to be satisfied to ensure representability of the resulting functor.  When this morphism is along a finite extension of fields, it is known as [[Weil restriction]].\n* For any abelian group ''A'', one can form the corresponding [[diagonalizable group]] ''D''(''A''), defined as a functor by setting ''D''(''A'')(''T'') to be the set of abelian group homomorphisms from ''A'' to invertible global sections of ''O''<sub>T</sub> for each ''S''-scheme ''T''.  If ''S'' is affine, ''D''(''A'') can be formed as the spectrum of a group ring.  More generally, one can form groups of multiplicative type by letting ''A'' be a non-constant sheaf of abelian groups on ''S''.\n* For a subgroup scheme ''H'' of a group scheme ''G'', the functor that takes an ''S''-scheme ''T'' to ''G''(''T'')/''H''(''T'') is in general not a sheaf, and even its sheafification is in general not representable as a scheme.  However, if ''H'' is finite, flat, and closed in ''G'', then the quotient is representable, and admits a canonical left ''G''-action by translation.  If the restriction of this action to ''H'' is trivial, then ''H'' is said to be normal, and the quotient scheme admits a natural group law.  Representability holds in many other cases, such as when ''H'' is closed in ''G'' and both are affine.<ref>{{Citation | last1=Raynaud | first1=Michel | author1-link=Michel Raynaud | title=Passage au quotient par une relation d'équivalence plate | publisher=[[Springer-Verlag]] | location=Berlin, New York |mr=0232781 | year=1967}}</ref>\n\n== Examples ==\n\n* The multiplicative group '''G'''<sub>m</sub> has the punctured affine line as its underlying scheme, and as a functor, it sends an ''S''-scheme ''T'' to the multiplicative group of invertible global sections of the structure sheaf.  It can be described as the diagonalizable group ''D''('''Z''') associated to the integers.  Over an affine base such as Spec ''A'', it is the spectrum of the ring ''A''[''x'',''y'']/(''xy''&nbsp;&minus;&nbsp;1), which is also written ''A''[''x'', ''x''<sup>&minus;1</sup>].  The unit map is given by sending ''x'' to one, multiplication is given by sending ''x'' to ''x'' ⊗ ''x'', and the inverse is given by sending ''x'' to ''x''<sup>&minus;1</sup>.  [[algebraic torus|Algebraic tori]] form an important class of commutative group schemes, defined either by the property of being locally on ''S'' a product of copies of '''G'''<sub>m</sub>, or as groups of multiplicative type associated to finitely generated free abelian groups.\n* The general linear group ''GL''<sub>''n''</sub> is an affine algebraic variety that can be viewed as the multiplicative group of the ''n'' by ''n'' matrix ring variety.  As a functor, it sends an ''S''-scheme ''T'' to the group of invertible ''n'' by ''n'' matrices whose entries are global sections of ''T''.  Over an affine base, one can construct it as a quotient of a polynomial ring in ''n''<sup>2</sup> + 1 variables by an ideal encoding the invertibility of the determinant.  Alternatively, it can be constructed using 2''n''<sup>2</sup> variables, with relations describing an ordered pair of mutually inverse matrices.\n* For any positive integer ''n'', the group μ<sub>n</sub> is the kernel of the ''n''th power map from '''G'''<sub>m</sub> to itself.  As a functor, it sends any ''S''-scheme ''T'' to the group of global sections ''f'' of ''T'' such that ''f''<sup>n</sup> = 1.  Over an affine base such as Spec ''A'', it is the spectrum of ''A''[x]/(''x''<sup>''n''</sup>&minus;1).  If ''n'' is not invertible in the base, then this scheme is not smooth.  In particular, over a field of characteristic ''p'', μ<sub>p</sub> is not smooth.\n* The additive group '''G'''<sub>a</sub> has the affine line '''A'''<sup>1</sup> as its underlying scheme.  As a functor, it sends any ''S''-scheme ''T'' to the underlying additive group of global sections of the structure sheaf.  Over an affine base such as Spec ''A'', it is the spectrum of the polynomial ring ''A''[''x''].  The unit map is given by sending ''x'' to zero, the multiplication is given by sending ''x'' to 1&nbsp;⊗&nbsp;''x''&nbsp;+&nbsp;''x''&nbsp;⊗&nbsp;1, and the inverse is given by sending ''x'' to&nbsp;&minus;''x''.\n* If ''p'' = 0 in ''S'' for some prime number ''p'', then the taking of ''p''th powers induces an endomorphism of '''G'''<sub>a</sub>, and the kernel is the group scheme α<sub>p</sub>. Over an affine base such as Spec ''A'', it is the spectrum of ''A''[x]/(''x''<sup>p</sup>).\n* The automorphism group of the affine line is isomorphic to the semidirect product of '''G'''<sub>a</sub> by '''G'''<sub>m</sub>, where the additive group acts by translations, and the multiplicative group acts by dilations.  The subgroup fixing a chosen basepoint is isomorphic to the multiplicative group, and taking the basepoint to be the identity of an additive group structure identifies '''G'''<sub>m</sub> with the automorphism group of '''G'''<sub>a</sub>.\n* A smooth genus one curve with a marked point (i.e., an [[elliptic curve]]) has a unique group scheme structure with that point as the identity.  Unlike the previous positive-dimensional examples, elliptic curves are projective (in particular proper).\n<!-- Check out page 24 of http://www.mathcs.emory.edu/~brussel/Scans/mumfordpicard.pdf -->\n\n<!-- TODO:\n* add in other linear group schemes such as GL_n, PGL, PSL\n-->\n\n== Basic properties ==\n\nSuppose that ''G'' is a group scheme of finite type over a field ''k''.  Let ''G''<sup>0</sup> be the connected component of the identity, i.e., the maximal connected subgroup scheme.  Then ''G'' is an extension of a [[étale group scheme|finite étale group scheme]] by ''G''<sup>0</sup>.  ''G'' has a unique maximal reduced subscheme ''G''<sub>red</sub>, and if ''k'' is perfect, then ''G''<sub>red</sub> is a smooth group variety that is a subgroup scheme of ''G''.  The quotient scheme is the spectrum of a local ring of finite rank.\n\nAny affine group scheme is the [[spectrum of a ring|spectrum]] of a commutative [[Hopf algebra]] (over a base ''S'', this is given by the relative spectrum of an ''O''<sub>S</sub>-algebra).  The multiplication, unit, and inverse maps of the group scheme are given by the comultiplication, counit, and antipode structures in the Hopf algebra.  The unit and multiplication structures in the Hopf algebra are intrinsic to the underlying scheme.  For an arbitrary group scheme ''G'', the ring of global sections also has a commutative Hopf algebra structure, and by taking its spectrum, one obtains the maximal affine quotient group.  Affine group varieties are known as linear algebraic groups, since they can be embedded as subgroups of general linear groups.\n\nComplete connected group schemes are in some sense opposite to affine group schemes, since the completeness implies all global sections are exactly those pulled back from the base, and in particular, they have no nontrivial maps to affine schemes.  Any complete group variety (variety here meaning reduced and geometrically irreducible separated scheme of finite type over a field) is automatically commutative, by an argument involving the action of conjugation on jet spaces of the identity.  Complete group varieties are called [[abelian variety|abelian varieties]]. This generalizes to the notion of abelian scheme; a group scheme ''G'' over a base ''S'' is abelian if the structural morphism from ''G'' to ''S'' is proper and smooth with geometrically connected fibers They are automatically projective, and they have many applications, e.g., in geometric [[class field theory]] and throughout algebraic geometry. A complete group scheme over a field need not be commutative, however; for example, any finite group scheme is complete.\n\n==Finite flat group schemes==\n\nA group scheme ''G'' over a noetherian scheme ''S'' is finite and flat if and only if ''O''<sub>''G''</sub> is a locally free ''O''<sub>''S''</sub>-module of finite rank.  The rank is a locally constant function on ''S'', and is called the order of&nbsp;''G''.  The order of a constant group scheme is equal to the order of the corresponding group, and in general, order behaves well with respect to base change and finite flat [[restriction of scalars]].\n\nAmong the finite flat group schemes, the constants (cf. example above) form a special class, and over an algebraically closed field of characteristic zero, the category of finite groups is equivalent to the category of constant finite group schemes.  Over bases with positive characteristic or more arithmetic structure, additional isomorphism types exist.  For example, if 2 is invertible over the base, all group schemes of order 2 are constant, but over the 2-adic integers, μ<sub>2</sub> is non-constant, because the special fiber isn't smooth.  There exist sequences of highly ramified 2-adic rings over which the number of isomorphism types of group schemes of order 2 grows arbitrarily large.  More detailed analysis of commutative finite flat group schemes over ''p''-adic rings can be found in Raynaud's work on prolongations.\n\nCommutative finite flat group schemes often occur in nature as subgroup schemes of abelian and semi-abelian varieties, and in positive or mixed characteristic, they can capture a lot of information about the ambient variety.  For example, the ''p''-torsion of an elliptic curve in characteristic zero is locally isomorphic to the constant elementary abelian group scheme of order ''p''<sup>2</sup>, but over '''F'''<sub>p</sub>, it is a finite flat group scheme of order ''p''<sup>2</sup> that has either ''p'' connected components (if the curve is ordinary) or one connected component (if the curve is [[supersingular]]).  If we consider a family of elliptic curves, the ''p''-torsion forms a finite flat group scheme over the parametrizing space, and the supersingular locus is where the fibers are connected.  This merging of connected components can be studied in fine detail by passing from a modular scheme to a [[rigid analytic space]], where supersingular points are replaced by discs of positive radius.\n\n==Cartier duality==\n\n{{main|Cartier duality}}\nCartier duality is a scheme-theoretic analogue of [[Pontryagin duality]] taking finite commutative group schemes to finite commutative group schemes.\n\n==Dieudonné modules==\n\n{{main|Dieudonné module}}\nFinite flat commutative group schemes over a perfect field ''k'' of positive characteristic ''p'' can be studied by transferring their geometric structure to a (semi-)linear-algebraic setting.  The basic object is the [[Dieudonné ring]] ''D'' = ''W''(''k''){''F'',''V''}/(''FV''&nbsp;&minus;&nbsp;''p''), which is a quotient of the ring of noncommutative polynomials, with coefficients in [[Witt vectors]] of ''k''.  ''F'' and ''V'' are the Frobenius and [[Verschiebung]] operators, and they may act nontrivially on the Witt vectors.  Dieudonne and Cartier constructed an antiequivalence of categories between finite commutative group schemes over ''k'' of order a power of \"p\" and modules over ''D'' with finite ''W''(''k'')-length.  The Dieudonné module functor in one direction is given by homomorphisms into the abelian sheaf ''CW'' of Witt co-vectors.  This sheaf is more or less dual to the sheaf of Witt vectors (which is in fact representable by a group scheme), since it is constructed by  taking a direct limit of finite length Witt vectors under successive Verschiebung maps ''V'': ''W''<sub>n</sub> → ''W''<sub>n+1</sub>, and then completing.  Many properties of commutative group schemes can be seen by examining the corresponding Dieudonné modules, e.g., connected ''p''-group schemes correspond to ''D''-modules for which ''F'' is nilpotent, and étale group schemes correspond to modules for which ''F'' is an isomorphism.\n\nDieudonné theory exists in a somewhat more general setting than finite flat groups over a field.  Oda's 1967 thesis gave a connection between Dieudonné modules and the first de Rham cohomology of abelian varieties, and at about the same time, Grothendieck suggested that there should be a crystalline version of the theory that could be used to analyze ''p''-divisible groups.  Galois actions on the group schemes transfer through the equivalences of categories, and the associated deformation theory of Galois representations was used in [[Andrew Wiles|Wiles]]'s work on the [[Shimura–Taniyama conjecture]].\n\n== See also ==\n*[[Invariant theory]]\n*[[Geometric invariant theory]]\n*[[GIT quotient]]\n*[[Quotient stack]]\n*[[groupoid scheme]]\n*[[Group-scheme action]]\n*[[Group-stack]]\n\n==References==\n<references/>\n\n*{{cite book\n |editor-last=Demazure\n |editor-first=Michel\n |editor2=[[Alexandre Grothendieck]]\n | title = Séminaire de Géométrie Algébrique du Bois Marie &ndash; 1962&ndash;64 &ndash; Schémas en groupes &ndash; (SGA 3) &ndash; vol. 1 (Lecture notes in mathematics '''151''')\n | year = 1970\n | publisher = [[Springer Science+Business Media|Springer-Verlag]]\n | location = Berlin; New York\n | language = French\n | pages = xv, 564\n}}\n*{{cite book\n |editor-last=Demazure\n |editor-first=Michel\n |editor2=[[Alexandre Grothendieck]]\n | title = Séminaire de Géométrie Algébrique du Bois Marie &ndash; 1962&ndash;64 &ndash; Schémas en groupes &ndash; (SGA 3) &ndash; vol. 2 (Lecture notes in mathematics '''152''')\n | year = 1970\n | publisher = [[Springer Science+Business Media|Springer-Verlag]]\n | location = Berlin; New York\n | language = French\n | pages = ix, 654\n}}\n*{{cite book\n |editor-last=Demazure\n |editor-first=Michel\n |editor2=[[Alexandre Grothendieck]]\n | title = Séminaire de Géométrie Algébrique du Bois Marie &ndash; 1962&ndash;64 &ndash; Schémas en groupes &ndash; (SGA 3) &ndash; vol. 3 (Lecture notes in mathematics '''153''')\n | year = 1970\n | publisher = [[Springer Science+Business Media|Springer-Verlag]]\n | location = Berlin; New York\n | language = French\n | pages = vii, 529\n}}\n*{{cite book |author1=Gabriel, Peter |author2=Demazure, Michel |title=Introduction to algebraic geometry and algebraic groups |publisher=North-Holland Pub. Co |location=Amsterdam |year=1980 |pages= |isbn=0-444-85443-6 |oclc= |doi= |accessdate=}}\n*Berthelot, Breen, Messing ''Théorie de Dieudonné Crystalline II''\n*Laumon, ''Transformation de Fourier généralisée''\n* {{Citation | last1=Shatz | first1=Stephen S. | editor1-last=Cornell | editor1-first=Gary | editor2-last=Silverman | editor2-first=Joseph H. | editor2-link=Joseph H. Silverman | title=Arithmetic geometry (Storrs, Conn., 1984) | publisher=[[Springer-Verlag]] | location=Berlin, New York | isbn=978-0-387-96311-2  |mr=861972 | year=1986 | chapter=Group schemes, formal groups, and ''p''-divisible groups | pages=29–78}}\n* {{Citation | last1=Serre | first1=Jean-Pierre | author1-link=Jean-Pierre Serre | title=Groupes algébriques et corps de classes | publisher=Hermann | location=Paris | series=Publications de l'Institut Mathématique de l'Université de Nancago [Publications of the Mathematical Institute of the University of Nancago], 7 | isbn=978-2-7056-1264-1 |mr=907288 | year=1984}}\n*[[John Tate]], ''Finite flat group schemes'', from ''Modular Forms and Fermat's Last Theorem''\n* {{Citation | last1=Waterhouse | first1=William | author1-link=William_C._Waterhouse | title=Introduction to affine group schemes | publisher=[[Springer-Verlag]] | location=Berlin, New York | series=Graduate Texts in Mathematics | isbn=978-0-387-90421-4 | year=1979 | volume=66 | doi=10.1007/978-1-4612-6217-6 | mr=0547117}}\n\n[[Category:Algebraic groups]]\n[[Category:Scheme theory]]\n[[Category:Hopf algebras]]\n[[Category:Duality theories]]"
    },
    {
      "title": "H-space",
      "url": "https://en.wikipedia.org/wiki/H-space",
      "text": "In [[mathematics]], an '''H-space''',<ref>The H in H-space was suggested by [[Jean-Pierre Serre]] in recognition of the influence exerted on the subject by [[Heinz Hopf]] (see J. R. Hubbuck. \"A Short History of H-spaces\", History of topology, 1999, pages 747–755).</ref> or a '''topological [[unital magma]]''', is a [[topological space]] ''X'' (generally assumed to be [[connected space|connected]]) together with a continuous map μ : ''X'' &times; ''X'' → ''X'' with an [[identity element]] ''e'' such that μ(''e'', ''x'') = μ(''x'', ''e'') = ''x'' for all ''x'' in ''X''.  Alternatively, the maps μ(''e'', ''x'') and μ(''x'', ''e'') are sometimes only required to be [[homotopic]] to the identity (in this case ''e'' is called homotopy identity), sometimes through basepoint preserving maps.  These three definitions are in fact equivalent for H-spaces that are [[CW complex]]es.  Every [[topological group]] is an H-space; however, in the general case, as compared to a topological group, H-spaces may lack [[associativity]] and [[inverse element|inverses]].\n\n==Examples and properties==\n\nThe multiplicative structure of an H-space adds structure to its [[homology group|homology]] and [[cohomology group]]s.  For example, the [[cohomology ring]] of a [[path-connected]] H-space with finitely generated and free cohomology groups is a [[Hopf algebra]].  Also, one can define the [[Pontryagin product]] on the homology groups of an H-space.\n\nThe [[fundamental group]] of an H-space is [[abelian group|abelian]].  To see this, let ''X'' be an H-space with identity ''e'' and let ''f'' and ''g'' be loops at ''e''.  Define a map ''F'': [0,1]&times;[0,1] → ''X'' by ''F''(''a'',''b'') = ''f''(''a'')''g''(''b'').  Then ''F''(''a'',0) = ''F''(''a'',1) = ''f''(''a'')''e'' is homotopic to ''f'', and ''F''(0,''b'') = ''F''(1,''b'') = ''eg''(''b'') is homotopic to ''g''.  It is clear how to define a homotopy from [''f''][''g''] to [''g''][''f''].\n\nAdams' [[Hopf invariant|Hopf invariant one]] theorem, named after [[Frank Adams]], states that ''S''<sup>0</sup>, ''S''<sup>1</sup>, ''S''<sup>3</sup>, ''S''<sup>7</sup> are the only [[n-sphere|spheres]] that are H-spaces. Each of these spaces forms an H-space by viewing it as the subset of norm-one elements of the [[real number|reals]], [[complex number|complexes]], [[quaternion]]s, and [[octonion]]s, respectively, and using the multiplication operations from these algebras. In fact, ''S''<sup>0</sup>, ''S''<sup>1</sup>, and ''S''<sup>3</sup> are groups ([[Lie group]]s) with these multiplications. But ''S''<sup>7</sup> is not a group in this way because octonion multiplication is not associative, nor can it be given any other continuous multiplication for which it is a group.\n\n==See also==\n*[[Topological group]]\n*[[Čech cohomology]]\n*[[Hopf algebra]]\n*[[Topological monoid]]\n\n==Notes==\n{{reflist}}\n\n==References==\n*{{citation| last=Hatcher |first= Allen |authorlink=Allen Hatcher|title=Algebraic Topology |url=http://www.math.cornell.edu/~hatcher/AT/ATpage.html |year= 2002 |publisher=Cambridge University Press |place=Cambridge |isbn=0-521-79540-0}}.  Section 3.C\n*{{citation\n | last = Stasheff | first = James D. |authorlink=Jim Stasheff|\n | journal = [[Transactions of the American Mathematical Society]]\n | mr = 0158400\n | pages = 275–292, 293–312\n | title = Homotopy associativity of ''H''-spaces. I, II\n | volume = 108\n | year = 1963\n | doi=10.2307/1993609}}.\n* {{citation| last=Stasheff|first= James D.|authorlink=Jim Stasheff|title= H-spaces from a Homotopy Point of View|publisher=Springer|place=Berlin| year = 2006}}.\n\n\n{{DEFAULTSORT:H-Space}}\n[[Category:Homotopy theory]]\n[[Category:Algebraic topology]]\n[[Category:Hopf algebras]]"
    },
    {
      "title": "Hopf algebra of permutations",
      "url": "https://en.wikipedia.org/wiki/Hopf_algebra_of_permutations",
      "text": "In algebra, the '''Malvenuto–Poirier–Reutenauer Hopf algebra of permutations''' or '''MPR Hopf algebra'''  is a [[Hopf algebra]] with a basis of all elements of all the finite symmetric groups ''S''<sub>''n''</sub>, and is a non-commutative analogue of the [[Hopf algebra of symmetric functions]]. It is both [[Free algebra|free]] as an [[Algebra (ring theory)|algebra]] and graded-[[Cofree coalgebra|cofree]] as a graded [[coalgebra]], so is in some sense as far as possible from being either commutative or cocommutative. It was introduced by {{harvtxt|Malvenuto|Reutenauer|1994}} and studied by {{harvtxt|Poirier|Reutenauer|1995}}.\n\n==Definition==\n\nThe underlying [[free abelian group]] of the MPR algebra has a basis consisting of the disjoint union of the symmetric groups ''S''<sub>''n''</sub> for ''n'' = 0, 1, 2, .... , which can be thought of as permutations.\n\nThe identity 1 is the empty permutation, and the counit takes the empty permutation to 1 and the others to 0.\n\nThe product of two permutations (''a''<sub>1</sub>,...,''a''<sub>''m''</sub>) and  (''b''<sub>1</sub>,...,''b''<sub>''n''</sub>) in MPR is\ngiven by the [[shuffle product]]  (''a''<sub>1</sub>,...,''a''<sub>''m''</sub>) ''ш'' (''m''&nbsp;+&nbsp;''b''<sub>1</sub>,...,''m''&nbsp;+&nbsp;''b''<sub>''n''</sub>).\n\nThe coproduct of a permutation ''a'' on ''m'' points is given by Σ<sub>''a''=''b''*''c''</sub>&nbsp;st(''b'')&nbsp;⊗&nbsp;st(''c''), where the sum is over the ''m''&nbsp;+&nbsp;1 ways to write ''a'' (considered as a sequence of ''m'' integers) as a concatenation of two sequences ''b'' and ''c'', and st(''b'') is the standardization of ''b'', where the elements of the sequence ''b'' are reduced to be a set of the form {1,&nbsp;2,&nbsp;...,&nbsp;''n''} while preserving their order.\n\nThe antipode has infinite order.\n\n==Relation to other algebras==\n\nThe Hopf algebra of permutations relates the rings of [[symmetric function]]s, [[quasisymmetric function]]s, and [[noncommutative symmetric function]]s, (denoted Sym, QSym, and NSym respectively), as depicted the following commutative diagram.  The duality between QSym and NSym is shown in the main diagonal of this diagram.\n\n[[Image:QSymDiagram.png|300px|(Relationship between QSym and nearby neighbors)]]\n\n==References==\n\n*{{citation | MR=2724822 | zbl=1211.16023\n|last=Hazewinkel|first= Michiel|last2= Gubareni|first2= Nadiya|last3= Kirichenko|first3= V. V.\n|title=Algebras, rings and modules.  Lie algebras and Hopf algebras|series= Mathematical Surveys and Monographs|volume= 168|publisher= American Mathematical Society|place= Providence, RI|year= 2010|ISBN= 978-0-8218-5262-0 }}\n*{{citation|mr=1358493 \n|last=Malvenuto|first= Claudia|last2= Reutenauer|first2=Christophe\n|title=Duality between quasi-symmetric functions and the Solomon descent algebra\n|journal=J. Algebra |volume=177 |year=1995|issue= 3|pages= 967–982|doi=10.1006/jabr.1995.1336}}\n*{{citation|MR=1334836 \n|last=Poirier|first= Stéphane|last2= Reutenauer|first2= Christophe\n|title=Algèbres de Hopf de tableaux\n|journal=Ann. Sci. Math. Québec|volume= 19 |year=1995|issue= 1|pages= 79–90}}\n\n[[Category:Hopf algebras]]"
    },
    {
      "title": "Hopf algebroid",
      "url": "https://en.wikipedia.org/wiki/Hopf_algebroid",
      "text": "In mathematics, in the theory of [[Hopf algebra]]s, a '''Hopf algebroid''' is a generalisation of weak Hopf algebras, certain skew Hopf algebras and commutative Hopf ''k''-algebroids. If ''k'' is a field, a commutative ''k''-algebroid is a cogroupoid object in the category of ''k''-algebras; the category of such is hence dual to the category of groupoid ''k''-schemes. This commutative version has been used in 1970-s in [[algebraic geometry]] and [[stable homotopy theory]]. The generalization of Hopf algebroids and its main part of the structure, [[associative bialgebroid]]s, to the noncommutative base algebra was introduced by J.-H. Lu in 1996 as a result on work on [[groupoid]]s in [[Poisson geometry]] (later shown equivalent in nontrivial way to a construction of Takeuchi from the 1970s and another by Xu around the year 2000). They may be loosely thought of as Hopf algebras over a noncommutative base ring, where weak Hopf algebras become Hopf algebras over a [[separable algebra]].  It is a theorem that a Hopf algebroid satisfying a finite projectivity condition over a separable algebra is a weak Hopf algebra, and conversely a weak Hopf algebra ''H'' is a Hopf algebroid over its separable subalgebra ''H<sup>L</sup>''. The antipode axioms have been changed by G. Böhm and K. Szlachányi (J. Algebra) in 2004 for tensor categorical reasons and to accommodate examples associated to depth two [[Frobenius algebra]] extensions.\n\n==Definition==\nA left Hopf algebroid (''H'', ''R'')  is a left bialgebroid together with an antipode: the bialgebroid (''H'', ''R'') consists of a total algebra ''H'' and a base algebra ''R'' and two mappings, an algebra homomorphism ''s'': ''R'' → ''H'' called a source map, an algebra anti-homomorphism ''t'': ''R'' → ''H'' called a target map, such that the commutativity condition ''s''(''r''<sub>1</sub>) ''t''(''r''<sub>2</sub>) = ''t''(''r''<sub>2</sub>) ''s''(''r''<sub>1</sub>) is satisfied for all ''r''<sub>1</sub>, ''r''<sub>2</sub> ∈ ''R''.  The axioms resemble those of a Hopf algebra but  are complicated by the possibility that ''R'' is a non-commutative algebra or its images under ''s'' and ''t'' are not in the center of ''H''. In particular a left bialgebroid (''H'', ''R'')  has an ''R''-''R''-bimodule structure on ''H'' which prefers the left side as follows:  ''r''<sub>1</sub> ⋅ ''h'' ⋅ ''r''<sub>2</sub> = ''s''(''r''<sub>1</sub>) ''t''(''r''<sub>2</sub>) ''h'' for all ''h'' in ''H'', ''r''<sub>1</sub>, ''r''<sub>2</sub> ∈ ''R''.  There is a coproduct Δ: ''H'' → ''H'' ⊗<sub>''R''</sub> ''H'' and counit ε: ''H'' → ''R''  that make (''H'', ''R'', Δ, ε) an ''R''-coring (with axioms like that of a [[coalgebra]] such that all mappings are ''R''-''R''-bimodule homomorphisms and all tensors over ''R'').  Additionally the bialgebroid (''H'', ''R'') must satisfy Δ(''ab'') = Δ(''a'')Δ(''b'') for all ''a'', ''b'' in ''H'', and a condition to make sure this last condition makes sense:  every image point Δ(''a'') satisfies ''a''<sub>(1)</sub> ''t''(''r'') ⊗ ''a''<sub>(2)</sub> =  ''a''<sub>(1)</sub> ⊗ ''a''<sub>(2)</sub> ''s''(''r'') for all ''r'' in ''R''. Also Δ(1) = 1 ⊗ 1.  The counit is required to satisfy ε(1<sub>''H''</sub>) = 1<sub>''R''</sub> and the condition ε(''ab'') = ε(''as''(ε(''b''))) = ε(''at''(ε(''b''))).\n\nThe antipode ''S'': ''H'' → ''H'' is usually taken to be an algebra anti-automorphism satisfying conditions of exchanging the source and target maps and satisfying two axioms like Hopf algebra antipode axioms;  see the references in Lu or in Böhm-Szlachányi for a more example-category friendly, though somewhat more complicated, set of axioms for the antipode ''S''.  The latter set of  axioms depend on the axioms of a right bialgebroid as well, which are a straightforward switching of left to right, ''s'' with ''t'', of the axioms for a left bialgebroid given above.\n\n==Examples==\nAs an example of left bialgebroid, take ''R'' to be any algebra over a field ''k''.  Let ''H'' be its algebra of linear self-mappings. Let s(r) be left multiplication by ''r'' on ''R''; let ''t''(''r'') be right multiplication by ''r'' on ''R''.  ''H'' is a left bialgebroid over ''R'', which may be seen as follows.  From the fact that ''H'' ⊗<sub>''R''</sub> ''H'' ≅ Hom<sub>''k''</sub>(''R'' ⊗ ''R'', ''R'') one may define a coproduct by Δ(''f'')(''r'' ⊗ ''u'') = ''f''(''ru'') for each linear transformation ''f'' from ''R'' to itself and all ''r'', ''u'' in ''R''. Coassociativity of the coproduct follows from associativity of the product on R.  A counit  is given by ε(''f'') = ''f''(1). The counit axioms of a coring follow from the identity element condition on multiplication in ''R''. The reader will be amused, or at least edified, to check that (''H'', ''R'') is a left bialgebroid.  In case ''R'' is an [[Azumaya algebra]], in which case ''H'' is isomorphic to ''R'' ⊗ ''R'', an antipode comes from transposing tensors, which makes ''H'' a Hopf algebroid over ''R''.  Another class of examples comes from letting  ''R'' be the ground field; in this case, the Hopf algebroid (''H'', ''R'') is a Hopf algebra.\n\n==References==\n\n{{Empty section|date=July 2014}}\n\n==Further reading==\n* {{cite book | last1=Böhm | first1=Gabriella | chapter=An alternative notion of Hopf algebroid | zbl=1080.16034 | editor1-last=Caenepeel | editor1-first=Stefaan | title=Hopf algebras in noncommutative geometry and physics. Proceedings of the conference on Hopf algebras and quantum groups, Brussels, Belgium, May 28–June 1, 2002 | location=New York, NY | publisher=Marcel Dekker | isbn=978-0-8247-5759-5 | series=Lecture Notes in Pure and Applied Mathematics | volume=239 | pages=31–53 | year=2005 }}\n* {{cite journal | last1=Böhm | first1=Gabriella | last2=Szlachányi | first2=Kornél | title=Hopf algebroid symmetry of abstract Frobenius extensions of depth 2 | zbl=1080.16036 | journal=Commun. Algebra | volume=32 | issue=11 | pages=4433–4464 | year=2004 | doi=10.1081/AGB-200034171 | arxiv=math/0305136 }}\n* Jiang-Hua Lu, \"Hopf algebroids and quantum groupoids\", Int. J. Math. 7, n. 1 (1996) pp. 47-70, https://arxiv.org/abs/q-alg/9505024, http://www.ams.org/mathscinet-getitem?mr=95e:16037, https://dx.doi.org/10.1142/S0129167X96000050\n\n[[Category:Hopf algebras]]"
    },
    {
      "title": "K-Poincaré algebra",
      "url": "https://en.wikipedia.org/wiki/K-Poincar%C3%A9_algebra",
      "text": "In [[physics]] and [[mathematics]], the '''κ-Poincaré algebra''', named after [[Henri Poincaré]], is a deformation of the [[Poincaré algebra]] into a [[Hopf algebra]]. In the [[bicrossproduct]] basis, introduced by Majid-Ruegg<ref>Majid-Ruegg, Phys. Lett. B '''334''' (1994) 348, ArXiv:[https://arxiv.org/abs/hep-th/9405107 hep-th/9405107]</ref> its commutation rules reads:\n\n* <math>[P_\\mu, P_\\nu] = 0 </math>\n* <math> [R_j , P_0] = 0, \\; [R_j , P_k] = i \\varepsilon_{jkl} P_l, \\; [R_j , N_k] = i \\varepsilon_{jkl} N_l, \\; [R_j , R_k] = i \\varepsilon_{jkl} R_l</math>\n* <math>[N_j , P_0] = i P_j, \\;[N_j , P_k] = i \\delta_{jk} \\left(  \\frac{1 - e^{- 2 \\lambda P_0}}{2 \\lambda}  + \\frac{ \\lambda }{2}  |\\vec{P}|^2 \\right) - i \\lambda P_j P_k, \\; [N_j,N_k] = -i \\varepsilon_{jkl} R_l</math>\n\nWhere <math>P_\\mu</math> are the translation generators, <math>R_j</math> the rotations and <math>N_j</math> the boosts.\nThe [[coproducts]] are:\n* <math>\\Delta P_j =  P_j \\otimes 1 +  e^{- \\lambda P_0} \\otimes P_j ~, \\qquad \\Delta P_0  = P_0 \\otimes 1 + 1 \\otimes P_0</math>\n* <math>\\Delta R_j  = R_j \\otimes 1 +  1 \\otimes R_j</math>\n* <math>\\Delta N_k  =  N_k \\otimes 1 + e^{-\\lambda P_0} \\otimes N_k  + i \\lambda \\varepsilon_{klm}  P_l \\otimes R_m .</math>\n\nThe [[Hopf algebra|antipodes]] and the [[Hopf algebra|counits]]:\n* <math>S(P_0) =  - P_0</math>\n* <math>S(P_j) =  -e^{\\lambda P_0} P_j</math>\n* <math>S(R_j) =  - R_j</math>\n* <math>S(N_j)  =  -e^{\\lambda P_0}N_j +i \\lambda \\varepsilon_{jkl} e^{\\lambda P_0} P_k R_l</math>\n* <math>\\varepsilon(P_0) =  0</math>\n* <math>\\varepsilon(P_j) =  0</math>\n* <math>\\varepsilon(R_j) =  0</math>\n* <math>\\varepsilon(N_j)  = 0</math>\n\nThe κ-Poincaré algebra is the dual Hopf algebra to the [[κ-Poincaré group]], and can be interpreted as its “infinitesimal” version.\n\n==References==\n{{Reflist}}\n\n{{DEFAULTSORT:K-Poincare algebra}}\n[[Category:Hopf algebras]]\n[[Category:Mathematical physics]]\n\n\n{{algebra-stub}}\n{{physics-stub}}"
    },
    {
      "title": "K-Poincaré group",
      "url": "https://en.wikipedia.org/wiki/K-Poincar%C3%A9_group",
      "text": "{{unreferenced|date=May 2014}}\nIn [[physics]] and [[mathematics]], the '''κ-Poincaré group''', named after [[Henri Poincaré]], is a [[quantum group]], obtained by deformation of the [[Poincaré group]] into a [[Hopf algebra]].\nIt is generated by the elements <math> a^\\mu </math> and <math>{\\Lambda^\\mu}_\\nu</math> with the usual constraint:\n\n: <math>\n\\eta^{\\rho \\sigma} {\\Lambda^\\mu}_\\rho {\\Lambda^\\nu}_\\sigma = \\eta^{\\mu \\nu} ~,\n</math>\nwhere <math>\\eta^{\\mu \\nu}</math> is the [[Minkowski space|Minkowskian metric]]:\n\n: <math>\n\\eta^{\\mu \\nu} = \\left(\\begin{array}{cccc} -1 & 0 & 0 & 0 \\\\ 0 & 1 & 0 & 0 \\\\ 0 & 0 & 1 & 0 \\\\ 0 & 0 & 0 & 1 \\end{array} \\right) ~.\n</math>\n\nThe commutation rules reads:\n* <math>[a_j ,a_0] = i \\lambda a_j ~, \\; [a_j,a_k]=0 </math>\n* <math> [a^\\mu , {\\Lambda^\\rho}_\\sigma  ]  = i \\lambda \\left\\{ \\left( {\\Lambda^\\rho}_0 - {\\delta^\\rho}_0 \\right) {\\Lambda^\\mu}_\\sigma - \\left( {\\Lambda^\\alpha}_\\sigma \\eta_{\\alpha 0}  + \\eta_{\\sigma 0} \\right) \\eta^{\\rho \\mu} \\right\\} </math>\n\nIn the (1&nbsp;+&nbsp;1)-dimensional case the commutation rules between <math> a^\\mu </math> and <math>{\\Lambda^\\mu}_\\nu</math> are particularly simple. The Lorentz generator in this case is:\n\n: <math>{\\Lambda^\\mu}_\\nu = \\left( \\begin{array}{cc} \\cosh \\tau  & \\sinh \\tau \\\\ \\sinh \\tau & \\cosh \\tau \\end{array} \\right) </math>\n\nand the commutation rules reads:\n\n* <math> [ a_0 , \\left( \\begin{array}{c} \\cosh \\tau \\\\ \\sinh \\tau \\end{array} \\right) ] = i \\lambda ~ \\sinh \\tau \\left( \\begin{array}{c} \\sinh \\tau \\\\ \\cosh \\tau \\end{array} \\right) </math>\n* <math> [ a_1 , \\left( \\begin{array}{c} \\cosh \\tau \\\\ \\sinh \\tau \\end{array} \\right) ] = i \\lambda \\left( 1- \\cosh \\tau \\right) \\left( \\begin{array}{c} \\sinh \\tau \\\\ \\cosh \\tau \\end{array} \\right) </math>\n\nThe [[coproducts]] are classical, and encode the group composition law:\n* <math>\\Delta a^\\mu = {\\Lambda^\\mu}_\\nu \\otimes a^\\nu + a^\\mu \\otimes 1 </math>\n* <math>\\Delta {\\Lambda^\\mu}_\\nu  = {\\Lambda^\\mu}_\\rho \\otimes {\\Lambda^\\rho}_\\nu </math>\n\nAlso the [[Hopf algebra|antipodes]] and the [[Hopf algebra|counits]] are classical, and represent the group inversion law and the map to the identity:\n* <math>S(a^\\mu) = - {(\\Lambda^{-1})^\\mu}_\\nu a^\\nu </math>\n* <math>S({\\Lambda^\\mu}_\\nu) = {(\\Lambda^{-1})^\\mu}_\\nu = {\\Lambda_\\nu}^\\mu </math>\n* <math>\\varepsilon (a^\\mu) = 0</math>\n* <math>\\varepsilon ({\\Lambda^\\mu}_\\nu) ={\\delta^\\mu}_\\nu </math>\n\nThe κ-Poincaré group is the dual Hopf algebra to the [[K-Poincaré algebra]], and can be interpreted as its “finite” version.\n\n==References==\n{{Reflist}}\n\n{{DEFAULTSORT:K-Poincare group}}\n[[Category:Hopf algebras]]\n[[Category:Mathematical physics]]\n\n\n{{algebra-stub}}\n{{physics-stub}}"
    },
    {
      "title": "List of finite-dimensional Nichols algebras",
      "url": "https://en.wikipedia.org/wiki/List_of_finite-dimensional_Nichols_algebras",
      "text": "In mathematics, a [[Nichols algebra]] is a [[Hopf algebra]] in a [[braided monoidal category|braided category]] assigned to an object ''V'' in this category (e.g. a [[braided vector space]]). The Nichols algebra is a quotient of the [[tensor algebra]] of ''V'' enjoying a certain [[universal property]] and is typically infinite-dimensional. Nichols algebras appear naturally in any pointed Hopf algebra and enabled their classification in important cases.<ref name=AS02>Andruskiewitsch, Schneider: ''Pointed Hopf algebras'',  New directions in Hopf algebras,  1–68, Math. Sci. Res. Inst. Publ., 43, Cambridge Univ. Press, Cambridge, 2002.</ref> The most well known examples for Nichols algebras are the [[Borel subgroup#Lie algebra|Borel parts]] <math>U_q(\\mathfrak{g})^+</math> of the infinite-dimensional [[quantum groups]] when ''q'' is no root of unity, and the first examples of finite-dimensional Nichols algebras are the [[Borel subgroup#Lie algebra|Borel parts]] <math>u_q(\\mathfrak{g})^+</math> of the Frobenius–Lusztig kernel (''small quantum group'') when ''q'' is a root of unity.\n\nThe following article lists all known finite-dimensional Nichols algebras <math>\\mathfrak{B}(V)</math> where <math>V</math> is a [[Yetter–Drinfeld category|Yetter–Drinfel'd module]] over a finite group <math>G</math>, where the group is generated by the support of <math>V</math>. For more details on Nichols algebras see [[Nichols algebra]].\n* There are two major cases:\n** <math>G</math> '''abelian''', which implies <math>V</math> is diagonally braided <math>x_i\\otimes x_j\\mapsto q_{ij}x_j\\otimes x_i</math>.\n** <math>G</math> '''nonabelian'''.\n* The '''rank''' is the number of irreducible summands <math>V=\\bigoplus_{i\\in I} V_i</math> in the semisimple Yetter–Drinfel'd module <math>V</math>. \n* The '''irreducible summands''' <math>V_i=\\mathcal{O}_{[g]}^\\chi</math> are each associated to a [[conjugacy class]] <math>[g]\\subset G</math> and an irreducible representation <math>\\chi</math> of the centralizer <math>\\operatorname{Cent}(g)</math>.\n* To any Nichols algebra there is by <ref name=\"AHS10\"/> attached \n** a generalized '''root system''' and a Weyl groupoid. These are classified in.<ref name=\"CH13\"/> \n** In particular '''several Dynkin diagrams''' (for inequivalent types of Weyl chambers). Each Dynkin diagram has one vertex per irreducible <math>V_i</math> and edges depending on their braided commutators in the Nichols algebra.  \n* The '''[[Hilbert series]]''' of the graded algebra <math>\\mathfrak{B}(V)</math> is given. An observation is that it factorizes in each case into polynomials <math>(n)_t:=1+t+t^2+\\cdots + t^{n-1}</math>. We only give the Hilbert series and dimension of the Nichols algebra in characteristic <math>0</math>.\n\nNote that a Nichols algebra only depends on the braided vector space <math>V</math> and can therefore be realized over many different groups. Sometimes there are two or three Nichols algebras with different <math>V</math> and non-isomorphic Nichols algebra, which are closely related (e.g. cocycle twists of each other). These are given by different conjugacy classes in the same column.\n\n== State of classification ==\n\n(as of 2015)\n\n=== Established classification results ===\n\n* Finite-dimensional diagonal Nichols algebras over the complex numbers were classified by Heckenberger in.<ref name=H09/> The case of arbitrary characteristic is ongoing work of Heckenberger, Wang.<ref name=HW14/>\n* Finite-dimensional Nichols algebras of semisimple Yetter–Drinfel'd modules of rank >1 over finite nonabelian groups (generated by the support) were classified by Heckenberger and Vendramin in.<ref name=HV14/>\n\n=== Negative criteria ===\n\nThe case of rank 1 (irreducible Yetter–Drinfel'd module) over a nonabelian group is still largely open, with few examples known.\n\nMuch progress has been made by Andruskiewitsch and others by finding subracks (for example diagonal ones) that would lead to infinite-dimensional Nichols algebras. As of 2015, known groups '''not''' admitting finite-dimensional Nichols algebras are <ref name=AFGV10a/><ref name=AFGV10b/> \n* for [[alternating group]]s <math>\\mathbb{A}_{n\\geq 5}</math> <ref name=AFGV10c/>\n* for [[symmetric group]]s <math>\\mathbb{S}_{n\\geq 6}</math> except a short list of examples<ref name=AFGV10c/>\n* some [[group of Lie type]] such as most <math>PSL_n(\\mathbb{F}_q)</math><ref name=AGC13/> and most unipotent classes in <math>Sp_{2n}(\\mathbb{F}_q)</math><ref name=AGC14/> \n* all [[sporadic group]]s except a short list of possibilities (resp. conjugacy classes in ATLAS notation) that are all real or ''j'' = 3-quasireal:\n**...for the [[Fisher group]] <math>Fi_{22}\\;</math> the classes <math>22A,22B\\;</math>\n**...for the [[baby monster group]] ''B'' the classes <math>16C,\\;16D,\\;32A,\\;32B,\\;32C,\\;32D,\\;34A,\\;46A,\\;46B\\;</math>\n**...for the [[monster group]] ''M'' the classes <math>32A,\\;32B,\\;46A,\\;46B,\\;92A,\\;92B,\\;94A,\\;94B\\;</math>\nUsually a large amount of conjugacy classes ae of type D (\"not commutative enough\"), while the others tend to possess sufficient abelian subracks and can be excluded by their consideration. Several cases have to be done by-hand. Note that the open cases tend to have very small centralizers (usually cyclic) and representations χ (usually the 1-dimensional sign representation). Significant exceptions are the conjugacy classes of order 16, 32 having as centralizers [[p-group]]s of order 2048 resp. 128 and currently no restrictions on χ.\n\n== Over abelian groups ==\n\nFinite-dimensional diagonal Nichols algebras over the complex numbers were classified by Heckenberger in <ref name=H09/> in terms of the braiding matrix <math>q_{ij}</math>, more precisely the data <math>q_{ii},q_{ij}q_{ji}</math>.  The small quantum groups <math>u_q(\\mathfrak{g})^+</math> are a special case  <math>q_{ij}=q^{(\\alpha_i,\\alpha_j)}</math>, but there are several exceptional examples involving the primes 2,3,4,5,7.\n\nRecently there has been progress understanding the other examples as exceptional Lie algebras and super-Lie algebras in finite characteristic.\n\n== Over nonabelian group, rank > 1 ==\n\n=== Nichols algebras from Coxeter groups ===\nFor every finite coxeter system  <math> (W,S) </math> the Nichols algebra over the conjugacy class(es) of reflections was studied in <ref name=MS00/> (reflections on roots of different length are not conjugate, see fourth example fellow). They discovered in this way the following first Nichols algebras over nonabelian groups :\n\n{| class=\"wikitable\" \n! scope=\"col\" width=\"150px\" |\n| [[File:Nichols Algebra over S3.png|80px]]\n| [[File:Nichols Algebra over S4.png|80px]]\n| [[File:Nichols Algebra over S5.png|100px]] \n| [[File:Nichols Algebra over D4.png|160px]]\n|-\n!  Rank, Type of root system of <math> \\mathfrak{B}(V) </math> <ref name=AHS10/> \n|  <math>A_1</math>\n|  <math>A_1</math>\n|  <math>A_1</math>\n|  <math>A_2</math>\n|-\n! Dimension of <math> V </math>\n| <math>3</math>\n| <math>6</math>\n| <math>10</math>\n| <math>2+2</math>\n|-\n! Dimension of Nichols algebra(s) \n| <math>12</math>\n| <math>576\\;=24^2</math>\n| <math>8294400</math>\n| <math>64</math>\n|-\n! [[Hilbert series]]\n| <math> (2)_t^2 (3)_t </math>\n| <math>(2)^2_t (3)^2_t (4)^2_t</math>\n| <math>(4)_t^4 (5)_t^2 (6)_t^4</math>\n| <math>(2)^4_{t} (2)^2_{t^2}</math>\n|-\n! Smallest realizing group\n| Symmetric group <math>\\;\\mathbb{S}_3  </math>\n| Symmetric group <math>\\;\\mathbb{S}_4  </math>\n| Symmetric group <math>\\;\\mathbb{S}_5 </math>\n| Dihedral group  <math>\\;\\mathbb{D}_4 </math>\n|-\n! ... and conjugacy classes\n| <math>  \\mathcal{O}_{(12)}^{-1} </math>\n| <math>  \\mathcal{O}_{(1234)}^{-1},\\quad \\mathcal{O}_{(12)}^{-1},\\quad \\mathcal{O}_{(12)}^{-1\\otimes \\sgn} </math>\n| <math> \\mathcal{O}_{(12)}^{-1},\\quad\\mathcal{O}_{(12)}^{-1\\otimes \\sgn} </math>\n| <math>  \\mathcal{O}_{b}^\\epsilon\\oplus \\mathcal{O}^\\epsilon_{a^2b},\\quad \\mathcal{O}_{b}^{sgn}\\oplus \\mathcal{O}^{sgn}_{a^2b} </math>\n|-\n!  Source\n| <ref name=MS00/> \n| <ref name=MS00/><ref name=AG03/>\n| <ref name=MS00/><ref name=FK99/>\n| <ref name=MS00/> \n|-\n! Comments\n| colspan=3 | Kirilov–Fomin algebras\n| This smallest nonabelian Nichols algebra of rank 2 is the case <math>\\Gamma_2</math> in the classification.<ref name=HV14/><ref name=HS10/> It can be constructed as smallest example of an infinite series <math>A_n</math> from <math>A_n\\cup A_n</math>, see.<ref name=Len12/> \n|}\nThe case <math> \\mathbb{S}_2\\cong \\mathbb{Z}_2 </math> is the rank 1 diagonal Nichols algebra <math> u_i(A_1)^+ </math> of dimension 2.\n\n=== Other Nichols algebras of rank 1 ===\n\n{| class=\"wikitable\" \n!  \n|<!-- Deleted image removed:  [[File:Nichols Algebra over A4.png|80px]] -->\n|<!-- Deleted image removed:  [[File:Nichols Algebra over A4.png|80px]] -->\n| [[File:Nichols Algebra over Aff5.png|80px]]\n| [[File:Nichols Algebra over Aff7.png|80px]]\n|-\n! Rank, Type of root system of <math> \\mathfrak{B}(V) </math> <ref name=AHS10/>\n|  <math>A_1</math>\n|  <math>A_1</math>\n|  <math>A_1</math>\n|  <math>A_1</math>\n|-\n! Dimension of <math> V </math>\n| <math>4</math>    \n| <math>4</math>\n| <math>5</math>\n| <math>7</math>\n|-\n! Dimension of Nichols algebra(s) \n| <math>72</math>    \n| <math>5,184</math>\n| <math>1,280</math>\n| <math>326,592</math>\n|-\n! [[Hilbert series]]\n| <math> (2)^2_t (3)_t (6)_t </math>\n| <math>(6)^4_{t} (2)^2_{t^2}</math>\n| <math>(4)^4_{t} (5)_t</math>\n| <math>(6)^6_{t} (7)_t</math>\n|-\n! Smallest realizing group\n| colspan=2 | Special linear group  <math> SL_2(3) </math> extending the alternating group <math> \\mathbb{A}_4 </math> \n| Affine linear group <math>\\mathbb{Z}_5\\rtimes\\mathbb{Z}_5^\\times</math>\n| Affine linear group <math>\\mathbb{Z}_7\\rtimes\\mathbb{Z}_7^\\times</math>\n|-\n! ... and conjugacy classes\n| <math>  \\mathcal{O}_{\\begin{pmatrix} -1 & 1 \\\\ 0 & -1\\end{pmatrix}}^{-1} </math>\n| <math> \\mathcal{O}_{\\begin{pmatrix} 1 & 1 \\\\ 0 & 1\\end{pmatrix}}^{\\zeta_6} </math>\n| <math> \\mathcal{O}_{i\\rtimes 2}^{-1},\\quad \\mathcal{O}_{i\\rtimes 3}^{-1} </math>\n| <math>  \\mathcal{O}_{i\\rtimes 3}^{-1},\\quad \\mathcal{O}_{i\\rtimes 5}^{-1} </math>\n|-\n!  Source\n| <ref name=Grana00/> \n| <ref name=HLV12/>\n| colspan=2| <ref name=AG03/>\n|-\n! Comments\n| There exists a Nichols algebra of rank 2 containing this Nichols algebra\n| Only example with many cubic (but not many quadratic) relations.\n| colspan=2 | Affine racks\n|}\n\n=== Nichols algebras of rank 2, type Gamma-3 ===\n\nThese Nichols algebras were discovered during the classification of Heckenberger and Vendramin.<ref name=\"HV13\"/>\n\n{| class=\"wikitable\"\n!  \n| [[File:Nichols Algebra HV1.png|150px]]\n| [[File:Nichols Algebra HV2.png|150px]]\n| '''only in characteristic 2''' [[File:Nichols Algebra HV3.png|150px]]\n|-\n!  Rank, Type of root system of <math> \\mathfrak{B}(V) </math> <ref name=AHS10/>\n|  <math>B_2,B_2</math>\n|  <math>B_2,B_2</math>\n|  <math>\\begin{pmatrix}2 & -2 \\\\ -2 & 2 \\end{pmatrix}</math><math>\n\\begin{pmatrix}2 & -2 \\\\ -1 & 2 \\end{pmatrix}</math><math>\n\\begin{pmatrix}2 & -4 \\\\ -1 & 2 \\end{pmatrix}</math>\n|-\n! Dimension of <math> V </math>\n| <math>3+2</math>    \n| <math>3+1</math> resp. <math>3+2</math>\n| <math>3+1</math> resp. <math>3+2</math>\n|-\n! Dimension of Nichols algebra(s)\n| <math>2,304</math>  \n| <math>10,368</math>\n| <math>2,239,488</math>\n|-\n! [[Hilbert series]]\n| <math>(2)_t^2(3)_t\\cdot (2)_{t}^2</math>\n| <math>(2)_t^2(3)_t\\cdot(6)_{t}</math><math>\\cdot (2)_{t^2}^2(3)_{t^2}\\cdot (2)_{t^3}(6)_{t^3}</math>\n| \n|-\n! Smallest realizing group and conjugacy class\n| <math> \\mathbb{S}_3\\times \\mathbb{Z}_2 </math>\n| <math> \\mathbb{S}_3\\times \\mathbb{Z}_6  </math>\n| \n|-\n! ... and conjugacy classes\n| <math>  \\mathcal{O}_{(12)}^{-1,1}\\oplus  \\mathcal{O}_{\\{z\\}}^{1,\\sigma_2}</math>\n| <math>  \\mathcal{O}_{(12)}^{-1,\\zeta_6}\\oplus  \\mathcal{O}_{\\{z\\}}^{1,\\zeta_6^{-1}} </math>\n| \n|-\n!  Source\n| <ref name=HV13/> \n| <ref name=HV13/>\n| <ref name=HV13/> \n|-\n! Comments\n| Only example with a 2-dimensional irreducible representation <math>\\sigma</math>\n| There exists a Nichols algebra of rank 3 extending this Nichols algebra\n| Only in characteristic 2. Has a non-Lie type root system with 6 roots.\n|}\n\n=== The Nichols algebra of rank 2 type Gamma-4 ===\n\n[[File:Nichols Algebra G4.png|150px]] This Nichols algebra was discovered during the classification of Heckenberger and Vendramin.<ref name=\"HV13\"/>\n\n{| class=\"wikitable\"\n!Root system\n| <math>B_2 </math>\n|-\n! Dimension of <math>V</math>\n| <math>2+4</math>\n|-\n! Dimension of Nichols algebra\n|<math>262,144 \\;= 2^{18}</math>\n|-\n! Hilbert series\n| <math>(2)_t^2(2)_{t^2}\n  \\cdot (2)_{t}^4(2)_{t^2}^2 \n  \\cdot (2)_{t^2}^4(2^2)_{t^4}^2 \n  \\cdot (2)_{t^3}^2(2)_{t^6}</math>\n|-\n! Smallest realizing group\n|  <math>\\tilde{\\mathbb{D}}_8</math> (semidihedral group)\n|-\n! ...and conjugacy class\n|<math>\\mathcal{O}_{[h]}^{-1}\\oplus \\mathcal{O}_{[g]}^{\\zeta_8}</math>\n|-\n! Comments\n|  Both rank 1 Nichols algebra contained in this Nichols algebra decompose over their respective support: The left node to a Nichols algebra over the Coxeter group <math>\\mathbb{D}_4</math>, the right node to a diagonal Nichols algebra of type <math>A_2</math>.\n|-\n|}\n\n=== The Nichols algebra of rank 2, type T ===\n\n[[File:Nichols Algebra T.png|150px]] This Nichols algebra was discovered during the classification of Heckenberger and Vendramin.<ref name=\"HV13\"/>\n\n{| class=\"wikitable\"\n!Root system\n| <math>G_2 </math>\n|-\n! Dimension of <math>V</math>\n| <math>1+4</math>\n|-\n! Dimension of Nichols algebra\n|<math>80,621,568</math>\n|-\n! Hilbert series\n| <math>(6)_t\\cdot (2)_t^2(3)_t(6)_t\\cdot (2)_{t^2}^2(3)_{t^2}(6)_{t^2}\n\\cdot (2)_{t^3}^2(3)_{t^3}(6)_{t^3}\\cdot (6)_{t^4}\\cdot (6)_{t^5}</math>\n|-\n! Smallest realizing group\n| <math>\\Z_6\\times SL_2(3)</math> \n|-\n! ...and conjugacy class\n| <math>\\mathcal{O}_{\\{z\\}}^{\\zeta_6,\\zeta_6^{-1}}\n  \\oplus\\mathcal{O}_{\\begin{pmatrix}-1 & 1 \\\\ 0 & -1\\end{pmatrix}}^{1,-1}</math>\n|-\n! Comments\n| The rank 1 Nichols algebra contained in this Nichols algebra is irreducible over its support <math>SL_2(3)</math> and can be found above.\n|-\n|}\n\n=== The Nichols algebra of rank 3 involving Gamma-3 ===\n\n[[File:Nichols Algebra HV2+1.png|150px]] This Nichols algebra was the last Nichols algebra discovered during the classification of Heckenberger and Vendramin.<ref name=\"HV14\"/>\n\n{| class=\"wikitable\"\n!Root system\n| Rank 3 Number 9 with 13 roots <ref name=\"CH13\"/>\n|-\n! Dimension of <math>V</math>\n| <math>3+2+1</math> resp. <math>3+1+1</math>\n|-\n! Dimension of Nichols algebra\n|<math>1,671,768,834,048</math>\n|-\n! Hilbert series\n| <math>(2)_t^2(3)_t\\cdot (6)_{t}\\cdot (6)_t       \n  \\cdot (2)_{t^2}^2(3)_{t^2}\\cdot (6)_{t^2} \n  \\cdot (2)_{t^3}(6)_{t^3}\\cdot (2)_{t^3}^2(3)_{t^3}</math><math>\n  \\cdot (2)_{t^4}(6)_{t^4} \\cdot (2)_{t^5}(6)_{t^5}\n  \\cdot (2)_{t^6}^2(3)_{t^6}\\cdot (6)_{t^7} \\cdot (6)_{t^8} \\cdot (6)_{t^9}</math>\n|-\n! Smallest realizing group\n|<math>\\mathbb{S}_3\\times \\mathbb{Z}_6\\times \\mathbb{Z}_6</math> \n|-\n! ...and conjugacy class\n| <math>\\mathcal{O} _{(12)}^{-1,\\zeta_6,1}\\oplus \\mathcal{O} _{\\{z\\}}^{1,\\zeta_6^{-1},1}\n  \\oplus \\mathcal{O} _{\\{w\\}}^{1,\\zeta_6,\\zeta_6^{-1}}</math>\n|-\n! Comments\n| The rank 2 Nichols algebra cenerated by the two leftmost node is of type <math>\\Gamma_3</math> and can be found above. The rank 2 Nichols algebra generated by the two rightmost nodes is either diagonal of type  <math>A_2</math> or  <math>A_3</math>.\n\n|-\n|}\n\n=== Nichols algebras from diagram folding ===\n\nThe following families Nichols algebras were constructed by Lentner using diagram folding,<ref name=\"Len12\"/> the fourth example appearing only in characteristic 3 was discovered during the classification of Heckenberger and Vendramin.<ref name=\"HV14\"/>\n\nThe construction start with a known Nichols algebra (here diagonal ones related to quantum groups) and an additional automorphism of the Dynkin diagram. Hence the two major cases are whether this automorphism exchanges two disconnected copies or is a proper diagram automorphism of a connected Dynkin diagram. The resulting root system is folding / restriction of the original root system.<ref name=CL15/> By construction, generators and relations are known from the diagonal case.\n\n{| class=\"wikitable\"\n!  \n| [[File:Nichols Algebra L An.png|200px]]\n| [[File:Nichols Algebra L Dn.png|200px]]\n| [[File:Nichols Algebra L E n.png|200px]]\n| '''only characteristic 3'''\n[[File:Nichols Algebra L Bn.png|200px]]\n|-\n! Rank, Type of root system of <math> \\mathfrak{B}(V) </math> <ref name=AHS10/>\n|  <math>A_n,\\; n\\geq 2</math>\n|  <math>D_n,\\; n\\geq 4</math>\n|  <math>E_6,E_7,E_8 </math>\n|  <math>B_n,\\;n\\geq 2</math>\n|-\n! Constructed from this diagonal Nichol algebra with <math>q_{ij}=\\pm 1</math>\n| <math>A_n\\times A_n</math>\n| <math>D_n\\times D_n</math>\n| <math>E_n\\times E_n</math>\n| <math>B_n\\times B_n</math> in characteristic 3.\n|-\n! Dimension of <math> V </math>\n| <math>2+2+\\cdots</math>    \n| <math>2+2+\\cdots</math>\n| <math>2+2+\\cdots</math>\n| <math>2+2+\\cdots</math>\n|-\n! Dimension of Nichols algebra(s) \n| <math>\\left(2^{n+1 \\choose 2} \\right)^2</math>    \n| <math>\\left(2^{n(n-1)} \\right)^2</math>\n| <math>\\left(2^{36} \\right)^2,\\;\\left(2^{63} \\right)^2,\\;\\left(2^{120} \\right)^2</math>\n| <math>\\left(3^{n(n-1)}2^{n} \\right)^2</math>\n|-\n! [[Hilbert series]]\n| colspan=4 | Same as the respective diagonal Nichols algebra\n|-\n! Smallest realizing group\n| colspan=4 | [[Extra special group]] (resp. almost extraspecial) with <math>2^{n+1}</math> elements, except that <math>D_{n},\\;2|n</math> requires a similar group with larger center of order <math> 2^3</math>.\n|-\n!  Source\n| colspan=3 | <ref name=\"Len12\"/>\n| <ref name=HV14/>\n|-\n! Comments\n| colspan=3 | \n| Supposedly a folding of the diagonal Nichols algebra of type <math>B_n</math> with <math>q=\\pm 1</math> which exceptionally appears in characteristic 3.\n|}\n\nThe following two are obtained by proper automorphisms of the connected Dynkin diagrams <math>{^2}A_{2n-1},{^2}E_6</math>\n\n{| class=\"wikitable\"\n!  scope=\"col\" width=\"150px\" |\n|  scope=\"col\" width=\"300px\" | [[File:Nichols Algebra L Cn.png|200px]]\n|  scope=\"col\" width=\"300px\" |[[File:Nichols Algebra L F4.png|200px]]\n|-\n! Rank, Type of root system of <math> \\mathfrak{B}(V) </math> <ref name=AHS10/>\n|  <math>C_{n},\\; n\\geq 3</math>\n|  <math>F_4</math>\n|-\n! Constructed from this diagonal Nichol algebra with <math>q_{ij}=\\pm 1</math>\n| <math>A_{2n-1}</math>\n| <math>E_6</math>\n|-\n! Dimension of <math> V </math>\n| <math>1+2+\\cdots</math>    \n| <math>1+1+2+2</math>\n|-\n! Dimension of Nichols algebra(s) \n| <math>2^{{2n \\choose 2}}</math>    \n| <math>2^{36}=68,719,476,736 </math>\n|-\n! [[Hilbert series]]\n| Same as the respective diagonal Nichols algebra\n| Same as the respective diagonal Nichols algebra\n<math>(2)^6_{t}\n(2)^5_{t^2}(2)^5_{t^3}(2)^5_{t^4}\n(2)^4_{t^5}(2)^3_{t^6} </math>\n<math>\\cdot\n  (2)^3_{t^7} (2)^2_{t^8}\n(2)_{t^9}(2)_{t^{10}}(2)_{t^{11}}</math>\n|-\n! Smallest realizing group\n| Group of order <math>2^{n+1}</math> with larger center of order <math>2^2</math> resp. <math>2^3</math> (for <math>n</math> even resp. odd)\n| Group of order <math>2^{4+1}</math> with larger center of order <math>2^3</math>\n\ni.e. <math>\\mathbb{Z}_2\\times \\mathbb{Z}_2\\times \\mathbb{D}_4</math>\n|-\n!... and conjugacy class\n|\n| <math>\\mathcal{O}_{\\{z_1\\}}\\oplus \\mathcal{O}_{\\{z_2\\}} \\oplus\\mathcal{O}_{[x_1]}\\oplus\\mathcal{O}_{[y_1]}</math>\n|-\n!  Source\n| colspan=2 | <ref name=\"Len12\"/>\n|-\n|}\n\nNote that there are several more foldings, such as <math>{^3}D_4,{^2}D_n</math> and also some not of Lie type, but these violate the condition that the support generates the group.\n\n==Poster with all Nichols algebras known so far==\n\n[[File:NicholsPlakat.png|700px]]\n\n(Simon Lentner, University Hamburg, please feel free to write comments/corrections/wishes in this matter: simon.lentner at uni-hamburg.de)\n\n==References==\n<references>\n\n<ref name=AHS10>Andruskiewitsch, Heckenberger, Schneider: ''The Nichols algebra of a semisimple Yetter–Drinfeld module'', Amer. J. Math., vol. 132, no. 6, December 2010, pp. 1493–1547.</ref>\n<ref name=CH13>Cuntz, Heckenberger: ''Finite Weyl groupoids'', Preprint (2010) {{arXiv|1008.5291}}, to appear in J. Reine Angew. Math. (2013)</ref>\n<ref name=H09>Heckenberger: ''Classification of arithmetic root systems, Adv. Math. 220 (2009), 59–124.</ref>\n<ref name=HW14>Heckenberger, Wang: ''Rank 2 Nichols Algebras of Diagonal Type over Fields of Positive Characteristic'', SIGMA 11 (2015), 011, 24 pages</ref>\n<ref name=HV14>Heckenberger, Vendramin: ''A classification of Nichols algebras of semi-simple Yetter–Drinfeld modules over non-abelian groups '', Preprint (2014) {{arXiv|1412.0857}}</ref>\n<ref name=AFGV10b>Andruskiewitsch, Fantino, Grana, Vendramin: ''Pointed Hopf algebras over the sporadic simple groups'', 2010.</ref>\n<ref name=AFGV10c>Andruskiewitsch, Fantino, Grana, Vendramin: ''Finite-dimensional pointed Hopf algebras with alternating groups are trivial'', 2010.</ref>\n<ref name=MS00>Schneider, Milinski: ''Nichols algebras over Coxeter groups'', 2000.</ref> \n<ref name=AG03>Andruskiewisch, Grana: ''From racks to pointed Hopf algebras'', Adv. in Math. 178 (2), 177–243 (2003)</ref> \n<ref name=FK99>Fomin,Kirilov: ''Quadratic algebras, Dunkl elements and Schubert calculus'', 1999.</ref>\n<ref name=HS10>Heckenberger, Schneider: ''Nichols algebras over groups with finite root system of rank 2 I'', 2010.</ref>\n<ref name=Len12>Lentner: Dissertation (2012) and ''New Large-Rank Nichols Algebras Over Nonabelian Groups With Commutator Subgroup Z_2'', Journal of Algebra 419 (2014) pp. 1–33.</ref>\n<ref name=Grana00>Grana: ''On Nichols algebras of low dimension'', New Trends in Hopf Algebra\nTheory; Contemp. Math. 267 (2000), 111–136</ref>\n<ref name=HLV12>Heckenberger, Lochmann, Vendramin: ''Braided racks, Hurwitz actions and Nichols algebras with many cubic relations'', \nTransform. Groups 17 (2012), no. 1, 157–194</ref>\n<ref name=HV13>Heckenberger, Vendramin: ''The classification of Nichols algebras over groups with finite root system of rank two '', Preprint (2013) {{arXiv|1311.2881}}</ref>\n<ref name=CL15>Cuntz, Lentner: ''A simplicial complex of Nichols algebras'', Preprint (2015) {{arXiv|1503.08117}}.</ref>\n<ref name=AFGV10a>Andruskiewitsch, Fantino, Grana, Vendramin: ''On Nichols algebras associated to simple racks'', 2010.</ref>\n\n<ref name=AGC13>Andruskiewitsch, Carnovale, García: ''Finite-dimensional pointed Hopf algebras over finite simple groups of Lie type I. Non-semisimple classes in PSL(n,q)'', Preprint (2013), arXiv:1312.6238</ref>\n<ref name=AGC14>Andruskiewitsch, Carnovale, García: ''Finite-dimensional pointed Hopf algebras over finite simple groups of Lie type II. Unipotent classes in symplectic groups'', Preprint (2013), arXiv:1312.6238</ref>\n </references>\n\n[[Category:Hopf algebras]]\n[[Category:Quantum groups]]"
    },
    {
      "title": "Nichols algebra",
      "url": "https://en.wikipedia.org/wiki/Nichols_algebra",
      "text": "In algebra, the '''Nichols algebra''' of a [[braided vector space]] (with the braiding often induced by a finite group) is a [[braided Hopf algebra]] which is denoted by <math>\\mathfrak{B}(V)</math> and named after the mathematician Warren Nichols. It takes the role of quantum Borel part of a pointed Hopf algebra<ref name=AS02/> such as a [[quantum groups]] and their well known finite-dimensional truncations. Nichols algebras can immediately be used to write down new such quantum groups by using the [[Braided Hopf algebra|Radford biproduct]]<ref name=AS02/>.\n\nThe classification of all such Nichols algebras and even all associated [[quantum groups]] (see Application) has been progressing rapidly, although still much is open: The case of an abelian group was solved in 2005,<ref name=H05/> but otherwise this phenomenon seems to be very rare, with a handful examples known and powerful negation criteria established (see below). See also this [[List of finite-dimensional Nichols algebras]].\n\nThe finite-dimensional theory is greatly governed by a theory of [[root system]]s and [[Dynkin diagram]]s, strikingly similar to those of [[semisimple Lie algebra]]s.<ref name=HS08/> A comprehensive introduction is found in the lecture of Heckenberger.<ref name=H08/>\n\n==Definition==\nConsider a Yetter–Drinfeld module ''V'' in the [[Yetter–Drinfeld category]] <math> {}^H_H\\mathcal{YD}</math>. This is especially a braided vectorspace, see [[Braided monoidal category]].\n\nThe [[tensor algebra]] <math>TV</math> of a Yetter–Drinfeld module <math> V\\in {}^H_H\\mathcal{YD}</math> is always a [[Braided Hopf algebra]]. The coproduct <math>\\Delta</math> and counit <math>\\epsilon</math> of <math>TV </math> is defined in such a way that the elements of  <math>V</math> are primitive, that is\nfor all <math>v\\in V</math>\n::<math>\\Delta(v)=1\\otimes v+v\\otimes 1</math>\n::<math>\\epsilon(v)=0</math>\n\nThe Nichols algebra can be uniquely defined by '''several equivalent characterizations''', some of which focus on the Hopf algebra structure and some are more combinatorial. Regardless, determining the Nichols algebra explicitly (even decide if it's finite-dimensional) can be very difficult and is open in several concrete instances (see below).\n\n===Definition I: Combinatorical formula===\nLet <math>V</math> be a [[braided vector space]], this means there is an action of the braid group <math>\\mathbb{B}_n</math> on <math>V^{\\otimes n}</math> for any <math>n\\in\\mathbb{N}</math>, where the transposition <math>(i,i+1)</math> acts as <math>id\\otimes\\cdots \\otimes \\tau\\otimes id\\cdots id</math>. Clearly there is a homomorphism to the symmetric group <math>\\pi:\\mathbb{B}_n\\to\\mathbb{S}_n</math> but neither does this admit a section, nor does the action on <math>V^{\\otimes n}</math> in general factorize over this.\n\nConsider nevertheless a set-theoretic section <math>s:\\mathbb{S}_n\\to \\mathbb{B}_n</math> sending transposition to transposition and arbitrary elements via any '''reduced expression'''. This is not a group homomorphism, but [[Matsumoto's theorem (group theory)]] tells us that the action of any <math>s(\\sigma)</math> on <math>V^{\\otimes n}</math> is well-defined independently of the choice of a reduced expression. Finally the Nichols algebra is then \n::<math>\\mathfrak{W}_n:=\\sum_{\\sigma\\in\\mathbb{S}_n} s(\\sigma):\\;\\; V^{\\otimes n}\\to V^{\\otimes n}\\qquad \\text{(quantum symmetrizer or quantum shuffle map)}</math>\n\n::<math>\\mathfrak{B}(V):= \\bigoplus_{n\\geq 0} V^{\\otimes n}/Ker(\\mathfrak{W}_n)</math>\nThis definition was later (but independently) given by Woronowicz. It has the disadvantage of being rarely useful in algebraic proofs but it represents an intuition in its own right and it has the didactical advantage of being very explicit and independent of the notation of a Hopf algebra.\n\n===Definition II: Prescribed primitives===\nThe Nichols algebra <math>\\mathfrak{B}(V)</math> is the unique Hopf algebra in the braided category <math>{}^H_H\\mathcal{YD}</math> generated by the given <math>V\\in {}^H_H\\mathcal{YD}</math>, such that <math>V\\subset \\mathfrak{B}(V)</math> are the '''only''' primitive elements.\n\nThis is the original definition due to Nichols and it makes very transparent the role of the Nichols algebra as a fundamental notion in the classification of Hopf algebras.\n\n===Definition III: Universal quotient===\nLet <math>V\\in {}^H_H\\mathcal{YD}</math>. There exists a largest [[ideal (ring theory)|ideal]] <math>\\mathfrak{I}\\subset TV </math> with the following properties:\n:: <math> \\mathfrak{I}\\subset \\bigoplus _{n=2}^\\infty T^nV,</math>\n\n:: <math> \\Delta (\\mathfrak{I})\\subset \\mathfrak{I}\\otimes TV+TV\\otimes \\mathfrak{I}</math> (this is automatic)\nThe Nichols algebra is\n:: <math>\\mathfrak{B}(V):= TV/\\mathfrak{I}</math>\n\n===Definition IV: Nondegenerate Pairing===\n\nThe unique Hopf pairing <math>V\\otimes TV^*\\to k</math> factorizes to a '''nondegenerate''' Hopf pairing between <math>\\mathfrak{B}(V)\\otimes \\mathfrak{B}(V^*)\\to k</math> and this fact characterizes the Nichols algebra uniquely. This theoretically very helpful characterization is due to Lusztig.\n\n===Definition V: Skew derivatives===\nThis is a somewhat explicit form of the previous definition: Chosen a homogeneous basis <math> v_i\\in V</math> (i.e. coaction/graduation <math> v_i\\mapsto g_i\\otimes v_i</math>) one may define '''skew derivations''' <math>\\partial_i</math>, using the universal property of the tensor algebra:\n::<math>\\partial_i(1)=0 \\quad \\partial_i(v_j)=\\delta_{ij} </math>\n\n::<math>\\partial_i(ab)=a\\partial_i(b)+\\partial_i(a)(g_i.b) </math>\n\nThen the Nichols algebra <math>\\mathfrak{B}(V)</math> is the quotient of <math>TV</math> by the largest homogeneous ideal which contains no constants and is invariant under all derivations <math>\\partial_i</math>. Roughly spoken, one may look in <math>TV</math> for elements in the kernel of all skew-derivations and divide these out; then look again for all elements that are now in the kernel of all skew-derivatives and divide them out as well etc.\n\n==Examples==\nWe give examples of finite-dimensional Nichols algebras. Over characteristic ''p'', this effect already may appear in the non-braided situation, namely the truncated universal envelopings of p-restricted Lie algebras. In characteristic zero and with a braiding coming from an abelian group, this seems to be a similarly frequent occurrence (however more involved, see Classification). For ''G'' nonabelian on the other side, only very few examples are known so far, and powerful negation criteria exclude many groups at all (see Classification).\n\n===1-dimensional examples===\nAs a first example, consider the 1-dimensional Yetter–Drinfeld module <math>V_\\pm=kx</math> over the [[Group Hopf algebra]] ''H'' = ''k''['''Z'''/2'''Z'''] with the [[Cyclic group]] multiplicatively denoted (as usual in algebra) and generated by some ''g''.\n* Take as ''H''-coaction (resp. '''Z'''/2'''Z'''-graduation) on <math>V_\\pm</math>: <math> x\\mapsto g\\otimes x</math>\n* Take as ''H''-action (resp. '''Z'''/2'''Z'''-action) on <math>V_\\pm</math>: <math> g\\otimes x\\mapsto \\pm x</math>\n* Thus the braiding is <math>x\\otimes x\\rightarrow \\pm x\\otimes x</math>\nThen, depending on the sign choice, the Nichols algebras are:\n\n::<math>\\mathfrak{B}(V_+)=k[x]\\qquad \\mathfrak{B}(V_-)=k[x]/(x^2)</math>\n\nNote that the first is as expected (the non-braided case), while the second has been '''truncated''' to the point that it's finite-dimensional! Similarly, ''V<sub>q</sub>'' over a higher cyclic group with ''g'' acting by some ''q'' in ''k'' has Nichols algebra <math>\\mathfrak{B}(V_q)=k[x]/(x^n)</math> if ''q'' ≠ 1 is a primitive ''n''-th root of unity, and <math>\\mathfrak{B}(V_q)=k[x]</math> otherwise.\n\n''(from a physical perspective, the ''V''<sub>+</sub> corresponds to a boson, while ''V''<sub>–</sub> represents a fermion restricted by [[Pauli exclusion principle]]; an analogy that repeats when considering braided commutators, being (anti)commutators in these cases, see also [[Supersymmetry as a quantum group]] and discussion)''\n\n===Higher-rank examples over ''G'' abelian: braided commutators===\nThe next examples show the interaction of two basis elements: Consider the two-dimensional Yetter–Drinfeld module ''V''<sub>0,1</sub> = ''kx'' ⊕ ''ky'' over the [[group Hopf algebra]] ''H'' = ''k''['''Z'''/2'''Z''' × '''Z'''/2'''Z'''] with the [[Klein four group]] multiplicatively denoted and generated by some ''g,h''.\n* Take as ''H''-coaction/graduation on ''V''<sub>0,1</sub>: <math> x\\mapsto g\\otimes x</math> and <math> x\\mapsto g\\otimes x</math>\n* Take as ''H''-action (resp. '''Z'''/2'''Z'''-action) on ''V''<sub>0,1</sub>:\n** <math> g\\otimes x\\mapsto -x</math>\n** <math> g\\otimes y\\mapsto +y</math>\n** <math> h\\otimes y\\mapsto -y</math>\n** <math> h\\otimes x\\mapsto \\pm x</math> with ''\"+\"'' for ''V''<sub>0</sub> (symmetric) and ''\"–\"'' for ''V''<sub>1</sub> (asymmetric)\n* Thus the braiding is\n** <math>x\\otimes x\\rightarrow -x\\otimes x</math>\n** <math>y\\otimes y\\rightarrow -y\\otimes y</math>\n** <math>x\\otimes y\\rightarrow y\\otimes x</math>\n** <math>y\\otimes x\\rightarrow \\pm x\\otimes y</math>\n\nThen, depending on the sign choice, the Nichols algebras are of dimension 4 and 8 (they appear in the classification under <math>q_{12}q_{21}=\\pm 1</math>):\n\n::<math>\\mathfrak{B}(V_0)=k[x,y]/(x^2,y^2,xy+yx),</math> \n::<math>\\mathfrak{B}(V_1)=k[x]/(x^2,y^2,xyxy+yxyx)</math>\n\nThere one can see the striking resemblance to [[Semisimple Lie algebra]]s: In the first case, the [[braided vector space|braided commutator]] [''x'', ''y''] (here: anticommutator) is zero, while  in the second, the [[Root system|root string]] is longer [''x'', [''x'', ''y'']] = 0. Hence these two belong to [[Dynkin diagram]]s <math>A_1\\cup A_1</math> and A<sub>2</sub>.\n\n{|\n| width=\"50\" | || [[File:A1A1.png|180px]] || width=\"180\" | || [[File:Dynkin diagram A2.png|180px]]\n|}\n\nOne also constructs examples with even longer root strings ''V''<sub>2</sub>, ''V''<sub>3</sub> corresponding to [[Dynkin diagram]]s B<sub>2</sub>, G<sub>2</sub> (but as well no higher ones).\n\n{|\n| width=\"45\" | || [[File:Dynkin diagram B2.png|180px]] || width=\"180\" | || [[File:Dynkin diagram G2b.png|180px]]\n|}\n\n===Universal enveloping of Lie algebras, Quantum groups===\n\nNichols algebras are probably best known for being the Borel part of the quantum groups and their generalizations. More precisely let \n:: <math>V:=x_1\\mathbb{C}\\oplus x_2\\mathbb{C}\\oplus\\cdots \\oplus x_n\\mathbb{C}</math>\nbe the diagonal Yetter-Drinfel'd module over an abelian group <math>\\Lambda=\\mathbb{Z}^n=\\langle K_1,\\ldots,K_n\\rangle </math> with braiding\n:: <math>x_i\\otimes x_j\\mapsto q_{ij} x_j\\otimes x_i\\qquad q_{ij}:=q^{(\\alpha_i,\\alpha_j)}</math>\nwhere <math>(\\alpha_i,\\alpha_j)</math> is the Killing form of a semisimple (finite-dimensional) Lie algebra <math>\\mathfrak{g}</math>, then the Nichols algebra is the positive part of Lusztig's small quantum group\n:: <math>\\mathfrak{B}(V)=u_q(\\mathfrak{g})^+</math>\n\n===Includes Super-Lie algebras===\n\nThere are more diagonal Nichols algebras than Lie algebras in Heckenbergers list, and the root system theory is systematic, but more complicated (see below). In particular is contains also the classification of Super-Lie-Algebras (example below)  as well as certain Lie algebras and Super-Lie-Algebras that only appear in a specific finite characteristic.\n\nThus Nichols algebra theory and root system theory provides a unified framework for these concepts.\n\n===Nondiagonal braidings, Nonabelian groups===\nOnly a handful of finite-dimensional Nichols algebras over ''k'' = '''C''' are known so far. It is known that in this case each irreducible Yetter–Drinfeld module <math>\\mathcal{O}_{[g]}^\\chi</math> corresponds to [[Conjugacy class]] of the group (together with an irreducible representation of the [[Centralizer and normalizer|centralizer]] of ''g''). An arbitrary Yetter–Drinfeld module is a [[direct sum]] of such <math>\\mathcal{O}_{[g]}^\\chi</math>, the number of summands is called '''rank'''; each summand corresponds to anode in the [[Dynkin diagram]] ''(see below)''. Note that for the abelian groups as above, the irreducible summands are 1-dimensional, hence rank and dimension coincide.\n\nParticular examples include the Nichols algebra associated to the conjugacy class(es) of reflections in a Coxeter group, they are related to the Fomin Kirilov algebras. It is known these Nichols algebras are finite dimensional for <math>\\mathbb{S}_3,\\mathbb{S}_4,\\mathbb{S}_5,\\mathbb{D}_4</math> but already the case <math>\\mathbb{S}_6</math> is open since 2000. Another class of exmamples can be constructed from abelian case by a folding through diagram automorphisms.\n\nSee here for a list [[List of finite-dimensional Nichols algebras]] to the extent of our knowledge.\n\n==Root system==\n\nA very remarkable feature is that for '''every''' Nichols algebra (under sufficient finiteness conditions) there exists a generalized root system with a set of roots <math>\\Phi</math>, which controls the Nichols algebra. This has been discovered in <ref name=H06/> for diagonal Nichols algebras in terms of the bicharacter <math>q_{ij}</math> and in <ref name=AHS10/> for general semisimple Nichols algebras. In contrast to ordinary crystallographic root systems known from Lie algebras, the same generalized root system <math>\\Phi</math> may possess several be '''different Weyl chambers''', corresponding to non-equivalent choices of sets of positive roots <math>\\Phi=\\Phi^+\\cup -\\Phi^+</math> and simple positive roots <math>\\alpha_1,\\ldots \\alpha_n </math>, having different Cartan matrices and different Dynkin diagrams.\n\nThe different Weyl chambers correspond in fact to different non-isomorphic Nichols algebras which are called Weyl-equivalent. Quantum groups are very special with respect to the fact that here all Borel parts are isomorphic; nevertheless even in this case Lusztig's reflection operator <math>T_s</math> is again ''not' \na Hopf algebra isomorphism!\n\n===Definition of Weyl groupoid and generalized roots system===\n\nLet <math>I=\\{1,\\ldots n\\}</math> where <math>n</math> is the rank, with formal basis <math>\\alpha_1,\\ldots \\alpha_n </math>.\n\nWe first discuss generalized Cartan graphs as in:<ref name=AHS10/>\n* A '''generalized Cartan matrix''' <math>c_{ij},\\;\\;i,j\\in I</math> is an integral matrix such that\n** <math>c_{ii}=2,\\quad c_{ij}<0 </math>\n** <math>c_{ij}=0\\Rightarrow c_{ji}=0</math>\n* A '''Cartan graph''' is a set of such Cartan matrices <math>c^a_{ij},\\;\\forall a\\in A</math> parametrized by a set of objects/chambers <math>A</math>, together with  (object change) morphism <math>r_i:A\\to A</math> such that\n** <math>r_i^2=id</math>\n** <math>c^a_{ij}=c^{r_i(a)}_{ij}</math>\n* Define maps \n::<math>s_i^a:\\mathbb{Z}^I\\to \\mathbb{Z}^I</math>\n::<math>s_i^a:\\;\\alpha_j\\mapsto \\alpha_j-c_{ij}^a \\alpha_i</math>\n(note that Lie algebra literature has also the transpose convention for <math>c_{ij}</math>, e.g. in Humphrey's book)\n* The '''Weyl groupoid''' is the category with objects <math>A</math> and morphisms <math>Hom(a,b)</math> formally the groups generated by the <math>s_i^a:a\\to r_i(a)</math>\n* The '''set of real roots''' <math>\\Phi_a^+</math> is the set <math>\\{ id ^a s _{i_1}\\cdots s_{i_k}(\\alpha_j)\\,|\\,\nk\\in \\mathbb{N}_0,\\,i_1,\\dots,i_k,j\\in I\\}\\subseteq \\mathbb{N}^I</math>\n* Define <math>m_{i,j}^a= |\\Phi ^a \\cap (\\mathbb{N}_0 \\alpha_i + \\mathbb{N}_0 \\alpha_j)|</math>, \n* Then a '''root system ''' <math>\\Phi</math> of type <math>(c_{i,j}^a)_{a\\in A}</math>  is a set\n** <math>\\Phi^a=\\Phi^a_+\\cup - \\Phi^a_+</math> with <math>\\Phi^a_+=\\Phi^a\\cap \\mathbb{N}_0^I</math>\n** <math>\\Phi^a\\cap \\mathbb{Z}\\alpha_i=\\{\\alpha_i,-\\alpha_i\\}</math>\n** <math>s_i^a(\\Phi^a) = \\Phi^{r_i(a)}</math>\n** For <math>i\\neq j</math> with <math>m_{ij}</math> finite <math>(r_i r_j)^{m_{i,j}^a}(a)=a</math>\n\n===Equivalence to Crystallographic Hyperplane Arrangements===\n\nIn <ref name=C10/> it was shown that Weyl groupoids are in 1:1 correspondence to '''crystallographic hyperplane arrangements'''. These are a set of hyperplanes in <math>\\mathbb{R}^n</math> through the origin and choices of normal vectors such that for every simplicial chamber bounded by <math>n</math> hyperplanes with normal vectors <math>\\alpha_1^\\perp,\\ldots \\alpha_n^\\perp</math> all other chosen normal vector <math>\\alpha^\\perp</math> can be expressed as ''integral'' linear combination of the <math>\\alpha_i^\\perp</math>.\n\nIn <ref name=CH10/> the set of all finite crystallographic hyperplane arrangements (and hence finite Weyl groupoids or finite generalized root systems) have been classified. Apart from the reflection arrangements <math>A_n,B_n,C_n,D_n,E_6,E_7,E_8,F_4,G_2</math> there is one more infinite family and altogether 74 exceptionswith rank up to <math>8</math>.\n\n===Example of rank 3 (also a super Lie algebra)===\n\nThe smallest crystallographic hyperplane arrangement, Weyl groupoid, generalized root system, which is not of ordinary Lie type, is as follows. It appears for a diagonal Nichols algebra, even a super Lie algebra. The hyperplane arrangement can be constructed from a [[cuboctahedron]] (a platonic solid):\n\n{|\n| width=\"50\" | || [[File:Rootsystem7RootsRank3.png|350px]]  || width=\"180\" | || [[File:Rootsystem7RootsRank3Projective.jpg|350px]]\n|}\n\nIt has <math>7</math> roots (<math>4</math> resp. <math>3</math> hyperplanes, in the pictures bounding equilateral triangle resp. diagonals in squares, in the super Lie algebra odd resp. even roots). It visibly has <math>2</math> different types of Weyl chambers (equilateral triangles resp. right triangles) with different Cartan matrices in which the roots in terms of simple roots are as follows:\n\n::<math>\\Phi^a_+=\\{(1,0,0),(0,1,0),(0,0,1),(1,1,0),(1,0,1),(0,1,1),(1,1,1)\\}</math>\n::In the picture the white chamber, e.g with basis <math>\\alpha_1,\\alpha_2,\\alpha_3</math>. Clearly, the Dynkin diagram of this type of chamber <math>a\\in A</math> is a simply-laced triangle,\nReflection on <math>\\alpha_2</math> brings us to the second type of chamber\n::<math>\\Phi^{a'}_+=\\{(1,0,0),(0,1,0),(0,0,1),(1,1,0),(0,1,1),(1,1,1),(1,2,1)\\}</math>\n::In the picture the gray chamber, e.g with basis <math>\\alpha_1',\\alpha_2',\\alpha_3'=\\alpha_{12},-\\alpha_2,\\alpha_{23}</math>. The Dynkin diagram of this type of chamber <math>a'\\in A</math> is just <math>A_2</math> (but one more root).\n\nThis root system is the smallest member of an infinite series. The pictures are from,<ref name=CL15/> where the example is also discussed thoroughly.\n\n==Classification (Details)==\n\n===Over abelian groups===\nThe Nichols algebras of finite dimension over '''abelian groups''' in ''k'' = '''C''' were classified by Istvan Heckenberger<ref name=H05/> in the years 2004–2005 by classifying arithmetic [[root system]]s and generalized [[Dynkin diagram]]s; where already Kharchenko had proven them to possess a [[Poincaré–Birkhoff–Witt theorem|Poincaré–Birkhoff–Witt basis]] of iterated (braided) commutators. The only information one requires is the braiding matrix, which is '''diagonal''' in this setting (see examples above)\n\n::<math>x_i\\otimes x_j \\mapsto q_{ij}x_j\\otimes x_i</math>\n\nWhile mostly only the classical ''Cartan-cases'' appear, there are several exotic diagrams possible for small primes, such as a triangle \n[[File:Dynkin Diagram Triangle.jpg|thumb|A rank 3 Dynkin diagram associated to a finite-dimensional Nichols algebra]]\nIn these cases the [[Weyl group|Weyl reflections]] of one diagram may not land in the \"same\" diagram, but a so-called '''Weyl equivalent'''. This is also the exact reason, that these exotic cases possess a Weyl-[[groupoid]] instead of a usual group.\n\nThe '''generators and relations''' of a Nichols algebra are ''not'' readily available from the root system. Rather, one has to perform tedious work with the Lynond words. This has been completely done in <ref name=An08/>\n\n===Negative criteria: abelian subracks===\nEspecially for irreducible ''V'' there are no submodules; however one may use the more abstract notion of ''subrack'' only reflecting the braiding of two contained elements. In several papers, Nicolas Andruskiewitsch ''et al.'' gave '''negative criteria''' excluding groups at all from possessing (indecomposable) Nichols algebras. Their techniques can be roughly summarized<ref name=AFGV10a/> ''(more details!)'':\n\n:: <TT>Consider a subrack that is abelian, check which representation may be inherited from the larger rack, and looked up in Heckenbegers List <ref name=H05/></TT>\n\nThis ansatz puts sometimes strong conditions especially on the braiding of any ''g''-graded element ''x'' with itself (e.g. the first example above shows ''q'' ≠ 1). Note that because ''g'' is central in the centralizer, it acts on the irreducible representation by a scalar as a consequence of the [[Schur lemma]]; hence this selfbraiding resp. 1-dim sub-Yetter-Drinfeld module / braided vectorspace / 1-dim subrack is '''diagonal'''\n::<math>x\\otimes x\\;\\stackrel{\\tau}{\\longmapsto}\\;q(x\\otimes x)\\;\\;\\Longleftrightarrow\\;\\; g.x=qx</math>\nIt is usually used to excludes ''g'' e.g. of being of odd order and/or χ of high dimension:<ref name=AFGV10b/>\n* If  ''g'' is '''real''' (i.e. conjugated to its inverse) then ''q'' = –1 (especially ''g'' has to be of even order)\n* If  ''g'' is '''quasi-real''' (i.e. conugated to some ''j''-th power) then\n**either ''q'' = –1 as above\n**or <math>g^{(j^2)}=g</math> and the representation χ is one-dimensional with ''q'' = ζ<sub>3</sub> a [[Root of unity|primitive 3rd root of unity]] (especially the order of ''g'' is divisible by 3)\n* If contrary ''g'' is an [[Involution (mathematics)#Group theory|involution]] and some centralizing ''h'' = ''tgt'' then the [[eigenvalue]]s of the ''h'' (viewed as matrix) acting on <math>\\mathcal{O}_{[g]}^\\chi</math> is strongly restricted.\n\n===Root systems over nonabelian groups===\n\nThe existence of a root system also in the nonabelian case <ref name=HS08/> implies rather immediately the following very strong implications:\n\nImmediate consequences are implied for ''rank 2'' Nichols algebras <math>\\mathfrak{B}\\left(\\mathcal{O}_{[g]}\\oplus\\mathcal{O}_{[h]}\\right)</math> which ''g, h'' '''discommuting'''; then:\n* The braided commutators [''x'', ''y''] of elements <math>x\\in\\mathcal{O}_{[g]}\\; y\\in\\mathcal{O}_{[h]}</math> are '''not all zero'''.\n* The space of braided commutators <math>ad_{\\mathcal{O}_{[g]}}\\mathcal{O}_{[h]}=[\\mathcal{O}_{[g]},\\mathcal{O}_{[h]}]</math> form an '''irreducible''' sub-Yetter–Drinfeld module <math>\\mathcal{O}_{[gh]}</math>  (i.e. the root is unique as in the Lie algebra case)\n* They're '''\"close to commuting\"'' <math>\\;(gh)^2=(hg)^2</math>\n\nThis implies roughly, that finite-dimensional Nichols algebras over nonabelian groups have to be (if at all) of very low rank or the group has to be close-to-abelian.\n\n===Negative criteria: nonabelian subracks (type D)===\nAs the abelian subracks use the structural classification of Heckenberger for Nichols algebras over abelian groups (see above) one can also consider nonabelian subracks. If such a subrack decomposes into several pieces (because now less element are present to conjugate), then the above results on root systems apply.\n\nA specific case<ref name=AFGV10b/> where this is highly successful is '''type D''', i.e. for <math>r,s\\in [g]\\;</math>\n* ''r'', ''s'' not conjugate in the generated subgroup <math>\\langle r,s\\rangle\\;</math>\n* <math>(rs)^2\\neq(sr)^2\\;</math>\nin this case the Nichols algebra of the subrack is '''infinite-dimensional''' and so is the entire Nichols algebra\n\n===Known groups not admitting finite-dimensional Nichols algebras===\nBoth negation techniques above have been very fruitful to '''negate''' (indecomposable) finite-dimensional Nichols algebras:<ref name=AFGV10b/>\n* for [[Alternating groups]]s <math>\\mathbb{A}_{n\\geq 5}</math> <ref name=AFGV10c/>\n* for [[Symmetric group]]s <math>\\mathbb{S}_{n\\geq 6}</math> except a short list of examples<ref name=AFGV10c/>\n* some [[group of Lie type]] ''(sources, complete list?)''\n* all [[Sporadic group]]s except a short list of possibilities (resp. conjugacy classes in ATLAS notation) that are all real or ''j'' = 3-quasireal:\n**...for the [[Fischer group]] <math>Fi_{22}\\;</math> the classes <math>22A,22B\\;</math>\n**...for the [[baby monster group]] ''B'' the classes <math>16C,\\;16D,\\;32A,\\;32B,\\;32C,\\;32D,\\;34A,\\;46A,\\;46B\\;</math>\n**...for the [[monster group]] ''M'' the classes <math>32A,\\;32B,\\;46A,\\;46B,\\;92A,\\;92B,\\;94A,\\;94B\\;</math>\nUsually a large amount of conjugacy classes ae of type D (\"not commutative enough\"), while the others tend to possess sufficient abelian subracks and can be excluded by their consideration. Several cases have to be done by-hand. Note that the open cases tend to have very small centralizers (usually cyclic) and representations χ (usually the 1-dimensional sign representation). Significant exceptions are the conjugacy classes of order 16, 32 having as centralizers [[p-group]]s of order 2048 resp. 128 and currently no restrictions on χ.\n\n==Applications==\nThe Nichols algebra appears as '''quantum Borel part''' in the classification of finite-dimensional pointed Hopf algebras<ref name=AS02/> (without small primes) by Nicolas Andruskiewitsch and Hans-Jürgen Schneider, especially [[Quantum groups]]. For example,  <math>U_q(\\mathfrak{g})</math> and their well known truncations for ''q'' a root of unity decompose just like an ordinary [[Semisimple Lie algebra]] into ''E''´s (Borel part), dual ''F''´s and ''K''´s (Cartan algebra):\n\n::<math>U_q(\\mathfrak{g})\\cong \\left(\\mathfrak{B}(V)\\otimes k[\\mathbb{Z}^n]\\otimes\\mathfrak{B}(V^*)\\right)^\\sigma</math>\n\nHere, as in the classical theory ''V'' is a vectorspace of dimension ''n'' (the '''rank''' of <math>\\mathfrak{g}</math>) spanned by the ''E''´s, and σ (a so-called cocylce twist) creates the nontrivial '''linking''' between ''E''´s and ''F''´s. Note that in contrast to classical theory, more than two linked components may appear. See ''cit. loc.'' for an exotic example with 4 parts of type A<sub>3</sub>.[[File:Dynkin4A3lift.png|thumb|generalized Dynkin diagram for a pointed Hopf algebra linking four A3 copies]]\n\nThe classification roughly reduces a given hypothetical example to a [[Braided Hopf algebra|Radford biproduct]] of the (coradical-) group and the (connected-) part, which contains the Nichols algebra, by taking the corresponding \"graded object\" (killing all linkings). With the knowledge from the classification of finite-dimensional Nichols algebras above, the authors prove no additional elements to appear in the connected part (generation in degree 1), and finally describe all possible liftings as \"dotted lines\" in generalized [[Dynkin diagrams]].\n\nRecently, this correspondence has been greatly extended to identify certain so-called '''coideal subalgebras''' to be in 1:1 correspondence<ref name=HS09/> to the [[Weyl group]], which has been conjectued as \"numerical coincidence\" earlier and proven in certain cases by-hand.\n\n==References==\n<ref name=AS02>Andruskiewitsch, Schneider: ''Pointed Hopf algebras'',  New directions in Hopf algebras,  1–68, Math. Sci. Res. Inst. Publ., 43, Cambridge Univ. Press, Cambridge, 2002.</ref>\n<ref name=H05>Heckenberger: ''Nichols algebras of diagonal type and arithmetic root systems'', Habilitation thesis 2005.</ref>\n<ref name=HS08>Heckenberger, Schneider: ''Root system and Weyl gruppoid for Nichols algebras'', 2008.</ref>\n<ref name=H08>Heckenberger: ''Nichols Algebras'' (Lecture Notes), 2008 http://www.mi.uni-koeln.de/~iheckenb/na.pdf</ref>\n<ref name=H06>Heckenberger: ''The Weyl groupoid of a Nichols algebra of diagonal type'', Invent. Math. 164 (2006), 175-188.</ref>\n<ref name=AHS10>Andruskiewitsch, Heckenberger, Schneider: ''The Nichols algebra of a semisimple Yetter-Drinfeld module'', Amer. J. Math. 132 (2010), no. 6, 1493–1547</ref>\n<ref name=C10>Cuntz: ''Crystallographic arrangements: Weyl groupoids and simplicial\n  arrangements'', Bull. London Math. Soc. 43 (2011), no.4, 734-744.</ref>\n<ref name=CH10>Cuntz, Heckenberger: ''Finite Weyl groupoids'', J. Reine Angew. Math. 702\n  (2015), 77-108.</ref>\n<ref name=CL15>Cuntz, Lentner: ''A simplicial complex of Nichols algebras'', Preprint under https://arxiv.org/abs/1503.08117.</ref>\n<ref name=An08>Angiono: ''A presentation by generators and relations of Nichols algebras of diagonal type and convex orders on root systems.'' Preprint  arXiv:1008.4144. to appear in J. Europ. Math. Soc.</ref>\n<ref name=AFGV10a>Andruskiewitsch, Fantino, Grana, Vendramin: ''On Nichols algebras associated to simple racks'', 2010.</ref>\n<ref name=AFGV10b>Andruskiewitsch, Fantino, Grana, Vendramin: ''Pointed Hopf algebras over the sporadic simple groups'', 2010.</ref>\n<ref name=AFGV10c>Andruskiewitsch, Fantino, Grana, Vendramin: ''Finite-dimensional pointed Hopf algebras with alternating groups are trivial'', 2010.</ref>\n<ref name=HS09>Heckenberger, Schneider: ''Right coideal subalgebras of Nichols algebras and the Duflo order of the Weyl grupoid'', 2009.</ref>\n<ref name=MS00>Schneider, Milinski: ''Nichols algebras over Coxeter groups'', 2000.</ref>\n<ref name=AG03>Andruskiewisch, Grana: ''From racks to pointed Hopf algebras'', 2003.</ref>\n<ref name=FK99>Fomin,Kirilov: ''Quadratic algebras, Dunkl elements and Schubert calculus'', 1999.</ref>\n<ref name=GranaZoo>Grana: http://mate.dm.uba.ar/~matiasg/zoo.html</ref>\n<ref name=HS10>Heckenberger, Schneider: ''Nichols algebras over groups with finite root system of rank 2 I'', 2010.</ref>\n<references />\n\n[[Category:Hopf algebras]]\n[[Category:Quantum groups]]"
    },
    {
      "title": "Noncommutative symmetric function",
      "url": "https://en.wikipedia.org/wiki/Noncommutative_symmetric_function",
      "text": "In mathematics, the '''noncommutative symmetric functions''' form a [[Hopf algebra]] NSymm analogous to the [[Hopf algebra of symmetric functions]]. The Hopf algebra NSymm was introduced by {{harvs|txt|MR=1327096\n|last1=Gelfand|first1= Israel M.|last2= Krob|first2= Daniel|last3= Lascoux|first3= Alain|last4= Leclerc|first4= Bernard|last5= Retakh|first5= Vladimir S.|last6=Thibon|first6= Jean-Yves\n|title=Noncommutative symmetric functions\n|journal=Adv. Math.|volume= 112 |year=1995|issue= 2|pages= 218–348}}.\nIt is noncommutative but cocommutative graded Hopf algebra. It has the Hopf algebra of [[symmetric function]]s as a quotient, and is a subalgebra of the [[Hopf algebra of permutations]], and is the graded dual of the Hopf algebra of [[quasisymmetric function]]. Over the rational numbers it is isomorphic as a Hopf algebra to the [[universal enveloping algebra]] of the free Lie algebra on countably many variables.\n\n==Definition==\n\nThe underlying algebra of the Hopf algebra of noncommutative symmetric functions is the free ring '''Z'''&lang;''Z''<sub>1</sub>,&nbsp;''Z''<sub>2</sub>,...&rang; generated by non-commuting variables ''Z''<sub>1</sub>,&nbsp;''Z''<sub>2</sub>,&nbsp;...\n\nThe coproduct takes ''Z''<sub>''n''</sub> to Σ&nbsp;''Z''<sub>''i''</sub>&nbsp;&otimes;&nbsp;''Z''<sub>''n''–''i''</sub>, where ''Z''<sub>0</sub>&nbsp;=&nbsp;1 is the identity.\n\nThe counit takes ''Z''<sub>''i''</sub> to 0 for ''i''&nbsp;>&nbsp;0 and takes ''Z''<sub>0</sub>&nbsp;=&nbsp;1 to&nbsp;1.\n==Related notions==\n\n{{harvtxt|Hazewinkel|2012}} shows that a [[Hasse–Schmidt derivation]]\n\n:<math>D: A \\to A [[t]]</math>\n\non a ring ''A'' is equivalent to an action of NSymm on ''A'': the part <math>D_i : A \\to A</math> of ''D'' which picks the coefficient of <math>t^i</math>, is the action of the indeterminate ''Z''<sub>''i''</sub>.\n\n===Relation to free Lie algebra===\nThe element Σ&nbsp;''Z''<sub>''n''</sub>''t''<sup>''n''</sup> is a [[group-like element]] of the Hopf algebra of formal power series over NSymm, so over the rationals its logarithm is primitive. The coefficients of its logarithm generate the free Lie algebra on a countable set of generators over the rationals. Over the rationals this identifies the Hopf algebra NSYmm with the universal enveloping algebra of the free Lie algebra.\n\n==References==\n\n*{{citation|MR=1327096\n|last1=Gelfand|first1= Israel M.|last2= Krob|first2= Daniel|last3= Lascoux|first3= Alain|last4= Leclerc|first4= Bernard|last5= Retakh|first5= Vladimir S.|last6=Thibon|first6= Jean-Yves\n|title=Noncommutative symmetric functions\n|journal=Adv. Math.|volume= 112 |year=1995|issue= 2|pages= 218–348|doi=10.1006/aima.1995.1032|arxiv=hep-th/9407124}}\n\n* {{Citation|title=Hasse–Schmidt Derivations and the Hopf Algebra of Non-Commutative Symmetric Functions|author=Hazewinkel|first=Michiel|journal=Axioms|year=2012|volume=1|issue=2|pages=149–154|doi=10.3390/axioms1020149}}\n\n[[Category:Hopf algebras]]"
    },
    {
      "title": "Pareigis Hopf algebra",
      "url": "https://en.wikipedia.org/wiki/Pareigis_Hopf_algebra",
      "text": "In algebra, the '''Pareigis Hopf algebra''' is the [[Hopf algebra]] over a field ''k'' whose left comodules are essentially the same as complexes over ''k'', in the sense that the corresponding monoidal categories are isomorphic. It was introduced by {{harvtxt|Pareigis|1981}} as a natural example of a Hopf algebra that is neither commutative nor cocommutative.\n\n==Construction==\n\nAs an algebra over ''k'', the Pareigis algebra is generated by elements ''x'',''y'', 1/''y'', with the relations ''xy''&nbsp;+&nbsp;''yx''&nbsp;=&nbsp;''x''<sup>2</sup>&nbsp;=&nbsp;0. The coproduct takes ''x'' to ''x''⊗1&nbsp;+&nbsp;(1/''y'')⊗''x'' and ''y'' to ''y''⊗''y'', and the counit takes ''x'' to 0 and ''y'' to&nbsp;1. The antipode takes ''x'' to ''xy'' and ''y'' to its inverse and has order&nbsp;4.\n\n==Relation to complexes==\n\nIf ''M'' = &oplus;''M''<sub>''n''</sub> is a complex with differential ''d'' of degree –1, then ''M'' can be made into a comodule over ''H'' by letting the coproduct take ''m'' to Σ ''y''<sup>''n''</sup>&otimes;''m''<sub>''n''</sub> + ''y''<sup>''n''+1</sup>''x''&otimes;''dm''<sub>''n''</sub>, where ''m''<sub>''n''</sub> is the component of ''m'' in ''M''<sub>''n''</sub>. This gives an equivalence between the monoidal category of complexes over ''k'' with the monoidal category of comodules over the Pareigis Hopf algebra.\n\n==See also==\n\n*[[Sweedler's Hopf algebra]] is the quotient of the Pareigis Hopf algebra obtained by putting&nbsp;''y''<sup>2</sup>&nbsp;=&nbsp;1.\n\n==References==\n\n*{{citation|MR=0623814 \n|last=Pareigis|first= Bodo\n|title=A noncommutative noncocommutative Hopf algebra in \"nature\" \n|journal=J. Algebra|volume= 70 |year=1981|issue= 2|pages= 356–374|doi=10.1016/0021-8693(81)90224-6}}\n \n[[Category:Hopf algebras]]"
    },
    {
      "title": "Quasisymmetric function",
      "url": "https://en.wikipedia.org/wiki/Quasisymmetric_function",
      "text": "{{for|quasisymmetric functions in the theory of  metric spaces or complex analysis|quasisymmetric map}}\nIn [[algebra]] and in particular in [[algebraic combinatorics]], a '''quasisymmetric function''' is any element in the '''ring of quasisymmetric functions''' which is in turn a subring of the [[formal power series]] ring with a countable number of variables.  This ring generalizes  the [[ring of symmetric functions]].  This ring can be realized as a specific limit of the [[ring (mathematics)|rings]] of quasisymmetric polynomials in ''n'' variables, as ''n'' goes to infinity. This ring serves as universal structure in which relations between quasisymmetric polynomials can be expressed in a way independent of the number ''n'' of variables (but its elements are neither polynomials nor functions).\n\n== Definitions ==\n\nThe '''ring of quasisymmetric functions''', denoted QSym, can be defined over any [[commutative ring]] ''R'' such as the  [[integers]]. \nQuasisymmetric \nfunctions are [[formal power series|power series]] of bounded degree in variables <math>x_1,x_2,x_3, \\dots </math> with coefficients in ''R'', which are shift invariant in the sense that the coefficient of  the monomial <math>x_1^{\\alpha_1}x_2^{\\alpha_2}  \\cdots x_k^{\\alpha_k}</math> is equal to the coefficient of the monomial <math>x_{i_1}^{\\alpha_1} x_{i_2}^{\\alpha_2}\\cdots x_{i_k}^{\\alpha_k}</math> for any strictly increasing sequence of positive integers \n<math>i_1< i_2< \\cdots < i_k</math> indexing the variables and any positive integer sequence <math>(\\alpha_1, \\alpha_2,\\ldots,\\alpha_k)</math> of exponents.<ref name=\"EC2\">\n[[Richard P. Stanley|Stanley, Richard P.]] ''Enumerative Combinatorics'', Vol. 2, Cambridge University Press, 1999. {{ISBN|0-521-56069-1}} (hardback) {{ISBN|0-521-78987-7}} (paperback).</ref>\nMuch of the study of quasisymmetric functions is based on that of [[symmetric functions]].\n\nA quasisymmetric function in finitely many variables is a ''quasisymmetric [[polynomial]]''.\nBoth symmetric and quasisymmetric polynomials may be characterized in terms of [[Group action (mathematics)|actions]] of the [[symmetric group]] <math>S_n</math>\non a [[polynomial ring]] in <math>n</math> variables <math>x_1,\\dots, x_n</math>. \nOne such action of <math>S_n</math> permutes variables,\nchanging a polynomial <math>p(x_1,\\dots,x_n)</math> by iteratively swapping pairs <math>(x_i, x_{i+1})</math>\nof variables having consecutive indices.\nThose polynomials unchanged by all such swaps\nform the subring of symmetric polynomials.\nA second action of <math>S_n</math> conditionally permutes variables, \nchanging a polynomial <math>p(x_1,\\ldots,x_n)</math>\nby swapping pairs <math>(x_i, x_{i+1})</math> of variables\n''except'' in monomials containing both variables.\nThose polynomials unchanged by all such conditional swaps form\nthe subring of quasisymmetric polynomials.  One quasisymmetric function in four variables is the polynomial\n\n: <math> x_1^2 x_2 x_3 + x_1^2 x_2 x_4 + x_1^2 x_3 x_4 + x_2^2 x_3 x_4. \\, </math>\n\nThe simplest symmetric function containing all of these monomials is\n\n: <math> \n\\begin{align}\nx_1^2 x_2 x_3 + x_1^2 x_2 x_4 + x_1^2 x_3 x_4 + x_2^2 x_3 x_4\n+ x_1 x_2^2 x_3 + x_1 x_2^2 x_4 + x_1 x_3^2 x_4 + x_2 x_3^2 x_4 \\\\\n{} + x_1 x_2 x_3^2 + x_1 x_2 x_4^2 + x_1 x_3 x_4^2 + x_2 x_3 x_4^2. \\,\n\\end{align}\n</math>\n\n== Important bases ==\n\nQSym is a [[graded algebra|graded]] ''R''-[[Algebra over a ring|algebra]], decomposing as \n\n: <math>\\operatorname{QSym} = \\bigoplus_{n \\ge 0} \\operatorname{QSym}_n, \\, </math>\n\nwhere <math>\\operatorname{QSym}_n</math> is the <math>R</math>-[[linear span|span]] of all quasisymmetric functions that are [[homogeneous polynomial|homogeneous]] of degree <math>n</math>.  Two natural [[linear basis|bases]] for <math>\\operatorname{QSym}_n</math> are the '''monomial basis''' <math>\\{M_{\\alpha} \\}</math> and the '''fundamental basis''' <math>\\{F_{\\alpha} \\}</math> indexed by [[composition (number theory)|composition]]s <math>\\alpha = (\\alpha_1, \\alpha_2, \\ldots , \\alpha_k)</math> of <math>n</math>, denoted <math>\\alpha \\vDash n</math>.    The monomial basis consists of <math>M_0=1</math> and all formal power series \n\n: <math>M_{\\alpha} = \\sum_{i_1 < i_2 < \\cdots < i_k} x_{i_1}^{\\alpha_1} x_{i_2}^{\\alpha_2} \\cdots x_{i_k}^{\\alpha_k}. \\, </math>\n\nThe fundamental basis consists <math>F_0=1</math> and all formal power series \n\n: <math>F_\\alpha = \\sum_{\\alpha \\succeq \\beta} M_\\beta, \\, </math>\n\nwhere <math>\\alpha \\succeq \\beta</math> means we can obtain <math>\\alpha</math> by adding together adjacent parts of <math>\\beta</math>, for example, (3,2,4,2)&nbsp;<math>\\succeq</math>&nbsp;(3,1,1,1,2,1,2).  Thus, when the ring <math>R</math> is the ring of [[rational numbers]], one has\n\n: <math>\\operatorname{QSym}_n = \\operatorname{span}_{\\mathbb{Q}} \\{ M_\\alpha \\mid \\alpha \\vDash n \\} = \\operatorname{span}_{\\mathbb{Q}} \\{ F_\\alpha \\mid \\alpha \\vDash n \\}. \\, </math>\n\nThen one can define the algebra of [[symmetric functions]] <math>\\Lambda = \\Lambda _0 \\oplus \\Lambda _1 \\oplus \\cdots</math> as the subalgebra of QSym spanned by the [[monomial symmetric polynomial|monomial symmetric functions]] <math>m_0=1</math> and all formal power series <math>m_\\lambda = \\sum M_\\alpha,</math> where the sum is over all compositions <math>\\alpha</math> which rearrange to the [[partition (number theory)|partition]] <math>\\lambda</math>.  Moreover, we have <math>\\Lambda_n = \\Lambda \\cap \\operatorname{QSym}_n</math>.  For example, <math>F_{(1,2)}=M_{(1,2)}+M_{(1,1,1)}</math> and <math>m_{(2,1)}=M_{(2,1)}+M_{(1,2)}.</math>\n\nOther important bases for quasisymmetric functions include the basis of quasisymmetric Schur functions,<ref name=\"HLMvW1\">{{citation|first1=J. |last1=Haglund|first2= K. |last2=Luoto|first3=S. |last3=Mason |first4= S. |last4=van Willigenburg|title= Quasisymmetric Schur functions|journal=J. Combin. Theory Ser. A|volume= 118 |year=2011|pages= 463–490|doi=10.1016/j.jcta.2009.11.002|issue=2}}</ref> and bases related to enumeration in matroids.<ref name =\"Luoto\">{{citation|first=K. |last=Luoto|title= A matroid-friendly basis for the quasisymmetric functions|journal=J. Combin. Theory Ser. A|volume= 115 |year=2008|pages= 777–798|bibcode=2007arXiv0704.0836L|arxiv=0704.0836|doi=10.1016/j.jcta.2007.10.003|issue=5}}</ref><ref name=\"BJR\">{{citation|first1=L. |last1=Billera|first2=N. |last2=Jia |first3= V. |last3=Reiner|title= A quasisymmetric function for matroids|journal= European J. Combin.|volume= 30 |year=2009|pages= 1727–1757|bibcode=2006math......6646B|arxiv=math/0606646|doi=10.1016/j.ejc.2008.12.007|issue=8}}</ref>\n\n== Applications ==\n\nQuasisymmetric functions have been applied in enumerative combinatorics, symmetric function theory, representation theory, and number theory.  Applications of\nquasisymmetric functions include enumeration of P-partitions,<ref name=\"StanThesis\">\n[[Richard P. Stanley|Stanley, Richard P.]] ''Ordered structures and partitions,'' Memoirs of the American Mathematical Society, No. 119, American Mathematical Society, 1972.</ref><ref name=\"Ppart\">\nGessel, Ira. ''Multipartite P-partitions and inner products of skew Schur functions,'' Combinatorics and algebra (Boulder, Colo., 1983),  289–317, Contemp. Math., 34, Amer. Math. Soc., Providence, RI, 1984.</ref>\npermutations,<ref name=\"GesselReutenauer\">{{citation|\n last1=Gessel|first1=Ira|last2= Reutenauer|first2= Christophe|title=Counting permutations with given cycle structure and descent set |journal= J. Combin. Theory Ser. A  |volume=64  |year=1993|pages= 189–215|issue= 2|\n doi=10.1016/0097-3165(93)90095-P}}</ref><ref name=\"Shareshian\">{{citation|last1= Shareshian|first1= John|last2= Wachs|first2= Michelle L.|author2-link= Michelle L. Wachs |title=<math>q</math>-Eulerian polynomials: excedance number and major index|journal= Electron. Res. Announc. Amer. Math. Soc.  |volume=13  |year=2007|pages= 33–45|doi= 10.1090/S1079-6762-07-00172-2|issue= 4|arxiv= math/0608274}}</ref><ref name=\"Shareshian2\">{{citation|last1= Shareshian|first1= John|last2= Wachs|first2= Michelle L.|author2-link= Michelle L. Wachs |title= Eulerian quasisymmetric functions|journal=Advances in Mathematics |volume=225 |issue=6 |year= 2010 |pages=2921–2966|doi= 10.1016/j.aim.2010.05.009}}</ref><ref name=\"Hyatt\">\n{{citation|last=Hyatt|first= Matthew|title=Eulerian quasisymmetric functions for the type B Coxeter group and other wreath product groups|arxiv=1007.0459|bibcode=2010arXiv1007.0459H|journal=Advances in Applied Mathematics |volume=48 |year=2012 |pages=465–505}}\n</ref> tableaux,<ref name=\"StanCox\">{{citation|last=Stanley|first=Richard P.|authorlink=Richard P. Stanley|title=On the number of reduced decompositions of elements of Coxeter groups|journal=  European J. Combin. |volume= 5  |year=1984 |pages= 359–372 |issue= 4 |doi=10.1016/s0195-6698(84)80039-6}}</ref> chains of posets,<ref name=\"StanCox\" /><ref name=\"Ehrenborg\">{{citation|last=Ehrenborg|first= Richard|title=On posets and Hopf algebras|journal=  Adv. Math. |volume= 119\n|year=1996|pages= 1–25|issue=  1|doi=10.1006/aima.1996.0026}}</ref> reduced decompositions in finite Coxeter groups (via [[Stanley symmetric function]]s),<ref name=\"StanCox\"/> and parking functions.<ref name=\"HagBook\">Haglund, James; The ''q'',''t''-Catalan numbers and the space of diagonal harmonics.\nUniversity Lecture Series, 41. American Mathematical Society, Providence, RI,  2008. viii+167 pp. {{ISBN|978-0-8218-4411-3}}; 0-8218-4411-3</ref> In symmetric function theory and representation theory, applications include the study of [[Schubert polynomial]]s,<ref name=\"Billey\">{{citation|last1=Billey|first1= Sara C.|last2=Jockusch|first2=William|last3= Stanley|first3= Richard P.|title=''Some combinatorial properties of Schubert polynomials''|journal=[[Journal of Algebraic Combinatorics]] |volume=2 |year=1993|pages= 345–374|issue=  4|doi=10.1023/A:1022419800503|url=https://deepblue.lib.umich.edu/bitstream/2027.42/46173/1/10801_2004_Article_415600.pdf}}</ref><ref name=\"Fomin\">{{citation|last1=Fomin|first1=Sergey|last2=Stanley|first2= Richard P. |title=Schubert polynomials and the nil-Coxeter algebra|journal= [[Advances in Mathematics]] |volume=103 |year=1994|pages= 196–207|issue= 2|doi=10.1006/aima.1994.1009}}</ref> Macdonald polynomials,<ref name=\"Assaf\">{{citation|last=Assaf|first= Sami|title=Dual Equivalence Graphs I: A combinatorial proof of LLT and Macdonald positivity|arxiv=1005.3759|bibcode = 2010arXiv1005.3759A }}</ref>\nHecke algebras,<ref name=\"Duchamp\">{{citation|last1=Duchamp|first1= Gérard|last2= Krob|first2= Daniel|last3= Leclerc|first3= Bernard|last4= Thibon|first4= Jean-Yves|title= Fonctions quasi-symétriques, fonctions symétriques non commutatives et algèbres de Hecke à <math>q=0</math>|journal= C. R. Acad. Sci. Paris |series=Sér. I Math.  |volume=322  |year=1996|pages= 107–112|issue= 2}}</ref> and Kazhdan–Lusztig polynomials.<ref name=\"Billera\">{{citation |last1=Billera |first1= Louis J. |last2= Brenti |first2= Francesco |year=2011 |title= Quasisymmetric functions and Kazhdan–Lusztig polynomials| eprint=0710.3965 |mode=cs2|journal = Israel Journal of Mathematics|volume = 184|pages = 317–348|doi = 10.1007/s11856-011-0070-0}}</ref> Often quasisymmetric functions provide a powerful bridge between combinatorial structures and symmetric functions.\n\n== Related algebras ==\n\nAs a graded Hopf algebra, the dual of the ring of quasisymmetric functions is the ring of noncommutative symmetric functions. \nEvery symmetric function is also a quasisymmetric function, and hence the ring of symmetric functions is a subalgebra of the ring of quasisymmetric functions.\n\nThe ring of quasisymmetric functions is the terminal object in category of graded Hopf algebras with a single character.<ref name=\"ABS\">{{citation|last1=Aguiar|first1= Marcelo|last2=Bergeron|first2= Nantel|last3= Sottile|first3= Frank |title=Combinatorial Hopf algebras and generalized Dehn–Sommerville relations|journal=  Compositio Mathematica  |volume=142  |year=2006|pages= 1–30 |issue= 1|bibcode=2003math.....10016A|arxiv=math/0310016|doi=10.1112/S0010437X0500165X}}</ref>\nHence any such Hopf algebra has a morphism to the ring of quasisymmetric functions.\n\nOne example of this is the [[peak algebra]].<ref name=\"Stem\">{{citation|last=Stembridge|first= John R. |title=Enriched P-partitions|journal=  [[Trans. Amer. Math. Soc.]]  |volume=349|year=1997|pages= 763–788  |issue=2|doi=10.1090/S0002-9947-97-01804-7}}</ref>\n\n=== Other related algebras ===\nThe [[Malvenuto–Reutenauer algebra]]<ref name=\"MR\">{{citation|last1=Malvenuto|first1=Clauda|last2= Reutenauer|first2= Christophe |title=Duality between quasi-symmetric functions and the Solomon descent algebra|journal=  [[Journal of Algebra]]  |volume=177  |year=1995 |pages=967–982  |issue= 3|doi=10.1006/jabr.1995.1336}}</ref> is a Hopf algebra based on permutations that relates the rings of symmetric functions, quasisymmetric functions, and [[noncommutative symmetric function]]s, (denoted Sym, QSym, and NSym respectively), as depicted the following commutative diagram.  The duality between QSym and NSym mentioned above is reflected in the main diagonal of this diagram.\n\n[[Image:QSymDiagram.png|300px|(Relationship between QSym and nearby neighbors)]]\n\nMany related Hopf algebras were constructed from Hopf monoids in the category of species by Aguiar and Majahan\n.<ref>Aguiar, Marcelo; Mahajan, Swapneel ''Monoidal Functors, Species and Hopf Algebras'' CRM Monograph Series, no. 29. American Mathematical Society, Providence, RI, 2010.</ref>\n\nOne can also construct the ring of quasisymmetric functions in noncommuting variables.<ref name=\"Hiver\">Hivert, Florent, Ph.D. Thesis, Marne-la-Vallée</ref><ref name=\"BZ\">{{citation|last1=Bergeron|first1= Nantel|last2= Zabrocki|first2= Mike|title= The Hopf algebras of symmetric functions and quasi-symmetric functions in non-commutative variables are free and co-free|journal=  J. Algebra Appl. |volume= 8  |year=2009|pages= 581–600|issue= 4|doi=10.1142/S0219498809003485|arxiv=math/0509265}}</ref>\n\n==References==\n{{Reflist}}\n==External links==\n*[http://www.birs.ca/events/2010/5-day-workshops/10w5031 BIRS Workshop on Quasisymmetric Functions]\n\n[[Category:Algebraic combinatorics]]\n[[Category:Types of functions]]\n[[Category:Polynomials]]\n[[Category:Symmetric functions|*]]\n[[Category:Ring theory]]\n[[Category:Hopf algebras]]"
    },
    {
      "title": "Quasitriangular Hopf algebra",
      "url": "https://en.wikipedia.org/wiki/Quasitriangular_Hopf_algebra",
      "text": "{{Refimprove|date=December 2009}}\nIn [[mathematics]], a [[Hopf algebra]], ''H'', is '''quasitriangular'''<ref>Montgomery & Schneider (2002), [{{Google books|plainurl=y|id=I3IK9U5Co_0C|page=72|text=Quasitriangular}} p. 72].</ref> if [[there exists]] an [[inverse element|invertible]] element, ''R'', of <math>H \\otimes H</math> such that\n\n:*<math>R \\ \\Delta(x)R^{-1} = (T \\circ \\Delta)(x) </math> for all <math>x \\in H</math>, where <math>\\Delta</math> is the coproduct on ''H'', and the linear map <math>T : H \\otimes H \\to H \\otimes H</math> is given by <math>T(x \\otimes y) = y \\otimes x</math>,\n\n:*<math>(\\Delta \\otimes 1)(R) = R_{13} \\ R_{23}</math>,\n\n:*<math>(1 \\otimes \\Delta)(R) = R_{13} \\ R_{12}</math>,\n\nwhere <math>R_{12} = \\phi_{12}(R)</math>, <math>R_{13} = \\phi_{13}(R)</math>, and <math>R_{23} = \\phi_{23}(R)</math>, where <math>\\phi_{12} : H \\otimes H \\to H \\otimes H \\otimes H</math>, <math>\\phi_{13} : H \\otimes H \\to H \\otimes H \\otimes H</math>, and <math>\\phi_{23} : H \\otimes H \\to H \\otimes H \\otimes H</math>, are algebra [[morphism]]s determined by\n\n:<math>\\phi_{12}(a \\otimes b) = a \\otimes b \\otimes 1,</math>\n\n:<math>\\phi_{13}(a \\otimes b) = a \\otimes 1 \\otimes b,</math>\n\n:<math>\\phi_{23}(a \\otimes b) = 1 \\otimes a \\otimes b.</math>\n\n''R'' is called the R-matrix.\n\nAs a consequence of the properties of quasitriangularity, the R-matrix, ''R'', is a solution of the [[Yang-Baxter equation]] (and so a [[Module (mathematics)|module]] ''V'' of ''H'' can be used to determine quasi-invariants of [[braid theory|braids]], [[knot (mathematics)|knots]] and [[link (knot theory)|links]]).  Also as a consequence of the properties of quasitriangularity, <math>(\\epsilon \\otimes 1) R = (1 \\otimes \\epsilon) R = 1 \\in H</math>; moreover \n<math>R^{-1} = (S \\otimes 1)(R)</math>, <math>R = (1 \\otimes S)(R^{-1})</math>, and <math>(S \\otimes S)(R) = R</math>.  One may further show that the\nantipode ''S'' must be a linear isomorphism, and thus ''S<sup>2</sup>'' is an automorphism.  In fact, ''S<sup>2</sup>'' is given by conjugating by an invertible element: <math>S^2(x)= u x u^{-1}</math> where <math>u := m (S \\otimes 1)R^{21}</math> (cf. [[Ribbon Hopf algebra]]s).\n\nIt is possible to construct a quasitriangular Hopf algebra from a Hopf algebra and its dual, using the [[Vladimir Drinfeld|Drinfeld]] quantum double construction.\n\nIf the Hopf algebra ''H'' is quasitriangular, then the category of modules over ''H'' is braided with braiding\n:<math>c_{U,V}(u\\otimes v) = T \\left( R \\cdot (u \\otimes v )\\right) = T \\left( R_1 u \\otimes R_2 v\\right) </math>.\n\n==Twisting==\nThe property of being a [[quasi-triangular Hopf algebra]] is preserved by [[Quasi-bialgebra#Twisting|twisting]] via an invertible element <math> F = \\sum_i f^i \\otimes f_i \\in \\mathcal{A \\otimes A} </math> such that <math> (\\varepsilon \\otimes id )F = (id \\otimes \\varepsilon)F = 1 </math> and satisfying the cocycle condition\n\n:<math> (F \\otimes 1) \\circ (\\Delta \\otimes id) F = (1 \\otimes F) \\circ (id \\otimes \\Delta) F </math>\n\nFurthermore, <math> u = \\sum_i f^i S(f_i)</math> is invertible and the twisted antipode is given by <math>S'(a) = u S(a)u^{-1}</math>, with the twisted comultiplication, R-matrix and co-unit change according to those defined for the [[quasi-triangular quasi-Hopf algebra]]. Such a twist is known as an admissible (or Drinfeld) twist.\n\n==See also==\n* [[Quasi-triangular quasi-Hopf algebra]]\n* [[Ribbon Hopf algebra]]\n\n== Notes ==\n<references/>\n\n== References ==\n* {{cite book | last=Montgomery | first=Susan | authorlink=Susan Montgomery | title=Hopf algebras and their actions on rings | series=Regional Conference Series in Mathematics | volume=82 | location=Providence, RI | publisher=[[American Mathematical Society]] | year=1993 | isbn=0-8218-0738-2 | zbl=0793.16029 }}\n* {{cite book |authorlink=Susan Montgomery |first=Susan | last=Montgomery | authorlink2=Hans-Jürgen Schneider |first2=Hans-Jürgen |last2=Schneider |title=New directions in Hopf algebras | series=Mathematical Sciences Research Institute Publications | volume=43 | publisher=[[Cambridge University Press]] | year=2002 | isbn=978-0-521-81512-3 | zbl=0990.00022 }}\n\n{{DEFAULTSORT:Quasitriangular Hopf Algebra}}\n[[Category:Hopf algebras]]"
    },
    {
      "title": "Representation theory of Hopf algebras",
      "url": "https://en.wikipedia.org/wiki/Representation_theory_of_Hopf_algebras",
      "text": "{{Unreferenced|date=December 2009}}\nIn [[abstract algebra]], a '''representation of a Hopf algebra''' is a [[algebra representation|representation]] of its underlying [[associative algebra]]. That is, a representation of a Hopf algebra ''H'' over a field ''K'' is a ''K''-[[vector space]] ''V'' with an [[Group action (mathematics)|action]] ''H'' × ''V'' → ''V'' usually denoted by juxtaposition ( that is, the image of (''h'',''v'') is written ''hv'' ). The vector space ''V'' is called an ''H''-module.\n\n==Properties==\nThe module structure of a representation of a Hopf algebra ''H'' is simply its structure as a module for the underlying associative algebra. The main use of considering the additional structure of a Hopf algebra is when considering all ''H''-modules as a category. The additional structure is also used to define invariant elements of an ''H''-module ''V''. An element ''v'' in ''V'' is [[Invariant (mathematics)|invariant]] under ''H'' if for all ''h'' in ''H'', ''hv'' = ε(''h'')''v'', where ε is the [[counit]] of ''H''. The subset of all invariant elements of ''V'' forms a submodule of ''V''.\n\n==Categories of representations as a motivation for Hopf algebras==\nFor an associative algebra ''H'', the [[tensor product]] ''V''<sub>1</sub> ⊗ ''V''<sub>2</sub> of two ''H''-modules ''V''<sub>1</sub> and ''V''<sub>2</sub> is a vector space, but not necessarily an ''H''-module. For the tensor product to be a [[functor]]ial product operation on ''H''-modules, there must be a linear binary operation Δ : ''H'' → ''H'' ⊗ ''H'' such that for any ''v'' in ''V''<sub>1</sub> ⊗ ''V''<sub>2</sub> and any ''h'' in ''H'',\n\n:<math>hv=\\Delta h(v_{(1)}\\otimes v_{(2)})=h_{(1)}v_{(1)}\\otimes h_{(2)}v_{(2)},</math>\n\nand for any ''v'' in ''V''<sub>1</sub> ⊗ ''V''<sub>2</sub> and ''a'' and ''b'' in ''H'',\n\n:<math>\\Delta(ab)(v_{(1)}\\otimes v_{(2)})=(ab)v=a[b[v]]=\\Delta a[\\Delta b(v_{(1)}\\otimes v_{(2)})]=(\\Delta a )(\\Delta b)(v_{(1)}\\otimes v_{(2)}).</math>\n\nusing sumless [[Sweedler's notation]], which is somewhat like an index free form of [[Einstein's summation convention]]. This is satisfied if there is a Δ such that Δ(''ab'') = Δ(''a'')Δ(''b'') for all ''a'', ''b'' in ''H''.\n\nFor the category of ''H''-modules to be a strict [[monoidal category]] with respect to ⊗, <math>V_1\\otimes(V_2\\otimes V_3)</math> and <math>(V_1\\otimes V_2)\\otimes V_3</math> must be equivalent and there must be unit object ε<sub>''H''</sub>, called the trivial module, such that ε<sub>''H''</sub> ⊗ ''V'', ''V'' and ''V'' ⊗ ε<sub>''H''</sub> are equivalent. \n\nThis means that for any ''v'' in \n\n:<math>V_1\\otimes(V_2\\otimes V_3)=(V_1\\otimes V_2)\\otimes V_3</math> \n\nand for ''h'' in ''H'',\n\n:<math>((\\operatorname{id}\\otimes \\Delta)\\Delta h)(v_{(1)}\\otimes v_{(2)}\\otimes v_{(3)})=h_{(1)}v_{(1)}\\otimes h_{(2)(1)}v_{(2)}\\otimes h_{(2)(2)}v_{(3)}=hv=((\\Delta\\otimes \\operatorname{id}) \\Delta h) (v_{(1)}\\otimes v_{(2)}\\otimes v_{(3)}).</math>\n\nThis will hold for any three ''H''-modules if Δ satisfies \n\n:<math>(\\operatorname{id}\\otimes \\Delta)\\Delta A=(\\Delta \\otimes \\operatorname{id})\\Delta A.</math>\n\nThe trivial module must be one-dimensional, and so an [[algebra homomorphism]] ε : ''H'' → ''F'' may be defined such that ''hv'' = ε(''h'')''v'' for all ''v'' in ε<sub>''H''</sub>. The trivial module may be identified with ''F'', with 1 being the element such that 1 ⊗ ''v'' = ''v'' = ''v'' ⊗ 1 for all ''v''. It follows that for any ''v'' in any ''H''-module ''V'', any ''c'' in ε<sub>''H''</sub> and any ''h'' in ''H'',\n\n:<math>(\\varepsilon(h_{(1)})h_{(2)})cv=h_{(1)}c\\otimes h_{(2)}v=h(c\\otimes v)=h(cv)=(h_{(1)}\\varepsilon(h_{(2)}))cv.</math>\n\nThe existence of an algebra homomorphism ε satisfying \n\n:<math>\\varepsilon(h_{(1)})h_{(2)} = h = h_{(1)}\\varepsilon(h_{(2)})</math> \n\nis a sufficient condition for the existence of the trivial module. \n\nIt follows that in order for the category of ''H''-modules to be a monoidal category with respect to the tensor product, it is sufficient for ''H'' to have maps Δ and ε satisfying these conditions. This is the motivation for the definition of a [[bialgebra]], where Δ is called the [[comultiplication]] and ε is called the [[counit]].\n\nIn order for each ''H''-module ''V'' to have a [[dual representation]] ''V'' such that the underlying vector spaces are dual and the operation * is functorial over the monoidal category of ''H''-modules, there must be a linear map ''S'' : ''H'' → ''H'' such that for any ''h'' in ''H'', ''x'' in ''V'' and ''y'' in ''V*'',\n\n:<math>\\langle y, S(h)x\\rangle = \\langle hy, x \\rangle.</math>\n\nwhere <math>\\langle\\cdot,\\cdot\\rangle</math> is the usual [[pairing]] of dual vector spaces. If the map <math>\\varphi:V\\otimes V^*\\rightarrow \\varepsilon_H</math> induced by the pairing is to be an ''H''-homomorphism, then for any ''h'' in ''H'', ''x'' in ''V'' and ''y'' in ''V*'',\n\n:<math>\\varphi\\left(h(x\\otimes y)\\right)=\\varphi\\left(x\\otimes S(h_{(1)})h_{(2)}y\\right)=\\varphi\\left(S(h_{(2)})h_{(1)}x\\otimes y\\right)=h\\varphi(x\\otimes y)=\\varepsilon(h)\\varphi(x\\otimes y),</math>\n\nwhich is satisfied if \n\n:<math>S(h_{(1)})h_{(2)}=\\varepsilon(h)=h_{(1)}S(h_{(2)})</math> \n\nfor all ''h'' in ''H''.\n\nIf there is such a map ''S'', then it is called an ''antipode'', and ''H'' is a Hopf algebra. The desire for a monoidal category of modules with functorial tensor products and dual representations is therefore one motivation for the concept of a Hopf algebra.\n\n==Representations on an algebra==\nA Hopf algebra also has representations which carry additional structure, namely they are algebras.\n\nLet ''H'' be a Hopf algebra.  If ''A'' is an [[algebra over a field|algebra]] with the product operation μ : ''A'' ⊗ ''A'' → ''A'', and ρ : ''H'' ⊗ ''A'' → ''A'' is a representation of ''H'' on ''A'', then ρ is said to be a representation of ''H'' on an algebra if μ is ''H''-[[equivariant]]. As special cases, Lie algebras, Lie superalgebras and groups can also have representations on an algebra.\n\n==See also==\n*[[Tannaka–Krein reconstruction theorem]]\n\n{{DEFAULTSORT:Representation Theory Of Hopf Algebras}}\n[[Category:Hopf algebras]]\n[[Category:Representation theory]]"
    },
    {
      "title": "Ribbon Hopf algebra",
      "url": "https://en.wikipedia.org/wiki/Ribbon_Hopf_algebra",
      "text": "A '''ribbon Hopf algebra''' <math>(A,m,\\Delta,u,\\varepsilon,S,\\mathcal{R},\\nu)</math> is a [[quasitriangular Hopf algebra]] which possess an invertible central element <math>\\nu</math> more commonly known as the ribbon element, such that the following conditions hold:\n\n:<math>\\nu^{2}=uS(u), \\; S(\\nu)=\\nu, \\; \\varepsilon (\\nu)=1</math>\n:<math>\\Delta (\\nu)=(\\mathcal{R}_{21}\\mathcal{R}_{12})^{-1}(\\nu \\otimes \\nu )</math>\n\nwhere <math>u=m(S\\otimes \\text{id})(\\mathcal{R}_{21})</math>.  Note that the element ''u'' exists for any quasitriangular Hopf algebra, and\n<math>uS(u)</math> must always be central and satisfies <math>S(uS(u))=uS(u), \\varepsilon(uS(u))=1, \\Delta(uS(u)) = \n(\\mathcal{R}_{21}\\mathcal{R}_{12})^{-2}(uS(u) \\otimes uS(u))</math>, so that all that is required is that it have a central square root with the above properties.\n\nHere\n:<math> A </math> is a vector space\n:<math> m </math> is the multiplication map <math>m:A \\otimes A \\rightarrow A</math>\n:<math> \\Delta </math> is the co-product map <math>\\Delta: A \\rightarrow A \\otimes A</math>\n:<math> u </math> is the unit operator <math>u:\\mathbb{C} \\rightarrow A</math>\n:<math> \\varepsilon </math> is the co-unit operator <math>\\varepsilon: A \\rightarrow \\mathbb{C}</math>\n:<math> S </math> is the antipode <math>S: A\\rightarrow A</math>\n:<math>\\mathcal{R}</math> is a universal R matrix\n\nWe assume that the underlying field <math>K</math> is <math>\\mathbb{C}</math>\n\nIf <math> A </math> is finite-dimensional, one could equivalently call it ''ribbon Hopf'' if and only if its category of (say, left) modules is ribbon; if <math> A </math> is finite-dimensional and quasi-triangular, then it is ribbon if and only if its category of (say, left) modules is pivotal.\n== See also ==\n*[[Quasitriangular Hopf algebra]]\n*[[Quasi-triangular quasi-Hopf algebra]]\n\n== References ==\n*{{cite journal |last=Altschuler |first=D. |last2=Coste |first2=A. |title=Quasi-quantum groups, knots, three-manifolds and topological field theory |journal=[[Communications in Mathematical Physics|Commun. Math. Phys.]] |volume=150 |year=1992 |issue= |pages=83–107 |arxiv=hep-th/9202047 |doi=10.1007/bf02096567|bibcode=1992CMaPh.150...83A }}\n*{{cite book |last=Chari |first=V. C. |last2=Pressley |first2=A. |title=A Guide to Quantum Groups |publisher=Cambridge University Press |year=1994 |isbn=0-521-55884-0 }}\n*{{cite journal |authorlink=Vladimir Drinfeld |first=Vladimir |last=Drinfeld |title=Quasi-Hopf algebras |journal=Leningrad Math J. |volume=1 |year=1989 |pages=1419–1457 }}\n*{{cite book |first=Shahn |last=Majid |title=Foundations of Quantum Group Theory |publisher=Cambridge University Press |year=1995 }}\n\n[[Category:Hopf algebras]]"
    },
    {
      "title": "Steenrod algebra",
      "url": "https://en.wikipedia.org/wiki/Steenrod_algebra",
      "text": "In [[algebraic topology]], a '''Steenrod algebra''' was defined by {{harvs|txt|last=Cartan|first=Henri|authorlink=Henri Cartan|year=1955}} to be the  algebra of stable [[cohomology operation]]s for mod <math>p</math> cohomology.\n\nFor a given [[prime number]] <math>p</math>, the Steenrod algebra <math>A_p</math> is the graded [[Hopf algebra]] over the field <math>\\mathbb{F}_p</math> of order <math>p</math>, consisting of all stable [[cohomology operation]]s for mod <math>p</math> [[cohomology]]. It is generated by the '''Steenrod squares''' introduced by {{harvs|txt|last=Steenrod|first=Norman|authorlink=Norman Steenrod|year=1947}} for <math>p=2</math>, and by the '''Steenrod reduced <math>p</math>th powers''' introduced in {{harvtxt|Steenrod|1953}} and the [[Bockstein homomorphism]] for <math>p>2</math>.\n\nThe term \"Steenrod algebra\" is also sometimes used for the algebra of cohomology operations of a [[generalized cohomology theory]].\n\n==Cohomology operations==\nA cohomology operation is a [[natural transformation]] between cohomology functors. For example, if we take cohomology with coefficients in a [[ring (mathematics)|ring]], the [[cup product]] squaring operation yields a family of cohomology operations:\n\n:<math>H^n(X;R) \\to H^{2n}(X;R)</math>\n:<math>x \\mapsto x \\smile x.</math>\n\nCohomology operations need not be homomorphisms of graded rings; see the Cartan formula below.\n\nThese operations  do not commute with [[suspension (topology)|suspension]]—that is, they are unstable. (This is because if <math>Y</math> is a suspension of a space <math>X</math>, the cup product on the cohomology of <math>Y</math> is trivial.) Steenrod constructed stable operations\n\n:<math>Sq^i : H^n(X;\\Z /2) \\to H^{n+i}(X;\\Z /2)</math>\n\nfor all <math>i</math> greater than zero. The notation <math>Sq</math> and their name, the Steenrod squares, comes from the fact that <math>Sq^n</math> restricted to classes of degree <math>n</math> is the cup square. There are analogous operations for odd primary coefficients, usually denoted <math>P^i</math> and called the reduced <math>p</math>-th power operations:\n\n:<math>P^i \\colon H^n(X;\\Z /p) \\to H^{n+2i(p-1)}(X;\\Z /p)</math>\n\nThe <math>Sq^i</math> generate a connected graded algebra over <math>\\Z /2</math>, where the multiplication is given by composition of operations. This is the mod 2 Steenrod algebra. In the case <math>p > 2</math>, the mod <math>p</math> Steenrod algebra is generated by the <math>P^i</math> and the [[Bockstein operation]] <math>\\beta</math> associated to the [[short exact sequence]]\n\n:<math>0 \\to \\Z /p \\to \\Z /p^2 \\to \\Z /p \\to 0.</math>\n\nIn the case <math>p=2</math>, the Bockstein element is <math>Sq^1</math> and the reduced <math>p</math>-th power <math>P^i</math> is <math>Sq^{2 i}</math>.\n\n==Axiomatic characterization==\n\n{{harvs|txt|last1=Steenrod|first1=Norman|authorlink1=Norman Steenrod|last2=Epstein|first2=David B. A. |authorlink2=David B. A. Epstein|year=1962}} showed that the Steenrod squares <math>Sq^n\\colon H^m \\to H^{m+n}</math> are characterized by the following 5 axioms:\n\n#Naturality: <math>Sq^n \\colon H^m(X;\\Z /2) \\to H^{m+n}(X;\\Z /2)</math> is an additive homomorphism and is functorial with respect to any <math>f\\colon X\\to Y.</math> so <math>f^*(Sq^n(x)) = Sq^n(f^*(x))</math>.\n#<math>Sq^0</math> is the identity homomorphism.\n#<math>Sq^n(x) = x \\smile x</math> for <math>x \\in H^n(X;\\Z /2)</math>.\n#If <math>n> \\deg(x)</math> then <math>Sq^n(x) = 0</math>\n#Cartan Formula: <math>Sq^n(x \\smile y) = \\sum_{i+j=n} (Sq^i x) \\smile (Sq^j y)</math>\n\nIn addition the Steenrod squares have the following properties: \n*<math>Sq^1</math> is the Bockstein homomorphism <math>\\beta</math> of the exact sequence <math>0 \\to \\Z/2 \\to \\Z/4 \\to \\Z/2 \\to 0.</math>\n*<math>Sq^i</math> commutes with the connecting morphism of the long exact sequence in cohomology. In particular, it commutes with respect to suspension <math>H^k(X;\\Z /2) \\cong H^{k+1}(\\Sigma X;\\Z /2)</math>\n*They satisfy the Ádem relations, described below\n\nSimilarly the following axioms characterize the reduced <math>p</math>-th powers for <math>p > 2</math>.\n\n#Naturality: <math>P^n: H^m(X,\\Z /p\\Z ) \\to H^{m+2n(p-1)}(X,\\Z /p\\Z )</math> is an additive homomorphism and natural.\n#<math>P^0</math> is the identity homomorphism.\n#<math>P^n</math> is the cup <math>p</math>-th power on classes of degree <math>2n</math>.\n#If <math>2n > \\deg(x)</math> then <math>P^n(x) = 0</math>\n#Cartan Formula:<math>P^n(x \\smile y) = \\sum_{i+j=n} (P^i x) \\smile (P^j y)</math>\n\nAs before, the reduced ''p''-th powers  also satisfy Ádem relations and commute with the suspension and boundary operators.\n\n==Ádem relations==\n\nThe Ádem relations for <math>p=2</math> were conjectured by {{harvs|txt|last=Wu|first=Wen-tsün|authorlink=Wu Wenjun|year=1952}} and established by {{harvs|txt|authorlink=José Ádem|first=José|last=Ádem|year=1952}}. They are given by\n\n:<math>Sq^i Sq^j = \\sum_{k=0}^{\\lfloor i/2 \\rfloor} {j-k-1 \\choose i-2k} Sq^{i+j-k} Sq^k</math>\n\nfor all <math>i,j>0</math> such that <math>i< 2j</math>. (The binomial coefficients are to be interpreted mod 2.) The Ádem relations allow one to write an arbitrary composition of Steenrod squares as a sum of Serre–Cartan basis elements.\n\nFor odd <math>p</math> the Ádem relations are\n:<math>P^{a}P^{b} = \\sum_i (-1)^{a+i}{(p-1)(b-i)-1 \\choose a-pi} P^{a+b-i}P^i</math>\nfor ''a''<''pb'' and\n:<math>P^{a}\\beta P^{b} = \\sum_i (-1)^{a+i}{(p-1)(b-i) \\choose a-pi} \\beta P^{a+b-i}P^i+\n\\sum_i (-1)^{a+i+1}{(p-1)(b-i)-1 \\choose a-pi-1} P^{a+b-i}\\beta P^i</math>\nfor <math>a\\le pb</math>.\n\n===Bullett–Macdonald identities===\n\n{{harvs|txt|last1=Bullett|first1=Shaun R.|last2=Macdonald|first2=Ian G.|authorlink2=Ian G. Macdonald|year=1982}} reformulated the Ádem relations as the following identities.\n\nFor <math>p=2</math> put\n:<math>P(t)=\\sum_{i\\geq 0}t^i\\text{Sq}^i</math>\nthen the Ádem relations are equivalent to \n:<math>P(s^2+st)\\cdot P(t^2)=P(t^2+st)\\cdot P(s^2)</math>\n\nFor <math>p > 2</math> put\n:<math>P(t)=\\sum_{i\\geq 0}t^i\\text{P}^i</math>\nthen the Ádem relations are equivalent to the statement that \n:<math> (1+s\\text{Ad} \\beta)P(t^p+t^{p-1}s+\\cdots+ts^{p-1})P(s^p)</math>\nis symmetric in <math>s</math> and <math>t</math>. Here <math>\\beta</math> is the Bockstein operation and <math>(\\operatorname{Ad} \\beta) P = \\beta P - P\\beta</math>.\n\n==Computations==\n\n===Infinite Real Projective Space===\nThe Steenrod operations for real projective space can be readily computed using the formal properties of the Steenrod squares. Recall that\n\n:<math>H^*(\\mathbb{RP}^\\infty;\\Z /2) \\cong \\Z /2[x],</math> \n\nwhere <math>\\deg(x) = 1.</math> For the operations on <math>H^1</math> we know that\n\n:<math>\\begin{align}\nSq^0(x) &= x \\\\\nSq^1(x) &= x^2 \\\\\nSq^k(x) &= 0 && \\text{ for any } k>1\n\\end{align}</math>\n\nUsing the operation\n\n:<math>Sq := Sq^0 + Sq^1 + Sq^2 + \\cdots</math>\n\nwe note that the Cartan relation implies that\n\n:<math>Sq\\colon H^*(X) \\to H^*(X)</math>\n\nis a ring morphism. Hence\n\n:<math>Sq(x^n) = (Sq(x))^n = (x + x^2)^n = \\sum_{i=0}^n {n \\choose i} x^{n+i}</math>\n\nSince there is only one degree <math>n+i</math> component of the previous sum, we have that\n\n:<math>Sq^i(x^n) = {n \\choose i}x^{n+i}</math>\n<!--\n===Infinite Complex Projective Space===\nRecall that the cohomology of the <math>K(\\Z ,2)</math>, <math>\\mathbb{CP}^\\infty</math>, is isomorphic to\n:<math>H^*(\\mathbb{CP}^\\infty) \\cong \\Z [x]</math> where <math>\\text{deg}(x) = 2</math>\nOn <math>H^2</math> the only non-trivial\n-->\n==Construction==\n\nSuppose that <math>\\pi</math> is any degree <math>n</math> subgroup of the symmetric group on <math>n</math> points, <math>u</math> a cohomology class in <math>H^q(X,B)</math>, <math>A</math> an abelian group acted on by <math>\\pi</math>, and <math>c</math> a cohomology class in <math>H_i(\\pi,A)</math>.  {{harvtxt|Steenrod|1953}} showed how to construct a reduced power <math>u^n/c</math> in <math>H^{nq-i}(X, (A \\otimes B \\otimes \\cdots \\otimes B)/\\pi)</math>, as follows.\n\n# Taking the external product of <math>u</math> with itself <math>n</math> times gives an equivariant cocycle on <math>X^n</math> with coefficients in <math>B \\otimes \\cdots \\otimes B</math>.\n#Choose <math>E</math> to be a [[contractible space]] on which <math>\\pi</math> acts freely and an equivariant map from <math>E \\times X</math> to <math>X^n.</math> Pulling back <math>u^n</math> by this map gives an equivariant cocyle on <math>E \\times X</math> and therefore a cocycle of <math>E/\\pi \\times X</math> with coefficients in <math>B \\otimes \\cdots \\otimes B</math>.\n#Taking the [[Cap product#The slant product|slant product]] with <math>c</math> in <math>H_i(E/\\pi, A)</math> gives a cocycle of <math>X</math> with coefficients in <math>H_0(\\pi, A \\otimes B \\otimes \\cdots \\otimes B)</math>.\n\nThe Steenrod squares and reduced powers are special cases of this construction where <math>\\pi</math> is a cyclic group of prime order <math>p=n</math> acting as a cyclic permutation of <math>n</math> elements, and the groups <math>A</math> and <math>B</math> are cyclic of order <math>p</math>, so that  <math>H_0(\\pi, A \\otimes B \\otimes \\cdots \\otimes B)</math> is also cyclic of order <math>p</math>.\n\n==The structure of the Steenrod algebra==\n\n{{harvs|txt|last=Serre|first=Jean-Pierre|authorlink=Jean-Pierre Serre|year=1953}} (for <math>p=2</math>) and {{harvs|txt|authorlink=Henri Cartan|last=Cartan|first=Henri|year=1954|year2=1955}} (for <math>p>2</math>) described the structure of the Steenrod algebra of stable mod <math>p</math> cohomology operations, showing that it is generated by the Bockstein homomorphism together with the Steenrod reduced powers, and the Ádem relations generate the ideal of relations between these generators. In particular they found an explicit basis for the Steenrod algebra. This basis relies on a certain notion of admissibility for integer sequences. We say a sequence\n\n:<math>i_1, i_2, \\ldots, i_n</math>\n\nis admissible if for each <math>j</math>, we have that <math>i_j \\ge 2i_{j+1}</math>. Then the elements\n\n:<math>Sq^I = Sq^{i_1} \\cdots Sq^{i_n},</math>\n\nwhere <math>I</math> is an admissible sequence, form a basis (the Serre–Cartan basis) for the mod 2 Steenrod algebra. There is a similar basis for the case  <math>p>2</math> consisting of the elements\n\n:<math>Sq_p^I = Sq_p^{i_1} \\cdots Sq_p^{i_n},</math>\n\nsuch that\n\n:<math>i_j\\ge pi_{j+1}</math>\n:<math>i_j\\equiv 0,1\\bmod 2(p-1)</math>\n:<math>Sq_p^{2k(p-1)} = P^k</math>\n:<math>Sq_p^{2k(p-1)+1} = \\beta P^k</math>\n\n==Hopf algebra structure and the Milnor basis==\n\nThe Steenrod algebra has more structure than a graded <math>\\mathbf{F}_p</math>-algebra. It is also a [[Hopf algebra]], so that in particular there is a diagonal or [[comultiplication]] map\n\n:<math>\\psi \\colon A \\to A \\otimes A.</math>\n\ninduced by the Cartan formula for the action of the Steenrod algebra on the cup product.\nIt is  easier to describe than the product map, and is given by\n\n:<math>\\psi(Sq^k) = \\sum_{i+j=k} Sq^i \\otimes Sq^j</math>\n\n:<math>\\psi(P^k) = \\sum_{i+j=k} P^i \\otimes P^j</math>\n\n:<math>\\psi(\\beta) = \\beta\\otimes1+1\\otimes\\beta.</math>\n\nThese formulas imply that the Steenrod algebra is [[co-commutative]].\n\nThe linear dual of <math>\\psi</math> makes the (graded) [[dual space|linear dual]] <math>A_*</math> of ''A'' into an algebra. {{harvtxt|Milnor|1958}} proved, for <math>p = 2</math>, that <math>A_*</math> is  a [[polynomial algebra]], with one generator <math>\\xi_k</math> of degree <math>2^k-1</math>, for every ''k'', and for <math>p > 2</math> the dual Steenrod algebra <math>A_*</math> is the tensor product of the polynomial algebra in generators <math>\\xi_k</math> of degree <math>2p^k-2</math> <math>(k\\ge 1)</math> and the exterior algebra in generators τ<sub>k</sub> of degree <math>2p^k-1</math> <math>(k\\ge 0)</math>. The monomial basis for <math>A_*</math> then gives another choice of basis for ''A'', called the Milnor basis. The dual to the Steenrod algebra is often more convenient to work with, because the multiplication is (super) commutative. The comultiplication for <math>A_*</math> is the dual of the product on ''A''; it is given by\n\n:<math>\\psi(\\xi_n) = \\sum_{i=0}^n \\xi_{n-i}^{p^i} \\otimes \\xi_i.</math> where &xi;<sub>0</sub>=1, and\n:<math>\\psi(\\tau_n) = \\tau_n\\otimes 1 + \\sum_{i=0}^n \\xi_{n-i}^{p^i} \\otimes \\tau_i</math> if ''p''>2\n\nThe only [[Primitive element (co-algebra)|primitive elements]] of ''A''<sub>*</sub> for ''p''=2  are the <math>\\xi_1^{2^i}</math>, and these are dual to the <math>Sq^{2^i}</math> (the only indecomposables of ''A'').\n\n==Relation to formal groups==\n\nThe dual Steenrod algebras are supercommutative Hopf algebras, so their spectra are algebra supergroup schemes. These group schemes are closely related to the automorphisms of 1-dimensional additive formal groups. For example, if ''p''=2 then the dual Steenrod algebra is the group scheme of automorphisms of the 1-dimensional additive formal group scheme ''x''+''y'' that are the identity to first order. These automorphisms are of the form \n:<math>x\\rightarrow x + \\xi_1x^2+\\xi_2x^4+\\xi_3x^8+\\cdots</math>\n\n==Algebraic construction==\n\n{{harvtxt|Smith|2007}} gave the following algebraic construction of the Steenrod algebra over a [[finite field]] <math>\\mathbb{F}_q</math> of order ''q''. If ''V'' is a [[vector space]] over <math>\\mathbb{F}_q</math> then write ''SV'' for the [[symmetric algebra]] of ''V''. There is an [[algebra homomorphism]] \n\n:<math>\\begin{cases} P(x):SV[[x]]\\to SV[[x]] \\\\ P(x)(v) = v+F(v)x=v+v^qx & v \\in V \\end{cases}</math>\n\nwhere ''F'' is the [[Frobenius endomorphism]] of ''SV''. If we put\n\n:<math>P(x)(f)=\\sum P^i(f)x^i \\qquad  p >2 </math> \n\nor \n\n:<math>P(x)(f)=\\sum Sq^{2i}(f)x^i \\qquad p =2</math> \n\nfor ''f''∈''SV'' then if ''V'' is infinite dimensional the elements ''P''<sup>''i''</sup> generate an algebra isomorphism to the subalgebra of the Steenrod algebra generated by the reduced ''p′''th powers for ''p'' odd, or the even Steenrod squares Sq<sup>2''i''</sup> for ''p'' = 2.\n\n==Applications==\n\nThe most famous early applications of the Steenrod algebra to outstanding topological problems were the solutions by [[J. Frank Adams]] of the [[Hopf invariant one]] problem and the [[vector fields on spheres]] problem. Independently Milnor and Bott, as well as Kervaire, gave a second solution of the Hopf invariant one problem, using operations in [[K-theory]]; these are the [[Adams operation]]s. One application of the mod 2 Steenrod algebra that is fairly elementary is the following theorem.\n\n'''Theorem'''. If there is a map S<sup>2''n'' - 1</sup> → S<sup>''n''</sup> of [[Hopf invariant one]], then ''n'' is a power of 2.\n\nThe proof uses the fact that each ''Sq''<sup>''k''</sup> is decomposable for ''k'' which is not a power of 2; \nthat is, such an element is a product of squares of strictly smaller degree.\n\n==Connection to the Adams spectral sequence and the homotopy groups of spheres==\n\nThe cohomology of the Steenrod algebra is the ''E''<sub>2</sub> term for the ([[local space|''p''-loca]]l) [[Adams spectral sequence]], whose abutment is the ''p''-component of the stable homotopy groups of spheres. More specifically, the ''E''<sub>2</sub> term of this spectral sequence may be identified as\n\n:<math>\\mathrm{Ext}^{s,t}_{A}(\\mathbb{F}_p, \\mathbb{F}_p).</math>\n\nThis is what is meant by the aphorism \"the cohomology of the Steenrod algebra is an approximation to the stable homotopy groups of spheres.\"\n\n==See also==\n\n*[[Pontryagin cohomology operation]]\n\n==References==\n\n===Pedagogical===\n*{{Citation | last=Malkiewich | first=Cary | title=The Steenrod Algebra | url=http://www.math.uiuc.edu/~cmalkiew/steenrod.pdf | deadurl=bot: unknown | archiveurl=https://web.archive.org/web/20170815173103/http://www.math.uiuc.edu/~cmalkiew/steenrod.pdf | archivedate=2017-08-15 | df= }}\n\n===References===\n\n*{{Citation | last=Ádem | first=José | authorlink=José Ádem|title=The iteration of the Steenrod squares in algebraic topology | jstor=88494 | mr=0050278 | year=1952 | journal=[[Proceedings of the National Academy of Sciences of the United States of America]] | issn=0027-8424 | volume=38 | issue=8 | pages=720–726 | doi=10.1073/pnas.38.8.720| pmid=16589167 | pmc=1063640 | bibcode=1952PNAS...38..720A }}\n*{{Citation | last1=Bullett | first1=Shaun R. | last2=Macdonald | first2=Ian G. | author2-link=Ian G. Macdonald | title=On the Ádem relations | doi=10.1016/0040-9383(82)90015-5 | mr=649764 | year=1982 | journal=[[Topology (journal)|Topology. An International Journal of Mathematics]] | issn=0040-9383 | volume=21 | issue=3 | pages=329–332}}\n*{{Citation | last=Cartan | first=Henri |authorlink=Henri Cartan| title=Sur les groupes d'Eilenberg-Mac Lane. II | jstor=88981 | mr=0065161 | year=1954 | journal=[[Proceedings of the National Academy of Sciences of the United States of America]] | issn=0027-8424 | volume=40 | issue=8 | pages=704–707 | doi=10.1073/pnas.40.8.704| pmid=16589542 | pmc=534145 | bibcode=1954PNAS...40..704C }}\n*{{Citation | last=Cartan | first=Henri | authorlink=Henri Cartan| title=Sur l'itération des opérations de Steenrod | doi=10.1007/BF02564270 | mr=0068219 | year=1955 | journal=[[Commentarii Mathematici Helvetici]] | issn=0010-2571 | volume=29 | issue=1 | pages=40–58}}\n* [[Allen Hatcher]], ''Algebraic Topology''. Cambridge University Press, 2002. Available free online from the [http://www.math.cornell.edu/~hatcher/AT/ATpage.html author's home page].\n*{{eom|id=S/s087550|title=Steenrod reduced power |first=S.N.|last= Malygin|first2=M.M.|last2= Postnikov}}\n*{{eom|id=S/s087560|title=Steenrod square |first=S.N.|last= Malygin|first2=M.M.|last2= Postnikov}}\n*{{Citation | last1=May | first1=J. Peter | author1-link=J. Peter May | title=The Steenrod Algebra and its Applications (Proc. Conf. to Celebrate N. E. Steenrod's Sixtieth Birthday, Battelle Memorial Inst., Columbus, Ohio, 1970) | chapter-url=http://www.math.uchicago.edu/~may/PAPERS/10.pdf  | publisher=[[Springer-Verlag]] | location=Berlin, New York | series=Lecture Notes in Mathematics | doi=10.1007/BFb0058524 | mr=0281196 | year=1970 | volume=168 | chapter=A general algebraic approach to Steenrod operations | pages=153–231| isbn=978-3-540-05300-2 | citeseerx=10.1.1.205.6640 }}\n*{{Citation | last1=Milnor | first1=John Willard | author1-link=John Milnor | title=The Steenrod algebra and its dual | jstor=1969932 | mr=0099653 | year=1958 | journal=[[Annals of Mathematics]] |series=Second Series | issn=0003-486X | volume=67 | issue=1 | pages=150–171 | doi=10.2307/1969932}}\n*{{Citation | last1=Mosher | first1=Robert E. | last2=Tangora | first2=Martin C. | title=Cohomology operations and applications in homotopy theory | origyear=1968 | url=https://books.google.com/books?id=FFCaPwAACAAJ | publisher=[[Dover Publications]] | location=New York | isbn=978-0-486-46664-4 | mr=0226634 | year=2008}}\n*{{eom|id=S/s087500|first=Yuli B. |last=Rudyak}}\n*{{Citation | last1=Serre | first1=Jean-Pierre | author1-link=Jean-Pierre Serre | title=Cohomologie modulo 2 des complexes d'Eilenberg-MacLane | doi=10.1007/BF02564562 | mr=0060234 | year=1953 | journal=[[Commentarii Mathematici Helvetici]] | issn=0010-2571 | volume=27 | issue=1 | pages=198–232}}\n*{{cite book | last1=Smith | first1=Larry | editor1-last=Hubbuck | editor1-first=John | editor2-last=Hu'ng | editor2-first=Nguyễn H. V. | editor3-last=Schwartz | editor3-first=Lionel | title=Proceedings of the School and Conference in Algebraic Topology | arxiv=0903.4997 | series=Geometry & Topology Monographs | mr=2402812 | year=2007 | volume=11 | contribution=An algebraic introduction to the Steenrod algebra | pages=327–348 | doi=10.2140/gtm.2007.11.327}}\n*{{Citation | last1=Steenrod | first1=Norman E. | author1-link=Norman Steenrod| title=Products of cocycles and extensions of mappings | jstor=1969172 | mr=0022071 | year=1947 | journal=[[Annals of Mathematics]] |series=Second Series | issn=0003-486X | volume=48 | issue=2 | pages=290–320 | doi=10.2307/1969172}}\n*{{Citation | last1=Steenrod | first1=Norman E. | author1-link=Norman Steenrod| title=Homology groups of symmetric groups and reduced power operations | jstor=88780 | mr=0054964 | year=1953 | journal=[[Proceedings of the National Academy of Sciences|Proceedings of the National Academy of Sciences of the United States of America]] | issn=0027-8424 | volume=39 | issue=3 | pages=213–217 | doi=10.1073/pnas.39.3.213| pmid=16589250 | pmc=1063756 | bibcode=1953PNAS...39..213S }}\n*{{Citation | last1=Steenrod | first1=Norman E. | author1-link=Norman Steenrod| title=Cyclic reduced powers of cohomology classes | jstor=88781 | mr=0054965 | year=1953 | journal=[[Proceedings of the National Academy of Sciences of the United States of America]] | issn=0027-8424 | volume=39 | issue=3 | pages=217–223 | doi=10.1073/pnas.39.3.217| pmid=16589251 | pmc=1063757 | bibcode=1953PNAS...39..217S }}\n*{{Citation | last1=Steenrod | first1=Norman E. | author1-link=Norman Steenrod| editor1-last=Epstein | editor1-first=David B. A. | editor1-link=David B. A. Epstein | title=Cohomology operations | url=https://books.google.com/books?id=CF3bt4oYZ2oC | publisher=[[Princeton University Press]] | series= Annals of Mathematics Studies | isbn=978-0-691-07924-0 | mr=0145525 | year=1962 | volume=50}}\n*{{Citation | last=Wu|first=Wen-tsün|authorlink=Wu Wenjun | title=Sur les puissances de Steenrod | publisher=La Bibliothèque Nationale et Universitaire de Strasbourg | series=Colloque de Topologie de Strasbourg | mr=0051510 | year=1952 | volume=IX}}\n\n[[Category:Algebraic topology]]\n[[Category:Hopf algebras]]"
    },
    {
      "title": "Supergroup (physics)",
      "url": "https://en.wikipedia.org/wiki/Supergroup_%28physics%29",
      "text": "The concept of '''supergroup''' is a [[generalization]] of that of [[group (mathematics)|group]]. In other words, every supergroup carries a natural group structure, but there may be more than one way to structure a given group as a supergroup. A supergroup is like a [[Lie group]] in that there is a well defined notion of [[smooth function]] defined on them. \nHowever the functions may have even and odd parts. Moreover, a supergroup has a [[super Lie algebra]] which plays a role similar to that of a [[Lie algebra]] for Lie groups in that they determine most of the representation theory and which is the starting point for classification.\n\n==Details<!--'Lie supergroup', 'Orthosymplectic groups', 'Superunitary group' redirect here-->==\nMore formally, a '''Lie supergroup'''<!--boldface per WP:R#PLA--> is a [[supermanifold]] ''G'' together with a multiplication morphism <math>\\mu :G \\times G\\rightarrow G</math>, an inversion morphism <math>i : G \\rightarrow G</math> and a unit morphism <math>e: 1 \\rightarrow G</math> which makes ''G'' a [[group object]] in the [[category theory|category]] of supermanifolds. This means that, formulated as commutative diagrams, the usual associativity and inversion axioms of a group continue to hold. Since every manifold is a super manifold, a Lie supergroup generalises the notion of a [[Lie group]].\n\nThere are many possible supergroups. The ones of most interest in theoretical physics are the ones which extend the [[Poincaré group]] or the [[conformal group]]. Of particular interest are the '''orthosymplectic groups'''<!--boldface per WP:R#PLA--> Osp(''M''|''N'')<ref>(''M''|''N'') is pronounced \"''M'' [[vertical bar]] ''N''.\" ''M'' denotes the [[bosonic dimensions]] and ''N'' denotes the [[Grassmann dimensions]] (cf. Larus Thorlacius, Thordur Jonsson (eds.), ''M-Theory and Quantum Geometry'', Springer, 2012, p. 263).</ref> and the '''superunitary groups'''<!--boldface per WP:R#PLA--> SU(''M''|''N'').\n\nAn equivalent algebraic approach starts from the observation that a super manifold is determined by its ring of [[supercommutative]] smooth functions, and that a morphism of super manifolds corresponds one to one with an algebra homomorphism between their functions in the opposite direction, i.e. that the category of supermanifolds is opposite to the category of algebras of smooth graded commutative functions. Reversing all the arrows in the commutative diagrams that define a Lie supergroup then shows that functions over the supergroup have the structure of a '''Z'''<sub>2</sub>-graded [[Hopf algebra]]. Likewise the representations of this Hopf algebra turn out to be '''Z'''<sub>2</sub>-graded [[comodule]]s. This Hopf algebra gives the global properties of the supergroup.\n\nThere is another related Hopf algebra which is the dual of the previous Hopf algebra. It can be identified with the Hopf algebra of graded differential operators at the origin. It only gives the local properties of the symmetries i.e., it only gives information about infinitesimal supersymmetry transformations. The representations of this Hopf algebra are [[Module (mathematics)|module]]s. Like in the non-graded case, this Hopf algebra can be described purely algebraically as the [[universal enveloping algebra]] of the [[Lie superalgebra]].\n\nIn a similar way one can define an affine algebraic supergroup as a group object in the category of superalgebraic [[affine varieties]]. An affine algebraic supergroup has a similar one to one relation to its [[Hopf algebra]] of superpolynomials. Using the language of [[Scheme (mathematics)|schemes]], which combines the geometric and algebraic point of view, algebraic supergroup schemes can be defined including super [[Abelian varieties]].\n\n==Notes==\n{{reflist}}\n\n==References==\n* [https://ncatlab.org/nlab/show/supergroup supergroup] in ''[[nLab]]''\n\n{{String theory topics |state=collapsed}}\n\n{{DEFAULTSORT:Supergroup (Physics)}}\n[[Category:Supersymmetry]]\n[[Category:Hopf algebras]]\n[[Category:Super linear algebra]]"
    },
    {
      "title": "Sweedler's Hopf algebra",
      "url": "https://en.wikipedia.org/wiki/Sweedler%27s_Hopf_algebra",
      "text": "\nIn mathematics, {{harvs|txt|first=Moss E.|last= Sweedler|authorlink=Moss Sweedler|year=1969|loc=p. 89–90}} introduced an example of an infinite-dimensional [[Hopf algebra]], and '''Sweedler's Hopf algebra''' ''H''<sub>4</sub> is a certain 4-dimensional quotient of it  that is neither commutative nor cocommutative.\n\n==Definition==\n\nThe following infinite dimensional Hopf algebra was introduced by {{harvtxt|Sweedler|1969|loc=pages 89–90}}. The Hopf algebra is generated as an algebra by three elements ''x'', ''g'', and ''g''<sup>−1</sup>.\n\nThe coproduct Δ is given by \n:Δ(g) = ''g'' ⊗''g'', Δ(''x'') = 1⊗''x'' + ''x'' ⊗''g''\n\nThe antipode ''S'' is given by\n:''S''(''x'') = –''x'' ''g''<sup>−1</sup>, ''S''(''g'') = ''g''<sup>−1</sup>\n\nThe counit ε is given by\n:ε(''x'')=0, ε(''g'') = 1\n\nSweedler's 4-dimensional Hopf algebra ''H''<sub>4</sub> is the quotient of this by the relations\n:''x''<sup>2</sup> = 0,   ''g''<sup>2</sup> = 1,  ''gx'' = –''xg''\nso it has a basis 1, ''x'', ''g'', ''xg'' {{harv|Montgomery|1993|loc=p.8}}.  Note that Montgomery describes a slight variant of this Hopf algebra using the opposite coproduct, i.e. the coproduct described above composed with the tensor flip on ''H''<sub>4</sub>⊗''H''<sub>4</sub>.\n\n\nSweedler's 4-dimensional Hopf algebra is a quotient of the [[Pareigis Hopf algebra]], which is in turn a quotient of the infinite dimensional Hopf algebra.\n\n==References==\n\n*{{Citation | last1=Armour | first1=Aaron | last2=Chen | first2=Hui-Xiang | last3=Zhang | first3=Yinhuo | title=Structure theorems of H<sub>4</sub>-Azumaya algebras | doi=10.1016/j.jalgebra.2005.10.020 | mr=2264134 | year=2006 | journal=[[Journal of Algebra]] | issn=0021-8693 | volume=305 | issue=1 | pages=360–393}}\n*{{Citation | last1=Montgomery | first1=Susan | title=Hopf algebras and their actions on rings | url=https://books.google.com/books?id=U895BpubbMkC | publisher=Published for the Conference Board of the Mathematical Sciences, Washington, DC | series=CBMS Regional Conference Series in Mathematics | isbn=978-0-8218-0738-5 | mr=1243637 | year=1993 | volume=82}}\n*{{Citation | last1=Sweedler | first1=Moss E. | title=Hopf algebras | url=https://books.google.com/books?id=8FnvAAAAMAAJ | publisher=W. A. Benjamin, Inc., New York | series=Mathematics Lecture Note Series | mr=0252485 | year=1969}}\n*{{Citation | last1=[[Fred Van Oystaeyen|Van Oystaeyen]] | first1=Fred | last2=Zhang | first2=Yinhuo | title=The Brauer group of Sweedler's Hopf algebra H<sub>4</sub> | doi=10.1090/S0002-9939-00-05628-8 | mr=1706961 | year=2001 | journal=[[Proceedings of the American Mathematical Society]] | issn=0002-9939 | volume=129 | issue=2 | pages=371–380}}\n\n[[Category:Hopf algebras]]"
    },
    {
      "title": "Taft Hopf algebra",
      "url": "https://en.wikipedia.org/wiki/Taft_Hopf_algebra",
      "text": "{{Orphan|date=June 2016}}\n\nIn algebra, a '''Taft Hopf algebra''' is a [[Hopf algebra]]  introduced by {{harvtxt|Taft|1971}} that is neither [[commutative]] nor [[cocommutative]] and has an [[Antipode (algebra)|antipode]] of large even order.\n\n==Construction==\n\nSuppose that ''k'' is a [[Field (algebra)|field]] with a primitive ''n'''th [[root of unity]] ζ for some positive integer ''n''. The Taft algebra is the ''n''<sup>2</sup>-dimensional [[associative algebra]] generated over ''k'' by ''c'' and ''x'' with the relations ''c''<sup>''n''</sup>=1, ''x''<sup>''n''</sup>=0, ''xc''=ζ''cx''. The coproduct takes ''c'' to ''c''&otimes;''c'' and ''x'' to ''c''&otimes;''x'' + ''x''&otimes;1.\nThe counit takes ''c'' to 1 and ''x'' to 0. The antipode takes ''c'' to ''c''<sup>−1</sup> and ''x'' to –''c''<sup>−1</sup>''x'': the order of the antipode is 2''n''.\n\n==References==\n\n*{{citation | MR=2724822 | zbl=1211.16023\n|last=Hazewinkel|first= Michiel|last2= Gubareni|first2= Nadiya|last3= Kirichenko|first3= V. V.\n|title=Algebras, rings and modules.  Lie algebras and Hopf algebras|series= Mathematical Surveys and Monographs|volume= 168|publisher= American Mathematical Society|place= Providence, RI|year= 2010|ISBN= 978-0-8218-5262-0 }}\n*{{citation | mr=0286868 | zbl=0222.16012\n|last=Taft|first= Earl J.\n|title=The order of the antipode of finite-dimensional Hopf algebra\n|journal=Proc. Natl. Acad. Sci. U.S.A.|volume= 68 |year=1971|pages= 2631–2633 |doi=10.1073/pnas.68.11.2631|pmc=389488}}\n\n[[Category:Hopf algebras]]"
    },
    {
      "title": "Universal enveloping algebra",
      "url": "https://en.wikipedia.org/wiki/Universal_enveloping_algebra",
      "text": "{{for|the universal enveloping W* algebra of a C* algebra|Sherman–Takeda theorem}}\nIn [[mathematics]], a '''universal enveloping algebra''' is the most general ([[unital algebra|unital]], [[associative algebra|associative]]) algebra that contains all [[representation of a Lie algebra|representations]] of a [[Lie algebra]].\n\nUniversal enveloping algebras are used in the [[representation theory]] of Lie groups and Lie algebras. For example, [[Verma module]]s can be constructed as quotients of the universal enveloping algebra.<ref>{{harvnb|Hall|2015}} Section 9.5</ref> In addition, the enveloping algebra gives a precise definition for the [[Casimir operator]]s. Because Casimir operators commute with all elements of a Lie algebra, they can be used to classify representations. The precise definition also allows the importation of Casimir operators into other areas of mathematics, specifically, those that have a [[differential algebra]]. They also play a central role in some recent developments in mathematics. In particular, their [[dual vector space|dual]] provides a commutative example of the objects studied in [[non-commutative geometry]], the [[quantum group]]s. This dual can be shown, by the [[Gelfand-Naimark theorem]], to contain the [[C-star algebra|C* algebra]] of the corresponding Lie group. This relationship generalizes to the idea of [[Tannaka-Krein duality]] between [[compact topological group]]s and their representations.\n\nFrom an analytic viewpoint, the universal enveloping algebra of the Lie algebra of a Lie group may be identified with the algebra of left-invariant differential operators on the group.\n\n==Informal construction==\nThe idea of the universal enveloping algebra is to embed a Lie algebra <math>\\mathfrak{g}</math> into an associative algebra <math>\\mathcal{A}</math> with identity in such a way that the abstract bracket operation in <math>\\mathfrak{g}</math> corresponds to the commutator <math>xy-yx</math> in <math>\\mathcal{A}</math>. There may be many ways to make such an embedding, but there is one \"largest\" such <math>\\mathcal{A}</math>, called the universal enveloping algebra of <math>\\mathfrak{g}</math>.\n\n===Generators and relations===\nLet <math>\\mathfrak{g}</math> be a Lie algebra, assumed finite-dimensional for simplicity, with basis <math>X_1,\\ldots X_n</math>. Let <math>c_{ijk}</math> be the [[structure constants]] for this basis, so that\n:<math>[X_i,X_j]=\\sum_{k=1}^n c_{ijk}X_k</math>.\nThen the universal enveloping algebra is the associative algebra (with identity) generated by elements <math>x_1,\\ldots x_n</math> subject to the relations\n:<math>x_i x_j-x_j x_i=\\sum_{k=1}^n c_{ijk}x_k</math>\nand ''no other relations''.\n\nConsider, for example, the Lie algebra  [[SL(2,C)|sl(2,C)]], spanned by the matrices\n:<math display=\"block\"> X = \\begin{pmatrix}\n0 & 1\\\\\n0 & 0\n\\end{pmatrix}\n\\qquad\nY = \\begin{pmatrix}\n0 & 0\\\\\n1 & 0\n\\end{pmatrix}\n\\qquad\nH = \\begin{pmatrix}\n1 & 0\\\\\n0 & -1\n\\end{pmatrix}  ~,</math>\nwhich satisfy the commutation relations <math>[H,X]=2X</math>, <math>[H,Y]=-2Y</math>, and <math>[X,Y]=H</math>. The universal enveloping algebra of sl(2,C) is then the algebra generated by three elements <math>x,y,h</math> subject to the relations\n:<math>hx-xh=2x,\\quad hy-yh=-2y,\\quad xy-yx=h</math>,\nand no other relations. We ''cannot'' take the universal enveloping algebra to be the algebra of <math>2\\times 2</math> matrices (or a subalgebra thereof), because, for example, the matrix <math>X</math> satisfies the additional relation <math>X^2=0</math>, which is not forced on us by the three defining relations of the universal enveloping algebra. That is to say, the product in the universal enveloping algebra is not the matrix product but a formal product in which ''only'' the three defining relations above are imposed. It turns out (as a consequence of the [[Poincaré–Birkhoff–Witt theorem]]) that the elements <math>1,x,x^2,\\dots</math> are all [[linearly independent]] in the universal enveloping algebra. This is a [[universal property]] of universal enveloping algebras.\n\n===Finding a basis===\nIn general, elements of the universal enveloping algebra are linear combinations of products of the generators in all possible orders. Using the defining relations of the universal enveloping algebra, we can always re-order those products in a particular order, say with all the factors of <math>x_1</math> first, then factors of <math>x_2</math>, etc. For example, whenever we have a term that contains <math>x_2 x_1</math> (in the \"wrong\" order), we can use the relations to rewrite this as <math>x_1 x_2</math> plus a [[linear combination]] of the <math>x_j</math>'s. Doing this sort of thing repeatedly eventually converts any element into a linear combination of terms in the desired order. Thus, elements of the form\n:<math>x_1^{k_1}x_2^{k_2}\\cdots x_n^{k_n}</math>\nwith the <math>k_j</math>'s being non-negative integers, span the enveloping algebra. (We allow <math>k_j=0</math>, meaning that we allow terms in which no factors of <math>x_j</math> occur.) The Poincaré–Birkhoff–Witt theorem, discussed below, asserts that these elements are linearly independent and thus form a basis for the universal enveloping algebra. In particular, the universal enveloping algebra is always infinite dimensional.\n\nThe Poincaré–Birkhoff–Witt theorem implies, in particular, that the elements <math>x_1,\\ldots x_n</math> themselves are linearly independent. It is therefore common—if potentially confusing—to identify the <math>x_j</math>'s with the generators <math>X_j</math> of the original Lie algebra. That is to say, we identify the original Lie algebra as the subspace of its universal enveloping algebra spanned by the generators. It should be emphasized, however, that if <math>\\mathfrak{g}</math> is an algebra of <math>n\\times n</math> matrices, the universal enveloping of <math>\\mathfrak{g}</math> is not contained in the algebra of <math>n\\times n</math> matrices, since the universal enveloping algebra is always infinite dimensional. Thus, in the case of sl(2,C), if we identify our Lie algebra as a subspace of its universal enveloping algebra, we must now interpret <math>X</math>, <math>Y</math> and <math>H</math> not as <math>2\\times 2</math> matrices, but rather as elements of some abstract algebra.\n\n===Formalities===\nThe formal construction of the universal enveloping algebra makes precise the idea of \"no other relations.\" Specifically, we first take the tensor algebra of <math>\\mathfrak{g}</math> and then quotient it by the ''smallest'' two-sided ideal containing elements of the form <math>x_i x_j -x_j x_i-\\sum c_{ijk}x_k</math>. The universal enveloping algebra is the quotient of the [[tensor algebra]] on [[Generators and relations|generators]] subject to [[Generators and relations|relations]] imposed by the structure constants; it is the most general [[unital associative algebra]] with a compatible [[Lie bracket]] with the original Lie algebra.\n\n==Formal definition==\nRecall that every Lie algebra <math>\\mathfrak{g}</math> is in particular a [[vector space]]. Thus, one is free to construct the [[tensor algebra]] <math>T(\\mathfrak{g})</math> from it. The tensor algebra is a [[free algebra]]: it simply contains all possible [[tensor product]]s of all possible vectors in <math>\\mathfrak{g}</math>, without any restrictions whatsoever on those products.\n\nThat is, one constructs the space\n:<math>T(\\mathfrak{g}) = K \\,\\oplus\\, \\mathfrak{g} \\,\\oplus\\, (\\mathfrak{g} \\otimes \\mathfrak{g}) \n\\,\\oplus\\, (\\mathfrak{g} \\otimes \\mathfrak{g} \\otimes \\mathfrak{g}) \\,\\oplus\\, \\cdots </math>\n\nwhere <math>\\otimes</math> is the tensor product, and <math>\\oplus</math> is the [[direct sum]] of vector spaces. Here, {{math|''K''}} is the field over which the Lie algebra is defined. From here, through to the remainder of this article, the tensor product is always explicitly shown. Many authors omit it, since, with practice, its location can usually be inferred from context. Here, a very explicit approach is adopted, to minimize any possible confusion about the meanings of expressions.\n\nThe universal enveloping algebra is obtained<ref>{{harvnb|Hall|2015}} Section 9.3</ref> by taking the [[Quotient space (linear algebra)|quotient]] by imposing the relations\n\n:<math>a \\otimes b - b \\otimes a = [a,b]</math>\n\nfor all {{math|''a''}} and {{math|''b''}} in the embedding of <math>\\mathfrak{g}</math> in <math>T(\\mathfrak{g}).</math> To avoid the tautological feeling of this equation, keep in mind that the bracket on the right hand side of this equation is actually the abstract \"bracket\" operation on the Lie algebra. Recall that the bracket operation on a Lie algebra is ''any'' bilinear map of <math>\\mathfrak{g}\\times\\mathfrak{g}</math> to <math>\\mathfrak{g}</math> that is skew-symmetric and satisfies the Jacobi identity. This bracket is not necessarily computed as <math>[X,Y]=XY-YX</math> for some associative product structure on <math>\\mathfrak{g}</math>. The goal of the universal enveloping algebra is to embed (in a canonical way) a Lie algebra into an associative algebra in such a way the abstract bracket operation on the original Lie algebra is now the commutator <math>ab-ba</math> in that associative algebra.\n\nTo be more precise, the universal enveloping algebra is defined as the [[Quotient space (linear algebra)|quotient space]]\n\n:<math>U(\\mathfrak{g}) = T(\\mathfrak{g})/I</math>\n\nwhere {{math|''I''}} is the two-sided [[Ideal (ring theory)|ideal]] over <math>T(\\mathfrak{g})</math> generated by elements of the form\n\n:<math>a\\otimes b - b \\otimes a - [a,b]</math>\n\nNote that the above is an element of\n:<math>\\mathfrak{g} \\oplus (\\mathfrak{g}\\otimes\\mathfrak{g}) \\subset T(\\mathfrak{g})</math>\n\nand so can be validly used to construct the ideal within <math>T(\\mathfrak{g})</math>. Thus, for example, given <math>a,b,c,d,f,g\\in\\mathfrak{g}</math>, one can write\n\n:<math>c\\otimes d \\otimes \\cdots \\otimes (a\\otimes b - b \\otimes a - [a,b]) \\otimes f \\otimes g \\cdots</math>\nas an element of {{math|''I''}}, and all elements of {{math|''I''}} are obtained as linear combinations of elements of the above form. Clearly, <math>I\\subset T(\\mathfrak{g})</math> is a subspace. In essence, the universal enveloping algebra is what remains of the tensor algebra after modding out the Poisson algebra structure.\n\n===Superalgebras===\nThe analogous construction for [[Lie superalgebra]]s is straightforward; one need only to keep careful track of the sign, when permuting elements. In this case, the (anti-)commutator of the superalgebra lifts to an (anti-)commuting Poisson bracket.\n\nOne can obtain a different result by taking the above construction, and replacing every occurrence of the tensor product by the [[exterior product]]. That is, one uses this construction to create the [[exterior algebra]] of the Lie group; this construction results in the [[Gerstenhaber algebra]], with the grading [[natural transformation|naturally]] coming from the grading on the exterior algebra. (This should not be confused with the [[Poisson superalgebra]]).\n\n===Other generalizations===\nThe construction has also been generalized for [[Malcev algebra]]s,<ref>{{cite journal | last1 = Perez-Izquierdo | first1 = J.M. | last2 = Shestakov | first2 = I.P. | year = 2004 | title = An envelope for Malcev algebras | url = | journal = Journal of Algebra | volume = 272 | issue = | pages = 379–393 | doi=10.1016/s0021-8693(03)00389-2}}</ref> [[Bol loop|Bol algebras]] <ref>{{cite journal | last1 = Perez-Izquierdo | first1 = J.M. | year = 2005 | title = An envelope for Bol algebras | url = | journal = Journal of Algebra | volume = 284 | issue = | pages = 480–493 | doi=10.1016/j.jalgebra.2004.09.038}}</ref> and [[alternative algebra|left alternative algebras]].<ref>{{cite journal | last1 = Josef | first1 = Rukavicka | year = 2013 | title = An envelope for left alternative algebras | url = http://www.m-hikari.com/ija/ija-2013/ija-9-12-2013/rukavickaIJA9-12-2013.pdf | format = PDF | journal = International Journal of Algebra | volume = 7 | issue = 10| pages = 455–462 }}</ref>\n\n==Universal property==\nThe universal enveloping algebra, or rather the universal enveloping algebra together with the canonical map  <math>h:\\mathfrak{g}\\to U(\\mathfrak{g})</math>, possesses a [[universal property]].<ref>{{harvnb|Hall|2015}} Theorem 9.7</ref> Suppose we have any Lie algebra map\n:<math>\\phi: \\mathfrak{g} \\to A</math>\nto a unital associative algebra {{math|''A''}} (with Lie bracket in {{math|''A''}} given by the commutator). More explicitly, this means that we assume\n:<math>\\phi([X,Y])=\\phi(X)\\phi(Y)-\\phi(Y)\\phi(X)</math>\nfor all <math>X,Y\\in\\mathfrak{g}</math>. Then there exists a ''unique'' unital [[algebra homomorphism]]\n\n:<math>\\widehat\\phi: U(\\mathfrak{g}) \\to A</math>\nsuch that\n:<math>\\phi = \\widehat \\phi \\circ h </math>\n\nwhere <math>h:\\mathfrak{g}\\to U(\\mathfrak{g})</math> is the canonical map. (The map <math>h</math> is obtained by embedding <math>\\mathfrak{g}</math> into its [[tensor algebra]] and then composing with the [[Quotient space (linear algebra)|quotient map]] to the universal enveloping algebra. This map is an embedding, by the Poincare-Birkhoff-Witt theorem.)\n\nTo put it differently, if <math>\\phi:\\mathfrak{g}\\rightarrow A</math> is a linear map into a unital algebra <math>A</math> satisfying <math>\\phi([X,Y])=\\phi(X)\\phi(Y)-\\phi(Y)\\phi(X)</math>, then <math>\\phi</math> extends to an algebra homomorphism of <math>\\widehat\\phi: U(\\mathfrak{g}) \\to A</math>. Since <math> U(\\mathfrak{g})</math> is generated by elements of <math>\\mathfrak{g}</math>, the map <math>\\widehat{\\phi}</math> must be uniquely determined by the requirement that\n:<math>\\widehat{\\phi}(X_{i_1}\\cdots X_{i_N})=\\phi(X_{i_1})\\cdots \\phi(X_{i_N}),\\quad X_{i_j}\\in\\mathfrak{g}</math>.\nThe point is that because there are no other relations in the universal enveloping algebra besides those coming from the commutation relations of <math>\\mathfrak{g}</math>, the map <math>\\widehat{\\phi}</math> is well defined, independent of how one writes a given element <math>x\\in U(\\mathfrak{g})</math> as a linear combination of products of Lie algebra elements.\n\nThe universal property of the enveloping algebra immediately implies that every representation of <math>\\mathfrak{g}</math> acting on a vector space <math>V</math> extends uniquely to a representation of <math>U(\\mathfrak{g})</math>. (Take <math>A=\\mathrm{End}(V)</math>.) This observation is important because it allows (as discussed below) the Casimir elements to act on <math>V</math>. These operators (from the center of  <math>U(\\mathfrak{g})</math>) act as scalars and provide important information about the representations. The [[Casimir element|quadratic Casimir element]] is of particular importance in this regard.\n\nThe [[tensor algebra]] on a vector space is the [[free functor]] from the category of vector spaces '''Vect''' to the category of algebras '''Alg''' which is left-adjoint to the [[forgetful functor]] mapping each algebra to its underlying vector space and each [[algebra homomorphism]] to its underlying [[linear map]]. The unit of this adjunction is the [[natural transformation]] of including each vector space ''V'' as the rank-one tensor product of itself in its tensor algebra T(''V''); the counit is the unique algebra homomorphism from the free algebra T(''Y'') on the underlying vector space of the algebra ''Y'' to ''Y'' given by evaluation of products and sums of elements of ''Y'' according to ''Y''<nowiki/>'s rules of [[multiplication]].\n\nLet ''T'' be the functor defined as the composition of the tensor algebra functor on vector spaces composed with the forgetful functor of underlying vector spaces of Lie algebras.\n\nThis universal property of universal enveloping algebras follows from the tensor algebra as a [[natural transformation]]. That is, there is a [[functor]] {{math|''T''}} from the [[category (mathematics)|category]] of Lie algebras over {{math|''K''}} to the category of unital associative {{math|''K''}}-algebras, taking a Lie algebra to the corresponding [[free algebra]]. Similarly, there is also a functor {{math|''U''}} that takes the same category of Lie algebras to the same category of unital associative {{math|''K''}}-algebras. The two are related by a [[natural transformation|natural map]] that takes {{math|''T''}} into {{math|''U''}}: that natural map is the action of quotienting. The [[universal property]] passes through the natural map.\n\nIf ''A'' is any unital associative algebra, it naturally generates a Lie algebra {{Math|''A<sub>L</sub>''}} by taking the Lie bracket to be the [[commutator]] on ''A''. This is a [[functor]] {{Math|''Lie''}} from the category of algebras '''Alg''' to the category of Lie algebras '''LieAlg''' over some underlying field—in fact, it is a [[free functor]]. The functor {{math|''U''}} of universal enveloping algebras is [[left adjoint]] to the functor {{Math|''Lie''}}, which maps an algebra {{math|''A''}} to the Lie algebra {{math|''A''<sub>''L''</sub>.}} The two are adjoint, but certainly are not [[Equivalence of categories|inverses]]: if we start with an associative algebra {{math|''A''}}, then {{math|''U''(''A''<sub>''L''</sub>)}} is ''not'' equal to {{math|''A''}}; it is in general much bigger. (If, however, ''A'' is a [[commutative algebra]], {{Math|''A<sub>L</sub>''}} is a [[Trivial (mathematics)|trivial]] Lie algebra and its universal enveloping algebra will [[Degenerate (mathematics)|degenerate]] to ''A''.) The unit of the adjunction is a natural embedding of ''A'' into {{Math|''A<sub>L</sub>''}}. The counit of the adjunction is the quotient of the universal enveloping algebra of a Lie algebra ''g'' with commutator Lie bracket by any other rules of the Lie algebra, for example that {{Math|1=''X''<sup>2</sup> = 0}} in sl(2, C) above. By functor composition, the universal enveloping algebra constructs an adjunction between the free Lie algebra on a vector space and the forgetful functor from Lie algebras to vector spaces.\n\n===Other algebras===\nAlthough the canonical construction, given above, can be applied to other algebras, the result, in general, does not have the universal property. Thus, for example, when the construction is applied to [[Jordan algebra]]s, the resulting enveloping algebra contains the [[special Jordan algebra]]s, but not the exceptional ones: that is, it does not envelope the [[Albert algebra]]s. Likewise, the Poincaré–Birkhoff–Witt theorem, below, constructs a basis for an enveloping algebra; it just won't be universal. Similar remarks hold for the [[Lie superalgebra]]s.\n\n==Poincaré–Birkhoff–Witt theorem ==\n{{main article|Poincaré–Birkhoff–Witt theorem}}\nThe Poincaré–Birkhoff–Witt theorem gives a precise description of <math>U(\\mathfrak{g})</math>. This can be done in either one of two different ways: either by reference to an explicit [[vector basis]] on the Lie algebra, or in a [[coordinate-free]] fashion.\n\n===Using basis elements===\nOne way is to suppose that the Lie algebra can be given a [[totally ordered]] basis, that is, it is the [[free vector space]] of a totally ordered set. Recall that a free vector space is defined as the space of all finite supported functions from a set {{math|''X''}} to the field {{math|''K''}} (finitely supported means that only finitely many values are non-zero); it can be given a basis <math>e_a:X\\to K</math> such that <math>e_a(b) = \\delta_{ab}</math> is the [[indicator function]] for <math>a,b\\in X</math>. Let <math>h:\\mathfrak{g}\\to T(\\mathfrak{g})</math> be the injection into the tensor algebra; this is used to give the tensor algebra a basis as well. This is done by lifting: given some arbitrary sequence of <math>e_a</math>, one defines the extension of <math>h</math> to be\n\n:<math>h(e_a\\otimes e_b \\otimes\\cdots \\otimes e_c) = h(e_a) \\otimes h(e_b) \\otimes\\cdots \\otimes h(e_c)</math>\n\nThe Poincaré–Birkhoff–Witt theorem then states that one can obtain a basis for <math>U(\\mathfrak{g})</math> from the above, by enforcing the total order of {{math|''X''}} onto the algebra. That is, <math>U(\\mathfrak{g})</math> has a basis\n\n:<math>e_a\\otimes e_b \\otimes\\cdots \\otimes e_c</math>\n\nwhere <math>a\\le b \\le \\cdots \\le c</math>, the ordering being that of total order on the set {{math|''X''}}.<ref>{{harvnb|Hall|2015}} Theorem 9.10</ref> The proof of the theorem involves noting that, if one starts with out-of-order basis elements, these can always be swapped by using the commutator (together with the [[structure constants]]). The hard part of the proof is establishing that the final result is unique and independent of the order in which the swaps were performed.\n\nThis basis should be easily recognized as the basis of a [[symmetric algebra]]. That is, the underlying vector spaces of <math>U(\\mathfrak{g})</math> and the symmetric algebra are isomorphic, and it is the PBW theorem that shows that this is so.  See, however, the section on the algebra of symbols, below, for a more precise statement of the nature of the isomorphism.\n\n===Coordinate-free===\nOne can also state the theorem in a coordinate-free fashion, avoiding the use of total orders and basis elements. This is convenient when there are difficulties in defining the basis vectors, as there can be for infinite-dimensional Lie algebras. It also gives a more natural form that is more easily extended to other kinds of algebras.  This is accomplished by constructing a [[filtration (mathematics)|filtration]] <math>U_m \\mathfrak{g}</math> whose limit is the universal enveloping algebra <math>U(\\mathfrak{g}).</math>\n\nFirst, a notation is needed for an ascending sequence of subspaces of the tensor algebra. Let\n:<math>T_m\\mathfrak{g} = K\\oplus \\mathfrak{g}\\oplus T^2\\mathfrak{g} \\oplus \\cdots \\oplus T^m\\mathfrak{g}</math>\nwhere\n:<math>T^m\\mathfrak{g} = T^{\\otimes m} \\mathfrak{g} = \\mathfrak{g}\\otimes \\cdots \\otimes \\mathfrak{g}</math>\n\nis the {{math|''m''}}-times tensor product of <math>\\mathfrak{g}.</math> The <math>T_m\\mathfrak{g}</math> form a [[filtration (mathematics)|filtration]]:\n:<math>K\\subset \\mathfrak{g}\\subset T_2\\mathfrak{g} \\subset \\cdots \\subset T_m\\mathfrak{g} \\subset\\cdots</math>\n\nMore precisely, this is a [[filtered algebra]], since the filtration preserves the algebraic properties of the subspaces. Note that the [[limit (category theory)|limit]] of this filtration is the tensor algebra <math>T(\\mathfrak{g}).</math>\n\nIt was already established, above, that quotienting by the ideal is a [[natural transformation]] that takes one from <math>T(\\mathfrak{g})</math> to <math>U(\\mathfrak{g}).</math> This also works naturally on the subspaces, and so one obtains a filtration <math>U_m \\mathfrak{g}</math> whose limit is the universal enveloping algebra <math>U(\\mathfrak{g}).</math>\n\nNext, define the space\n:<math>G_m\\mathfrak{g} = U_m \\mathfrak{g}/U_{m-1} \\mathfrak{g}</math>\nThis is the space <math>U_m \\mathfrak{g}</math> modulo all of the subspaces <math>U_n \\mathfrak{g}</math> of strictly smaller filtration degree. Note that <math>G_m\\mathfrak{g}</math> is ''not at all'' the same as the leading term <math>U^m\\mathfrak{g}</math> of the filtration, as one might naively surmise. It is not constructed through a set subtraction mechanism associated with the filtration.\n\nQuotienting <math>U_m \\mathfrak{g}</math> by <math>U_{m-1} \\mathfrak{g}</math> has the effect of setting all Lie commutators defined in <math>U_m \\mathfrak{g}</math> to zero. One can see this by observing that the commutator of a pair of elements whose products lie in <math>U_{m} \\mathfrak{g}</math> actually gives an element in <math>U_{m-1} \\mathfrak{g}</math>. This is perhaps not immediately obvious: to get this result, one must repeatedly apply the commutation relations, and turn the crank. The essence of the Poincaré–Birkhoff–Witt theorem is that it is always possible to do this, and that the result is unique.\n\nSince commutators of elements whose products are defined in <math>U_{m} \\mathfrak{g}</math> lie in <math>U_{m-1} \\mathfrak{g}</math>, the quotienting that defines <math>G_m\\mathfrak{g}</math> has the effect of setting all commutators to zero. What PBW states is that the commutator of elements in <math>G_m\\mathfrak{g}</math> is necessarily zero. What is left are the elements that are not expressible as commutators.\n\nIn this way, one is lead immediately to the [[symmetric algebra]].  This is the algebra where all commutators vanish. It can be defined as a filtration <math>S_m \\mathfrak{g}</math> of symmetric tensor products <math>\\mbox{Sym}^m \\mathfrak{g}</math>. Its limit is the symmetric algebra <math>S(\\mathfrak{g})</math>. It is constructed by appeal to the same notion of naturality as before. One starts with the same tensor algebra, and just uses a different ideal, the ideal that makes all elements commute:\n\n:<math>S(\\mathfrak{g}) = T(\\mathfrak{g}) / (a\\otimes b - b\\otimes a)</math>\n\nThus, one can view the Poincaré–Birkhoff–Witt theorem as stating that <math>G(\\mathfrak{g})</math> is isomorphic to the symmetric algebra <math>S(\\mathfrak{g})</math>, both as a vector space ''and'' as a commutative algebra.\n\nThe <math>G_m\\mathfrak{g}</math> also form a filtered algebra; its limit is <math>G(\\mathfrak{g}).</math>  This is the [[associated graded algebra]] of the filtration.\n\nThe construction above, due to its use of quotienting, implies that the limit of <math>G(\\mathfrak{g})</math> is isomorphic to <math>U(\\mathfrak{g}).</math>  In more general settings, with loosened conditions, one finds that <math>S(\\mathfrak{g})\\to G(\\mathfrak{g})</math> is a projection, and one then gets PBW-type theorems for the associated graded algebra of a [[filtered algebra]]. To emphasize this, the notation <math>\\mbox{gr}U(\\mathfrak{g})</math> is sometimes used for <math>G(\\mathfrak{g}),</math> serving to remind that it is the filtered algebra.\n\n===Other algebras===\nThe theorem, applied to [[Jordan algebra]]s, yields the [[exterior algebra]], rather than the symmetric algebra. In essence, the construction zeros out the anti-commutators. The resulting algebra is ''an'' enveloping algebra, but is not universal. As mentioned above, it fails to envelop the exceptional Jordan algebras.\n\n==Left-invariant differential operators==\nSuppose <math>G</math> is a real Lie group with Lie algebra <math>\\mathfrak{g}</math>. Following the modern approach, we may identify <math>\\mathfrak{g}</math> with the space of left-invariant vector fields (i.e., first-order left-invariant differential operators). Specifically, if we initially think of <math>\\mathfrak{g}</math> as the tangent space to <math>G</math> at the identity, then each vector in <math>\\mathfrak{g}</math> has a unique left-invariant extension. We then identify the vector in the tangent space with the associated left-invariant vector field. Now, the commutator (as differential operators) of two left-invariant vector fields is again a vector field and again left-invariant. We can then define the bracket operation on <math>\\mathfrak{g}</math> as the commutator on the associated left-invariant vector fields.<ref>E.g. {{harvnb|Helgason|2001}} Chapter II, Section 1</ref> This definition agrees with any other standard definition of the bracket structure on the Lie algebra of a Lie group.\n\nWe may then consider left-invariant differential operators of arbitrary order. Every such operator <math>A</math> can be expressed (non-uniquely) as a linear combination of products of left-invariant vector fields. The collection of all left-invariant differential operators on <math>G</math> forms an algebra, denoted <math>D(G)</math>. It can be shown that <math>D(G)</math> is isomorphic to the universal enveloping algebra <math>U(\\mathfrak{g})</math>.<ref>{{harvnb|Helgason|2001}} Chapter II, Proposition 1.9</ref>\n\nIn the case that <math>\\mathfrak{g}</math> arises as the Lie algebra of a real Lie group, one can use left-invariant differential operators to give an analytic proof of the [[Poincaré–Birkhoff–Witt theorem]]. Specifically, the algebra <math>D(G)</math> of left-invariant differential operators is generated by elements (the left-invariant vector fields) that satisfy the commutation relations of <math>\\mathfrak{g}</math>. Thus, by the universal property of the enveloping algebra, <math>D(G)</math> is a quotient of <math>U(\\mathfrak{g})</math>. Thus, if the PBW basis elements are linearly independent in <math>D(G)</math>—which one can establish analytically—they must certainly be linearly independent in <math>U(\\mathfrak{g})</math>. (And, at this point, the isomorphism of <math>D(G)</math> with <math>U(\\mathfrak{g})</math> is apparent.)\n\n==Algebra of symbols==\nThe isomorphism of <math>U(\\mathfrak{g})</math> and <math>S(\\mathfrak{g})</math>, ''as associative algebras'', leads to the concept of the '''algebra of symbols''' <math>\\star(\\mathfrak{g})</math>. This is the space of [[symmetric polynomial]]s, endowed with a product, the <math>\\star</math>, that places the algebraic structure of the Lie algebra onto what is otherwise a standard associative algebra. That is, what the PBW theorem obscures (the commutation relations) the algebra of symbols restores into the spotlight.\n\nThe algebra is obtained by taking elements of <math>S(\\mathfrak{g})</math> and replacing each generator <math>e_i</math> by an indeterminate, commuting variable <math>t_i</math> to obtain the space of symmetric polynomials <math>K[t_i]</math> over the field <math>K</math>. Indeed, the correspondence is trivial: one simply substitutes the symbol <math>t_i</math> for <math>e_i</math>. The resulting polynomial is called the '''symbol''' of the corresponding element of <math>S(\\mathfrak{g})</math>. The inverse map is\n:<math>w: \\star(\\mathfrak{g})\\to U(\\mathfrak{g})</math>\nthat replaces each symbol <math>t_i</math> by <math>e_i</math>. The algebraic structure is obtained by requiring that the product <math>\\star</math> act as an isomorphism, that is, so that\n:<math>w(p \\star q) = w(p)\\otimes w(q)</math>\nfor polynomials <math>p,q\\in \\star(\\mathfrak{g}).</math>\n\nThe primary issue with this construction is that <math>w(p)\\otimes w(q)</math> is not trivially, inherently a member of <math>U(\\mathfrak{g})</math>, as written, and that one must first perform a tedious reshuffling of the basis elements (applying the [[structure constants]] as needed) to obtain an element of <math>U(\\mathfrak{g})</math> in the properly ordered basis. An explicit expression for this product can be given: this is the '''Berezin formula'''.<ref>{{cite journal | last1 = Berezin | first1 = F.A. | authorlink = Felix Berezin | year = 1967 | title = Some remarks about the associated envelope of a Lie algebra | url = | journal = Funct. Anal. Appl. | volume = 1 | issue = | page = 91 | doi=10.1007/bf01076082}}</ref> It follows essentially from the [[Baker–Campbell–Hausdorff formula]] for the product of two elements of a Lie group.\n\nA closed form expression is given by<ref>Xavier Bekaert, \"[http://www.ulb.ac.be/sciences/ptm/pmif/Rencontres/ModaveI/Xavier.pdf Universal enveloping algebras and some applications in physics]\" (2005) ''Lecture, Modave Summer School in Mathematical Physics''.</ref>\n\n:<math>p(t)\\star q(t)= \\left. \\exp\\left(t_i \nm^i \\left(\\frac{\\partial}{\\partial u}, \\frac{\\partial}{\\partial v} \\right)\n\\right) p(u)q(v)\\right \\vert_{u=v=t}</math>\n\nwhere\n:<math>m(A,B)=\\log\\left(e^Ae^B\\right)-A-B</math>\nand <math>m^i</math> is just <math>m</math> in the chosen basis.\n\nThe universal enveloping algebra of the [[Heisenberg algebra]] is the [[Weyl algebra]] (modulo the relation that the center be the unit); here, the <math>\\star</math> product is called the [[Moyal product]].\n\n==Representation theory==\nThe universal enveloping algebra preserves the representation theory: the [[representation of a Lie algebra|representations]] of <math>\\mathfrak{g}</math> correspond in a one-to-one manner to the [[module (mathematics)|module]]s over <math>U(\\mathfrak{g})</math>. In more abstract terms, the [[abelian category]] of all [[representation of a Lie algebra|representations]] of <math>\\mathfrak{g}</math> is [[isomorphism of categories|isomorphic]] to the abelian category of all left modules over <math>U(\\mathfrak{g})</math>.\n\nThe representation theory of [[semisimple Lie algebra]]s rests on the observation that there is an isomorphism, known as the [[Kronecker coefficient|Kronecker product]]:\n:<math>U(\\mathfrak{g}_1\\oplus\\mathfrak{g}_2)\\cong U(\\mathfrak{g}_1)\\otimes U(\\mathfrak{g}_2)</math>\nfor Lie algebras <math>\\mathfrak{g}_1, \\mathfrak{g}_2</math>. The isomorphism follows from a lifting of the embedding\n:<math>i(\\mathfrak{g}_1 \\oplus \\mathfrak{g}_2)\n=i_1(\\mathfrak{g}_1)\\otimes 1 \\oplus 1\\otimes i_2(\\mathfrak{g}_2)</math>\nwhere\n:<math>i:\\mathfrak{g}\\to U(\\mathfrak{g})</math>\nis just the canonical embedding (with subscripts, respectively for algebras one and two). It is straightforward to verify that this embedding lifts, given the prescription above. See, however, the discussion of the bialgebra structure in the article on [[tensor algebra]]s for a review of some of the finer points of doing so: in particular, the [[shuffle product]] employed there corresponds to the Wigner-Racah coefficients, i.e. the [[6j-symbol|6j]] and [[9j-symbol]]s, etc.\n\nAlso important is that the universal enveloping algebra of a [[free Lie algebra]] is isomorphic to the [[free associative algebra]].\n\nConstruction of representations typically proceeds by building the [[Verma module]]s of the [[highest weight]]s.\n\nIn a typical context where <math>\\mathfrak{g}</math> is acting by ''[[infinitesimal transformation]]s'', the elements of <math>U(\\mathfrak{g})</math> act like [[differential operator]]s, of all orders. (See, for example, the realization of the universal enveloping algebra as left-invariant differential operators on the associated group, as discussed above.)\n\n==Casimir operators==\nThe [[center of an algebra|center]] of <math>U(\\mathfrak{g})</math> is <math>Z(U(\\mathfrak{g}))</math> and can be identified with the centralizer of <math>\\mathfrak{g}</math> in <math>U(\\mathfrak{g})</math>. That is, since the elements of <math>\\mathfrak{g}</math> generate <math>U(\\mathfrak{g})</math>, any element of <math>U(\\mathfrak{g})</math> that commutes with each Lie algebra element is in the center of <math>U(\\mathfrak{g})</math>. Thus, the center is directly useful for classifying representations of <math>\\mathfrak{g}</math>.\n\nFor a finite-dimensional [[semisimple Lie algebra]], the [[Casimir operator]]s form a distinguished basis from the center <math>Z(U(\\mathfrak{g}))</math>. These may be constructed as follows.\n\nFrom the PBW theorem, it is clear that all central elements are linear combinations of symmetric [[homogenous polynomial]]s in the basis elements <math>e_a</math> of the Lie algebra. The [[Casimir invariant]]s are the irreducible homogenous polynomials of a given, fixed degree. That is, given a basis <math>e_a</math>, a Casimir operator of order <math>m</math> has the form\n\n:<math>C_{(m)} = \\kappa^{ab\\cdots c}e_a\\otimes e_b\\otimes \\cdots\\otimes e_c</math>\n\nwhere there are <math>m</math> terms in the tensor product, and <math>\\kappa^{ab\\cdots c}</math> is a completely symmetric tensor of order <math>m</math> belonging to the adjoint representation. That is, <math>\\kappa^{ab\\cdots c}</math> can be (should be) thought of as an element of <math>\\left(\\mbox{ad}_\\mathfrak{g}\\right)^{\\otimes m}.</math> Recall that the adjoint representation is given directly by the [[structure constants]], and so an explicit indexed form of the above equations can be given, in terms of the Lie algebra basis; this is originally a theorem of [[Israel Gel'fand]]. That is, from <math>[x,C_{(m)}]=0</math>, it follows that\n\n:<math>f_{ij}^{\\;\\; k} \\kappa^{jl\\cdots m} \n+ f_{ij}^{\\;\\; l} \\kappa^{kj\\cdots m} + \\cdots \n+ f_{ij}^{\\;\\; m} \\kappa^{kl\\cdots j} = 0\n</math>\nwhere the structure constants are\n:<math>[e_i,e_j]=f_{ij}^{\\;\\; k}e_k</math>\n\nAs an example, the quadratic Casimir operator is\n:<math>C_{(2)} = \\kappa^{ij} e_i\\otimes e_j</math>\nwhere <math>\\kappa^{ij}</math> is the inverse matrix of the [[Killing form]] <math>\\kappa_{ij}.</math>  That the Casimir operator <math>C_{(2)}</math> belongs to the center <math>Z(U(\\mathfrak{g}))</math> follows from the fact that the Killing form is invariant under the adjoint action.\n\nThe center of the universal enveloping algebra of a simple Lie algebra is given in detail by the [[Harish-Chandra isomorphism]].\n\n===Rank===\nThe number of algebraically independent Casimir operators of a finite-dimensional [[semisimple Lie algebra]] is equal to the rank of that algebra, i.e. is equal to the rank of the [[Chevalley basis|Cartan-Weyl basis]]. This may be seen as follows. For a {{math|''d''}}-dimensional vector space {{math|''V''}}, recall that the [[determinant]] is the [[completely antisymmetric tensor]] on <math>V^{\\otimes d}</math>. Given a matrix {{math|''M''}}, one may write the [[characteristic polynomial]] of {{math|''M''}} as\n:<math>\\det(tI-M)=\\sum_{n=0}^d p_nt^n</math>\n\nFor a {{math|''d''}}-dimensional Lie algebra, that is, an algebra whose [[Adjoint representation of a Lie algebra|adjoint representation]] is {{math|''d''}}-dimensional, the linear operator\n:<math>\\mbox{ad}:\\mathfrak{g}\\to\\mbox{End}(\\mathfrak{g})</math>\nimplies that <math>\\mbox{ad}_x</math> is a {{math|''d''}}-dimensional endomorphism, and so one has the characteristic equation\n:<math>\\det(tI-\\mbox{ad}_x)=\\sum_{n=0}^d p_n(x)t^n</math>\nfor elements <math>x\\in \\mathfrak{g}.</math>  The non-zero roots of this characteristic polynomial (that are roots for all {{math|''x''}}) form the [[root system]] of the algebra. In general, there are only {{math|''r''}} such roots; this is the rank of the algebra. This implies that the highest value of {{math|''n''}} for which the <math>p_n(x)</math> is non-vanishing is {{math|''r''.}}\n\nThe <math>p_n(x)</math> are [[homogeneous polynomial]]s of degree {{math|''d''-''n''.}}  This can be seen in several ways: Given a constant <math>k\\in K</math>, ad is linear, so that <math>\\mbox{ad}_{kx}=k\\,\\mbox{ad}_x.</math> By [[plug and chug|plugging and chugging]] in the above, one obtains that\n\n:<math>p_n(kx)=k^{d-n}p_n(x).</math>\n\nBy linearity, if one expands in the basis,\n:<math>x=\\sum_{i=1}^d x_i e_i</math>\nthen the polynomial has the form\n:<math>p_n(x)=x_ax_b\\cdots x_c \\kappa^{ab\\cdots c}</math>\nthat is, a <math>\\kappa</math> is a tensor of rank <math>m=d-n</math>. By linearity and the commutativity of addition, i.e. that <math>\\mbox{ad}_{x+y}=\\mbox{ad}_{y+x},</math>, one concludes that this tensor must be completely symmetric. This tensor is exactly the Casimir invariant of order {{math|''m''.}}\n\nThe center <math>Z(\\mathfrak{g})</math> corresponded to those elements <math>z\\in Z(\\mathfrak{g})</math> for which <math>\\mbox{ad}_x(z)=0</math> for all {{math|''x'';}}  by the above, these clearly corresponds to the roots of the characteristic equation. One concludes that the roots form a space of rank {{math|''r''}} and that the Casimir invariants span this space. That is, the Casimir invariants generate the center <math>Z(U(\\mathfrak{g})).</math>\n\n===Example: Rotation group SO(3)===\nThe [[rotation group SO(3)]] is of rank one, and thus has one Casimir operator. It is three-dimensional, and thus the Casimir operator must have order (3-1)=2 i.e. be quadratic. Of course, this is the Lie algebra of <math>A_1.</math> As an elementary exercise, one can compute this directly. Changing notation to <math>e_i=L_i,</math> with <math>L_i</math> belonging to the adjoint rep, a general algebra element is <math>xL_1+yL_2+zL_3</math> and direct computation gives\n\n:<math>\\det\\left(xL_1+yL_2+zL_3-tI\\right)=-t^3-(x^2+y^2+z^2)t+2xyz</math>\n\nThe quadratic term can be read off as <math>\\kappa^{ij}=\\delta^{ij}</math>, and so the squared [[angular momentum operator]] for the rotation group is that Casimir operator. That is,\n:<math>C_{(2)} = L^2 = e_1\\otimes e_1 +  e_2\\otimes e_2 + e_3\\otimes e_3</math>\nand explicit computation shows that\n:<math>[L^2, e_k]=0</math>\nafter making use of the [[structure constants]]\n:<math>[e_i, e_j]=\\epsilon_{ij}^{\\;\\;k}e_k</math>\n\n===Example: Pseudo-differential operators===\nA key observation during the construction of <math>U(\\mathfrak{g})</math> above was that it was a differential algebra, by dint of the fact that any derivation on the Lie algebra can be lifted to <math>U(\\mathfrak{g})</math>. Thus, one is led to a ring of [[pseudo-differential operator]]s, from which one can construct Casimir invariants.\n\nIf the Lie algebra <math>\\mathfrak{g}</math> acts on a space of linear operators, such as in [[Fredholm theory]], then one can construct Casimir invariants on the corresponding space of operators. The quadratic Casimir operator corresponds to an [[elliptic operator]].\n\nIf the Lie algebra acts on a differentiable manifold, then each Casimir operator corresponds to a higher-order differential on the cotangent manifold, the second-order differential being the most common and most important.\n\nIf the action of the algebra is [[Isometry group|isometric]], as would be the case for [[Riemannian manifold|Riemannian]] or [[pseudo-Riemannian manifold]]s endowed with a metric and the symmetry groups [[SO(N)]] and [[indefinite orthogonal group|SO (P, Q)]], respectively, one can then contract upper and lower indices (with the metric tensor) to obtain more interesting structures. For the quadratic Casimir invariant, this is the [[Laplacian]]. Quartic Casimir operators allow one to square the [[stress–energy tensor]], giving rise to the [[Yang-Mills action]]. The [[Coleman–Mandula theorem]] restricts the form that these can take, when one considers ordinary Lie algebras. However, the [[Lie superalgebra]]s are able to evade the premises of the Coleman–Mandula theorem, and can be used to mix together space and internal symmetries.\n\n==Examples in particular cases==\nIf <math>\\mathfrak{g} = \\mathfrak{sl}_2</math>, then it has a basis of matrices<blockquote><math>h = \\begin{pmatrix}\n-1 & 0 \\\\\n0 & 1\n\\end{pmatrix}, \\text{ }\ng = \\begin{pmatrix}\n0 & 1 \\\\\n0 & 0\n\\end{pmatrix}, \\text{ }\nf = \\begin{pmatrix}\n0 & 0 \\\\\n1 & 0\n\\end{pmatrix}</math></blockquote>which satisfy the following identities under the standard bracket:<blockquote><math>[h,g] = -2g</math>, <math>[h,f] = -2f</math>, and <math>[g,f] = - h </math></blockquote>this shows us that the universal enveloping algebra has the presentation<blockquote><math>U(\\mathfrak{sl}_2) = \\frac{\\mathbb{C}\\langle x,y,z\\rangle}{(xy - yx + 2y, xz - zx + 2z, yz - zy + x)}</math></blockquote>as a non-commutative ring.\n\nIf <math>\\mathfrak{g}</math> is ''abelian'' (that is, the bracket is always {{math|0}}), then <math>U(\\mathfrak{g})</math> is commutative; and if a [[basis (linear algebra)|basis]] of the [[vector space]] <math>\\mathfrak{g}</math>  has been chosen, then <math>U(\\mathfrak{g})</math> can be identified with the [[polynomial]] algebra over {{math|''K''}}, with one variable per basis element.\n\nIf <math>\\mathfrak{g}</math> is the Lie algebra corresponding to the [[Lie group]] {{math|''G''}}, then <math>U(\\mathfrak{g})</math> can be identified with the algebra of left-invariant [[differential operator]]s (of all orders) on {{math|''G''}}; with <math>\\mathfrak{g}</math> lying inside it as the left-invariant [[vector field]]s as first-order differential operators.\n\nTo relate the above two cases: if <math>\\mathfrak{g}</math> is a vector space {{math|''V''}} as abelian Lie algebra, the left-invariant differential operators are the constant coefficient operators, which are indeed a polynomial algebra in the [[partial derivative]]s of first order.\n\nThe center <math>Z(\\mathfrak{g})</math> consists of the left- and right- invariant differential operators; this, in the case of {{math|''G''}} not commutative, is often not generated by first-order operators (see for example [[Casimir operator]] of a semi-simple Lie algebra).\n\nAnother characterization in Lie group theory is of <math>U(\\mathfrak{g})</math> as the [[convolution]] algebra of [[Distribution (mathematics)|distribution]]s [[Support (mathematics)#Support of a distribution|support]]ed only at the [[identity element]] {{math|''e''}} of {{math|''G''}}.\n\nThe algebra of differential operators in {{math|''n''}} variables with polynomial coefficients may be obtained starting with the Lie algebra of the [[Heisenberg group]]. See [[Weyl algebra]] for this; one must take a quotient, so that the central elements of the Lie algebra act as prescribed scalars.\n\nThe universal enveloping algebra of a finite-dimensional Lie algebra is a filtered [[quadratic algebra]].\n\n== Hopf algebras and quantum groups ==\nThe construction of the [[group algebra]] for a given [[group (mathematics)|group]] is in many ways analogous to constructing the universal enveloping algebra for a given Lie algebra. Both constructions are universal and translate representation theory into module theory. Furthermore, both group algebras and universal enveloping algebras carry natural [[coalgebra|comultiplications]] that turn them into [[Hopf algebra]]s. This is made precise in the article on the [[tensor algebra]]: the tensor algebra has a Hopf algebra structure on it, and because the Lie bracket is consistent with (obeys the consistency conditions for) that Hopf structure, it is inherited by the universal enveloping algebra.\n\nGiven a Lie group {{math|''G''}}, one can construct the vector space {{math|C(''G'')}} of continuous complex-valued functions on {{math|''G''}}, and turn it into a [[C*-algebra]]. This algebra has a natural Hopf algebra structure: given two functions\n<math>\\phi, \\psi\\in C(G)</math>, one defines multiplication as\n:<math>(\\nabla(\\phi, \\psi))(x)=\\phi(x)\\psi(x)</math>\nand comultiplication as\n:<math>(\\Delta(\\phi))(x\\otimes y)=\\phi(xy),</math>\nthe counit as\n:<math>\\epsilon(\\phi)=\\phi(e)</math>\nand the antipode as\n:<math>(S(\\phi))(x)=\\phi(x^{-1}).</math>\nNow, the [[Gelfand-Naimark theorem]] essentially states that every commutative Hopf algebra is isomorphic to the Hopf algebra of continuous functions on some compact topological group {{math|''G''}}—the theory of compact topological groups and the theory of commutative Hopf algebras are the same. For Lie groups, this implies that {{math|C(''G'')}} is isomorphically dual to <math>U(\\mathfrak{g})</math>; more precisely, it is isomorphic to a subspace of the dual space <math>U^*(\\mathfrak{g}).</math>\n\nThese ideas can then be extended to the non-commutative case. One starts by defining the [[quasi-triangular Hopf algebra]]s, and then performing what is called a [[quantum deformation]] to obtain the '''quantum universal enveloping algebra''', or [[quantum group]], for short.\n\n==See also==\n*[[Milnor–Moore theorem]]\n*[[Harish-Chandra homomorphism]]\n\n==References==\n{{reflist}}\n* {{citation | last1=Dixmier | first1=Jacques | authorlink=Jacques Dixmier | title=Enveloping algebras | origyear=1974 | url=https://books.google.com/books?isbn=0821805606 | publisher=[[American Mathematical Society]] | location=Providence, R.I. | series=[[Graduate Studies in Mathematics]] | isbn=978-0-8218-0560-2 | mr=0498740 | year=1996 | volume=11}}\n*{{Citation| last=Hall|first=Brian C.|title=Lie Groups, Lie Algebras, and Representations: An Elementary Introduction|edition=2nd|series=Graduate Texts in Mathematics|volume=222|publisher=Springer|year=2015|isbn=978-3319134666}}\n*{{Citation | last1=Helgason | first1=Sigurdur | title=Differential geometry, Lie groups, and symmetric spaces | publisher=[[American Mathematical Society]] | location=Providence, R.I. | series=Graduate Studies in Mathematics | isbn=978-0-8218-2848-9 |mr=1834454 | year=2001 | volume=34 | doi=10.1090/gsm/034}}\n* {{citation | url=http://www.ams.org/bookstore?fn=20&arg1=tb-aa&ikey=GSM-131%20 | title=Lie Superalgebras and Enveloping Algebras | first=Ian M. | last=Musson | year=2012 | series=Graduate Studies in Mathematics | volume=131 | location=Providence, R.I. | publisher=[[American Mathematical Society]] | isbn=0-8218-6867-5 | zbl=1255.17001 }}\n* [[Shlomo Sternberg]] (2004), ''[http://www.math.harvard.edu/~shlomo/docs/lie_algebras.pdf Lie algebras]'', Harvard University.\n* {{nlab|id=universal+enveloping+algebra|title = Universal enveloping algebra}}\n\n[[Category:Ring theory]]\n[[Category:Hopf algebras]]\n[[Category:Representation theory of Lie algebras]]"
    }
  ]
}