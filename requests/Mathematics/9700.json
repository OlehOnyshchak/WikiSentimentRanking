{
  "pages": [
    {
      "title": "ROOT",
      "url": "https://en.wikipedia.org/wiki/ROOT",
      "text": "{{About|the computing library developed by CERN|the part of a plant|Root|other uses|Root (disambiguation)}}\n{{Infobox software\n| name = ROOT\n| logo = ROOT Logo.png\n| logo_size = 297px\n| screenshot = CMS ROOT plot.png\n| caption = The CMS experiments presented on July 4, 2012, the status of the Standard Model Higgs search. All the plots presented that day were done using ROOT.\n| developer = [[CERN]]\n| latest_release_version = 6.18.00\n| latest_release_date = {{Start date and age|2019|06|25}}\n| Originally  written by = René Brun & Fons Rademakers <ref>{{Cite web|url=https://root.cern.ch/project-founders|title=Project Founders|website=root.cern|language=en|access-date=2019-06-19}}</ref>\n| programming language = [[C++]]\n| operating_system = [[Microsoft Windows]], [[OS X]], [[Linux]], [[Solaris (operating system)|Solaris]], [[IBM AIX]]\n| platform = [[IA-32]], [[x86-64]]\n| size = 42–169 [[Megabytes|MB]]\n| genre = [[Data analysis]], [[Plot (graphics)|Plotting]]\n| license = [[LGPL]]/[[GPL]]\n| website = {{URL|root.cern}}\n}}\n'''ROOT''' is an [[Object-oriented programming|object-oriented]] [[Computer program|program]] and [[Library (computing)|library]] developed by [[CERN]]. It was originally designed for [[particle physics]] [[data analysis]] and contains several features specific to this field, but it is also used in other applications such as [[astronomy]] and [[data mining]].  The latest release is 6.18.00, as of 2019-06-25.<ref>{{Cite web|url=https://root.cern/downloading-root|title=downloading ROOT {{!}} ROOT a Data analysis Framework|website=root.cern|language=en|access-date=2019-06-25}}</ref>\n\n== Description ==\nCERN maintained a [[CERN Program Library|program library]] written in [[FORTRAN]] for many years; development and maintenance were discontinued in 2003 in favour of ROOT, written in [[C++]].\nROOT development was initiated by René Brun and Fons Rademakers in 1994. Some parts are published under the [[GNU Lesser General Public License|LGPL]], and others are based on [[GNU General Public License|GPL]] software and thus are also published under the terms of the GPL. It provides [[platform independent]] access to a computer's graphics subsystem and [[operating system]] using [[Abstraction (computer science)|abstract layers]]. Parts of the abstract platform are: a [[graphical user interface]] and a [[Graphical user interface builder|GUI builder]], container classes, [[Reflection (computer science)|reflection]], a C++ [[Scripting language|script]] and [[command line]] [[Interpreter (computing)|interpreter]] ([[CINT]] in version 5, [[Cling (command line interpreter)|cling]] in version 6), object [[serialization]] and [[Persistence (computer science)|persistence]].\n\nThe packages provided by ROOT include those for\n* [[Histogram]]ming and [[Graph of a function|graphing]] to view and analyze [[Distribution (mathematics)|distributions]] and [[Function (mathematics)|functions]],\n* [[curve fitting]] (regression analysis) and minimization of [[Functional (mathematics)|functionals]],\n* [[statistics]] tools used for [[data analysis]],\n* [[Matrix (mathematics)|matrix]] algebra,\n* [[four-vector]] computations, as used in [[high energy physics]],\n* standard [[Function (mathematics)|mathematical functions]],\n* [[Multivariate analysis|multivariate data analysis]], e.g. using [[neural networks]],\n* image manipulation, used, for instance, to analyze [[astronomical]] pictures,\n* access to distributed data (in the context of the [[Grid computing|Grid]]),\n* [[distributed computing]], to parallelize [[Data analysis|data analyses]],\n* [[Persistence (computer science)|persistence]] and [[serialization]] of objects, which can cope with changes in class definitions of persistent data,\n* access to [[databases]],\n* [[3D computer graphics|3D]] [[Visualization (graphic)|visualizations]] (geometry),\n* creating files in various graphics formats, like [[PDF]], [[PostScript]], [[Portable Network Graphics|PNG]], [[Scalable Vector Graphics|SVG]], [[LaTeX]], etc.\n* interfacing [[Python (programming language)|Python]] and [[Ruby programming language|Ruby]] code in both directions,\n* interfacing [[Monte Carlo method|Monte Carlo]] [[event generator]]s.\n\n[[File:Atlas_ROOT_plot.png|thumb|The ATLAS experiments presented on July 4th 2012 the status of the Standard Model Higgs search. All the plots presented that day were done using ROOT.]]\n\nA key feature of ROOT is a data container called ''tree'', with its substructures ''branches'' and ''leaves''. A tree can be seen as a sliding window to the raw data, as stored in a file. Data from the next entry in the file can be retrieved by advancing the index in the tree. This avoids memory allocation problems associated with object creation, and allows the tree to act as a lightweight container while handling buffering invisibly.\n\nROOT is designed for high [[Computer performance|computing efficiency]], as it is required to process data from the [[Large Hadron Collider]]'s experiments estimated at several [[petabyte]]s per year. {{As of|2009}} ROOT is mainly used in [[data analysis]] and [[data acquisition]] in [[particle physics]] (high energy physics) experiments, and most {{As of|2009|alt=current}} experimental plots and results in those subfields are obtained using ROOT.\n\nThe inclusion of a C++ interpreter ([[CINT]] until version 5.34, Cling from version 6.00) makes this package very versatile as it can be used in interactive, scripted and compiled modes in a manner similar to commercial products like [[MATLAB]].\n\nOn July 4, 2012 the ATLAS and CMS LHC's experiments presented  the status of the Standard Model Higgs search. [https://root.cern.ch/higgs-plots All the plots presented that day were done using ROOT].\n\n== Criticisms ==\nCriticisms of ROOT include its difficulty for beginners, as well as various aspects of its design and implementation. Frequent causes of frustration include extreme code bloat, heavy use of global variables,<ref>{{cite web|url=http://insectnation.org/articles/problems-with-root.html|title=The problem with ROOT (a.k.a. The ROOT of all Evil)|last=Buckley|first=Andy|work=InsectNation|accessdate=3 May 2016|date=2007-08-27}}</ref> and a perverse class hierarchy. From time to time these issues are discussed on the ROOT users mailing list.<ref>{{cite web|url=http://root.cern.ch/root/roottalk/roottalk06/0763.html|title=Re: Wikipedia criticism about root|publisher=|accessdate=3 May 2016}}</ref><ref>{{cite web|url=http://root.cern.ch/root/roottalk/roottalk06/0782.html|title=RE: Re: Wikipedia criticism about root|publisher=|accessdate=3 May 2016}}</ref> While scientists dissatisfied with ROOT have in the past managed to work around its flaws,<ref>{{cite web|url=http://zzz.physics.umn.edu/computing/contrib/root/localdoc#recommendations_to_root_users|title=What is ROOT?|date=1 June 2009|publisher=|accessdate=3 May 2016}}</ref> some of the shortcomings are slowly being addressed by the ROOT team. The CINT interpreter, for example, has been replaced by the Cling interpreter,<ref>{{cite web|url=http://root.cern.ch/root/htmldoc/notes/release-notes.html|title=ROOT Version 6.06 Release Notes|date=2 June 2015|publisher=|accessdate=3 May 2016}}</ref> and numerous bugs are fixed with every release.\n\n== Applications of ROOT ==\nSeveral particle physics collaborations have written software based on ROOT, often in favor of using more generic solutions (e.g. using ROOT containers instead of [[Standard Template Library|STL]]).\n\n* Some of the running particle physics experiments using software based on ROOT\n** [[A Large Ion Collider Experiment|ALICE]]\n** [[ATLAS experiment|ATLAS]]\n** [[BaBar experiment]]\n** [[Belle Experiment]]\n** [[BES III]]\n** CB-ELSA/TAPS\n** [[Compact Muon Solenoid|CMS]]\n** [[COMPASS experiment]] (Common Muon and Proton Apparatus for Structure and Spectroscopy)\n** [[CUORE]] (Cryogenic Underground Observatory for Rare Events)\n** [[D0 experiment]]\n** [[GlueX| GlueX Experiment]]\n** [[GRAPES-3]] (Gamma Ray Astronomy PeV EnergieS)\n** [[LHCb]]\n** [[MINERνA]] (Main Injector Experiment for ν-A)\n** [[MINOS]] (Main injector neutrino oscillation search)\n** [[NA61 experiment]] (SPS Heavy Ion and Neutrino Experiment)\n** [[NOνA]]\n** [[OPERA experiment]]\n** [[PHENIX detector]]\n** PHOBOS experiment at [[Relativistic Heavy Ion Collider]]\n** [[SNO+]]\n** [[STAR detector]] (Solenoidal Tracker at RHIC)\n** [[T2K experiment]]\n* Future particle physics experiments currently developing software based on ROOT\n** [[Mu2e]]\n** Compressed Baryonic Matter experiment (CBM)\n** [[PANDA experiment]] (antiProton Annihilation at Darmstadt (PANDA))\n** [[Belle II experiment]] (an electron positron collider at KEK (Japan))\n** [[Deep Underground Neutrino Experiment]] (DUNE)\n** [[Hyper-Kamiokande]] (HK (Japan))\n* Astrophysics ([[X-ray astronomy|X-ray]] and [[Gamma ray astronomy|gamma-ray astronomy]], [[astroparticle physics]]) projects using ROOT\n**[[AGILE (satellite)|AGILE]]\n** [[Alpha Magnetic Spectrometer]] (AMS)\n** [[Antarctic Impulse Transient Antenna]] (ANITA)\n** [[ANTARES (telescope)|ANTARES neutrino detector]]\n** [[Cryogenic Rare Event Search with Superconducting Thermometers|CRESST (Dark Matter Search)]]\n** [[Dark Matter Time Projection Chamber|DMTPC]]\n** [[DEAP]]-3600/[[Cryogenic Low-Energy Astrophysics with Neon]](CLEAN)\n** [[Fermi Gamma-ray Space Telescope]]\n** [[IceCube Neutrino Detector|ICECUBE]]\n** [[High Altitude Water Cherenkov Experiment|HAWC]]\n** [[High Energy Stereoscopic System]] (H.E.S.S.)\n** [[Hitomi (satellite)|Hitomi]] (ASTRO-H)\n** [[MAGIC (telescope)|MAGIC]]\n** [[Milagro (experiment)|Milagro]]\n** [[Pierre Auger Observatory]]\n** [[VERITAS]]\n** [[Payload for Antimatter Matter Exploration and Light-nuclei Astrophysics|PAMELA]]\n** POLAR\n** [[PoGOLite]]\n* Computational Neuroscience projects using ROOT\n** [http://miind.sf.net/ The MIIND Project Home Page]\n\n== See also ==\n{{Portal|Free and open-source software}}\n* [[Matplotlib]] – a plotting and analysis system for [[Python (programming language)|Python]]\n* [[SciPy]] – a scientific data analysis system for [[Python (programming language)|Python]], based on the [[NumPy]] classes\n* [[Perl Data Language]] – a set of array programming extensions to the [[Perl]] programming language\n* [[HippoDraw]] – an alternative C++-based data analysis system\n* [[Java Analysis Studio]] – a Java-based AIDA-compliant data analysis system\n* [[R (programming language)|R programming language]]\n* [[AIDA (computing)]] – open interfaces and formats for particle physics data processing\n* [[Geant4]] – a platform for the simulation of the passage of particles through matter using Monte Carlo methods\n* [[Physics Analysis Workstation|PAW]]\n* [[IGOR Pro]]\n* [[Scientific Linux]]\n* [[Scientific computing]]\n* [[OpenDX]]\n* [[OpenScientist]]\n* [[CERN Program Library]] – legacy program library written in Fortran77, still available but not updated\n\n== References ==\n{{Reflist}}\n\n== External links ==\n{{Wikibooks|ROOT}}\n* [https://root.cern/ The ROOT System Home Page]\n* [https://root.cern/gallery Image galleries]\n* [https://root.cern/drupal/content/users-guide ROOT User's Guide]\n* [https://root.cern/doc/master/index.html ROOT Reference Guide]\n* [https://root-forum.cern.ch/ ROOT Forum]\n* [https://roofit.sourceforge.net/ The RooFit Toolkit for Data Modeling], an extension to ROOT to facilitate [[maximum likelihood]] fits\n* The [https://root.cern/tmva Toolkit for Multivariate Data Analysis with ROOT (TMVA)] is a ROOT-integrated project providing a machine learning environment for the processing and evaluation of multivariate classification, both binary and multi class, and regression techniques targeting applications in high-energy physics ([http://tmva.sourceforge.net/ here] or [https://sourceforge.net/p/tmva/wiki/Home/ here]).\n\n[[Category:C++ libraries]]\n[[Category:Data analysis software]]\n[[Category:Data management software]]\n[[Category:Experimental particle physics]]\n[[Category:Free physics software]]\n[[Category:Free plotting software]]\n[[Category:Free science software]]\n[[Category:Free software programmed in C++]]\n[[Category:Numerical software]]\n[[Category:Physics software]]\n[[Category:Plotting software]]\n[[Category:CERN software]]"
    },
    {
      "title": "ScaLAPACK",
      "url": "https://en.wikipedia.org/wiki/ScaLAPACK",
      "text": "The '''ScaLAPACK''' (or Scalable LAPACK) library includes a subset of [[LAPACK]] routines redesigned for [[distributed memory]] [[MIMD]] [[parallel computer]]s. It is currently written in a Single-Program-Multiple-Data style using explicit [[message passing]] for interprocessor communication. It assumes matrices are laid out in a two-dimensional block cyclic decomposition.<ref>{{cite journal|author=J. Dongarra and D. Walker|title=The Design of Linear Algebra Libraries for High Performance Computers|url=http://acts.nersc.gov/scalapack/hands-on/datadist.html}}</ref><ref>{{cite journal|author=J. Demmel, M. Heath, and H. van der Vorst|title=Parallel Numerical Linear Algebra|url=http://acts.nersc.gov/scalapack/hands-on/datadist.html}}</ref><ref>{{cite web|title=2d block-cyclic data layout|url=http://acts.nersc.gov/scalapack/hands-on/datadist.html}}</ref>\n\nScaLAPACK is designed for heterogeneous computing and is portable on any computer that supports [[Message_Passing_Interface|MPI]] or [[Parallel_Virtual_Machine|PVM]].\n\nScaLAPACK depends on [[PBLAS]] operations in the same way [[LAPACK]] depends on [[BLAS]]. \n\nAs of version 2.0 the code base directly includes PBLAS and BLACS and has dropped support for PVM.\n\n==Examples==\n*[[Programming with Big Data in R]] fully utilizes ScaLAPACK and two-dimensional block cyclic decomposition for [[Big Data]] statistical analysis which is an extension to [[R (programming language)|R]].\n\n==References==\n{{Reflist|30em}}\n\n==External links==\n*[http://www.netlib.org/scalapack/ The ScaLAPACK Project] on Netlib.org\n\n{{compu-soft-stub}}\n\n[[Category:Numerical software]]"
    },
    {
      "title": "Silo (library)",
      "url": "https://en.wikipedia.org/wiki/Silo_%28library%29",
      "text": "{{More footnotes|date=October 2009}}\n{{Context|date=October 2009}}\n{{Infobox file format\n| name                   = Silo\n| icon                   = \n| logo                   = \n| screenshot             = \n| caption                = \n| extension              = .silo\n| mime                   = \n| type code              = \n| uniform type           = \n| magic                  = \n| developer              = [[Lawrence Livermore National Laboratory]]\n| released               = \n| latest release version = 4.10.2\n| latest release date    = October 14, 2014\n| genre                  = [[scientific data format]]\n| container for          = \n| contained by           = \n| extended from          = \n| extended to            = \n| standard               = \n| url                    = {{URL|wci.llnl.gov/simulation/computer-codes/silo}}\n}}\n\n'''Silo''' is a computer [[file format|data format]] and [[Library (computing)|library]] developed at [[Lawrence Livermore National Laboratory]] (LLNL) for storing [[rectilinear grid|rectilinear]], curvilinear, unstructured, or point [[Polygon mesh|meshes]] in 2D and 3D.  It supports data upon those meshes, including scalar, vector, and tensor variables; volume fraction-based materials; and mass fraction-based species. It fully supports block structured [[adaptive mesh refinement]] (AMR) meshes by way of mesh blocks structured in a hierarchy.  Silo sits on top of other low-level storage libraries such as PDB, [[NetCDF]], and [[HDF5]].\n\nCurrently, [[VisIt]], an [[open source software]] package with its start at LLNL, supports the Silo format for [[Scientific visualization|visualization]] and analysis, among many other formats.\n\nAs of Version 4.8, July, 2010, the Silo source code is now available\nunder the standard BSD Open Source License.\n\nThe source code for two compression libraries which have been part of\nprevious releases of the Silo library is not available under the\nterms of the BSD Open Source license. These are the Hzip and FPzip\ncompression libraries.\n\nFor this reason, two different releases of the Silo source code are\nmade available.\n\n==References==\n<!--<nowiki>\nSee http://en.wikipedia.org/wiki/Wikipedia:Footnotes for an explanation of how to generate footnotes using the <ref> and </ref> tags, and the template below. \n</nowiki>-->\n<references/>\n{{Lawrence Livermore National Laboratory|state=autocollapse}}\n[[Category:Numerical software]]\n[[Category:Lawrence Livermore National Laboratory]]\n{{computer-stub}}"
    },
    {
      "title": "Simcenter Amesim",
      "url": "https://en.wikipedia.org/wiki/Simcenter_Amesim",
      "text": "{{Infobox Software\n| name                   = Simcenter Amesim\n| logo                   = Siemens AG logo.svg\n|logo size=150px\n| screenshot             = Simcenter Amesim.jpg\n| caption                = Modelling and Simulation with Simcenter Amesim\n| developer              = [[Siemens PLM Software]]\n| released               = 1995\n| latest_release_version = Simcenter Amesim 2019.1\n| programming language   = \n| platform               = [[Cross-platform]]\n| language               = [[English language|English]], [[Chinese language|Chinese]]\n| genre                  = [[Mathematical model|modeling]], [[Computer Simulation|simulation]], [[Graphical user interface|Graphical User Interface]]\n| license                = [[Proprietary software|Proprietary]]\n| website                = [http://www.plm.automation.siemens.com/en_us/products/lms/imagine-lab/amesim/index.shtml Simcenter Amesim website]\n}}\n'''Simcenter Amesim''' is a commercial [[simulation]] software for the modeling and analysis of multi-domain systems. It is part of [[systems engineering]] domain and falls into the [[mechatronic]] engineering field.\n\nThe software package is a suite of tools used to model, analyze and predict the performance of [[mechatronics]] systems. Models are described using [[nonlinear]] time-dependent analytical equations that represent the system’s hydraulic, pneumatic, thermal, electric or mechanical behavior. Compared to 3D [[Computer-aided engineering|CAE]] modeling this approach gives the capability to simulate the behavior of systems before detailed [[Computer-aided design|CAD]] geometry is available, hence it is used earlier in the system design cycle or [[V-Model]].\n\nTo create a simulation model for a system, a set of [[library (computing)|libraries]] is used, they contain pre-defined components for different [[physics|physical]] domains. The icons in the system have to be connected and for this purpose each icon has ports, which have several inputs and outputs. [[Causality]] is enforced by linking the inputs of one icon to the outputs of another icon (and vice versa).\n\nSimcenter Amesim libraries are written in C language and also support [[Modelica]]<ref>{{cite web|title=Modelica and the Modelica Association|url=https://www.modelica.org}}</ref>  which is a non-proprietary, object-oriented, equation based language to model complex physical systems containing, e.g., mechanical, electrical, electronic, hydraulic, thermal, control, electric power or process-oriented subcomponents.  The software runs on [[Linux]] and on [[Microsoft Windows|Windows]] platforms.\n\nSimcenter Amesim is a part of the [[Siemens PLM Software]] Simcenter portfolio. This combines 1D simulation, 3D CAE and physical testing with intelligent reporting and data analytics. This portfolio is intended to provide engineers and analysts with a comprehensive solution for development of complex products that include smart systems, through implementing a [[Predictive engineering analytics|Predictive Engineering Analytics]] approach.<ref>{{cite web|title=Siemens PLM Software Simcenter|url=http://www.plm.automation.siemens.com/en_us/products/simcenter/}}</ref>\n\n==History==\nThe Simcenter Amesim software was developed by Imagine S.A. a company which was acquired in June 2007 by [[LMS International]], which itself was [http://schnitgercorp.com/2012/11/08/siemens-plm-lms-shakes-up-cae/ acquired] in November 2012 by [[Siemens AG]].\nThe Imagine S.A. company was created in 1987 by Dr Michel Lebrun from the University Claude Bernard in France, to control complex dynamic systems coupling hydraulic servo-actuators with finite-elements mechanical structures. The initial engineering project involved the deck elevation of the sinking [[Ekofisk]] North Sea petroleum platforms.\nIn the early 1990s, the association with Pr C. W. Richards,<ref>{{cite conference|author=Sanada, K., Richards, C. W., Longmore, D. K., Johnston, D. N. and Burrows, C. R.|title=Practical requirements for modelling the dynamics of hydraulic pipelines|conference=2nd JHPS International Symposium on Fluid Power|year=1993|url=http://opus.bath.ac.uk/13767/}}</ref><ref>{{cite conference|author=Tilley, D. G., Richards, C. W., Tomlinson, S. P. and Burrows, C. R.|title=Role of simulation in the design of fluid power systems|conference=IFAC Symposium on Computer Aided Design in Control Systems|year=1991|url=http://opus.bath.ac.uk/3285/}}</ref> coming from the University of Bath in England, led to the first commercial release of Simcenter Amesim in 1995 which was then dedicated to fluid control systems.\nSimcenter Amesim is used by companies in the automotive,<ref>{{cite conference|author=Zhang Dong-xu|author2=Zeng Xiao-hua |author3= Wang Peng-yu |author4= Wang Qing-nian|title=Co-simulation with Amesim and MATLAB for differential dynamic coupling of Hybrid Electric Vehicle|conference=Intelligent Vehicles Symposium, 2009 IEEE|year=2009|url=http://ieeexplore.ieee.org/xpl/login.jsp?tp=&arnumber=5164373&url=http%3A%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D5164373}}</ref><ref>{{cite conference|author1=Guizhi Sun |author2=Minxiang Wei |author3=Jinju Shao |author4=Man Pei |title=Automotive Powertrain Modeling and Simulation Based on Amesim|conference=SAE Asia Pacific Automotive Engineering Conference|year=2007|url=http://papers.sae.org/2007-01-3464/}}</ref><ref>{{cite journal|author1=CHEN Fei |author2=SUN Ren-yun |author3=CHEN You-rong |author4=SHAN Yu-mei |title=Research of Closed Loop Control for CNG Engine Injection Based on Amesim/Simlink|journal=Journal of Xihua University (Natural Science Edition)|year=2009|url=http://en.cnki.com.cn/Article_en/CJFDTOTAL-SCGX200901024.htm}}</ref><ref>{{cite conference|title=Integration of Physical Amesim Engine Model in Hardware in the Loop Environment, Dedicated to Engine Control Unit Testing|conference=SAE World Congress & Exhibition|year=2007|url=http://papers.sae.org/2007-01-1300/}}</ref> aerospace<ref>{{cite journal|author=LI Kuo,GUO Ying-Qing(College of Power Engineering and Energy,Northwestern Polytechnical University,Xi'an Shanxi 710072,China)|title=Application of Amesim in Aero-Power Plant System|journal=Computer Simulation|year=2009|url=http://en.cnki.com.cn/Article_en/CJFDTOTAL-JSJZ200901032.htm}}</ref><ref>{{cite journal|author1=GUO Jun |author2=WU Yafeng |author3=CHU Nisheng |title=Application of Amesim in aircraft hydraulic system|journal=Computer Aided Engineering|year=2006|url=http://en.cnki.com.cn/Article_en/CJFDTOTAL-JSFZ200602011.htm}}</ref><ref>{{cite journal|author1=PAN Hui |author2=ZHANG Li-hui |title=Application of Amesim in dynamic characteristic simulation of liquid rocket engine system|journal=Journal of Rocket Propulsion|year=2011|url=http://en.cnki.com.cn/Article_en/CJFDTOTAL-HJTJ201103001.htm}}</ref>  and other advanced manufacturing industries.<ref>{{cite journal|author=Wang Tao Tao Wei(West Branch of Zhejiang University of Technology)|title=Amesim-based Motion Simulation and Control of Hydraulic Excavator|journal=Metal Mine|year=2008|url=http://en.cnki.com.cn/Article_en/CJFDTOTAL-JSKS200810027.htm}}</ref><ref>{{cite journal|title=Robust trajectory tracking control of hydraulic excavator bucket|journal=Journal of Jilin University (Engineering and Technology Edition)|year=2006|url=http://en.cnki.com.cn/Article_en/CJFDTOTAL-JLGY200606020.htm}}</ref><ref>{{cite journal|author1=Zhong Hua Huang |author2=Hong Wei Gao |author3=Ya Xie |title=Hybrid Excavator Test Bed Hydraulic Load System Design|journal=Advanced Materials Research|year=2012|volume=Advanced Designs and Researches for Manufacturing|pages=1322–1325|url=http://www.scientific.net/AMR.605-607.1322}}</ref>\n\n==Usage==\nSimcenter Amesim is a ''multi-domain'' software. It allows to link between different physics domains (hydraulic, pneumatic, mechanic, electrical, thermal, electromechanical).  It is based on the [[Bond graph]] theory.\n\nThe [[computer model|modelling]] of a system is done in four steps:\n* ''sketch'' mode: in which the different components are linked,\n* ''submodel'' mode: in which the physical submodel associated to each component is chosen,\n* ''parameter'' mode: in which the parameters for each submodel are set,\n* ''run'' mode: in which the simulation is started and results analyzed.\n\nBetween the submodel and parameter mode, the Simcenter Amesim model is [[compiler|compiled]].\nUnder the Windows platform, Simcenter Amesim works with the [[free software|free]] [[GNU Compiler Collection|Gcc]] compiler, which is provided with the software. It also works with the [[Microsoft]] [[Visual C++]] compiler and its free Express edition. Since the version 4.3.0 Simcenter Amesim uses the [[Intel]] compiler on all platforms.\n\n==Platform Facilities==\nSimcenter Amesim features:\n\n*''Platform Facilities''\n**[[graphical user interface]], interactive help, supercomponents, post-processed variables, experiments management, [[meta-data]], [[Finite-state machine|statechart]] designer\n*''Analysis Tools''\n**table editor, plots, dashboard, 3D animation, replay of results, linear analysis ([[eigenvalues]], [[Mode shape|modal shapes]], [[transfer function]]s, [[root locus]]), activity index, power and energy computation\n*''Optimization, Robustness, DOE''\n**Design Of Experiments (parameter study, full factorial, central composite), [[Optimization (mathematics)|optimization]] (NLPQL, [[genetic algorithm]]), Monte-Carlo (random, Latin Hypercube, Optimized Latin Hypercube, with uniform or [[Gaussian distribution|gaussian]] distribution)\n*''Solvers and Numerics''\n**[[Solver (computer science)|LSODA]], DASSL, DASKR, Fixed-step solvers, discrete partitioning, [[Parallel computing|parallel processing]], Simcenter Amesim/Simcenter Amesim cosimulations\n*''Software Interfaces''\n**generic co-simulation (to be used to co-simulate with any software coupled to Simcenter Amesim), functional mock-up interface (export)\n*''MIL/SIL/HIL and Real-Time''\n**plant/[[Control engineering|control]] ([[Simulink]] interface, [[Labview]] interface), various [[Real-time computing|Real-Time (RT)]] targets (xPC, [[dSPACE GmbH|dSPACE]], Opal-RT, [[Labview|LabVIEW]], [[ETAS|ETAS]], ...)\n*''Simulator Scripting''\n**[[script (computing)|scripting]] functions to pilot the simulations (from [[Microsoft Excel]] thanks to the provided [[Visual Basic]] [[subroutine]]s, from [[MATLAB]], [[Scilab]], [[Python (programming language)|Python]]), circuit [[Api|API]] (to build your own Simcenter Amesim-based applications in C and in Python version), script file generator (circuit API file automatically written from the existing model)\n*''Customization''\n**own customized pre and post-processing tools with [[Python (programming language)|python]], script caller assistant, editor of parameters group, app designer\n*''Modelica Platform''\n**support of the Modelica modeling language, and support of subsets of the Modelica Standard Library (MSL) with dedicated tools: modelica editor, modelica import assistant, modelica [[compiler]], modelica assembly\n*''1D/3D CAE''\n**CAD Import (an integrated CAD reading, processing, parameter extracting and sketch generation tool), [[Computational Fluid Dynamics|CFD]] software co-simulation (Simcenter STAR-CCM+]], Fluent, [[ANSYS CFX|CFX]], [Simcenter STAR-CD], Eole, ...), [[Finite element method|FEA]] import of reduced modal basis with pre-defined frontier nodes, [[Multibody system|MBS]] software cosimulation and import/export  (Simcenter 3D or MSC.Adams)\n*''Development''\n**The user can develop his own submodels, by assembling different standard submodels (supercomponent) using the Component Customization functionality, or by programming them in [[C (programming language)|C]] or in [[Fortran]] with Submodel Editor. The C [[source code]] of most of the standard submodels are provided allowing the user to start from this base to fit them to his needs.\n\n==Physical Libraries==\nTo create a system simulation model in Simcenter Amesim, components from different physical domains are assembled. The physical libraries have been developed through engineering services and partnerships with customers. In version 2019.1, Simcenter Amesim offered 48 libraries (> 6500 multi-physics models) to answer various application requirements.\n\nSome Simcenter Amesim libraries:\n\n*''[[Control theory|Control]]'':\n** Libraries: [[Signal (electronics)|signal]] and control, engine signal control\n** Components: continuous blocks, tables, functions, logics, [[hysteresis]], [[discrete signal]], routing, bus, cyclic components, ...\n*''[[Electrical network|Electrics]]'':\n** Libraries: electric motors and drives, electric storage, electrical basics and converters, electric static conversion, electromechanical, automotive electrics, fuel cell\n** Components: resistor, inductor, capacitor, transformer, battery, alternators, synchronuous machines, induction machines, direct current machines, generators, direct Park, reverse Park, rectifiers, inverters, choppers, gradators, wires, fuses, relays, fans, blowers, lamps, window lift systems, magnetic coils, airgaps, leakages, piezoelectric actuators, ...\n*''[[Mechanics]]'':\n** Libraries: 1D mechanical, 2D mechanical, 3D mechanical, cam and followers, powertrain, vehicle dynamics\n** Components: masses, springs, dampers, cams, rocker-arms, followers, rack and pinion, screw nut, worm gear, levers, gears, bearings, seals, couplings, clutches, chassis, tires, ...\n*''[[Fluids]]'':\n** Libraries: hydraulics, hydraulic component design, hydraulic resistance, filling, pneumatics, pneumatic component design, gas mixture, moist air\n** Components: tanks, volumes, orifices, pressure drops, bends, expansions, contractions, T-junction, bearings, poppets, spools, pistons, jacks, diaphragms, leakages, sealings, ... hydraulic/pneumatic pipes with wave effects and water-hammer effect, flexible hoses, speed of sound, shocks, ... fluids and gases properties database, ...\n*''[[Thermodynamics]]'':\n** Libraries: thermal, thermal-hydraulics, thermal-hydraulic component design, two-phase flow, air conditioning, cooling system, heat exchangers assembly tool\n** Components: thermal capacities, conduction, convection, radiation, exchangers, radiators, condensers, pumps, thermostats, compressors\n*''IC [[Engine]]'':\n** Libraries: IFP drive, IFP engine, IFP exhaust, CFD1D\n** Components: drivers, gearboxes, crankshaft, camshaft, cylinder, combustion, wall heat exchanges, air path, engine valves, compressors, turbochargers, pipes, injectors, after-treatment, catalyst, ...\n*''[[Aeronautics#Aeronautical engineering|Aerospace & Defense]]'':\n** Libraries: aeronautics and space, gas turbine, aircraft fuel systems, liquid propulsion, aircraft electrics\n** Components: flight mission definition, atmosphere models, flight dynamics (longitudinal, lateral, 6DOF), propellers (use of [[XFOIL]] to compute lift and drag characteristics), compressors, turbines, fuel tanks with acceleration, orifices, flap valves, compressors/pumps/turbines, combustion chambers, nozzle, electric VFG, transformer rectifiers, three-phase loads, DC generic loads ...\n\n==Simcenter System Simulation Solutions==\n[https://www.plm.automation.siemens.com/global/en/products/simcenter/simcenter-amesim.html Simcenter Amesim] :\n*''Simcenter Amesim'':\n** an integrated, scalable system simulation platform which allows system simulation engineers to virtually assess and optimize the mechatronic systems' performance. It boosts overall system engineering productivity from the early development stages until the final performance validation and controls calibration. Ready-to-use multi-physics libraries combined with application and industry-oriented solutions supported by powerful platform capabilities let system simulation engineers rapidly create models and accurately perform analysis. \n\n*''Simcenter Amesim Component Customization'':\n** a tool for model customization and [[Intellectual property|IP]] protection to adapt and customize the appearance of models, create and publish ready-to-use catalogs, facilitate the exchange of models using the encryption capability. \n\n*''Simcenter Amesim Run'':\n** a run-only version to share validated models and run existing Simcenter Amesim models by non-experts. \n\n*''Simcenter Amesim Submodel Editor'':\n** a tool to develop new components in order to capitalize the know-how\n\n[https://www.plm.automation.siemens.com/global/en/products/simcenter/simcenter-sysdm.html Simcenter Sysdm] :\n*manages system data originating from Simcenter Amesim and other system simulation tools, providing a collaborative environment for model-based systems engineering data. \n\n[https://www.plm.automation.siemens.com/global/en/products/simcenter/simcenter-system-architect.html Simcenter System Architect] :\n*provides simulation architects and project engineers with a platform that will help them rapidly create heterogeneous system simulation architectures and seamlessly evaluate system performance. \n\n[https://www.plm.automation.siemens.com/global/en/products/simcenter/simcenter-webapp-server.html Simcenter Webapp Server] : \n*offers a cost-effective, easy-to-use, zero-installation solution. This server-client, web-based solution provides access to system simulation results relevant to model consumers thanks to predefined model parameterization.\n\n==Education and Research==\nSimcenter Amesim is used by engineering schools and universities.\nIt is also the reference framework for various [[Research]] projects in Europe. A free Simcenter Amesim Student Edition license can be downloaded [https://www.plm.automation.siemens.com/plmapp/education/simcenter/en_us/free-software/student/ here].\n\n== Release history ==\n\n{| class=\"wikitable\" style=\"font-size: 90%; text-align: left; \"\n|-\n! Name/Version !! Build Number !! Date\n|-\n| AMESim\n| -\n| 1995\n|-bgcolor=ffffcc\n| AMESim 1.0\n| v100\n| 1996\n|-bgcolor=ffffcc\n| AMESim 1.5\n| v150\n| 1997\n|-bgcolor=ffffcc\n| AMESim 2.0\n| v200\n| 1998\n|-bgcolor=ffffcc\n| AMESim 2.5\n| v250\n| April 1999\n|-bgcolor=ffffcc\n| AMESim 3.0\n| v300\n| June 2000\n|-bgcolor=ffffcc\n| AMESim 3.5\n| v350\n| May 2001\n|-bgcolor=ffffcc\n| AMESim 4.0\n| v400\n| March 2002\n|-bgcolor=ffffcc\n| AMESim 4.1\n| v410\n| April 2003\n|-bgcolor=ffffcc\n| AMESim 4.2\n| v420\n| September 2004\n|-bgcolor=ffffcc\n| AMESim 4.3\n| v430\n| October 2005\n|-bgcolor=ffffcc\n| AMESim Rev 7A\n| v700\n| April 2007\n|-bgcolor=ffffcc\n| AMESim Rev 7B\n| v710\n| December 2007\n|-bgcolor=ffffcc\n| AMESim Rev 8A\n| v800\n| June 2008\n|-bgcolor=ffffcc\n| AMESim Rev 8B\n| v810\n| December 2008\n|-bgcolor=ffffcc\n| AMESim Rev 9\n| v900\n| November 2009\n|-bgcolor=ffffcc\n| AMESim Rev 10\n| v1000\n| November 2010\n|-bgcolor=ffffcc\n| AMESim Rev 11\n| v1100\n| November 2011\n|-bgcolor=ffffcc\n| AMESim Rev 12\n| v1200\n| March 2013\n|-bgcolor=ffffcc\n| AMESim Rev 13\n| v1300\n| December 2013\n|-bgcolor=ffffcc\n|LMS Imagine.Lab Amesim 14\n|v1400\n|February 2015\n|-bgcolor=ffffcc\n|LMS Imagine.Lab Amesim 15\n|v1501\n|July 2016\n|-bgcolor=ffffcc\n|Simcenter Amesim 16\n|v1600\n|January 2018\n|-bgcolor=ffffcc\n|Simcenter Amesim 17\n|v17\n|October 2018\n|-bgcolor=ffffcc\n|Simcenter Amesim 2019.1\n|v2019.1\n|April 2019\n|}\n\n==See also==\n{{div col|colwidth=22em}}\n* [[Model-based design|Model-Based Design]]\n* [[Lumped parameters|Lumped-Parameters]]\n* [[Distributed element model|Distributed-Parameters]]\n* [[Bond graphs|Bond-Graphs]]\n* [[Mechatronics]]\n* [[Control theory|Control]]\n* [[Real-time computing|Real-Time (RT)]]\n* [[Hardware-in-the-loop simulation|Hardware In the Loop (HIL)]]\n* [[Systems engineering|Systems Engineering]]\n* [[Simulink]]\n* [[20-sim]]\n* [[Wolfram SystemModeler]]\n{{div col end}}\n\n==References==\n{{reflist|2}}\n\n==External links==\n*[https://www.plm.automation.siemens.com/global/en/products/simcenter/simcenter-amesim.html Simcenter Amesim webpage]\n*[https://community.plm.automation.siemens.com/t5/Simcenter-Blog/bg-p/Simcenter_blog/label-name/simcenter%20amesim Simcenter Amesim on Simcenter Community]\n*[https://community.plm.automation.siemens.com/t5/1D-Simulation-Knowledge-Base/tkb-p/Simcenter_1D_tkb System Simulation Knowledge Base]\n*[https://www.youtube.com/playlist?list=PL1m1vu8_quoBHBELkeavgEG1uwhRPR2wK Simcenter System Simulation videos]\n*[https://www.slideshare.net/siemensplm Simcenter Amesim on SlideShare]\n*[http://www.functional-mockup-interface.org Functional Mock-up Interface]\n\n[[Category:Simulation software]]\n[[Category:Numerical software]]\n[[Category:Computer-aided engineering]]\n[[Category:Simulation programming languages]]\n[[Category:Fortran]]"
    },
    {
      "title": "Simulink",
      "url": "https://en.wikipedia.org/wiki/Simulink",
      "text": "{{Infobox software\n| name                   = Simulink\n| logo                   = Simulink Logo.png\n| logo size              = 100px\n| screenshot             = [[Image:Simulink model of a wind turbine.tif|300px|Simulink model of a wind turbine]]\n| caption                = Simulink model of a wind turbine\n| developer              = [[MathWorks]]\n| latest release version = 9.2 (part of R2018b)\n| latest release date    = {{Start date and age|2018|09|12}}\n| operating system       = [[Linux]], [[macOS]], [[Microsoft Windows]]<ref>{{cite web|url=http://www.mathworks.com/products/simulink/requirements.html?s_cid=wiki_simulink_1|title=System Requirements and Platform Availability by Product|work=mathworks.com|accessdate=15 October 2015}}</ref>\n| license                = [[Proprietary software|Proprietary]]\n| website                = {{URL|https://www.mathworks.com/products/simulink.html|mathworks.com}}\n}}\n\n'''Simulink''', developed by [[MathWorks]], is a graphical programming environment for modeling, simulating and analyzing multidomain [[dynamical systems]]. Its primary interface is a [[visual modeling|graphical block diagramming tool]] and a customizable set of block [[library (computer science)|libraries]]. It offers tight integration with the rest of the [[MATLAB]] environment and can either drive MATLAB or be scripted from it. Simulink is widely used in [[automatic control]] and [[digital signal processing]] for multidomain simulation and [[model-based design]]<ref>{{cite web | url = http://www.vega-group.com/assets/documents/10000421matlabsimulink.pdf | title = The Successful development process with MATLAB Simulink in the framework of ESA's ATV project | format = PDF | publisher = Vega Group PLC | accessdate = 2011-11-01 | deadurl = yes | archiveurl = https://web.archive.org/web/20110717191512/http://www.vega-group.com/assets/documents/10000421matlabsimulink.pdf | archivedate = 2011-07-17 | df =  }}</ref><ref>{{cite web|url=http://papers.sae.org/2010-01-1999/|title=Model Based Design Accelerates the Development of Mechanical Locomotive Controls|work=sae.org|accessdate=28 June 2015}}</ref>.\n\n== Add-on products ==\nMathWorks and other third-party hardware and software products can be used with Simulink. For example, [[Stateflow]] extends Simulink with a design environment for developing [[state machines]] and [[Flowchart|flow charts]].\n\n[[MathWorks]] claims that, coupled with another of their products,<ref>{{cite web|url=http://www.mathworks.com/products/simulink-coder?s_cid=wiki_simulink_3|title=Automatic Code Generation - Simulink Coder|work=mathworks.com|accessdate=28 June 2015}}</ref> Simulink can [[automatic code generation|automatically generate]] [[C (programming language)|C]] [[source code]] for [[real-time computing|real-time]] implementation of systems. As the efficiency and flexibility of the code improves, this is becoming more widely adopted for production systems,<ref>[http://ti.arc.nasa.gov/m/pub-archive/1296h/1296%20(Denney).pdf A Software Safety Certification Plug-in for Automated Code Generators: Feasibility Study and Preliminary Design]</ref><ref>{{cite web|url=http://www.greencarcongress.com/2009/10/general-motors-developed-twomode-hybrid-powertrain-with-mathworks-modelbased-design-cut-24-months-of.html|title=Green Car Congress: General Motors Developed Two-Mode Hybrid Powertrain With MathWorks Model-Based Design; Cut 24 Months Off Expected Dev Time|author=BioAge Media|work=greencarcongress.com|accessdate=28 June 2015}}</ref> in addition to being a tool for [[embedded system]] design work because of its flexibility and capacity for quick iteration{{citation needed|date=April 2015}}. Embedded Coder creates code efficient enough for use in embedded systems.<ref>[http://www.techsource.com.sg/eresources/eres_storyDetails.asp?stid=10 Lotus Engineering Develops Control Systems Software to Reduce Diesel Emissions]</ref><ref>[http://www.cedes.se/Registrerade%20dokument/17%20RH%20JN%20A%20comparison%20of%20code%20generators.pdf A Comparison of Three Code Generators for Models Created in Simulink] {{webarchive|url=https://web.archive.org/web/20100811055925/http://www.cedes.se/Registrerade%20dokument/17%20RH%20JN%20A%20comparison%20of%20code%20generators.pdf |date=2010-08-11 }}</ref><ref>{{cite web|url=http://www.automotivedesignline.com/howto/193300307|archive-url=https://web.archive.org/web/20071018215921/http://automotivedesignline.com/howto/193300307|dead-url=yes|archive-date=18 October 2007|title=Multitarget modeling reduces ECU software costs|work=EETimes|accessdate=28 June 2015}}</ref>\n\nSimulink Real-Time (formerly known as xPC Target), together with x86-based real-time systems, is an environment for simulating and testing Simulink and Stateflow models in real-time on the physical system.  Another MathWorks product<ref>{{cite web|url=http://www.mathworks.com/products/embedded-coder?s_cid=wiki_simulink_5|title=Code Generation - Embedded Coder - Simulink|work=mathworks.com|accessdate=28 June 2015}}</ref> also supports specific embedded targets.  When used with other generic products,<ref>[http://www.mathworks.com/products/slhdlcoder?s_cid=wiki_simulink_6 HDL Coder]</ref> Simulink and [[Stateflow]] can automatically generate [[logic synthesis|synthesizable]] [[VHDL]] and [[Verilog]]{{citation needed|date=April 2015}}.\n<!-- Deleted image removed: [[File:Matlab.family.png|300px|left|Matlab product family]] -->\n\nSimulink Verification and Validation enables systematic verification and validation of models through modeling style checking, [[requirements traceability]] and model coverage analysis. Simulink Design Verifier uses [[formal methods]] to identify design errors like [[integer overflow]], [[division by zero]] and dead logic, and generates test case scenarios for [[model checking]] within the Simulink environment.\n\n[[SimEvents]] is used to add a library of graphical building blocks for modeling queuing systems to the Simulink environment, and to add an event-based simulation engine to the time-based simulation engine in Simulink.<ref>{{cite web|title=Introduction to Discrete-Event Simulation | last=Cassandras| first=Christos | publisher= Springer US | date=2007-11-27 | url=http://www.springerlink.com/content/g82w56/?v=editorial| accessdate=2009-11-03}}</ref>\n\nTherefore in Simulink any type of simulation can be done and the model can be simulated at any point in this environment.\n\nDifferent type of blocks can be accessed using the Simulink library browser. And therefore the benefit could be taken out from this environment efficiently.\n\n== Release history ==\n{| class=\"wikitable\"\n|-\n! MATLAB Version<ref>{{cite web| url = http://www.mathworks.com/help/releases/R2015b/pdf_doc/simulink/slref.pdf|title = MatLab & Simulink: Simulink Reference R2015b|author = Mathworks|accessdate= 28 September 2015}}</ref><ref name=\"growth\">{{cite web | url = http://www.mathworks.com/support/solutions/en/data/1-6BTU54/?solution=1-6BTU54&s_cid=wiki_simulink_7 | title = list of version and release numbers for Simulink | author = Mathworks | accessdate = December 14, 2010 |date=June 2009}}</ref> !! Release name !! Simulink version !! Year !! Notes\n|-\n| 1.0\n|\n|\n| 1984\n|-\n| 2\n|\n|\n| 1986\n|-\n| 3\n|\n|\n| 1987\n|-\n| 3.5\n|\n|\n| 1990\n| Ran on MS-DOS but required at least a 386 processor. Version 3.5m required [[math coprocessor]]\n|-\n| 4\n|\n|\n| 1992\n| Renamed from Simulab to SIMULINK <ref>{{cite web|url=http://www.thefreelibrary.com/THE+MATHWORKS+ANNOUNCES+SHIPMENT+OF+SIMULINK+ON+MICROSOFT+WINDOWS-a012283038|title=THE MATHWORKS ANNOUNCES SHIPMENT OF SIMULINK ON MICROSOFT WINDOWS|work=thefreelibrary.com|accessdate=28 June 2015}}</ref>\n|-\n| 4.2c\n| R7\n|\n| 1994\n| Ran on Windows 3.1. Required a math coprocessor\n|-\n| 5.0\n| R8\n|\n| 1996\n|-\n| 5.1\n| R9\n|\n| rowspan=2|  1997\n|-\n| 5.1.1\n| R9.1\n|\n|-\n| 5.2\n| R10\n|\n| rowspan=2|  1998\n|-\n| 5.2.1\n| R10.1\n|\n|-\n| 5.3\n| R11\n|\n| rowspan=2|  1999\n|-\n| 5.3.1\n| R11.1\n|\n|-\n| 6.0\n| R12\n|\n| 2000\n|-\n| 6.1\n| R12.1\n|\n| 2001\n|-\n| 6.5\n| R13\n| Simulink 5.0.2\n| 2002\n|-\n| 6.5.1\n| R13SP1\n| Simulink 5.1\n| rowspan=2|  2003\n|-\n| 6.5.2\n| R13SP2\n| Simulink 5.2\n|-\n| 7\n| R14\n| Simulink 6.0\n| rowspan=2|  2004\n|-\n| 7.0.1\n| R14SP1\n| Simulink 6.1\n|-\n| 7.0.4\n| R14SP2\n| Simulink 6.2\n| rowspan=2|  2005\n|-\n| 7.1\n| R14SP3\n| Simulink 6.3\n|-\n| 7.2\n| R2006a\n| Simulink 6.4\n| rowspan=2|  2006\n|-\n| 7.3\n| R2006b\n| Simulink 6.5\n|-\n| 7.4\n| R2007a\n| Simulink 6.6\n| rowspan=2|  2007\n|-\n| 7.5\n| R2007b\n| Simulink 7.0\n| Last release for Windows 2000 and PowerPC Mac.\n|-\n| 7.6\n| R2008a\n| Simulink 7.1\n| rowspan=2|  2008\n|-\n| 7.7\n| R2008b\n| Simulink 7.2\n|-\n| 7.8\n| R2009a\n| Simulink 7.3\n| rowspan=2|  2009\n| First release for 32-bit & 64-bit Windows 7.\n|-\n| 7.9\n| R2009b\n| Simulink 7.4\n| First release for Intel 64-bit Mac, and last for Solaris SPARC.\n|-\n| 7.10\n| R2010a\n| Simulink 7.5\n| rowspan=2|  2010\n| Last release for Intel 32-bit Mac.\n|-\n| 7.11\n| R2010b\n| Simulink 7.6\n|-\n| 7.12\n| R2011a\n| Simulink 7.7\n| rowspan=2|  2011\n|-\n| 7.13\n| R2011b\n| Simulink 7.8\n|-\n|-\n| 7.14\n| R2012a\n| Simulink 7.9\n| rowspan=2|  2012\n|-\n| 8\n| R2012b\n| Simulink 8.0\n|-\n|-\n| 8.1\n| R2013a\n| Simulink 8.1\n| rowspan=2|  2013\n|-\n| 8.2\n| R2013b\n| Simulink 8.2\n|-\n|-\n| 8.3\n| R2014a\n| Simulink 8.3\n| rowspan=2|  2014\n|-\n| 8.4\n| R2014b\n| Simulink 8.4\n|-\n|-\n| 8.5\n| R2015a\n| Simulink 8.5\n| rowspan=2|  2015\n|-\n|-\n| 8.6\n| R2015b\n| Simulink 8.6\n|Last release supporting 32-bit Windows\n|-\n| 9.0\n| R2016a\n| Simulink 8.7\n| rowspan=2|  2016\n|-\n| 9.1\n| R2016b\n| Simulink 8.8\n|-\n|-\n| 9.2\n| R2017a\n| Simulink 8.9\n| rowspan=2|  2017\n|-\n| 9.3\n| R2017b\n| Simulink 9.0\n|-\n|-\n| 9.4\n| R2018a\n| Simulink 9.1\n| rowspan=2|  2018\n|-\n| 9.5\n| R2018b\n| Simulink 9.2\n|-\n| 9.6\n| R2019a\n| Simulink 9.3\n| 2019\n|}\n\n==See also==\n* [[Modelica]]\n* [[OpenModelica]]\n* [[JModelica.org]]\n* [[Simcenter Amesim]]\n* [[Dymola]]\n* [[EcosimPro]]\n* [[LabVIEW]]\n* [[ModelCenter]]\n* [[OpenMDAO]]\n* Simplorer\n* [[Web based simulation]]\n* [[Wolfram SystemModeler]]\n* [[Xcos]]\n* [[20-sim]]\n\n== References ==\n{{Reflist}}\n\n==External links==\n* {{official website|https://www.mathworks.com/products/simulink.html}}\n\n{{Authority control}}\n\n[[Category:Cross-platform software]]\n[[Category:Linux software]]\n[[Category:Mathematical modeling]]\n[[Category:Numerical software]]\n[[Category:Simulation programming languages]]\n[[Category:Simulation software]]\n[[Category:Visual programming languages]]"
    },
    {
      "title": "SLATEC",
      "url": "https://en.wikipedia.org/wiki/SLATEC",
      "text": "{{third-party|date=February 2014}}\n'''SLATEC Common Mathematical Library''' is a [[FORTRAN 77]] library of over 1400 general purpose mathematical and statistical routines.  The code was developed at [[US Government]] research laboratories and is therefore [[public domain software]].\n\n\"SLATEC\" is an [[acronym]] for the [[Sandia National Laboratories|Sandia]], [[Los Alamos National Laboratory|Los Alamos]], [[Air Force Research Laboratory|Air Force Weapons Laboratory]] Technical Exchange Committee, an organization formed in 1974  to foster the exchange of technical information between the computer centers of three US government laboratories.\n\n== Project history and current status ==\n\nIn 1977, the SLATEC Common Mathematical Library (CML) Subcommittee decided to construct a library of FORTRAN subprograms to provide portable, non-proprietary, mathematical software that could be used on a variety of computers, including  [[supercomputer]]s, at the three sites. The computers centers of the [[Lawrence Livermore National Laboratory]], the [[National Bureau of Standards]] and the [[Oak Ridge National Laboratory]] also participated from 1980–81 onwards.<ref>{{cite web|last=Fong|first= Kirby W.|title=Guide to the SLATEC Common Mathematical Library|url=http://www.netlib.org/slatec/guide|publisher=netlib.org|accessdate=13 November 2010|author2=Jefferson, Thomas H. |author3=Suyehiro, Tokihiko |author4= Walton, Lee |date=July 1993}}</ref>\n\nThe main repository for SLATEC is [[Netlib]].<ref>http://www.netlib.org/slatec</ref> The current version is 4.1 (July 1993). Since then, a very small number of minor corrections has been made without incrementing the version number.<ref>The file ''src/changes'' in the official distribution lists two such corrections, made in 1994 and 1999.</ref>\n\nThe [[GNU Scientific Library]] (GSL), initiated in 1996 and stable since 2001, was started with the explicit aim to provide a more modern replacement for SLATEC.<ref>GSL design document https://www.gnu.org/software/gsl/design/gsl-design.html#SEC1 as of October 2012.</ref>\n\n== Contents ==\n\nEach subroutine in SLATEC is tagged as belonging to one of 13 subpackages. Some of these subpackages are also well known as free-standing FORTRAN subprogram libraries, including [[BLAS]], [[EISPACK]], [[FFTPACK]], [[LINPACK]] and [[QUADPACK]]. The following table shows all subpackages and the number of subroutines they contain:\n\n{| class=\"wikitable sortable\" style=\"text-align:center; width:80%;\"\n|+\n|-\n!subpackage \n!number of routines \n!separately available in [[Netlib]]\n!purpose\n|-\n|[[BLAS]]\n| 114\n|yes\n|Basic [[linear algebra]]\n|-\n|DASSL\n| 16\n|no\n|solve differential/algebraic equation systems\n|-\n|DEPAC\n| 10\n|no\n|solve [[ordinary differential equation]]s ([[Runge-Kutta method]] and similar)\n|-\n|[[EISPACK]]\n| 71\n|yes\n|[[eigenvalue]]s and [[eigenvector]]s\n|-\n|[[FFTPACK]]\n| 48\n|yes\n|[[fast Fourier transform]]\n|-\n|FISHPACK\n| 19\n|yes\n|use [[cyclic reduction]] to directly solve second- and fourth-order finite difference approximations to separable elliptic Partial Differential Equations in various coordinate systems<ref>http://www.cisl.ucar.edu/css/software/fishpack/, {{cite web |url=http://people.sc.fsu.edu/~jburkardt/f77_src/fishpack/fishpack.html |title=Archived copy |accessdate=2011-10-11 |deadurl=yes |archiveurl=https://web.archive.org/web/20111010184456/http://people.sc.fsu.edu/~jburkardt/f77_src/fishpack/fishpack.html |archivedate=2011-10-10 |df= }}</ref>\n|-\n|FNLIB\n| 161\n|yes, as 'FN'\n|[[special function]]s\n|-\n|[[LINPACK]]\n| 128\n|yes\n|[[linear algebra]], outdated<ref>As http://www.netlib.org/linpack says, LINPACK is largely superseded by LAPACK.</ref>\n|-\n|PCHIP\n| 41\n|no\n|piecewise cubic Hermite interpolation\n|-\n|[[QUADPACK]]\n| 59\n|yes\n|numerical integration of one-dimensional functions\n|-\n|SDRIVE\n| 36\n|no\n|solve [[ordinary differential equation]]s\n|-\n|SLAP\n| 124\n|yes\n|[[sparse matrix|sparse]] [[linear algebra]] package\n|-\n|XERROR\n| 17\n|no\n|error handling\n|}\n\n==References==\n{{Reflist}}\n\n==Further reading==\n* Walter H. Vandevender, Karen H. Haskell, ''The SLATEC mathematical subroutine library'', [[Association for Computing Machinery|ACM]] SIGNUM Newsletter, Volume 17 Issue 3, September 1982 {{doi|10.1145/1057594.1057595}}\n\n==External links==\n* [http://www.netlib.org/slatec/ SLATEC source code] at [[Netlib]]\n* [http://gams.nist.gov/serve.cgi/Package/SLATEC/ SLATEC information] at [[Guide to Available Mathematical Software|GAMS]]\n\n[[Category:Fortran libraries]]\n[[Category:Numerical software]]\n[[Category:Public-domain software with source code]]"
    },
    {
      "title": "SnapPea",
      "url": "https://en.wikipedia.org/wiki/SnapPea",
      "text": "[[Image:SnapPea-horocusp view.png|250px|thumbnail|cusp view of the [[Borromean rings]] complement.  A fundamental parallelogram is drawn.]]\n\n'''SnapPea''' is [[free software]] designed to help [[mathematician]]s, in particular [[low-dimensional topology|low-dimensional topologists]], study [[hyperbolic 3-manifold]]s.  The primary developer is [[Jeffrey Weeks (mathematician)|Jeffrey Weeks]], who created the first version<ref>Weeks, Jeffrey R., SnapPea C source code, (1999)</ref> as part of his doctoral thesis,<ref>Weeks, Jeffrey R., ''Convex hulls and isometries of cusped hyperbolic $3$-manifolds.'' Topology Appl. 52 (1993), no. 2, 127—149.</ref> supervised by [[William Thurston]]. It is not to be confused with the unrelated android malware with the same name.<ref>{{cite web|url=https://www.forbes.com/sites/thomasbrewster/2016/11/30/gooligan-android-malware-1m-google-account-breaches-check-point-finds/|title=Android 'Gooligan' Hackers Just Scored The Biggest Ever Theft Of Google Accounts|first=Thomas|last=Fox-Brewster|date=|website=forbes.com|accessdate=21 May 2017}}</ref><ref>{{cite web|url=http://blog.checkpoint.com/2015/07/10/adware-or-apt-snappea-downloader-an-android-malware-that-implements-12-different-exploits/|title=Adware or APT – SnapPea Downloader - An Android Malware that implements 12 different exploits|author=|date=10 July 2015|website=Check Point Blog|accessdate=21 May 2017}}</ref><ref>{{cite web|url=http://www.howtogeek.com/135836/how-to-manage-your-android-device-from-windows-with-snappea|title=How to Manage Your Android Device from Windows with SnapPea|author=|date=|website=howtogeek.com|accessdate=21 May 2017}}</ref>\n\nThe latest version is 3.0d3.  [[Marc Culler]], [[Nathan Dunfield]] and collaborators have extended the SnapPea kernel and written [[Python (programming language)|Python]] extension modules which allow the kernel to be used in a Python program or in the interpreter.  They also provide a graphical user interface written in Python which runs under most [[operating system]]s (see external links below).\n\nThe following people are credited in SnapPea 2.5.3's list of acknowledgments:  [[Colin Adams (mathematician)|Colin Adams]], [[Bill Arveson]], [[Pat Callahan (mathematician)|Pat Callahan]], [[Joe Christy]], [[David Gabai|Dave Gabai]], [[Charlie Gunn]], [[Martin Hildebrand]], [[Craig Hodgson]], [[Diane Hoffoss]], [[A. C. Manoharan]], [[Al Marden]], [[Dick McGehee]], [[Rob Meyerhoff]], [[Lee Mosher]], [[Walter Neumann]], [[Carlo Petronio]], [[Mark Phillips (mathematician)|Mark Phillips]], [[Alan Reid (mathematician)|Alan Reid]], and [[Makoto Sakuma]].\n\nThe [[C (programming language)|C]] source code is extensively commented by Weeks and contains useful descriptions of the mathematics involved with references.\n\nThe SnapPeaKernel is released under [[GNU GPL]] 2+<ref>[http://www.math.uic.edu/t3m/hg/SnapPeaKernel/ReadMe.txt ReadMe file for the SnapPea kernel], accessed 2013-09-06.</ref> as is SnapPy.<ref>{{cite web|url=http://www.math.uic.edu/t3m/SnapPy/doc/ |title=SnapPy — SnapPy 2.1 documentation |publisher=Math.uic.edu |date= |accessdate=2014-03-12}}</ref>\n\n==Algorithms and functions==\nAt the core of SnapPea are two main algorithms.  The first attempts to find a minimal [[ideal triangulation]] of a given [[link complement]].  The second computes the [[canonical decomposition (hyperbolic manifold)|canonical decomposition]] of a cusped [[hyperbolic 3-manifold]].  Almost all the other functions of SnapPea rely in some way on one of these decompositions.\n\n===Minimal ideal triangulation===\nSnapPea inputs data in a variety of formats.  Given a [[link diagram]], SnapPea can ideally triangulate the [[link complement]].  It then performs a sequence of simplifications to find a minimal ideal triangulation.\n\nOnce a minimal ideal triangulation is found, SnapPea can try to find a hyperbolic structure. In his Princeton lecture notes, [[William Thurston|Thurston]] noted a method for describing the geometric shape of each hyperbolic tetrahedron by a complex number and a set of nonlinear equations of complex variables whose solution would give a complete hyperbolic metric on the 3-manifold. These equations consist of ''edge equations'' and ''cusp (completeness) equations''. SnapPea uses an iterative method utilizing [[Newton's method]] to search for solutions. If no solution exists, then the link complement is retriangulated randomly, repeating the process.\n\nThe minimality of the triangulation is meant to increase the likelihood that such a solution exists, since heuristically one might expect the minimal triangulation to be \"straightened\" without causing degenerations or overlapping of tetrahedra.\n\nFrom this description of the hyperbolic structure on a link complement, SnapPea can then perform [[hyperbolic Dehn surgery|hyperbolic Dehn filling]] on the cusps to obtain more hyperbolic 3-manifolds.  SnapPea does this by taking any given slopes which determine certain ''Dehn filling equations'' (also explained in Thurston's notes), and then adjusting the shapes of the ideal tetrahedra to give solutions to these equations and the edge equations. For almost all slopes, this gives an incomplete hyperbolic structure on the link complement, whose completion gives a hyperbolic structure on the Dehn-filled manifold.  Its volume is the sum of the volumes of the adjusted tetrahedra.\n\n===Canonical decomposition===\nSnapPea is usually able to compute the canonical decomposition of a cusped hyperbolic 3-manifold from a given ideal triangulation.  If not, then it randomly retriangulates and tries again.  This has never been known to fail.\n\nThe canonical decomposition allows SnapPea to tell two cusped hyperbolic 3-manifolds apart by turning the problem of recognition into a combinatorial question, i.e. checking if the two manifolds have combinatorially equivalent canonical decompositions.  SnapPea is also able to check if two ''closed'' hyperbolic 3-manifolds are isometric by drilling out short [[geodesic]]s to create cusped hyperbolic 3-manifolds and then using the canonical decomposition as before.\n\nThe recognition algorithm allow SnapPea to tell two hyperbolic knots or links apart.  Weeks, et al., were also able to compile different censuses of hyperbolic 3-manifolds by using the algorithm to cull lists of duplicates.\n\nAdditionally, from the canonical decomposition, SnapPea is able to:\n*Compute the Ford domain\n*Compute the symmetry group\n\n===Computable invariants===\n\n===Censuses===\nSnapPea has several databases of hyperbolic 3-manifolds available for systematic study.\n*Cusped census\n*Closed census\n\n==See also==\n* [[Regina (program)|Regina]] incorporates aspects of SnapPea. \n* [[Computational topology]]\n\n==References==\n{{Reflist}}\n\n\n==External links==\n* [http://www.geometrygames.org/SnapPea/ SnapPea] Jeff Weeks' site\n* [http://www.math.uic.edu/~t3m/SnapPy/ SnapPy] Culler and Dunfield's extension\n* [https://web.archive.org/web/20170111110654/http://www.ms.unimelb.edu.au/~snap/orb.html Orb] Damian Heard's extension, allows :\n:*hyperbolic manifolds with totally geodesic boundary\n:*orbifolds where the orbifold locus contains trivalent vertices\n\n[[Category:3-manifolds]]\n[[Category:Numerical software]]\n[[Category:Free software programmed in C]]\n[[Category:Free mathematics software]]"
    },
    {
      "title": "SOFA (astronomy)",
      "url": "https://en.wikipedia.org/wiki/SOFA_%28astronomy%29",
      "text": "{{ infobox software\n| name                   = SOFA software libraries\n| latest_release_version = 2018-01-30\n| latest_release_date    = 2018-01-30\n| programming language   = [[C (programming language)|C]] and [[Fortran]]\n| operating system       = [[Cross-platform]]\n| genre                  = [[List of numerical analysis software|Numerical library]]\n| license                = SOFA Software License\n| website                = http://www.iausofa.org/\n}}\n\nThe '''SOFA (Standards of Fundamental Astronomy) software libraries''' are a collection of [[subroutines]] that implement official [[International Astronomical Union]] [[algorithms]] for [[astronomy|astronomical]] computations.\n\nAs of February 2009 they are available in both [[Fortran]] and [[C (programming language)|C]] [[source code]] format.\n\n==Capabilities==\nThe subroutines in the libraries cover the following areas:\n\n* [[Calendars]]\n* [[Time standard|Time scales]]\n* [[Earth's rotation]] and [[sidereal time]]\n* [[Ephemerides]] (limited precision)\n* [[Precession (astronomy)|Precession]], [[nutation]], [[polar motion]]\n* [[Proper motion]]\n* [[Star catalog]] conversions\n* [[Astrometric]] transformations\n* [[Galactic coordinate system|Galactic Coordinates]]\n\n==Licensing==\nAs of the February 2009 release, SOFA [[Software license|licensing]] changed to allow use for any purpose, provided certain requirements are met.<ref>{{citation|title = SOFA Software License for Issue 2009-02-01|url = http://www.iau-sofa.rl.ac.uk/2009_0201_C/sofa/copyr.lis|date = 2008-09-30|accessdate = 2009-09-09|publisher = [[International Astronomical Union]]}}.</ref> Previously, commercial usage was specifically excluded and required written agreement of the SOFA board.<ref>{{citation|title = SOFA Software License for Issue 2008-03-01|url = http://www.iau-sofa.rl.ac.uk/2008_0301/sofa/copyr.lis|date = 2007-05-21|accessdate = 2009-09-09|publisher = [[International Astronomical Union]]}}.</ref>\n\n== See also==\n* [[Naval Observatory Vector Astrometry Subroutines]]\n\n== References ==\n{{reflist}}\n\n==External links==\n*[http://www.iausofa.org/ SOFA Home Page]\n*[http://www.scholarpedia.org/article/Standards_of_Fundamental_Astronomy Scholarpedia overview of SOFA]\n*[http://www.iau.org/ International Astronomical Union] and [http://www.iau.org/science/scientific_bodies/working_groups/191/ Working group \"Standards of Fundamental Astronomy]\n\n[[Category:Celestial mechanics]]\n[[Category:Celestial coordinate system]]\n[[Category:Numerical software]]\n[[Category:Astronomy software]]\n\n{{Astronomy-stub}}\n{{compu-library-stub}}"
    },
    {
      "title": "SOFA Statistics",
      "url": "https://en.wikipedia.org/wiki/SOFA_Statistics",
      "text": "{{Multiple issues|\n{{COI|date=November 2014}}\n{{third-party|date=November 2014}}\n{{advert|date=March 2013}}\n}}\n\n{{Infobox software\n| name = SOFA Statistics\n| screenshot = [[File:Sofa main screen.jpg|350px|Screenshot of SOFA Statistics]]\n| caption = SOFA Statistics\n| developer = Paton-Simpson & Associates Ltd\n| latest release version = 1.5.1\n| latest release date = {{Start date and age|2019|05|19|df=yes}}\n| operating system = [[Cross-platform]]\n| programming language = [[Python (programming language)|Python]]\n| genre = [[Statistics|Statistical analysis]]\n| license = [[Affero General Public License|AGPL]]\n| website = {{URL|http://www.sofastatistics.com}}\n| status = Active\n}}\n\n'''SOFA Statistics''' is an [[open-source software|open-source]] [[statistical package]].  The name stands for ''S''tatistics ''O''pen ''F''or ''A''ll.  It has a [[graphical user interface]] and can connect directly to [[MySQL]], [[PostgreSQL]], [[SQLite]], [[MS Access ]](mdb), and [[Microsoft SQL Server]].  Data can also be imported from [[Comma-separated values|CSV]] and [[Tab-separated values|Tab-Separated]] files or spreadsheets ([[Microsoft Excel]], [[OpenOffice.org Calc]], [[Gnumeric]], [[Google Docs]]). The main statistical tests available are [[T test|Independent and Paired t-tests]], [[Wilcoxon signed-rank test|Wilcoxon signed ranks]], [[Mann–Whitney U]], [[Pearson's chi-squared test|Pearson's chi squared]], [[Kruskal–Wallis one-way analysis of variance|Kruskal Wallis H]], [[analysis of variance|one-way ANOVA]], [[Spearman's rank correlation coefficient|Spearman's R]], and [[Pearson product-moment correlation coefficient|Pearson's R]]. Nested tables can be produced with row and column percentages, totals, [[Standard deviation|sd]], [[Arithmetic mean|mean]], [[median]], [[Quartile|lower and upper quartiles]], and sum.\n\nInstallation packages are available for several [[Operating System]]s such as [[Microsoft Windows]], [[Ubuntu (operating system)|Ubuntu]], [[ArchLinux]], [[Linux Mint]], and [[macOS]] (Leopard upwards).\n\nSOFA Statistics is written in [[Python (programming language)|Python]], and the [[widget toolkit]] used is [[wxPython]].  The statistical analyses are based on functions available through the [[Scipy]] stats module.\n\n==See also==\n{{Portal|Free and open-source software}}\n*[[Comparison of statistical packages]]\n*[[List of statistical packages]]\n\n==References==\n{{Reflist}}\n\n==External links==\n*[http://www.sofastatistics.com/home.php SOFA Statistics Homepage]\n*[https://sourceforge.net/projects/sofastatistics/ SOFA Statistics project page at SourceForge]\n*[https://launchpad.net/sofastatistics/ SOFA Statistics project page at Launchpad]\n*[https://web.archive.org/web/20100211142619/http://showmedo.com/videotutorials/video?name=7520010&fromSeriesID=752 SOFA Statistics page at Showmedo]\n\n{{Statistical software}}\n\n[[Category:Cross-platform free software]]\n[[Category:Cross-platform software]]\n[[Category:Free statistical software]]\n[[Category:Numerical software]]\n[[Category:Science software for Linux]]\n[[Category:Science software for MacOS]]\n[[Category:Science software for Windows]]\n[[Category:Software that uses wxPython]]\n[[Category:Software using the GNU AGPL license]]"
    },
    {
      "title": "Solver",
      "url": "https://en.wikipedia.org/wiki/Solver",
      "text": "{{For|the band|Solver (band)}}\n{{refimprove|date=September 2009}}\nA '''solver''' is a piece of [[mathematical software]], possibly in the form of a stand-alone [[computer program]] or as a [[Library (computing)|software library]], that 'solves' a mathematical problem. A solver takes problem descriptions in some sort of generic form and calculates their solution. In a solver, the emphasis is on creating a program or library that can easily be applied to other problems of similar type.\n\nTypes of problems with existing dedicated solvers include:\n\n* [[Linear equation|Linear]] and [[non-linear equation]]s. In the case of a single equation, the \"solver\" is more appropriately called a [[root-finding algorithm]].\n* [[System of linear equations|Systems of linear equations]].\n* [[Nonlinear system]]s. \n* [[Systems of polynomial equations]], which are a special case of non linear systems, better solved by specific solvers.\n* Linear and non-linear [[Optimization (mathematics)|optimisation]] problems\n* Systems of [[ordinary differential equation]]s\n* Systems of [[differential algebraic equation]]s\n* [[Boolean satisfiability problem]]s, including [[SAT solver]]s\n* [[Quantified boolean formula]] solvers<ref>[https://www.bc.edu/content/dam/bc1/schools/mcas/cs/pdf/honors-thesis/sample5.pdf Using QBF Solvers to Solve Games and Puzzles] - Boston College</ref>\n* [[Constraint satisfaction problem]]s\n* [[Shortest path problem]]s\n* [[Minimum spanning tree]] problems\n* [[Search algorithm]]s\n* ''Game solvers'' for problems in [[game theory]]<ref>Bowling, Michael, and Manuela Veloso. [https://apps.dtic.mil/dtic/tr/fulltext/u2/a385122.pdf An analysis of stochastic game theory for multiagent reinforcement learning]. No. CMU-CS-00-165. Carnegie-Mellon Univ Pittsburgh Pa School of Computer Science, 2000.</ref>\n\nThe [[General Problem Solver]] (''GPS'') is a particular computer program created in 1957 by [[Herbert A. Simon|Herbert Simon]], [[Cliff Shaw|J. C. Shaw]], and [[Allen Newell]] intended to work as a universal problem solver, that theoretically can be used to solve every possible problem that can be formalized in a symbolic system, given the right input configuration. It was the first computer program which separated its knowledge of problems (in the form of [[problem domain|domain]] rules) from its strategy of how to solve problems (as a general search [[Software engine|engine]]).\n\nGeneral solvers typically use an architecture similar to the GPS to decouple a problem's definition from the strategy used to solve it. The advantage in this decoupling is that the solver doesn't depend on the details of any particular problem instance. The strategy utilized by general solvers was based on a general algorithm (generally based on [[backtracking]]) with the only goal of completeness. This induces an exponential [[computational time]] that dramatically limits their usability. Modern solvers use a more specialized approach, which takes advantage of the structure of the problems that the solver aims to spend as little time as possible backtracking. \n\nFor problems of a particular class (e.g., systems of [[non-linear equation]]s) there are usually a wide range of different algorithms available; sometimes a solver implements multiple algorithms, but sometimes just one.\n\n==See also==\n* [[TK Solver]]: A rule based problem solver with back solving capabilities.\n* [[Mathematical software]] for other types of mathematical software.\n* [[Problem solving environment]]: a specialized software combining automated problem-solving methods with human-oriented tools for guiding the problem resolution.\n* [[Satisfiability modulo theories]] for solvers of logical formulas with respect to combinations of background theories expressed in classical first-order logic with equality.\n* [[Semantic reasoner]]\n=== Lists of solvers ===\n* [[List of SMT solvers]]\n* [[List of solvers for ordinary differential equations]]\n\n==References==\n{{Reflist}}\n{{Expand section|date=September 2010}}\n\n{{DEFAULTSORT:Solver (Computer Science)}}\n[[Category:Numerical software]]\n[[Category:Formal methods tools]]\n\n\n{{Science-software-stub}}"
    },
    {
      "title": "Sonic Visualiser",
      "url": "https://en.wikipedia.org/wiki/Sonic_Visualiser",
      "text": "{{Infobox software\n| name                   = Sonic Visualiser\n| screenshot             = \n| caption                = \n| developer              = Centre for Digital Music at [[Queen Mary, University of London]]\n| latest_release_version = 3.2.1\n| latest_release_date    = {{release date and age|2019|01|08|df=yes}}\n| released               = \n| operating_system       = [[Linux]], [[MacOS]], [[Windows]]\n| programming language   = \n| genre                  = \n| license                = [[GPLv2|GPLv2 or later]]\n| website                = {{URL|https://www.sonicvisualiser.org}}\n}}\n\n'''Sonic Visualiser''' is an application for viewing and analysing the contents of music audio files. It is free software distributed under the [[GNU]] [[General Public License]] that people use to visualise, analyse, and annotate sound files. The program is useful in musical as well as scientific work, and is notable for its ability to use highly specialised third-party plugins <ref>http://www.charm.rhul.ac.uk/analysing/p9_0_1.html</ref> in the vamp plugin<ref>https://www.vamp-plugins.org/</ref> format. It was developed at the [[Queen Mary University of London]]'s Centre for Digital Music and is compatible with [[Linux]], [[OS X]], and [[Windows]] operating systems.<ref>http://www.sonicvisualiser.org/</ref>\n\n== See also ==\n\n*[[Comparison of free software for audio]]\n*[[List of information graphics software]]\n*[[Baudline]]\n*[[Praat]]\n\n== References ==\n{{Reflist}}\n\n== External links ==\n*{{Official website|https://www.sonicvisualiser.org}}\n*[https://code.soundsoftware.ac.uk/projects/sonic-visualiser/repository/entry/CHANGELOG Changelog / Release Notes]\n*[https://www.sonicvisualiser.org/community.html Community and Developer Resources]\n*[https://www.sonicvisualiser.org/doc/reference/3.1.1/en/ Documentation for version 3.1.1]\n*[https://www.sonicvisualiser.org/screenshots.html Screenshots]\n*[https://www.sonicvisualiser.org/videos.html Videos]\n\n{{Media player (application software)}}\n\n[[Category:Acoustics software]]\n[[Category:Audio software]]\n[[Category:Audio software for Linux]]\n[[Category:Linux media players]]\n[[Category:Numerical software]]\n[[Category:Science software for Linux]]\n[[Category:Science software for MacOS]]\n[[Category:Science software for Windows]]\n[[Category:Time–frequency analysis]]\n[[Category:Unix software]]\n\n\n{{free-software-stub}}"
    },
    {
      "title": "TK Solver",
      "url": "https://en.wikipedia.org/wiki/TK_Solver",
      "text": "{{More footnotes|date=May 2012}}\n{{Infobox Software\n| name                   = TK Solver\n| logo                   = \n| screenshot             = \n| caption                = \n| author                 = \n| developer              = Software Arts; Universal Technical Systems\n| released               = \n| latest release version = 5.0\n| latest release date    = \n| latest preview version = \n| latest preview date    = \n| operating system       = Windows\n| platform               = \n| language               =\n| genre                  = Mathematics/engineering\n| license                = \n| website                = {{URL|https://www.uts.com/}}\n}}\n\n'''TK Solver''' (originally '''TK!Solver''') is a mathematical modeling and problem solving software system based on a declarative, rule-based language, commercialized by Universal Technical Systems, Inc.\n\n== History ==\n\nInvented by [[Milos Konopasek]] in the late 1970s and initially developed in 1982 by [[Software Arts]], the company behind [[VisiCalc]], TK Solver was acquired by Universal Technical Systems in 1984 after Software Arts fell into financial difficulty and was sold to [[Lotus Software]]. Konopasek's goal in inventing the TK Solver concept was to create a problem solving environment in which a given mathematical model built to solve a specific problem could be used to solve related problems (with a redistribution of input and output variables) with minimal or no additional programming required: once a user enters an equation, TK Solver can evaluate that equation as is&mdash;without isolating unknown variables on one side of the equals sign.\n\n== Core technology ==\n\nTK Solver's core technologies are a [[declarative programming]] language, algebraic equation solver, an iterative equation solver, and a structured, object-based interface.  The interface comprises nine classes of objects that can be shared between and merged into other TK files:\n\n* Rules: equations, formulas, function calls which may include logical conditions\n* Variables: a listing of the variables that are used in the rules, along with values (numeric or non-numeric) that have been entered by the user or calculated by the software\n* Units: all units conversion factors, in a single location, to allow automatic update of values when units are changed\n* Lists: ranges of numeric and non-numeric values which can be associated with a variable or processed directly by procedure functions\n* Tables: collections of lists displayed together\n* Plots: line charts, scatterplots, bar charts, and [[pie chart]]s\n* Functions: rule-based, table look-up, and procedural programming components\n* Formats: settings for displaying numeric and string values\n* Comments: for explanation and documentation\n\nEach class of object is listed and stored on its own worksheet—the Rule Sheet, Variable Sheet, Unit Sheet, etc.  Within each worksheet, each object has properties summarized on subsheets or viewed in a property window. The interface uses toolbars and a hierarchal navigation bar that resembles the directory tree seen on the left side of the [[Windows Explorer]].\n\nThe declarative programming structure is embodied in the rules, functions and variables that form the core of a mathematical model.\n\n== Rules, variables and units ==\n\nAll rules are entered in the Rule Sheet or in user-defined functions. Unlike a spreadsheet or [[imperative programming]] environment, the rules can be in any order or sequence and are not expressed as assignment statements. \"A + B = C / D\" is a valid rule in TK Solver and can be solved for any of its four variables. Rules can be added and removed as needed in the Rule Sheet without regard for their order and incorporated into other models.  A TK Solver model can include up to 32,000 rules, and the library that ships with the current version includes utilities for higher mathematics, statistics, engineering and science, finances, and programming.\n\nVariables in a rule are automatically posted to the Variable Sheet when the rule is entered and the rule is displayed in mathematical format in the MathLook View window at the bottom of the screen. Any variable can operate as an input or an output, and the model will be solved for the output variables depending on the choice of inputs.\n\nA database of unit conversion factors also ships with TK Solver, and users can add, delete, or import unit conversions in a way similar to that for rules.  Each variable is associated with a \"calculation\" unit, but variables can also be assigned \"display\" units and TK automatically converts the values.  For example, rules may be based upon meters and kilograms, but units of inches and pounds can be used for input and output.\n\n== Problem-solving ==\n\nTK Solver has three ways of solving systems of equations.  The \"direct solver\" solves a system algebraically by the principle of consecutive substitution.  When multiple rules contain multiple unknowns, the program can trigger an iterative solver which uses the [[Newton-Raphson]] algorithm to successively approximate based on initial guesses for one or more of the output variables.  Procedure functions can also be used to solve systems of equations.  Libraries of such procedures are included with the program and can be merged into files as needed.  A list solver feature allows variables to be associated with ranges of data or probability distributions, solving for multiple values, which is useful for generating tables and plots and for running [[Monte Carlo simulations]].  The premium version now also includes a \"Solution Optimizer\" for direct setting of bounds and constraints in solving models for minimum, maximum, or specific conditions.\n\nTK Solver includes roughly 150 built-in [[subroutine|functions]]: mathematical, [[trigonometry|trigonometric]], [[Boolean logic|Boolean]], [[calculus|numerical calculus]], matrix operations, [[database]] access, and programming functions, including string handling and calls to externally compiled routines.  Users may also define three types of functions: declarative rule functions; list functions, for table lookups and other operations involving pairs of lists; and procedure functions, for loops and other procedural operations which may also process or result in arrays (lists of lists).  The complete [[National Institute of Standards and Technology|NIST]] database of thermodynamic and transport properties is included, with built-in functions for accessing it. TK Solver is also the platform for engineering applications marketed by UTS, including Advanced Spring Design, Integrated Gear Software, Interactive Roark’s Formulas, Heat Transfer on TK, and Dynamics and Vibration Analysis.\n\n== Data display and sharing ==\n\nTables, plots, comments, and the MathLook notation display tool can be used to enrich TK Solver models.  Models can be linked to other components with Microsoft [[Visual Basic]] and [[.NET Framework|.NET]] tools, or they can be web-enabled using the RuleMaster product or linked with [[Microsoft Excel|Excel]] spreadsheets using the Excel Toolkit product.  There is also a DesignLink option linking TK Solver models with CAD drawings and solid models.  In the premium version, standalone models can be shared with others who do not have a TK license, opening them in Excel or the free TK Player.\n\n==Reception==\n''[[BYTE]]'' in 1984 stated that \"TK!Solver is superb for solving almost any kind of equation\", but that it did not handle [[matrix (mathematics)|matrices]], and that a programming language like [[Fortran]] or [[APL (programming language)|APL]] was superior for [[system of linear equations|simultaneous solution of linear equations]]. The magazine concluded that despite limitations, it was a \"powerful tool, useful for scientists and engineers. No similar product exists\".<ref name=\"miller198412\">{{Cite magazine |last=Miller |first=Alan R. |date=December 1984 |title=TK!Solver |url=https://archive.org/stream/byte-magazine-1984-12/1984_12_BYTE_09-13_Communications#page/n261/mode/2up |magazine=BYTE |pages=263–272}}</ref>\n\n'''Note:''' TK Solver 5.0 has Matrix handing functionality.<ref>{{Cite web|url=https://uts.com/itemdetails.asp?itemid=0100-50-0010-00|title=TK Solver 5.0 Premium (Standalone) from Universal Technical Systems|website=uts.com|access-date=2017-04-20}}</ref>\n\n== See also ==\n* [[Optimization (mathematics)]]\n* [[Multidisciplinary design optimization]]\n\n==References==\n{{Reflist}}\n\n\n\n[[Category:1982 software]]\n[[Category:Numerical software]]"
    },
    {
      "title": "Tpoint",
      "url": "https://en.wikipedia.org/wiki/Tpoint",
      "text": "{{ref-improve|date=December 2009}}\n\n'''TPoint''' is [[computer]] [[software]] that implements a mathematical [[Model (abstract)|model]] of conditions leading to [[error]]s in [[telescope]] pointing and tracking. The model can then be used in a telescope control system to correct the pointing and tracking. Such errors are typically caused by [[machine|mechanical]] or [[structural]] [[wikt:defect|defects]]. For example, TPoint can analyze and compensate for systematic errors such as [[polar alignment|polar misalignment]], mechanical and optical non-orthogonality, lack of roundness in telescope mounting drive [[gear]]s, as well as for [[flexure]] of the mounting caused by [[gravity]].\n\nTPoint is in use on the majority of professional telescopes worldwide, including the [[Anglo-Australian Observatory]], [[Keck Observatory]], [[Gemini Observatory]], and many others. It has significantly improved the performance and efficiency of telescope operation and has had an especially strong impact on the development of [[Automation|automated]] and [[robotic telescope]]s. \n\nTPoint is also widely used by [[amateur astronomy|amateur astronomers]]. [[Software Bisque]] distributes TPoint for Mac OS and Windows as an add-on to TheSkyX Serious Astronomer Edition and TheSkyX Professional; this version is used to improve the pointing on amateur telescopes.<ref name=ST-July2012>{{cite journal|last=di Cicco|first=Dennis|title=The Paramount MX|journal=Sky & Telescope|date=July 2012|volume=124|issue=1|pages=64–67|issn=0037-6604}}</ref>\n==History==\nTPoint was invented and developed by Patrick Wallace.<ref name=ST-July2012/> It grew out of work he and John Straede performed\nat the [[Anglo-Australian Telescope]] (AAT) between 1974 and 1980\nusing [[Interdata]] 70 computers. In the early 1980s, it was ported to the [[Digital Equipment Corporation]] [[VAX]] running under\nthe VMS operating system and between 1990 and 1992 was also ported to run on the [[Personal Computer|PC]]/[[MS-DOS]] platform as well\nas various [[UNIX]] platforms. A TPoint add-on is available for TheSkyX Serious Astronomer Edition and TheSkyX Professional Edition from Software Bisque, and it runs under both Macintosh OS and Microsoft Windows. <ref> {{cite news | first = Patrick | last = Wallace | title = TPOINT - Telescope Pointing Analysis System (v4.4) | date = 9 Dec 1994 | publisher = DRAL/ Rutherford Appleton Laboratory | url = http://docs.jach.hawaii.edu/EXTERNAL/SUN/100/sun100.pdf | work = Starlink Project | pages = 27 28 | accessdate = 2013-01-02 | deadurl = yes | archiveurl = https://web.archive.org/web/20100611143703/http://docs.jach.hawaii.edu/EXTERNAL/SUN/100/sun100.pdf | archivedate = 11 June 2010 | df =  }}</ref>\n\n==External links==\n* [http://www.tpointsw.uk/ TPoint official webpage]\n* [http://www.bisque.com/sc/shops/store/tpoint-add-on-win.aspx Software Bisque TPoint Page]\n\n==References==\n{{reflist}}\n\n[[Category:Telescopes]]\n[[Category:Numerical software]]"
    },
    {
      "title": "Vensim",
      "url": "https://en.wikipedia.org/wiki/Vensim",
      "text": "{{technical|date=August 2016}}\n{{Infobox software\n| name                   = Vensim\n| logo                   = \n| caption                = \n| collapsible            = \n| author                 = \n| developer              = Ventana Systems, Inc.\n| released               = {{start date and age|df=yes|paren=yes|1990}}\n| latest release version = Version 6.4\n| latest release date    = {{start date and age|df=yes|paren=yes|2016|06}}\n| latest preview version = \n| latest preview date    = \n| frequently updated     = \n| programming language   = C\n| operating system       = Windows and OS{{nbsp}}X applications, Linux and iOS libraries\n| platform               = \n| size                   = \n| language               = \n| status                 = \n| genre                  = [[Simulation software]]\n| license                = [[Proprietary software|Proprietary]]\n| website                = {{url|http://vensim.com}}\n}}\n\n'''Vensim''' is [[simulation software]] developed by Ventana Systems. It primarily supports [[continuous simulation]] ([[System Dynamics|system dynamics]]), with some [[Discrete event simulation|discrete event]] and [[agent-based model]]ling capabilities. It is available commercially and as a free \"Personal Learning Edition\".\n\n== Modeling environment ==\n\nVensim provides a graphical modeling interface with [[stock and flow]] and [[causal loop diagram]]s, on top of a text-based system of equations in a [[declarative programming]] language. It includes a patented method for interactive tracing of behavior through causal links in model structure,<ref>{{cite web|url=http://vensim.com/causal-tracing/|title=Vensim Causal Tracing™|website=Vensim - Ventana Systems}}</ref><ref>{{cite web|url=https://www.google.com/patents/EP0527907A1?cl=en&dq=causal+tracing&hl=en&sa=X&ved=0ahUKEwiVhI3i2ZbOAhWLKCYKHbilAGkQ6AEIHjAA|title=Simulation system employing causal tracing. US Patent Application EP19910909851, Feb. 26 1991}}</ref><ref>{{cite web|url=http://patents.justia.com/patent/5428740|title=Applying successive data group operations to an active data group. Patent # 5,428,740|website=Justitia.com}}</ref> as well as a language extension for automating quality control experiments on models called Reality Check.<ref>{{cite journal|title=Reality check: A bridge between systems thinking and system dynamics|first1=David W.|last1=Peterson|first2=Robert L.|last2=Eberlein|journal=System Dynamics Review|volume=10|issue=2–3|pages=159–174|year=1994|doi=10.1002/sdr.4260100205}}</ref>\n\nThe modeling language supports arrays (subscripts) and permits mapping among dimensions and aggregation. Built-in allocation functions satisfy constraints that are sometimes not met by conventional approaches like [[logit]].<ref>''[http://vensim.com/allocation-by-priority-alloc-p/ Vensim Allocation by Priority]</ref> It supports discrete delays, queues and a variety of stochastic processes.\n\nThere are multiple paths for cross sectional and time-series data import and export, including text files, spreadsheets and ODBC. Models may be calibrated against data using optimization, [[Kalman Filter]]ing<ref>{{cite thesis|url=http://hdl.handle.net/1721.1/27424|title=Hypothesis, estimation, and validation of dynamic social models : energy demand modeling|last1=Peterson|first1=David Walter|year=1975|type=Ph.D.|publisher=Massachusetts Institute of Technology. Dept. of Electrical Engineering and Computer Science}}</ref> or [[Markov chain Monte Carlo]] methods. Sensitivity analysis options provide a variety of ways to test and sample models, including Monte Carlo simulation with Latin Hypercube sampling.\n\nVensim model files can be packaged and published in a customizable read-only format that can be executed by a freely available Model Reader. This allows sharing of interactive models with users who do not own the program and/or who the model author does not wish to have access to the model's code base.<ref>{{cite web|url=http://vensim.com/vensim-model-reader/|title=Vensim Model Reader|website=Vensim - Ventana Systems}}</ref>\n\n== Applications ==\n\nVensim is general-purpose software, used in a wide variety of problem domains. Common or high-profile applications include:\n* Transportation and Energy<ref>{{cite conference|title=Evaluating NGATS Research Priorities at JPDO|first1=Daniel|last1=Goldner|first2=Sherry|last2=Borener|conference=6th AIAA Aviation Technology, Integration and Operations Conference (ATIO)|year=2006|location=Wichita, Kansas, US|doi = 10.2514/6.2006-7726}}</ref><ref>{{cite journal|url=http://epb.sagepub.com/content/35/6/1070.short|title=Transition Challenges for Alternative Fuel Vehicle and Transportation Systems|first1=Jeroen|last1=Struben|first2=John D.|last2=Sterman|journal=Environment and Planning B: Planning and Design|year=2008|volume=35|issue=6|pages=1070–1097|doi=10.1068/b33022t|hdl=1721.1/102784}}</ref>\n* Business Strategy<ref>{{cite journal|title=Getting Big Too Fast: Strategic Dynamics with Increasing Returns and Bounded Rationality|first1=John|last1=Sterman|first2=Rebecca|last2=Henderson|first3=Eric|last3=Beinhocker|first4=Lee|last4=Newman|journal=Management Science|year=2007|volume=53|issue=4|pages=683–696|doi=10.1287/mnsc.1060.0673}}</ref>\n* Health<ref>{{cite journal|title=Selecting a Dynamic Simulation Modeling Method for Health Care Delivery Research—Part 2: Report of the ISPOR Dynamic Simulation Modeling Emerging Good Practices Task Force|author=Deborah A. Marshall|display-authors=etal|journal=Value in Health|year=2015|volume=18|issue=2|pages=147–160|doi=10.1016/j.jval.2015.01.006|pmid = 25773550}}</ref>\n* Security and Terrorism<ref>{{cite journal|title=Radicalization under deep uncertainty: a multi-model exploration of activism, extremism, and terrorism|last1=Pruyt|first1=E.|last2=Kwakkel|first2=J. H.|year=2014|journal=System Dynamics Review|volume=30|issue=1–2|pages=1–28|doi=10.1002/sdr.1510}}</ref>\n* Project Management<ref>{{cite journal|title=Modeling the rework cycle: capturing multiple defects per task|last1=Rahmandad|first1=H.|last2=Hu|first2=K.|journal=System Dynamics Review|volume=26|issue = 4|pages=291–315|year=2010|doi=10.1002/sdr.435}}</ref>\n* [[Marketing Science]] in Pharmaceuticals and Consumer Products<ref>{{cite web|url=http://www.ventanasystems.com/model_typeslist/marketing/|title=Ventana Systems, Inc. Marketing Models|website=Ventana Systems}}</ref>\n* [[Logistics]]<ref>{{cite journal|url=https://www.researchgate.net/publication/227616857|title=Upstream Volatility in the Supply Chain: The Machine Tool Industry as a Case Study|first1=Edward G., Jr.|last1=Anderson|first2=Charles H.|last2=Fine|first3=Geoffrey G.|last3=Parker|journal=Production and Operations Management|volume=9|issue=3|pages=239–261|year=2000|doi=10.1111/j.1937-5956.2000.tb00136.x|citeseerx=10.1.1.38.7001}}</ref>\n* Environment<ref>{{cite web|url=https://www.climateinteractive.org/tools/c-roads/|title=The C-ROADS model|website=Climate Interactive|date=2014-01-02}}</ref><ref>{{cite journal|doi=10.1016/j.envsoft.2012.06.004|title=Management flight simulators to support climate negotiations|first1=John D.|last1=Sterman|first2=Thomas|last2=Fiddaman|first3=Travis|last3=Franck|first4=Andrew|last4=Jones|first5=Stephanie|last5=McCauley|first6=Philip|last6=Rice|first7=Elizabeth|last7=Sawin|first8=Lori|last8=Siegel|journal=Environmental Modelling & Software|volume=44|year=2013|pages=122–135}}</ref><ref>{{cite journal|title=System dynamics modelling of the Endangered African penguin populations on Dyer and Robben islands, South Africa|first1=Florian|last1=Weller|first2=Richard B.|last2=Sherley|first3=Lauren J.|last3=Waller|first4=Katrin|last4=Ludynia|first5=Deon|last5=Geldenhuys|first6=Lynne J.|last6=Shannon|first7=Astrid|last7=Jarre|journal=Ecological Modelling|volume=327|year=2016|pages=44–56|doi=10.1016/j.ecolmodel.2016.01.011}}</ref>\n\n==See also==\n\n* [[Comparison of system dynamics software]]\n* [[Computer Simulation|Computer simulation]]\n* [[List of computer simulation software]]\n* [[Monte Carlo Simulation|Monte Carlo simulation]]\n\n== External links ==\n* [http://vensim.com Official Vensim web site]\n* [http://ventanasystems.com Official Ventana Systems, Inc. web site]\n* [http://simulation.tbm.tudelft.nl/ema-workbench/contents.html Exploratory Modelling and Analysis (EMA) Workbench]\n* [http://tools.systemdynamics.org/sdm-doc/ SDM-doc documentation tool]<ref>{{cite journal|last=Martinez-Moyano|first=I. J.|year=2012|title=Documentation for model transparency|journal=System Dynamics Review|volume=28|issue = 2|pages=199–208|doi=10.1002/sdr.1471}}</ref>\n* [http://forio.com Forio.com - host for online Vensim models]\n\n== References ==\n\n{{Reflist|30em}}\n\n<!--- categories --->\n[[Category:Environmental science software]]\n[[Category:Mathematical software]]\n[[Category:Numerical software]]\n[[Category:Probabilistic software]]\n[[Category:Risk management software]]\n[[Category:Science software for Windows]]\n[[Category:Scientific simulation software]]\n[[Category:Simulation programming languages]]\n[[Category:Simulation software]]"
    },
    {
      "title": "VisSim",
      "url": "https://en.wikipedia.org/wiki/VisSim",
      "text": "{{About|the visual block diagram language||Vissim (disambiguation){{!}}Vissim}}\n{{Advert|date=May 2013}}\n\n{{Infobox programming language\n| name                   = VisSim/solidThinking Embed\n| logo                   = [[File:VisSimIcon.png|75px]]\n| paradigm               = [[Modular]], [[Visual programming language|Visual Programming]], [[Simulation language]]\n| developer              = [[Visual Solutions/solidThinking]]\n| latest release version = Embed 2016\n| latest release date    = January 2016\n| license                = [[Proprietary software]]\n| website                = http://www.vissim.com, http://www.solidthinking.com/embed_land.html\n| caption                = ''VisSim Viewer icon''\n| year                   = 1989\n| influenced_by          = [[C (programming language)|C]], [[MASSCOMP|Laboratory Workbench]], [[Stardent Computer|AVS (Advanced Visualization System)]]\n| operating_system       = [[Windows]]\n| file_ext = .VSM\n}}\n'''VisSim''' is a visual [[block diagram]] program for simulation of [[dynamical system]]s and [[model based design]] of [[embedded systems]], with its own [[vsual programming language|visual language]]. It is developed by Visual Solutions of [[Westford, Massachusetts]]. Visual Solutions, has been acquired by [[Altair Engineering|Altair]] in August 2015 and its products have been rebranded as solidThinking Embed as a part of [[solidThinking]]'s Model Based Development Suite. With solidThinking Embed, you can develop virtual prototypes of dynamic systems. Models are built by sliding blocks into the work area and wiring them together with the mouse. Embed automatically converts the control diagrams into C-code ready to be downloaded to the target hardware.\n\nVisSim or now solidThinking Embed uses a graphical data flow paradigm to implement dynamic systems based on differential equations. Version 8 adds interactive [[UML state machine|UML]] [[Object Management Group|OMG]] 2 compliant [[State diagram|state chart graphs]] that are placed in VisSim diagrams. This allows the modeling of state based systems such as startup sequencing of process plants or serial protocol decoding.\n\n==Applications==\nVisSim/solidThinking Embed is used in [[control system]] design and [[digital signal processing]] for multidomain simulation and design.<ref name=References>[https://books.google.com/books?q=VisSim+Visual+Solutions Books on wide variety of technical subjects referencing VisSim] on the [[Google Books Library Project]]</ref> It includes blocks for arithmetic, Boolean, and [[transcendental function]]s, as well as [[digital filter]]s, [[transfer function]]s, [[numerical integration]] and interactive plotting.<ref name=userguide>''Visual simulation with student VisSim'', by Karen Darnell, 1996, PWS Pub. Co., Boston, {{ISBN|0-534-95485-5}}</ref> The most commonly modeled systems are aeronautical, biological/medical, digital power, electric motor, electrical, hydraulic, mechanical, process, thermal/HVAC and econometric.<ref name=References />\n\n===Distributing VisSim models===\n[[File:VisSim screenshot.PNG|left|thumb|VisSim viewer screenshot with sample model.]]\nA read-only version of the software, [http://www.vissim.com/downloads/demos.html VisSim Viewer], is available free of charge and provides a way for people not licensed to use VisSim to run VisSim models.<ref name=Viewer>[http://vissim.com/products/vissim_viewer.html Viewer page] on company website</ref> This program is intended to allow models to be more widely shared while preserving the model in its published form.<ref name=Viewer /> The viewer will execute any VisSim model, and only allows changes to block and simulation parameters to illustrate different design scenarios. Sliders and buttons may be activated if included in the model.\n\n==Code generation==\nThe \"VisSim/C-Code\" add-on generates [[ANSI C]] code for the model, and generates target specific code for on-chip devices like PWM, ADC, encoder, GPIO, I2C etc. This is useful for development of [[embedded systems]]. After the behavior of the controller has been simulated, C-code can be generated, compiled and run on the target. For debugging, VisSim supports an interactive JTAG linkage, called \"Hotlink\", that allows interactive gain change and plotting of on-target variables. The VisSim generated code has been called efficient and readable, making it well suited for development of embedded systems.<ref>{{Cite web |url=http://www.akademik.unsri.ac.id/download/journal/files/waset/v47-35.pdf |title=Graphical Environment for Modeling Control Systems in Full Scope Training Simulators |access-date=2010-09-09 |archive-url=https://web.archive.org/web/20110721120159/http://www.akademik.unsri.ac.id/download/journal/files/waset/v47-35.pdf |archive-date=2011-07-21 |dead-url=yes |df= }}</ref> VisSim's author served on the X3J11 ANSI C committee and wrote several C compilers, in addition to co-authoring a book on C.<ref>[https://scholar.google.com/scholar?q=Peter+A.+Darnell&hl=en&btnG=Zoeken&lr= Books on C by Peter A. Darnell and Philip E. Margolis]</ref> This deep understanding of ANSI C, and the nature of the resulting [[machine code]] when compiled, is the key to the code generator's efficiency. VisSim can target small [[16-bit]] [[fixed-point arithmetic|fixed point]] systems like the [[Texas Instruments]] [[MSP430]], using only 740 bytes flash and 64 bytes of RAM for a small closed-loop [[Pulse-width modulation]] (PWM) actuated system, as well as allowing very high control sample rates over 500&nbsp;kHz on larger [[32-bit]] [[floating point processor]]s like the [[Texas Instruments]] 150&nbsp;MHz F28335.\n\n==Use of model-based development==\n{{Main article|Model based design}}\nThe technique of simulating system performance off-line, and then generating code from the simulation is known as \"model-based development\". Model-based development for [[embedded system]]s is becoming widely adopted for production systems because it shortens development cycles for hardware development in the same way that [[Model-driven architecture]] shortens production cycles for software development.<ref>[https://books.google.com/books?id=LGzS1uiUa7AC Principles of model-driven architecture], Stephen J. Mellor, Addison-Wesley, 2004</ref>\n\n[[Model building]] is a visual way of describing a situation. In an engineering context, instead of writing and solving a [[system of equations]], model building involves using visual \"blocks\" to solve the problem. The advantage of using models is that in some cases problems which appear difficult if expressed mathematically may be easier to understand when represented pictorially.\n\nVisSim uses a hierarchical composition to create nested block diagrams. A typical model would consist of \"virtual plants\" composed of various VisSim \"layers\", combined if necessary with custom blocks written in C or FORTRAN. A virtual controller can be added and tuned to give desired overall system response. [[Graphical control element (software)|Graphical control element]] such as sliders and buttons allow control of [[what-if analysis]] for operator training or controller tuning.\n\nAlthough VisSim was originally designed for use by [[control engineer]]s, it can be used for any type of mathematical model.\n\n== Optional features ==\n{| style=\"width:320px; float:right; border:1px solid #ccc; background:#f9f9f9; font-size:88%; line-height:1.5em;\"\n| [[File:VisSim-320x240.ogv]]\n|-\n|\nScreenshots show the simulation of a [[sine]] function in VisSim. Noise is added to the model, then filtered out using a [[Butterworth filter]]. The signal traces of the sine function with noise and filtered noise are first shown together, and then shown in separate windows in the plot block.\n|-\n| This video size: 50% (320x240 pixels)\n|-\n| Other size: [[:File:VisSim-640x480.ogv|100% (640x480 pixels)]]\n|}\n\n* CAN bus ([[Controller-area network]]) packet read and write\n* Communication system [[Physical layer]] simulation ([[modulator]]s, [[encoders]], [[PLL]]s, [[Costas Loop]], [[BPSK]], [[QPSK]], [[DQPSK]], [[QAM]], [[Bit error rate|Bit Error Rate]] (BER), [[Eye Diagram]], [[Viterbi algorithm]], [[Reed-Solomon]], etc.)\n* [[C programming language|C]] [[Automatic programming|code generation]] - Generates executable C code directly from the block diagram\n* [[Electric motor]] simulation library for AC induction, [[Brushless DC]], and [[Stepper motor]]s\n* Embedded system targeting for Texas Instruments [[C2000]] and [[MSP430]], [[ARM Cortex-M]] chips. Supports on-chip peripherals like serial ports, [[Controller area network|CAN]], [[Pulse-width modulation|PWM]], [[Quadrature encoder|Quadrature Encoder Pulse (QEP)]], Event Capture, [[Serial Peripheral Interface Bus]] (SPI), [[I²C]], [[Analog-to-digital converter]] (ADC), [[Digital-to-analog converter]] (DAC), and [[GPIO]].\n* [[Fixed-point arithmetic]] blockset for bit-true simulation and code generation\n* Frequency domain analysis ([[Bode plot]], [[Root locus]], [[Nyquist plot]])\n* [[Global optimization]] of system parameters\n* [[Neural network]]s\n* OPC ([[OLE for process control]]) client gives read and write of OPC tags for real-time simulation of [[SCADA]]/HMI virtual plants\n* Real-time [[analog signal]] and digital I/O under Windows\n* Serial([[RS-232]]/[[RS-485]]) serial data read and write. Allows real-time reading and writing of serial data from the VisSim diagram. It supports pattern matching, string based transmit, and simulated data streams.\n* UDP ([[User Datagram Protocol]]) packet read and write. Allows real-time reading and writing of ethernet based UDP packets from the VisSim diagram\n\n==See also==\n* [[Web based simulation]]\n* [[MATLAB]]/[[Simulink]]\n* [[20-sim]]\n\n==References==\n{{Reflist}}\n* [http://www.ieeecss.org/columns/October2007/Oct2007VisSimProductSpotlight.pdf Texas Instruments MSP430 spotlight article]{{Dead link|date=July 2018 |bot=InternetArchiveBot |fix-attempted=yes }} published in [[IEEE]] magazine.\n* [http://www.vissim.com VisSim web site]\n* [https://books.google.com/books/about/Mechatronics_System_Design.html?id=_D58QgAACAAJ Mechatronics System Design], by Devdas Shetty, Richard A. Kolk, Edition 2, Cengage Learning, 2011, {{ISBN|143906198X}}, {{ISBN|9781439061985}}\n* [https://books.google.com/books?isbn=9780387946757 C: A Software Engineering Approach], by Peter A Darnell, Philip E Margolis, 3rd edition, 1996, {{ISBN|978-0-387-94675-7}}\n\n== External links ==\n* [https://www.springer.com/engineering/signals/book/978-3-642-01358-4 A Simulation-Aided Introduction with VisSim/Comm] Digital Transmission Series: Signals and Communication Technology, Guimaraes, Dayan Adionel, 2010, {{ISBN|978-3-642-01358-4}}\n* [https://books.google.com/books?id=oJk-g-JDREwC&pg=PA972 Hybrid Intelligent Aircraft Landing Controller and Its Hardware Implementation], by Jih-gau Juang and Bo-Shian Lin in Advances in Natural Computation: Second International Conference, ICNC 2006, {{ISBN|978-3-540-45907-1}}\n\n{{Numerical analysis software}}\n{{Fractal software}}\n\n{{DEFAULTSORT:Vissim}}\n[[Category:Mathematical modeling]]\n[[Category:Numerical software]]\n[[Category:Real-time simulation]]\n[[Category:Simulation programming languages]]\n[[Category:Specific models]]\n[[Category:Visual programming languages]]\n[[Category:Articles containing video clips]]"
    },
    {
      "title": "Comparison of linear algebra libraries",
      "url": "https://en.wikipedia.org/wiki/Comparison_of_linear_algebra_libraries",
      "text": "{{unreferenced|date=June 2010}}\nThe following tables provide a comparison of '''[[linear algebra]] [[Library (computing)|software libraries]]''', either specialized or general purpose libraries with significant linear algebra coverage.\n\n== Dense linear algebra ==\n\n=== General information ===\n{| class=\"wikitable sortable\" style=\"font-size: smaller; text-align: center; width: auto;\"\n|-\n! style=\"width: 12em\"|\n! Creator\n! Language\n! First public release\n! Latest stable version\n! Source code availability\n! License\n! Notes\n|-\n! [[ALGLIB]]\n| ALGLIB Project\n| C++, C#, FreePascal, VBA\n| 2006\n| 3.12.0 / 08.2017\n| {{free}}\n| GPL/commercial\n| General purpose numerical analysis library with C++ and C# interfaces.\n|-\n! [[Automatically Tuned Linear Algebra Software|ATLAS]]\n| R. Clint Whaley et al.\n| C\n| 2001\n| 3.10.3 / 07.2016\n| {{free}}\n| BSD\n| Automatically tuned implementation of BLAS. Also includes LU and Cholesky decompositions.\n|-\n![[Dlib]]\n|Davis E. King\n|C++\n|2006\n|19.7 / 09/2017\n|{{Free}}\n|Boost\n|C++ template library; binds to optimized BLAS such as the Intel MKL; Includes matrix decompositions, non-linear solvers, and machine learning tooling\n|-\n! [[GNU Scientific Library]]\n| GNU Project\n| C, C++\n| 1996\n| 2.5 / 06.2018\n| {{free}}\n| [[GNU General Public License|GPL]]\n| General purpose numerical analysis library. Includes some support for linear algebra.\n|-\n! [[IMSL Numerical Libraries]]\n| Rogue Wave Software\n| C, Java, C#, Fortran, Python\n| 1970\n| many components\n| {{nonfree}}\n| Proprietary\n| General purpose numerical analysis library.\n|-\n! [[LAPACK]]\n| \n| Fortran\n| 1992\n| 3.7.0 / 12.2016\n| {{free}}\n| [[BSD licenses|3-clause BSD]]\n| Numerical linear algebra library with long history\n|-\n! [[Math Kernel Library|MKL]]\n| Intel\n| C++, Fortran\n| 2003\n| 2017 update 2 / 09.2016\n| {{nonfree}}\n| Intel Simplified Software License\n| Numerical analysis library optimized for Intel CPUs\n|-\n! [[Math.NET_Numerics]]\n| C. Rüegg, M. Cuda, et al.\n| C#\n| 2009\n| 3.20 / 07.2017\n| {{free}}\n| [[MIT_License]]\n| C# numerical analysis library with linear algebra support\n|-\n! [[NAG Numerical Library]]\n| [[Numerical Algorithms Group|The Numerical Algorithms Group]]\n| C, Fortran\n| 1971\n| many components\n| {{nonfree}}\n| Proprietary\n| General purpose numerical analysis library.\n|-\n! [[NMath]]\n| [[CenterSpace Software]]\n| C#\n| 2003\n| 4.0 / November 2009\n| {{nonfree}}\n| Proprietary\n| Math and statistical libraries for the [[.NET Framework]]\n|-\n! [[SciPy]]\n| [[Enthought]]\n| Python\n| 2001\n| 1.0.0 / 10.2017\n| {{free}}\n| [[BSD licenses|BSD]]\n| Based on Python\n|-\n! [[Eigen (C++ library)|Eigen]]\n| Benoît Jacob\n| C++\n| 2008\n| 3.3.7 / 12.2018\n| {{free}}\n| [[Mozilla Public License|MPL2]]\n| Eigen is a C++ template library for linear algebra: matrices, vectors, numerical solvers, and related algorithms.\n|-\n! [[Armadillo (C++ library)|Armadillo]]\n| [[NICTA]]\n| C++\n| 2009\n| 9.200 / 10.2018\n| {{free}}\n| [[Apache License 2.0]]\n| C++ template library for linear algebra; includes various decompositions and factorisations; syntax ([[Application programming interface|API]]) is similar to [[MATLAB]].\n|-\n! [[librsb]]\n| Michele Martone\n| C, Fortran, M4\n| 2011\n| 1.2 / September 2016\n| {{free}}\n| [[GNU General Public License|GPL]]\n| High-performance multi-threaded primitives for large sparse matrices. Support operations for iterative solvers: multiplication, triangular solve, scaling, matrix I/O, matrix rendering. Many variants: e.g.: symmetric, hermitian, complex, quadruple precision.\n|}\n\n=== Matrix types and operations ===\nMatrix types (special types like bidiagonal/tridiagonal are not listed):\n* ''Real'' - general (nonsymmetric) real\n* ''Complex'' - general (nonsymmetric) complex\n* ''SPD'' - symmetric positive definite (real)\n* ''HPD'' - Hermitian positive definite (complex)\n* ''SY'' - symmetric (real)\n* ''HE'' - Hermitian (complex)\n* ''BND'' - band\n\nOperations:\n* ''TF'' - triangular factorizations (LU, Cholesky)\n* ''OF'' - orthogonal factorizations (QR, QL, generalized factorizations)\n* ''EVD'' - eigenproblems\n* ''SVD'' - singular value decomposition\n* ''GEVD'' - generalized EVD\n* ''GSVD'' - generalized SVD\n\n{| class=\"wikitable sortable\" style=\"text-align: center; width: auto;\"\n|-\n! style=\"width: 12em\" |\n! Real\n! Complex\n! SPD\n! HPD\n! SY\n! HE\n! BND\n! TF\n! OF\n! EVD\n! SVD\n! GEVD\n! GSVD\n|-\n! [[ALGLIB]]\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{no}}\n! {{no}}\n! {{no}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{no}}\n|-\n! [[Automatically Tuned Linear Algebra Software|ATLAS]]\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{no}}\n! {{no}}\n! {{no}}\n! {{yes}}\n! {{no}}\n! {{no}}\n! {{no}}\n! {{no}}\n! {{no}}\n|-\n! [[Dlib]]\n! {{Yes}}\n! {{Yes}}\n! {{Yes}}\n! {{Yes}}\n! {{Yes}}\n! {{Yes}}\n! {{No}}\n! {{Yes}}\n! {{Yes}}\n! {{Yes}}\n! {{Yes}}\n! {{No}}\n! {{No}}\n|-\n! [[GNU Scientific Library]]\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{no}}\n! {{no}}\n! {{no}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{no}}\n|-\n! [[ILNumerics.Net]]\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{no}}\n! {{no}}\n! {{no}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{no}}\n! {{no}}\n|-\n! [[IMSL Numerical Libraries]]\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{no}}\n! {{no}}\n! {{yes}}\n! {{yes}}\n! {{no}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{no}}\n|-\n! [[LAPACK]]\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n|-\n! [[Math Kernel Library|MKL]]\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n|-\n! [[NAG Numerical Library]]\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n|-\n! [[NMath]]\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{no}}\n! {{no}}\n|-\n! [[SciPy]] (Python packages)\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{no}}\n! {{no}}\n! {{no}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{no}}\n! {{no}}\n|-\n! [[Eigen (C++ library)|Eigen]]\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{no}}\n|-\n! [[Armadillo (C++ library)|Armadillo]]\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{no}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{yes}}\n! {{no}}\n|}\n\n[[Category:Numerical libraries|*Comparison of linear algebra libraries]]"
    },
    {
      "title": "ALGLIB",
      "url": "https://en.wikipedia.org/wiki/ALGLIB",
      "text": "{{Infobox software\n | name                   = ALGLIB\n | latest release version = 3.14.0\n | latest release date    = {{Start date and age|2018|06|16|df=yes}}\n | developer              = ALGLIB Project\n | operating_system       = [[Cross-platform]]\n | genre                  = [[List of numerical analysis software|Numerical library]]\n | license                = Dual (commercial, [[GPL]])\n | website                = {{URL|http://www.alglib.net/}}\n}}\n'''ALGLIB''' is a [[cross-platform]] [[Open-source software|open source]] [[numerical analysis]] and [[data processing]] [[Library (computing)|library]]. It can be used from several programming languages ([[C++]], [[C Sharp (programming language)|C#]], [[VB.NET]], [[Python (programming language)|Python]], [[Object Pascal|Delphi]]).\n\nALGLIB started in 1999 and has a long history of steady development with roughly 1-3 releases per year. It is used by several open source projects, commercial libraries, and applications (e.g. [[Tree of Life Web Project|TOL project]], [[Math.NET Numerics]],<ref>{{cite web|url=http://numerics.mathdotnet.com/ |title=Math.NET Numerics |publisher=Numerics.mathdotnet.com |date= |accessdate=2010-07-10}}</ref><ref>{{cite web|url=https://github.com/mathnet/mathnet-numerics/blob/master/CONTRIBUTORS.md |title=Math.NET Numerics Contributors |publisher=GitHub.com |accessdate=2013-05-07}}</ref> [[SpaceClaim]]<ref>{{cite web|url=http://www2.spaceclaim.com/UsingSpaceClaim/misc/userlicense.aspx |title=End User License |publisher=.spaceclaim.com |date= |accessdate=2010-07-10}}</ref>).\n\n== Features ==\nDistinctive features of the library are:\n* Support for several programming languages with identical APIs ({{as of|2017|lc=y}}, it supports C++, C#, FreePascal/Delphi, VB.NET and Python)\n* Self-contained code with no mandatory external dependencies and easy installation\n* Portability (it was tested under x86/x86-64/ARM, [[Microsoft Windows|Windows]] and [[Linux]])\n* Two independent backends (pure C# implementation, native C implementation) with automatically generated APIs (C++, C#, ...)\n* Same functionality of commercial and GPL versions\n\nALGLIB provides functions for:\n* [[Linear algebra]] (direct algorithms, solvers, EVD/SVD)\n* [[Fast Fourier transform]]s\n* [[Numerical integration]]\n* [[Interpolation]]\n* [[Linear least squares (mathematics)|Linear]] and [[Non-linear least squares|nonlinear least-squares fitting]]\n* Optimization\n* [[Ordinary differential equation]]s\n* [[Special functions]]\n* [[Statistics]] ([[descriptive statistics]], [[hypothesis testing]])\n* [[Data analysis]] (classification/regression, including neural networks)\n* Multiple precision versions of [[linear algebra]], [[interpolation]] and optimization algorithms (using [[MPFR]] for floating point computations)\n\n== See also ==\n{{Portal|Free and open-source software}}\n* [[List of numerical analysis software]]\n* [[List of numerical libraries]]\n\n== References ==\n{{Reflist}}\n\n== External links ==\n* [http://www.alglib.net/ Official ALGLIB website]\n\n[[Category:Numerical libraries]]"
    },
    {
      "title": "AMD Core Math Library",
      "url": "https://en.wikipedia.org/wiki/AMD_Core_Math_Library",
      "text": "'''AMD Core Math Library''' ('''ACML''') is an end-of-life <ref>[https://developer.amd.com/tools-and-sdks/archive/acml-product-features/ AMD Core Math Library Product Features]{{Dead link|date=March 2018}}</ref> [[software development]] library released by [[AMD]]. This library provides mathematical routines optimized for AMD processors. \n\n==Features==\nACML consists of the following main components:<ref name=\"AMD-Core-Math-Library-dotcom\">{{Cite web |url=http://developer.amd.com/tools-and-sdks/cpu-development/amd-core-math-library-acml/ |title=ACML |access-date=2014-10-19 |archive-url=https://web.archive.org/web/20141015020116/http://developer.amd.com/tools-and-sdks/cpu-development/amd-core-math-library-acml/ |archive-date=2014-10-15 |dead-url=yes |df= }}</ref>\n* A full implementation of Level 1, 2 and 3 [[Basic Linear Algebra Subprograms]] (BLAS), with optimizations for AMD Opteron processors.\n* A full suite of [[Linear Algebra]] ([[LAPACK]]) routines.\n* A comprehensive suite of [[Fast Fourier transform]] (FFTs) in single-, double-, single-complex and double-complex data types.\n* Fast scalar, vector, and array math transcendental library routines\n* [[Random Number Generator]]s in both single- and double-precision\n\n==Supported platforms==\nAMD offers pre-compiled binaries for [[Linux]], [[Solaris (operating system)|Solaris]], and [[Microsoft Windows|Windows]] available for download. Supported compilers include [[GNU Fortran]], [[Intel Fortran Compiler]], [[Microsoft Visual Studio]], [[Numerical Algorithms Group|NAG]], [[PathScale]], [[PGI compiler]], and [[Sun Studio (software)|Sun Studio]].<ref>[https://developer.amd.com/tools-and-sdks/archive/acml-downloads-resources/ ACML Downloads & Resources]{{Dead link|date=November 2018}}</ref>\n\n==See also==\n* [[GPUOpen]] - Open-source software suite for visual effects, HPC, and GPGPU\n* [[Framewave]] - formerly the AMD Performance Library\n* [[Open64]] - AMD has an Open64 compiler distribution that can be used with ACML\n* [[Math Kernel Library]] (MKL)\n\n==License==\nACML has a proprietary license. The library is distributed in binary form free of charge, but cannot be freely redistributed.<ref>[http://developer.amd.com/tools-and-sdks/cpu-development/amd-core-math-library-acml/acml-redistribution-agreements/ Redistribution Agreements] {{Webarchive|url=https://web.archive.org/web/20141015020107/http://developer.amd.com/tools-and-sdks/cpu-development/amd-core-math-library-acml/acml-redistribution-agreements/ |date=2014-10-15 }}, ACML Redistribution Agreements</ref><ref>[http://amd-dev.wpengine.netdna-cdn.com/wordpress/media/2012/10/ACML-EULA.pdf ACML EULA], End-user license agreement</ref>\n\n==References==\n{{Reflist}}\n\n==External links==\n*[https://web.archive.org/web/20081010124022/http://ati.amd.com/technology/streamcomputing/Stream_Computing_User_Guide.pdf Streaming Computing (User Guide)]\n\n{{Numerical linear algebra}}\n\n[[Category:Advanced Micro Devices products]]\n[[Category:Numerical libraries]]"
    },
    {
      "title": "CAPD library",
      "url": "https://en.wikipedia.org/wiki/CAPD_library",
      "text": "{{Infobox software\n| name                   = CGAL\n| title                  = \n| logo                   = <!-- [[File: ]] -->\n| logo caption           = \n| screenshot             = <!-- [[File: ]] -->\n| caption                = \n| collapsible            = \n| author                 = \n| developer              = [[Jagiellonian University]]\n| released               = 2005 <!-- {{Start date|YYYY|MM|DD|df=yes/no}} -->\n| discontinued           = \n| latest release version = 4.0\n| latest release date    = 2013\n| latest preview version = \n| latest preview date    = <!-- {{Start date and age|YYYY|MM|DD|df=yes/no}} -->\n| programming language   = [[C++]] \n| operating system       = [[Multi-platform]]\n| platform               = \n| size                   = \n| language               = \n| language count         = <!-- DO NOT include this parameter unless you know what it does -->\n| language footnote      = \n| genre                  = [[Application framework]]\n| license                = GPL <ref>http://capd.ii.uj.edu.pl/capd/license.html</ref>\n| alexa                  = \n| website                = {{URL|http://capd.ii.uj.edu.pl/}}\n| standard               = \n| AsOf                   = \n}}\n\nThe '''CAPD library''' ('''Computer Assisted Proofs in Dynamics''') is a software [[library (computing)|library]] that aims to provide a set of flexible C++ modules designed for [[verified computing|rigorous numerics]] in [[dynamical system|Dynamical Systems]] and [[homology (mathematics)|homology]] computation. It has been used in a research of [[Chaos theory|chaotic dynamics]], bifurcations, heteroclinic/homoclinic solutions and periodic orbits. The RedHom (Reduction Homology) subproject provides efficient methods for computation of a homology of sets based on geometric and algebraic reductions.\n\nThe CAPD library is developed at the Faculty of Mathematics and Computer Science at the [[Jagiellonian University]]. The software is available under an open source [[GPL]] license.\n\n== References ==\n{{refs}}\n* [http://capd.ii.uj.edu.pl/ CAPD project website]\n* [http://redhom.ii.uj.edu.pl/ RedHom subproject website]\n\n[[Category:C++ libraries]]\n[[Category:Free computer libraries]]\n[[Category:Free software programmed in C++]]\n[[Category:Generic programming]]\n[[Category:Numerical libraries]]"
    },
    {
      "title": "GNU Multiple Precision Arithmetic Library",
      "url": "https://en.wikipedia.org/wiki/GNU_Multiple_Precision_Arithmetic_Library",
      "text": "{{Infobox software\n| name                 = GNU Multiple Precision Arithmetic Library\n| logo                 = Gmplogo2.svg\n| screenshot           = \n| caption              = \n| developer            = [[GNU Project]]\n| released             = {{Start date and age|1991}}<ref>{{cite web\n | url=https://gmplib.org/download/gmp/archive/\n | title=GNU MP archive\n | accessdate=2018-12-03}}</ref>\n| programming language = [[C (programming language)|C]], ([[C++]], [[assembly language|assembly]] optionally)\n| genre                = [[Mathematical software]]\n| license              = Dual [[GNU Lesser General Public License|LGPLv3]] and [[GNU General Public License|GPLv2]]<ref name=what/>\n| website              = {{URL|https://gmplib.org}}\n}}\n\n'''GNU Multiple Precision Arithmetic Library''' ('''GMP''') is a [[free software|free]] library for [[arbitrary-precision arithmetic]], operating on signed [[integer]]s, [[rational number]]s, and [[floating point]] numbers.<ref name=what>{{cite web\n| url=https://gmplib.org/#WHAT\n| title=What is GMP?\n| accessdate=2014-04-07}}</ref> There are no practical limits to the precision except the ones implied by the available [[virtual memory|memory]] in the machine GMP runs on (operand dimension limit is 2<sup>32</sup>-1 bits on 32-bit machines and 2<sup>37</sup> bits on 64-bit machines).<ref>{{cite web\n| url=https://gmplib.org/list-archives/gmp-bugs/2009-July/001538.html\n| title=Problems with mpz_set_str and huge strings\n| last=Granlund\n| first=Torbjorn\n| date=2009-07-06\n| accessdate=2013-03-17}}</ref> GMP has a rich set of functions, and the functions have a regular interface. The basic interface is for [[C (programming language)|C]] but wrappers exist for other languages including [[Ada (programming language)|Ada]], [[C++]], [[C Sharp (programming language)|C#]], [[Julia (programming language)|Julia]], [[.NET]], [[OCaml]], [[Perl]], [[PHP]], [[Python (programming language)|Python]], [[R (programming language)|R]], [[Ruby (programming language)|Ruby]] and the [[Wolfram Language]]. In the past, [[Kaffe]], a [[Java virtual machine]], used GMP to support Java built-in arbitrary precision arithmetic. This feature has been removed from recent releases, causing protests from people who claim that they used Kaffe solely for the speed benefits afforded by GMP.<ref>{{cite web\n| url=http://www.kaffe.org/pipermail/kaffe/2008-February/191039.html\n| title=Removed GMP math?\n| last=Hughes\n| first=Andrew John\n| date=2008-02-28\n| accessdate=2013-03-17}}</ref> As a result, GMP support has been added to [[GNU Classpath]].<ref>{{cite web\n| url=https://www.gnu.org/software/classpath/announce/20090205.html\n| title=GNU Classpath 0.98 \"Better Late Than Never\"\n| date=2009-02-05\n| accessdate=2013-03-17}}</ref>\n\nThe main target applications of GMP are [[cryptography]] applications and research, Internet security applications, and [[computer algebra system]]s.\n\nGMP aims to be faster than any other [[bignum]] library for all operand sizes. Some important factors in doing this are:\n* Using full [[word (data type)|words]] as the basic arithmetic type.\n* Using different [[algorithm]]s for different [[operand]] sizes; algorithms that are faster for very big numbers are usually slower for small numbers.\n* Highly [[optimization (computer science)|optimized]] [[assembly language]] code for the most important [[inner loop]]s, specialized for different [[central processing unit|processors]].\n\nThe first GMP release was made in 1991. It is constantly developed and maintained.<ref name=main>{{cite web\n | url=https://gmplib.org/\n | title=GNU MP Bignum Library\n | accessdate=2018-12-03}}</ref>\n\nGMP is part of the [[GNU]] project (although its website being off gnu.org may cause confusion), and is distributed under the [[GNU Lesser General Public License]] (LGPL).\n\nGMP is used for integer arithmetic in many [[computer algebra system]]s such as [[Mathematica]]<ref>{{cite web\n| url=http://library.wolfram.com/infocenter/Conferences/7518/Macalester_talk.txt\n| title=The Mathematica Kernel: Issues in the Design and Implementation\n| date=October 2006\n| accessdate=2013-03-17}}</ref> and [[Maple (software)|Maple]].<ref>{{cite web\n| url=https://www.maplesoft.com/support/help/AddOns/view.aspx?path=GMP\n| title= The GNU Multiple Precision (GMP) Library\n| publisher=[[Maplesoft]]\n| accessdate=2013-03-17}}</ref> It is also used in the [[Computational Geometry Algorithms Library]] (CGAL) because geometry algorithms tend to 'explode' when using ordinary floating point CPU math.<ref>{{cite web\n| url=https://www.cgal.org/Manual/\n| title=CGAL Manuals}}</ref>\n\nGMP is needed to build the [[GNU Compiler Collection]] (GCC).<ref>GCC uses the [[GNU MPFR]] library, which in turn relies on GMP. {{cite web\n| url=https://gcc.gnu.org/gcc-4.3/changes.html#mpfropts\n| title=GCC 4.3 Release Series: Changes, New Features, and Fixes\n| date=2012-11-02\n| accessdate=2013-03-17}}</ref>\n\n== Examples ==\n\nHere is an example of C code showing the use of the GMP library to multiply and print large numbers:\n\n<source lang=\"C\">\n#include <stdio.h>\n#include <gmp.h>\n\nint main(void) {\n mpz_t x,y,result;\n\n mpz_init_set_str(x, \"7612058254738945\", 10);\n mpz_init_set_str(y, \"9263591128439081\", 10);\n mpz_init(result);\n\n mpz_mul(result, x, y);\n gmp_printf(\"    %Zd\\n\"\n            \"*\\n\"\n            \"    %Zd\\n\"\n            \"--------------------\\n\"\n            \"%Zd\\n\", x, y, result);\n\n /* free used memory */\n mpz_clear(x);\n mpz_clear(y);\n mpz_clear(result);\n\n return 0;\n}\n</source>\n\nThis code calculates the value of 7612058254738945 × 9263591128439081.\n\nCompiling and running this program gives this result. (The -lgmp flag is used if compiling on Unix-type systems.)\n\n<source lang=\"text\">\n    7612058254738945\n*\n    9263591128439081\n--------------------\n70514995317761165008628990709545\n</source>\n\nFor comparison, one can write instead the following equivalent C++ program. (The -lgmpxx -lgmp flags are used if compiling on Unix-type systems.)\n\n<source lang=\"cpp\">\n#include <iostream>\n#include <gmpxx.h>\n\nint main() {\n  mpz_class x(\"7612058254738945\");\n  mpz_class y(\"9263591128439081\");\n\n  std::cout << \"    \" << x << \"\\n\"\n            << \"*\\n\"\n            << \"    \" << y << \"\\n\"\n            << \"--------------------\\n\"\n            << x * y << \"\\n\";\n\n  return 0;\n}\n</source>\n\n== Language bindings ==\n{| class=\"wikitable\"\n|-\n! Library name\n! Language\n! License\n|-\n| [https://gmplib.org/ GNU Multi-Precision Library]\n| [[C (programming language)|C]], [[C++]]\n| [[GNU Lesser General Public License|LGPL]]\n|-\n| [https://metacpan.org/pod/Math::GMP Math::GMP]\n| [[Perl]]\n| [[GNU Lesser General Public License|LGPL]]\n|-\n| [https://github.com/aleaxit/gmpy General Multiprecision Python Project]\n| [[Python (programming language)|Python]]\n| LGPL\n|-\n| [https://cran.r-project.org/web/packages/gmp/index.html R package 'gmp']\n| [[R (programming language)|R]]\n| GPL\n|-\n| [http://rubygems.org/gems/gmp The RubyGems project]\n| [[Ruby (programming language)|Ruby]]\n| [[Apache License|Apache 2.0]]\n|-\n| [https://www.php.net/gmp GNU Multi-Precision Library for PHP]\n| [[PHP]]\n| [[PHP License|PHP]]\n|-\n| [http://www.math.uni.wroc.pl/~hebisch/prog/ GNU Multi-Precision Routines for SBCL]\n| [[Common Lisp]]\n| [[Public domain software|Public Domain]]\n|-\n| [http://chgmp.sourceforge.net/ Ch GMP]\n| [[Ch (computer programming)|Ch]]\n| [[Proprietary software|Proprietary]]\n|-\n| [http://bmdfm.com/ Parallel GMP Wrapper for BMDFM]\n| [[BMDFM | BMDFM LISP / C]]\n| [[Public domain software|Public Domain]]\n|-\n| [[Glasgow Haskell Compiler]]<br /><small>(The implementation of <code>Integer</code><br />is basically a binding to GMP)</small>\n| [[Haskell (programming language)|Haskell]]\n| [[BSD licenses|BSD]]\n|-\n| [https://github.com/Playermet/luajit-gmp luajit-gmp]\n| [[Lua (programming language)|LuaJIT]]\n| [[MIT License|MIT]]\n|-\n| [https://code.google.com/archive/p/gmp-wrapper-for-delphi gmp-wrapper-for-delphi]\n| [[Delphi (programming language)|Delphi]]\n| [[MIT License|MIT]]\n|-\n| [https://github.com/ocaml/Zarith Zarith]\n| [[OCaml]]\n| LGPL\n|-\n| [https://github.com/MachineCognitis/Math.Gmp.Native Math.Gmp.Native Library]\n| [[.NET]]\n| [[MIT License|MIT]]\n|-\n| [https://github.com/FedeOmoto/nim-gmp nim-gmp]\n| [[Nim (programming language)|Nim]]\n| [[MIT License|MIT]]\n|}\n\n== See also ==\n* [[GNU MPFR]] – library for arbitrary-precision computations with correct rounding, based on GNU MP\n* [[Class Library for Numbers|CLN]] – a class library for arbitrary precision \n* [[MPIR (mathematics software)|MPIR]] – a fork of GMP with mostly compatible interface which aims to provide MSVC-based compilation system for Windows platforms\n\n== References ==\n{{Reflist}}\n\n== External links ==\n* {{Official website}}\n\n{{GNU}}\n\n{{DEFAULTSORT:Gnu Multi-Precision Library}}\n[[Category:C libraries]]\n[[Category:Computer arithmetic]]\n[[Category:Free software programmed in C]]\n[[Category:GNU Project software|Multiple Precision Arithmetic Library]]\n[[Category:Numerical libraries]]\n[[Category:Software using the LGPL license]]\n[[Category:Software written primarily in assembly language]]"
    },
    {
      "title": "IMSL Numerical Libraries",
      "url": "https://en.wikipedia.org/wiki/IMSL_Numerical_Libraries",
      "text": "'''IMSL''' ('''International Mathematics and Statistics Library''') is a commercial collection of [[library (computer science)|software libraries]] of [[numerical analysis]] functionality that are implemented in the computer [[programming language]]s [[C (programming language)|C]], [[Java (programming language)|Java]], [[C Sharp (programming language)|C#.NET]], and [[Fortran]]. A [[Python (programming language)|Python]] interface is also available.\n\nThe IMSL Libraries are provided by [[Rogue Wave Software]].  \n\n== Version history ==\nThe first IMSL Library for the Fortran language was released in 1970, followed by a C language version originally called C/Base in 1991, a Java language version in 2002 and the C# language version in 2004. \n\nSeveral recent product releases have involved making IMSL Library functions available from [[Python (programming language)|Python]]. These releases are Python wrappers to IMSL C Library functions (PyIMSL wrappers) and PyIMSL Studio, a prototyping and production application development environment based on Python and the IMSL C Library. The PyIMSL wrappers were first released in August 2008. PyIMSL Studio was introduced in February 2009. PyIMSL Studio is available for download at no charge for non-commercial use or for commercial evaluation.\n\nCurrent versions:\n*IMSL C Library V 8.0 - November 2011\n*IMSL C# Library V 6.5.2 - November 2015\n*IMSL Fortran Library V 7.0 - October 2010\n*PyIMSL Studio V 1.5 - August 2009\n*PyIMSL wrappers V 1.5 - August 2009\n*JMSL Library V 6.1 - August 2010\n\n== Platform availability ==\nThe IMSL Numerical Libraries are supported on various operating systems, hardware and compilers.\n*Operating system support includes [[Unix]], [[Linux]],  [[Mac OS]] and [[Microsoft Windows]]\n*Hardware support includes [[AMD]], [[Intel]], [[Apple Inc.]], [[Cray]], [[Fujitsu]], [[Hitachi]], [[Hewlett-Packard|HP]], [[IBM]], [[NEC]], [[Silicon Graphics|SGI]] and [[Sun Microsystems]]\n*[[Compiler]] support includes [[Absoft Fortran Compilers|Absoft]], [[GNU Compiler Collection|GCC]], [[Intel C++ Compiler|Intel]], [[Microsoft Visual C++|Microsoft]], and [[The Portland Group|Portland]]\n\n== See also ==\n*[[List of numerical analysis software]]\n*[[List of numerical libraries]]\n\n==External links==\n*[https://www.roguewave.com/products-services/imsl-numerical-libraries Rogue Wave Software's IMSL Libraries page]\n\n[[Category:Fortran libraries]]\n[[Category:Numerical libraries]]"
    },
    {
      "title": "Integer set library",
      "url": "https://en.wikipedia.org/wiki/Integer_set_library",
      "text": "{{Infobox software\n| title                  = isl\n| name                   = isl\n| logo                   = <!-- [[File: ]] -->\n| screenshot             = <!-- [[File: ]] -->\n| caption                = \n| collapsible            = \n| author                 = \n| developer              = Sven Verdoolaege, [[INRIA]] and others\n| released               = <!-- {{Start date|YYYY|MM|DD|df=yes/no}} -->\n| discontinued           = \n| latest release version = 0.21\n| latest release date    = {{Start date and age|2019|03|26|df=no}}\n| latest preview version = \n| latest preview date    = <!-- {{Start date and age|YYYY|MM|DD|df=yes/no}} -->\n| status                 = \n| programming language   = \n| operating system       = \n| platform               = \n| size                   = \n| language               = \n| genre                  = [[Mathematical software]]\n| license                = [[MIT License|MIT]]\n| website                = {{URL|http://isl.gforge.inria.fr}}\n}}\n'''isl''' ('''integer set library''') is a portable [[C (programming language)|C]] [[Library (computing)|library]] for manipulating [[Set (mathematics)|sets]] and relations of [[integer]] points [[bounded set|bounded]] by [[Linear inequality|linear]] [[Constraint (mathematics)|constraints]].<ref name=\"Verdoolaege2010\">{{cite journal|last1=Verdoolaege|first1=Sven|title=isl: An Integer Set Library for the Polyhedral Model|volume=6327|year=2010|pages=299–302|issn=0302-9743|doi=10.1007/978-3-642-15582-6_49}}</ref>\n\nThe following operations are supported:<ref>{{cite web\n| url=http://isl.gforge.inria.fr//manual.pdf\n| title=isl Manual\n| date=2015-06-11\n| accessdate=2015-09-02}}</ref>\n* [[intersection]], [[Union (set theory)|union]], [[set difference]]\n* [[Empty set|emptiness]] check\n* [[convex hull]]\n* (integer) [[affine hull]]\n* integer [[Projection (mathematics)|projection]]\n* computing the [[Lexicographical order|lexicographic minimum]] using parametric integer programming\n* [[Coalescing (computer science)|coalescing]]\n* parametric [[Vertex enumeration problem|vertex enumeration]]\n\nIt also includes an [[Linear programming|ILP]] solver based on generalized [[Basis (linear algebra)|basis]] [[Lattice reduction|reduction]], [[transitive closure]]s on [[Map (mathematics)|maps]] (which may encode [[infinite graph]]s), [[dependence analysis]] and [[Upper and lower bounds|bounds]] on [[piecewise]] step-polynomials.\n\nAll computations are performed in exact integer arithmetic using [[GNU Multiple Precision Arithmetic Library|GMP]] or imath.\n\nMany [[program analysis]] techniques are based on integer set manipulations. The integers typically represent iterations of a [[Control flow#Loops|loop]] nest or elements of an [[Array data structure|array]].\nisl uses parametric [[integer programming]] to obtain an explicit representation in terms of integer divisions.\n\nIt is used as backend polyhedral library in the [[GNU Compiler Collection|GCC]] Graphite framework<ref>{{cite web\n| url=https://gcc.gnu.org/install/prerequisites.html\n| title=GCC prerequisites\n| date=2015-07-26\n| accessdate=2015-09-02}}</ref> for [[loop optimization]]s.\n\n==See also==\n{{Portal|Free and open-source software}}\n* [[Frameworks supporting the polyhedral model]]\n* [[Integer programming]]\n\n==References==\n{{reflist}}\n\n==External links==\n* [http://isl.gforge.inria.fr/ Official ISL web site]\n* [http://labexcompilation.ens-lyon.fr/polyhedral-school/program/#Sven Integer sets and relations: from high-level modeling to low-level implementation (Sven Verdoolaege)]\n\n[[Category:Computer arithmetic]]\n[[Category:C libraries]]\n[[Category:Numerical libraries]]\n[[Category:Free software programmed in C]]\n[[Category:Software using the MIT license]]"
    },
    {
      "title": "List of .NET libraries and frameworks",
      "url": "https://en.wikipedia.org/wiki/List_of_.NET_libraries_and_frameworks",
      "text": "This article contains a list of notable libraries that can be used in [[List of CLI languages|.NET languages]]. While the [[.NET framework]] provides a basis for [[Application software|application development]], which provides platform independence, language interoperability and extensive framework libraries, the development ecosystem around .NET is dependent on user libraries that are developed independently of the framework. \n\n[[Standard Libraries (CLI)]] (including the [[Base Class Library|Base Class Library (BCL)]]) are not included in this article because they have a [[Base Class Library|separate article]].\n\n== Application development in .NET Framework ==\n\nPrograms written for .NET Framework execute in a [[software]] environment known as [[Common Language Runtime]] (CLR), an [[process virtual machine|application virtual machine]] that provides services such as security, [[memory management]], and [[exception handling]]. Framework includes a large class library called [[Framework Class Library]] (FCL), which together with CLR constitute the .NET framework.\n\nThanks to the hosting virtual machine, different [[List of CLI languages|.NET CLI compliant languages]] can operate on the same kind of data structures. Therefore, all CLI compliant languages can use the [[Framework Class Library]] and other .NET libraries that are written in one of the CLI compliant languages. When source code of a CLI compliant language is compiled, the compiler generates a platform independent code in the [[Common Intermediate Language]] (also referred to as bytecode), which is stored in [[Assembly (CLI)|CLI assemblies]]. When a .NET application is executed, the just-in-time compiler (JIT) turns the CIL code into platform specific machine code. To improve performance, the .NET Framework also comes with Native Image Generator (NGEN), which performs ahead-of-time compilation to machine code.\n\nThis architecture has several implications. The framework provides [[language interoperability]] (each language can use code written in other languages) across the [[List of CLI languages|.NET CLI compliant languages]] [[programming language]]s. Calls from one language to another are exactly the same as would be within a single programming language. If a library is written in one CLI language, it can be used in any other CLI language. Moreover, applications that consist only of pure .NET assemblies, can be transferred to any platform that contains implementation of .NET framework and executed on that platform. For example, an application written for Microsoft .NET on [[Microsoft Windows|Windows]] can also be executed on [[Mono (software)|Mono]] (a cross platform alternative implementation of .NET) on [[Linux]] or [[macOS]]. Such applications are automatically [[cross-platform]] (or platform independent) to the extent to which the .NET framework itself is ported to different platforms.\n\nAbility to transfer applications across platforms is extremely important for software developers, because in this way they can use the same code base for the application on any platform, enabling code reuse and avoiding code duplication. Both lead to reduced development and maintenance costs.\n\nHowever, platform independence is only guaranteed in the described way when none of the assemblies constituting an application depends on any code that is not pure .NET code. Many .NET libraries, however, make use of [[Native code|native libraries]] (written e.g. in C or C++) or system calls through [[.NET Framework#Interoperability|interoperability mechanisms]] such as [[Component Object Model|COM]] interoperability and the [[Platform Invocation Services|P/Invoke]] feature, which makes possible to call [[native code]] and thus call into libraries written in [[compiled language]]s (as opposed to managed) such as C or C++.\n\nIn these cases, platform independence of applications written for the .NET framework also depends on the ability to transfer non-.NET libraries, on which application depends, to target platforms. Any additional such library may add significantly to the effort necessary to transfer the application to other platforms. Sometimes, the best solution is to re-implement the parts of application that depend on such a library for each targeted platform. In many cases, the vast majority of the application's code base can be easily transferred across platforms, and only small specific portions of code dependent on problematic libraries must be re-implemented for each platform. Sometimes, a special [[compatibility layer]] is introduced that provides a uniform [[API]] to the platform dependent parts of code. Then, even if the higher level code heavily depends on platform dependent parts, dependence is resolved through API calls that are the same on all platforms, and the same high level code can still be used on different target platforms.\n\nA notable example is the [[Windows Forms]] [[graphical user interface|graphical]] (GUI) [[Library (computing)|class library]]. The library provides access to [[Windows USER|Windows User Interface]] Common Controls by [[Wrapper pattern|wrapping]] the [[Windows API]] in [[managed code]].<ref name=DeSmet>{{cite web|url=http://www.informit.com/articles/article.aspx?p=2048355&seqNum=4|title=C# 4.0 Unleashed By Bart De Smet. Sams Publishing, Jan 4, 2011 Chapter 5}}</ref> The library is therefore not easily transferred to platforms other than Windows. In spite of that, the cross-platform .NET implementation [[Mono (software)|Mono]] implements the library. Because of that, an application that depends on Windows Forms, can be ported to other forms by using the Mono runtime on which the Windows Forms library is implemented (beside Windows, this includes Unix and OSX). The Mono's implementation of the library is written in C# in order to avoid Windows dependence.<ref name=\"GuiToolkitsMono\">{{cite web |url=http://www.mono-project.com/docs/gui/| title=GUI Toolkits| last= | first= | work=Mono site| publisher= | date=21 April 2016| archive-url=https://web.archive.org/web/20160402171119/http://www.mono-project.com/docs/gui/ | archive-date=2016-04-02|access-date=2016-04-21}}</ref>\nMost of the Windows Forms API works on Mono, except for some minor incompatibilities and implementation bugs. However, many .NET libraries that were written on Windows and depend on Windows Forms, also make direct P/Invoke calls straight to the Windows API and bypass the Windows Forms API (this is sometimes done to avoid limitations of the Windows Forms). Such libraries will be broken when transferred to platforms other than Windows, although Windows Forms itself is available on these platforms via Mono implementation. For a [[graphical user interface|GUI]] [[Library (computing)|class library]], the Mono project endorses use of the [[GTK#]] library,{{citation needed|date=April 2016}} which is a .NET binding for the [[Gtk+]] toolkit written in C.\n\nGUI libraries are not the only critical area of interest for .NET developers. Other libraries that may be problematic include 3D graphics libraries, sound and video libraries and device dependent libraries in general. While some areas are very well covered by core .NET libraries (such as database connectivity, file I/O, sockets, HTTP, XML manipulation, standard cryptography), the others (such as numerical libraries, general parsing libraries) are easy to implement in pure .NET but may be under represented as compared to availability of corresponding native libraries. For developers of both proprietary and open source software (including free software), licensing information is also critically important. Entries in the list therefore provide information about the scope of the listed libraries, main dependencies (especially when these affect platform dependence), and licensing information.\n\n== Historical background ==\nThe [[.NET Framework]] has long supported cross-platform software development. The framework has been designed from the beginning for language interoperability, and parts of it were standardized in open standard (The [[.NET Framework#Common Language Infrastructure|Common Language Infrastructure]] and framework's most used programming language, [[C Sharp (programming language)|C#]]). The original framework was first implemented only on [[Microsoft Windows|Windows operating systems]]. [[Microsoft]], the framework developer, and its partners, were working towards making their patents that cover some .NET - implemented technologies essential for framework implementation, available under \"[[Reasonable and Non Discriminatory Licensing|reasonable and non-discriminatory terms]]\", which evolved into several patent promises issued by Microsoft. This made alternative third party implementations of the framework possible such as [[Mono (software)|Mono]], [[Portable.NET]], and emulation [http://crossnet.codeplex.com/ CrossNet].<ref>{{cite web |url=http://www.codeplex.com/crossnet |title=CrossNet |publisher=Codeplex.com |date= |accessdate=17 April 2012}}</ref>\n\nIn spite of that, it has long been a concern within the [[Open source community]] that using alternative .NET implementations for cross-platform development, especially of free software, is unsafe because of the possibility of Microsoft patent claims against such implementations. The [[Free Software Foundation]]'s [[Richard Stallman]] has openly opposed inclusion of C# implementations in the default installation of GNU/Linux distributions and stated that they (the community) should discourage people from writing programs in C#. Primary concerns were parts of the framework implementations that were not subject to standards and were not explicitly included in Microsoft's patent promises.\n\nThe 2010s saw some significant shifts in Microsoft's approach towards the Open software community. The company open sourced the [[.NET Compiler Platform]] (\"Roslyn\") and the [[ASP.NET]] in April 2014, and later the [[.NET Core]] (open sourced on November 2014<ref name=landwerth-dotnetcore-oss>{{cite web |title=.NET Core is Open Source|url=http://blogs.msdn.com/b/dotnet/archive/2014/11/12/net-core-is-open-source.aspx|website=.NET Framework Blog|publisher=Microsoft |accessdate=30 December 2014|date=12 November 2014|first=Immo|last=Landwerth}}</ref>) and other software. In February 2016, Microsoft acquired [[Xamarin]], developer of [[Mono (software)|Mono]], an open source and cross platform implementation of .NET. On March 31, 2016 Microsoft announced at [[Build (developer conference)|Microsoft Build]] that they will completely [[Software relicensing|re-license]] Mono under the MIT license.<ref name=\"Anderson1\">{{cite web|url=https://www.theregister.co.uk/2016/03/31/xamarin_tools_code_free_and_open_source/|title=Microsoft to make Xamarin tools and code free and open source.|work=The Register|date=31 March 2016|first=Tim|last=Anderson}}</ref> Microsoft issued the Patent Promise for Mono stating that they won't assert any \"applicable patents\" against parties that are \"using, selling, offering for sale, importing, or distributing Mono\".<ref name=Ferraira1>{{cite web|url=http://techreport.com/news/29929/xamarin-now-comes-free-with-visual-studio|title=Xamarin now comes free with Visual Studio.|work=The Tech Report|date=31 March 2016|first=Bruno|last=Ferraira}}</ref><ref name=\"Microsoft_PP_Mono\">{{cite web | url=https://github.com/mono/mono/blob/master/PATENTS.TXT| title=Microsoft Patent Promise for Mono | last= | first= | work=Mono on GitHub| publisher= Mono Project| date= 2016-03-28 |archiveurl=https://web.archive.org/web/20160416133644/https://github.com/mono/mono/blob/master/PATENTS.TXT | archivedate=2016-04-16|accessdate=16 April 2016}}</ref> It was also announced that the Mono Project was contributed to the [[.NET Foundation]], a nonprofit organization established by [[Microsoft Corporation|Microsoft]] in March 2014 to improve [[open-source software]] development and collaboration around the [[.NET Framework]].<ref name=\"tc2014\">{{cite web |last1=Lardinois |first1=Frederic |date=April 3, 2014 |title=Microsoft Launches .NET Foundation To Foster The .NET Open Source Ecosystem |url=https://techcrunch.com/2014/04/03/microsoft-launches-net-foundation-to-foster-the-net-open-source-ecosystem/ |website=[[TechCrunch]]}}</ref>\n\nIn light of these developments, a strong open source community has begun to develop around the .NET framework (especially on [[GitHub]]), starting a number of libraries and software projects<ref name=\"NetOpenProjects\">{{cite web|url=https://github.com/Microsoft/dotnet/blob/master/dotnet-developer-projects.md|title=.NET Open Source Developer Projects|work=GitHub|date=15 April 2015|first=|last=|archive-url=https://web.archive.org/web/20160415164104/https://github.com/Microsoft/dotnet/blob/master/dotnet-developer-projects.md|archive-date=2016-04-15|access-date=2016-04-15|deadurl=yes|df=}}</ref> targeting the .NET framework for its cross platform character.\n\n== Libraries and frameworks ==\n{{Multiple issues|section=yes|\n{{Expand section|date=April 2016}}\n{{Refimprove section|date=April 2016}}\n}}\nThis section lists a number of notable .NET libraries (both open source and proprietary) arranged by topics.\n\n=== .NET implementations ===\n{{Anchor|.NET Standard}}\n{{Redirect|.NET Standard|open specification (technical standard) behind .NET standardized by ISO and ECMA|ECMA 335}}\nThere are four primary .NET implementations that are actively developed and maintained:\n;.NET Standard: The .NET Standard is a set of [[Application programming interface|APIs]] that are implemented per the [[Base Class Library]] of any .NET implementation. A library can target a version of the .NET Standard (rather than an implementation) and then it could be used (without recompiling) by any implementation that supports that level of the standard. This enables portability across different .NET implementations.\n\n{| class=\"wikitable\"\n|-\n!rowspan=2|Implementation !!colspan=9|.NET Standard Versions<ref>{{cite web |title=.NET Standard |url=https://docs.microsoft.com/en-us/dotnet/standard/net-standard |website=docs.microsoft.com |language=en-us}}</ref><ref>{{cite web |title=This repo is building the .NET Standard. Contribute to dotnet/standard development by creating an account on GitHub |url=https://github.com/dotnet/standard/blob/master/docs/versions.md |publisher=.NET Foundation |date=3 April 2019}}</ref>\n|-\n!                                   1.0    !! 1.1    !! 1.2    !! 1.3    !! 1.4    !! 1.5        !! 1.6        !! 2.0       !! 2.1\n|-\n| .NET Core                      || 1.0    || 1.0    || 1.0    || 1.0    || 1.0    || 1.0        || 1.0        || 2.0       || 3.0\n|-\n| .NET Framework                 || 4.5    || 4.5    || 4.5.1  || 4.6    || 4.6.1  || 4.6.1      || 4.6.1      || 4.6.1     || N/A<ref group=\"notes\">There are no plans for the .NET Framework to support .NET Standard 2.1</ref><ref>{{cite web |title=Announcing .NET Standard 2.1 |url=https://devblogs.microsoft.com/dotnet/announcing-net-standard-2-1/ |website=.NET Blog |date=5 November 2018}}</ref>\n|-\n| Mono                           || 4.6    || 4.6    || 4.6    || 4.6    || 4.6    || 4.6        || 4.6        || 5.4       || 6.2\n|-\n| Xamarin.iOS                    || 10.0   || 10.0   || 10.0   || 10.0   || 10.0   || 10.0       || 10.0       || 10.14     || 12.12\n|-\n| Xamarin.Mac                    || 3.0    || 3.0    || 3.0    || 3.0    || 3.0    || 3.0        || 3.0        || 3.8       || 5.12\n|-\n| Xamarin.Android                || 7.0    || 7.0    || 7.0    || 7.0    || 7.0    || 7.0        || 7.0        || 8.0       || 9.3\n|-\n| Universal Windows Platform     || 10.0   || 10.0   || 10.0   || 10.0   || 10.0   || [[Windows 10 version history#Version_1709_(Fall_Creators_Update)|10.0.16299]] || 10.0.16299 || 10.0.16299 || TBD\n|-\n| Windows (8)                    || 8.0    || 8.0    || 8.1    ||        ||        ||            ||            ||           ||\n|-\n| Windows Phone                  || 8.1    || 8.1    || 8.1    ||        ||        ||            ||            ||           ||\n|-\n| Windows Phone Silverlight      || 8.0    ||        ||        ||        ||        ||            ||            ||           ||\n|-\n| [[Unity (game engine)|Unity]]  || 2018.1 || 2018.1 || 2018.1 || 2018.1 || 2018.1 || 2018.1     || 2018.1     || 2018.1    || TBD\n|}\n\nThe table lists the minimum supported implementation version for each version of .NET Standard.\n\n;[[.NET Framework]]: the original .NET implementation that has existed since 2002.\n;[[Mono (software)|Mono]]: an open source cross-platform implementation of .NET Framework. It runs on Linux, Mac OS, Android, and Windows.\n;[[.NET Core]]: a re-implementation of .NET Framework with the goal of making it cross-platform.\n;[[Universal Windows Platform]] ('''UWP'''): an implementation of .NET used for building [[UWP apps]]. It's designed to unify development for different targeted types of devices, including PCs, tablets, phablets, phones, and the [[Xbox]].\n\nEach implementation of .NET includes the following components:\n* One or more runtimes. Examples are [[Common Language Runtime|CLR]] for .NET Framework and [[CoreCLR]] for .NET Core.\n* A class library. Class library of each implementation must implements the .NET Standard, but may also implement additional APIs. Examples are .NET Framework Base Class Library and .NET Core Base Class Library.\nOptionally, implementations can also include:\n* One or more application frameworks. Examples are [[ASP.NET]] (included in .NET Framework and .NET Core), [[Windows Forms]] (included in .NET Framework, Mono and in .NET Core since version 3.0), and [[Windows Presentation Foundation]] (WPF) (included in the .NET Framework and in the .NET Core since version 3.0).\n* Development tools. Some development tools are shared among multiple implementations. Examples are [[Visual Studio Code]], .NET Software Development Kit (SDK), or [[NuGet]].\n\n=== Software frameworks ===\n;Native: '''[https://csnative.codeplex.com/ C# Native]''' or '''csnative''' compiles C# code to machine code.\n;SharpLang: [https://github.com/xen2/SharpLang SharpLang] compiles C# and other .NET languages to native machine code, using [[LLVM]] as a backend.\n;Cosmos: [https://github.com/CosmosOS/Cosmos Cosmos] is a C# Open Source Managed Operating System, an operating system \"construction kit\".\n;Fling OS: Fling OS is a C#-based operating system designed for learning low-level development.\n;MOSA Project: [https://github.com/mosa/MOSA-Project/ MOSA Project] - Managed Operating System Alliance Project - a C# Operating System.\n\n=== Web frameworks ===\n;[[ASP.NET]]: a server-side web application framework designed for web development to produce dynamic web pages. It is the successor to Microsoft's [[Active Server Pages|Active Server Pages (ASP)]] technology built on the [[Common Language Runtime|Common Language Runtime (CLR)]]. It provides separate patterns for developing web applications ASP.NET MVC, ASP.NET Web API, and ASP.NET Web Pages (a platform using only Razor pages), which have merged into a unified MVC 6.<ref name=\"asp.net\">{{cite web|url=http://docs.asp.net/en/latest/conceptual-overview/aspnet.html#unify|title=Introduction to ASP.NET 5 — ASP.NET 0.0.1 documentation|work=asp.net}}</ref>\n;[[ASP.NET Core]]: a successor and re-implementation of ASP.NET as a modular web framework, together with other frameworks like Entity Framework. The framework uses the new open-source .NET Compiler Platform (codename \"Roslyn\") and is cross platform.\n;[[Blazor]]: a web UI framework based on C#, Razor, and HTML that runs in the web browsers via WebAssembly. Blazor was designed to simplify the task of building fast single-page applications that run in any browser. It enables web developers to write .NET-based web apps that run client-side in web browsers using open web standards.\n;Ooui: a web framework for programming interactive user interfaces written in C# that run in a web browser. Ooui can target [[WebAssembly|WebAssembly (WASM)]], enabling [[#Xamarin.Forms|Xamarin.Forms]] applications to be deployed in WASM and run in-browser without the need for a server-side scripting.<ref name=\"OouiInfoQ\">{{cite web | url=https://www.infoq.com/news/2018/04/net-browser-ooui | title=Running .NET in the Browser with Ooui |author= Jeff Martin | work= |date=18 April 2018  | publisher= | archive-url=https://web.archive.org/web/20181126171403/https://www.infoq.com/news/2018/04/net-browser-ooui |archive-date=2018-11-26 |access-date=2018-11-26 }}</ref>\n\n=== Logging frameworks ===\n;[https://github.com/apache/logging-log4net log4net]: one of the oldest logging libraries and frameworks for .NET. It was created as port of the Java framework [[log4j]], and development later continued under the [[Apache]] Logging Services project. The library pioneered development of standard logging concepts such as log levels, loggers and appenders. It is released under the [[Apache License]] 2.0. At the current stage, log4net is a stable and mature library with a slow release cycle.<ref name=\"LoggingFrameworksStackify\">{{cite web |url=https://stackify.com/nlog-vs-log4net-vs-serilog/ | title=NLog vs log4net vs Serilog: Compare .NET Logging Frameworks | last=Timms | first=Simon | work=Developer Tips, Tricks & Resources | publisher=Stackify | date=27 August 2018 | archive-url=  | archive-date=2018-12-19|access-date=2018-12-19 }}</ref><ref name=\"Log4netStackify\">{{cite web |url=https://stackify.com/log4net-guide-dotnet-logging/ | title=Ultimate log4net Tutorial for .NET Logging – 14 Best Practices, Resources and Tips | last=Watson | first=Matt | work=Developer Tips, Tricks & Resources | publisher=Stackify | date=9 February 2017 | archive-url=  | archive-date=2018-12-19 |access-date=2018-12-19 }}</ref>\n;[https://nlog-project.org/ NLog]: a .NET open-source logging framework that was first released in 2006. It is being actively developed and is released under the [[BSD License]].<ref name=\"LoggingFrameworksStackify\" />\n;[https://serilog.net/ Seriog]: an open-source .NET logging library created in 2013. It is distinguished by supporting true structured logging (beyond just transforming an object value to text) out of the box. It is released under the [[Apache License]] 2.0.<ref name=\"LoggingFrameworksStackify\" />\n\n=== Numerical libraries ===\n{{Main|List of Numerical Libraries for .NET}}\n\n{{Expand section|date=April 2016}}\n\n==== Open-source numerical libraries ====\n;[[AForge.NET]]: a computer vision and artificial intelligence library. It implements a number of genetic, fuzzy logic and machine learning algorithms with several architectures of artificial neural networks with corresponding training algorithms.\n;[[ALGLIB]]: a cross-platform open source numerical analysis and data processing library. It consists of algorithm collections written in different programming languages (C++, C#, FreePascal, Delphi, VBA) and has dual licensing - commercial and [[Gnu Public license|GPL]].\n;[https://diffsharp.github.io/DiffSharp/ DiffSharp]: an automatic differentiation library for exact and efficient calculation of derivatives. It includes symbolic and numerical differentiation. Released under [[GPL|GPLv3]].<ref name=\"MathFSharp\"/>\n;[https://gbaydin.github.io/FsAlg/ FsAlg]: a lightweight linear algebra library that supports generic types, implemented in F#. Released under the [[BSD License]].<ref name=\"MathFSharp\"/>\n;[[IMSL Numerical Libraries for .NET]]: a commercial library of mathematical, statistical, data mining, financial and charting classes written in C#.\n;NeuronDotNet: a [[GPL]]-licensed artificial neural network library entirely written in C#. Because it only depends on the core .NET assemblies, it is easily portable across platforms.\n;[[suanshu.net]]: a large collection of numerical algorithms by Numerical Method Inc., which includes linear algebra, (advanced) optimization, interpolation, Markov model, principal component analysis, time series analysis, hypothesis testing, regressions, statistics, ordinary and partial differential equation solvers.\n;[[Math.NET Numerics]]: aims to provide methods and algorithms for numerical computations in science, engineering and every day use. Covered topics include special functions, linear algebra, probability models, random numbers, interpolation, integral transforms and more. MIT/X11 license.<ref name=\"MathFSharp\">{{cite web | url=http://fsharp.org/guides/math-and-statistics/ |title=Guide - Math and Statistics Programming with F# | last= | first= | work=| publisher=fsharp.org|date=| archive-url=https://web.archive.org/web/20160425104519/http://fsharp.org/guides/math-and-statistics/ | archive-date=2016-04-25|access-date=2016-04-25 }}</ref>\n;[[Meta.Numerics]]: is a library for advanced scientific computation in the .NET Framework.\n;NAG: a collection of mathematical and statistical routines.\n;[[NLinear]]: a generic linear algebra toolkit in C# compatible with Silverlight.\n\n==== Proprietary numerical libraries ====\n;[https://developer.nvidia.com/alea-gpu Alea GPU]: a framework for developing GPU-accelerated algorithms in F# on .NET and Mono.<ref name=\"MathFSharp\"/>\n;[[ILNumerics.Net]]: a commercial high performance, typesafe numerical array classes and functions for general math, FFT and linear algebra, aims .NET/mono, 32&64 bit, script-like syntax in C#, 2D & 3D plot controls, efficient memory management. Released under GPLv3 or commercial license.<ref name=\"MathFSharp\"/>\n;[[Measurement Studio]]: a commercial integrated suite UI controls and class libraries for use in developing test and measurement applications. The analysis class libraries provide various digital signal processing, signal filtering, signal generation, peak detection, and other general mathematical functionality.\n;[https://msdn.microsoft.com/en-us/devlabs/hh145003.aspx Microsoft Solver Foundation]: a .NET package for designing and optimizing mathematical models.<ref name=\"MathFSharp\"/>\n;[[NMath]]: Commercial numerical component libraries for the .NET platform by [[CenterSpace Software]], including signal processing (FFT) classes, a linear algebra (LAPACK & BLAS) framework, and a statistics package.<ref name=\"MathFSharp\"/>\n;[[Extreme Optimization Numerical Libraries]]: a commercial collection of mathematical and statistical classes for Microsoft .NET. It includes a large selection of standard algorithms from matrix factorization, function optimization, numerical integration, K-means clustering, and principal component analysis (PCA).<ref name=\"MathFSharp\"/>\n;[[suanshu.net]]: a large collection of numerical algorithms by Numerical Method Inc., which includes linear algebra, (advanced) optimization, interpolation, Markov model, principal component analysis, time series analysis, hypothesis testing, regressions, statistics, ordinary and partial differential equation solvers.\n\n=== 2D graphics ===\n==== Open-source 2D graphics libraries ====\n;[http://netcontrols.org/nplot/wiki/ NPlot]: a free, open source and cross platform charting library for .NET, released under the 3-clause-BSD license. Library includes classes for adding graphs to Windows Forms and ASP.NET, or to generate bitmaps.<ref name=\"Lerflaten\">{{cite web |url=http://www.4guysfromrolla.com/articles/072507-1.aspx#postadlink| title= ASP.NET Charting with NPlot| last=Lerflaten | first=Olav | work=| publisher= | date=25 July 2007| archive-url= https://web.archive.org/web/20160423002508/http://www.4guysfromrolla.com/articles/072507-1.aspx| archive-date=2016-04-23|access-date=2016-04-21 }}</ref>\n;[http://www.oxyplot.org/ OxyPlot]: a cross-platform charting library for .NET and supports WinForms, WPF, Xamarin and UWP platforms, released under the [[MIT license]].<ref name=\"OxyplotOceanAirdrop\">{{cite web | url=http://oceanairdrop.blogspot.com/2018/03/oxyplot-charting-control.html | title=OxyPlot Charting Control | last=Airdrop | first=Ocean | work=Ocean Airdrop | publisher= | date=10 March 2018 | archive-url=  |access-date=2018-10-26 }}</ref>\n;[http://www.carlosag.net/Tools/WebChart/ WebCharts]: a web control for creating charts that render as images(png, jpg, gif, etc.).<ref name=\"Mitchel\">{{cite web | url=http://aspnet.4guysfromrolla.com/articles/120804-1.aspx| title=A Look at WebCharts, a Free .NET Charting Control| last=Mitchell| first=Scott| work=| publisher= | date=8 December 2004| archive-url= https://web.archive.org/web/20160423004424/http://aspnet.4guysfromrolla.com/articles/120804-1.aspx |archive-date=2016-04-23 |access-date=2016-04-21 }}</ref>\n;[http://zedgraph.sourceforge.net/ ZedGraph]: a .NET 2D charting library for drawing line, bar, and pie Charts, released under the [[LGPL]] license. Library provides a high degree of flexibility, where very many aspects of how graphs will be displayed can be configured.<ref name=\"OpenHub\">{{cite web | url= https://www.openhub.net/p/8629| title=Project Summary at OpenHUB | last=| first=| work=| publisher= | date=| archive-url= https://web.archive.org/web/20160423011917/https://www.openhub.net/p/8629| archive-date=2016-04-23|access-date=2016-04-21 }}</ref><ref name=\"Anthony\">{{cite web | url=http://www.webdistortion.com/2008/11/12/web-application-graphing-solutions-from-around-the-web/| title=28 useful graphing solutions for web developers| last=Anthony| first=Paul| work=| publisher= |date=12 November 2008| access-date=2016-04-21 }}</ref><ref name=\"MikeCora\">{{cite web |url=https://www.cs.ubc.ca/~tmm/courses/cpsc533c-05-fall/projects/mcora/report.pdf | title=ShadyStats: Visualizing Game Statistics using Hierarchical Parallel Coordinates. A scientific article using Zedgraph. |last= Cora| first= Mike| work=| publisher= | date=| archive-url=https://www.cs.ubc.ca/~tmm/courses/cpsc533c-05-fall/projects/mcora/report.pdf |archive-date=2016-04-21|access-date=2016-04-21 }}</ref><ref>{{cite web |url=http://imtuoradea.ro/auo.fmte/files-2014-v1/Roman%20%20Lucian-SOFTWARE%20APPLICATION%20FOR%20ASSESSMENT%20THE%20RELIABILITY%20OF%20SUSPENSION%20SYSTEM%20AT%20OPEL%20CARS%20AND%20OF%20ROAD%20PROFILES.pdf | title=Software Application for Assessment the Reliability of the Suspension System at Opel Cars and of Road Profiles. A scientific article using Zedgraph. |last=Roman |first= Lucian | work= Fascicle of Management and Technological Engineering | publisher=| date=May 2014 | archive-url=https://web.archive.org/web/20160423014508/http://imtuoradea.ro/auo.fmte/files-2014-v1/Roman%20%20Lucian-SOFTWARE%20APPLICATION%20FOR%20ASSESSMENT%20THE%20RELIABILITY%20OF%20SUSPENSION%20SYSTEM%20AT%20OPEL%20CARS%20AND%20OF%20ROAD%20PROFILES.pdf |archive-date=2016-04-23 | access-date=2016-04-21 }}</ref>\n\n==== Proprietary 2D graphics libraries ====\n;[http://manufaktura-controls.com Manufaktura Controls]: a set of libraries for drawing music scores in desktop, mobile and web applications.\n\n=== 3D graphics ===\n==== Open-source 3D graphics libraries ====\n;[http://www.vtk.org/Wiki/VTK/CSharp/ActiViz.NET ActiViz.NET]: consists of C# wrappers around the [[VTK]] library. The source code is released under the [[BSD license]].<ref name=\"Messier \">{{cite web | url=http://www.prweb.com/releases/2011/1/prweb8101442.htm| title=Kitware’s ActiViz .NET Tool is Now Free and Open Source| last=Messier | first=Nicole | work=| publisher= |date= 31 January 2011| archive-url=https://web.archive.org/web/20160422214713/http://www.prweb.com/releases/2011/1/prweb8101442.htm | archive-date=2016-04-22|access-date=2016-04-21 }}</ref>\n;[https://github.com/Blotch3D/Blotch3D Blotch3D]: adds real-time 3D graphics; can be built for multiple platforms. Blotch3D sits on top of [[MonoGame]] and retains all its features. It is released under the [[Microsoft Public License]].\n;[http://helix-toolkit.org/ Helix Toolkit]: a 3D graphics toolkit that builds on and extends 3D capabilities of the [[Windows Presentation Foundation|WPF]]. Due to its dependence on WPF, the toolkit is limited to Windows platforms. It is released under the [[MIT]] license.<ref name=\"HelixGithub\">{{cite web | url=https://github.com/helix-toolkit/helix-toolkit\n|title=Helix repository on GitHub| last= | first= | work=| publisher= GitHub| date=| archive-url=https://web.archive.org/web/20160425094825/https://github.com/helix-toolkit/helix-toolkit | archive-date=2016-04-25|access-date=2016-04-25 }}</ref><ref name=\"HelixGettingStarted\">{{cite web | url=https://github.com/helix-toolkit/helix-toolkit/wiki/Getting-started-with-WPF-3D\n|title=Getting started with WPF 3D| last= | first= | work=| publisher= GitHub| date=| archive-url=https://web.archive.org/web/20160425095827/https://github.com/helix-toolkit/helix-toolkit/wiki/Getting-started-with-WPF-3D| archive-date=2016-04-25|access-date=2016-04-25 }}</ref><ref name=\"HelixHome\">{{cite web | url=http://helix-toolkit.org/\n|title=Helix Toolkit web site| last= | first= | work=| publisher=GitHub |date=| archive-url=https://web.archive.org/web/20160425100102/http://helix-toolkit.org/ | archive-date=2016-04-25|access-date=2016-04-25 }}</ref>\n;[http://www.monogame.net/ MonoGame]: free software used by game developers to make their [[Microsoft Windows|Windows]] and [[Windows Phone]] games run on other systems. It currently supports [[OS X]], [[Linux]], [[iOS]], [[Android (operating system)|Android]], [[PlayStation Mobile]], and the [[OUYA]] console. On Microsoft platforms it uses SharpDX and DirectX.<ref name=\"channel9.msdn.com\">[http://channel9.msdn.com/Events/Ch9Live/Channel-9-Live-at-BUILD-2012/Monogame-at-Build-2012 Monogame at Build 2012 | Channel 9 Live at BUILD 2012 | Channel 9<!-- Bot generated title -->]</ref> When targeting non-Microsoft platforms, platform specific capabilities are utilized by the OpenTK library. It is released under the [[Microsoft Public License]].\n;[[OpenTK|Open Toolkit]] (OpenTK): a low-level C# binding for [[OpenGL]], [[OpenGL ES]] and [[OpenAL]]. It runs on Windows, Linux, Mac OS X, BSD, Android and iOS. It can be used standalone or integrated into a GUI.\n;[[Windows Presentation Foundation]] (WPF): is a graphical subsystem for rendering user interfaces, developed by Microsoft. It also contains a 3D rendering engine. In addition, interactive 2D content can be overlaid on 3D surfaces natively.<ref>[http://msdn.microsoft.com/en-us/library/aa663364.aspx Introducing Windows Presentation Foundation]</ref><ref name=\"tims\">{{cite web | url = http://blogs.msdn.com/tims/archive/2007/07/27/what-s-new-in-wpf-3-5-here-s-fifteen-cool-features.aspx | title = What's New in WPF 3.5? Here's Fifteen Cool Features... | accessdate = 2007-10-14}}</ref> It only runs on Windows operating systems.\n;[https://code.videolan.org/videolan/LibVLCSharp LibVLCSharp ]:LibVLCSharp is a cross-platform audio and video API for .NET platforms based on [https://www.videolan.org/ VideoLAN]'s LibVLC Library. It provides a comprehensive multimedia API that can be used across mobile, server and desktop to render video and output audio as well as encode and stream. It works on Android, iOS, Windows, Mac and Linux.\n\n==== Proprietary 3D graphics libraries ====\n;[https://www.ab4d.com/PowerToys.aspx Ab3d.PowerToys]: a framework for .NET 3D with cameras, 3D models, 3D lines, 3D text and more.\n;[http://www.altsoftlab.com/altsketch.aspx AltSketch]: a pure C#, 100% managed Vector Graphics Library. It has integration with GUI systems and Mobile platforms.\n;[[Unity (game engine)|Unity]]: a [[cross-platform]] [[game engine]] developed by [[Unity Technologies]]<ref name=\"Riccitiello interview\">{{cite interview | interviewer=Dean Takahashi | first=John | last=Riccitiello | date=October 23, 2014| url=https://venturebeat.com/2014/10/23/john-riccitiello-sets-out-to-identify-the-engine-of-growth-for-unity-technologies-interview/|title=John Riccitiello sets out to identify the engine of growth for Unity Technologies (interview)|work=VentureBeat|accessdate=January 18, 2015}}</ref> and used to develop [[video game]]s for [[Personal computer|PC]], [[Video game console|consoles]], [[mobile device]]s and [[website]]s.\n\n=== Image processing ===\n;[[AForge.NET]]: a computer vision and artificial intelligence library.<ref name=\"AforgeEyetrackingVerma\">{{cite web |url=https://www.researchgate.net/publication/267769423_Real-time_Static_and_Dynamic_Hand_Gesture_Recognition_for_Human-Computer_Interaction |title=Real-time, Static and Dynamic Hand Gesture Recognition for Human-Computer Interaction | authors=S M Hassan Ahmed, Todd C Alexander, Georgios Anagnostopoulos | work= | publisher=University of Miami | date=May 2015 | archive-url=https://www.researchgate.net/publication/267769423_Real-time_Static_and_Dynamic_Hand_Gesture_Recognition_for_Human-Computer_Interaction |archive-date=2018-11-26 |access-date=2018-11-26 }}</ref><ref name=\"AforgeGestureAhmed\">{{cite web |url=https://www.academia.edu/3996497/Development_of_an_eye-tracking_control_system_using_AForge.NET_framework |title=Development of an eye-tracking control system using AForge.NET framework | authors=Suraj Verma, Prashant Pillai, Yim-Fun Hu | work=Int. J. Intelligent Systems Technologies and Applications, Vol. 11 | publisher=Inderscience Enterprises | date=2012 | archive-url=https://web.archive.org/web/20181126130207/http://www.academia.edu/3996497/Development_of_an_eye-tracking_control_system_using_AForge.NET_framework |archive-date=2018-11-26 |access-date=2018-11-26 }}</ref> It implements a number of image processing algorithms and filters. It is released under the [[LGPLv3]] and partly [[GPLv3]] license. Majority of the library is written in C# and thus cross-platform.{{citation needed|date=April 2016}} Functionality of AForge.NET has been extended by the [[Accord.NET]] library.<ref name=\"AforgeExtensionAccordSousa\">{{cite web |url=http://crsouza.com/2010/05/20/accord-net-framework-an-extension-to-aforge-net/ |title=Accord.NET Framework – An extension to AForge.NET | last=Souza| first=César | work= | publisher= | date=20 May 2010 | archive-url=http://crsouza.com/2010/05/20/accord-net-framework-an-extension-to-aforge-net/ |archive-date=2018-11-26 |access-date=2018-11-26 }}</ref><ref name=\"AccordModules\">{{cite web | url=http://accord-framework.net/docs/html/R_Project_Accord_NET.htm | title=Framework Modules| last=| first=| work=Accord.NET Framework documetation| publisher= | date=| archive-url=https://web.archive.org/web/20181126122705/http://accord-framework.net/docs/html/R_Project_Accord_NET.htm |archive-date=2018-11-26 |access-date=2018-11-26 }}</ref>\n;[[Accord.NET]]: another computer vision and artificial intelligence library, available under the [[GNU Lesser General Public License|Gnu Lesser General Public License]], version 2.1. It is mainly written in C#.\n\n=== Graphical user interface frameworks ===\n==== Open-source GUI frameworks ====\n;[https://github.com/AvaloniaUI/Avalonia Avalonia]\n: a cross-platform [[XAML]]-based user interface (UI) framework. It has been inspired by Microsoft's [[Windows Presentation Foundation|Windows Presentation Foundation (WPF)]] (which was codenamed Avalon at an early development stage), and beside XAML for definition of widget controls it also features flexible [[Cascading Style Sheets|CSS]] - like styling system (unlike the WPF's styling where styles are stored in the \"Resources\" collection). It supports the following operating systems: Windows (.NET Framework, .NET Core), Linux (GTK), MacOS, Android and iOS. It is released under the [[MIT license]]. Avalonia is currently in beta stage.<ref name=\"AvaloniaScott\">{{cite web | url=https://www.hanselman.com/blog/WhatWouldACrossplatformNETUIFrameworkLookLikeExploringAvalonia.aspx| title=What would a cross-platform .NET UI Framework look like? Exploring Avalonia| last=Hanselman| first=Scott | work=| publisher= | date=September 2017| archive-url=https://www.hanselman.com/blog/WhatWouldACrossplatformNETUIFrameworkLookLikeExploringAvalonia.aspx |archive-date=2018-11-26 |access-date=2018-11-26 }}</ref><ref name=\"CrossPlatformUiDotNetLexLi\">{{cite web | url=https://blog.lextudio.com/the-story-about-net-cross-platform-ui-frameworks-dd4a9433d0ea | title=The Story About .NET Cross Platform UI Frameworks |author=Lex Li | work=3 July 2017  | publisher= | date= | archive-url=https://blog.lextudio.com/the-story-about-net-cross-platform-ui-frameworks-dd4a9433d0ea?gi=ed6c9cc36c51  |archive-date=2018-11-26 |access-date=2018-11-26 }}</ref>\n\n;[https://github.com/picoe/Eto Eto.Forms]\n: a cross-platform desktop and mobile user interface framework released under the [[BSD license]].<ref name=\"EtoFormsWade\">{{cite web | url=https://dotnetcoretutorials.com/2018/03/19/cross-platform-winforms-kinda/ | title=Cross Platform WinForms (Kinda) |author=Wade | work=.NET Core Tutorials | publisher= | date=19 March 2018 | archive-url=https://web.archive.org/web/20181126153207/https://dotnetcoretutorials.com/2018/03/19/cross-platform-winforms-kinda/ |archive-date=2018-11-26 |access-date=2018-11-26 }}</ref><ref name=\"CrossPlatformUiDotNetLexLi\" />\n\n;[[Gtk Sharp|Gtk#]]\n: C# wrappers around the underlying [[GTK+]] and [[GNOME]] libraries, written in [[C (programming language)|C]] and available on Linux, MacOS and Windows.<ref name=\"CrossPlatformUiDotNetLexLi\" />\n\n;[https://github.com/ddobrev/QtSharp QtSharp]\n: C# bindings for the [[Qt (framework)|Qt framework]].<ref name=\"CrossPlatformUiDotNetLexLi\" />\n\n;[https://platform.uno/ Uno Platform]\n: an open source cross-platform graphical user interface for building applications that allow Universal Windows Platform - based code to run on [[iOS]], [[Android (operating system)|Android]], and [[WebAssembly]].<ref name=\"BillsonUno\">{{cite web |url=https://hackernoon.com/cross-platform-mobile-apps-with-net-and-uno-dee2b024281d | title=Cross Platform Mobile Apps with .NET and Uno | last=Billson| first=Alex | work= | publisher= | date=15 Jul 2018 | archive-url=  | archive-date=2019-01-20|access-date=2019-01-20 }}</ref>\n:Platform is released under the [[Apache 2.0]] license.\n\n;[[Windows Forms]]\n: a Microsoft's GUI framework. The original Microsoft implementation runs on Windows operating systems and provides access to [[Windows USER|Windows User Interface]] Common Controls by [[Wrapper pattern|wrapping]] the [[Windows API]] in [[managed code]].<ref name=DeSmet/> The alternative [[Mono (software)|Mono]]'s implementation is open source and cross-platform (it runs on Windows, Linux, Unix and OS X). It is mainly compatible with the original implementation but not completely. The library is written in C# in order to avoid Windows dependence.<ref name=\"GuiToolkitsMono\"/> \n\n:At the [[Microsoft Connect]] event on December 4, 2018, [[Microsoft]] announced releasing of Windows Forms as open source project on [https://github.com/dotnet/winforms GitHub]. It is released under the [[MIT License]]. Windows Forms has become available for projects targeting the [[.NET Core]] framework. However, the framework is still available only on Windows platform and the Mono's incomplete implementation of WinForms remains the only cross-platform implementation.<ref name=\"OpenSourcingGuiMartin\">{{cite web |url=https://www.infoq.com/news/2018/12/msft-open-source-wpf-winforms | title=Microsoft Open Sources WPF, WinForms, and WinUI | last=Martin  | first=Jeff | work=InfoQ | publisher= | date=4 December 2018| archive-url=  | archive-date=2018-12-06|access-date=2018-12-06 }}</ref><ref name=\"OpenSourcingGuiHanselman\">{{cite web |url=https://www.hanselman.com/blog/AnnouncingWPFWinFormsAndWinUIAreGoingOpenSource.aspx | title=Announcing WPF, WinForms, and WinUI are going Open Source | last=Hanselman | first=Scott | work= | publisher= | date=4 December 2018| archive-url=  | archive-date=2018-12-06|access-date=2018-12-06 }}</ref>\n\n;[[Windows Presentation Foundation]]: a graphical subsystem for rendering user interfaces in Windows-based applications by Microsoft. It is based on [[DirectX]] and employs XAML, an XML-based language, to define and link various interface elements.<ref Name=WpfXamlOverview>[http://msdn.microsoft.com/en-us/library/ms752059.aspx MSDN.NET Development: WPF: XAML Overview]</ref> WPF applications can be deployed as standalone desktop programs or hosted as an embedded object in a website.{{citation needed|date=April 2016}}\n:At the [[Microsoft Connect]] event on December 4, 2018, [[Microsoft]] announced releasing of WPF as open source project on [https://github.com/dotnet/wpf?WT.mc_id=-blog-scottha GitHub]. It is released under the [[MIT License]]. Windows Presentation Foundation has become available for projects targeting the [[.NET Core]] framework. However, the system is still available only on Windows platform.<ref name=\"OpenSourcingGuiMartin\" /><ref name=\"OpenSourcingGuiHanselman\" />\n\n;The Windows UI Library (WinUI): a set of Microsoft UI controls and features for the [[Universal Windows Platform]] (UWP). At the [[Microsoft Connect]] event on December 4, 2018, [[Microsoft]] announced releasing of WinUI as open source project on [https://github.com/Microsoft/microsoft-ui-xaml?WT.mc_id=-blog-scotthaa GitHub]. WinUI has become available for projects targeting the [[.NET Core]] framework. It is released under the [[MIT License]]. However, the library is still available only on Windows platform.<ref name=\"OpenSourcingGuiMartin\" /><ref name=\"OpenSourcingGuiHanselman\" />\n\n;[[Xwt (toolkit)|Xwt]]: a GUI toolkit that maps API calls to native platform calls of the underlying platform, exposing one unified API across different platforms and making possible for the graphical user interfaces to have native look and feel on different platforms.<ref name=\"CrossPlatformUiDotNetLexLi\" />\n\n==== Proprietary GUI frameworks ====\n;Xamarin.Forms: a cross-platform UI toolkit for development of native user interfaces that can be run on iOS, Android, and Universal Windows Platform apps. <ref name=\"XamarinFormsMsDocs\">{{cite web | url=https://docs.microsoft.com/en-us/xamarin/xamarin-forms/get-started/hello-xamarin-forms/quickstart?pivots=windows | title=Xamarin.Forms Quickstart |authors= | work=Microsoft Docs  | publisher=Microsoft | date=  | archive-url= |archive-date=2018-11-26 |access-date=2018-11-26 }}</ref><ref name=\"XamarinFormsWilliams\">{{cite web | url=https://arctouch.com/blog/xamarin-forms-more-capable-than-you-think/ | title=Xamarin.Forms is Much More Capable Than You Think |author=Nathan Williams | work= | publisher=ArcTouch | date=  | archive-url=https://web.archive.org/web/20181126155602/https://arctouch.com/blog/xamarin-forms-more-capable-than-you-think/ |archive-date=2018-11-26 |access-date=2018-11-26 }}</ref><ref name=\"CrossPlatformUiDotNetLexLi\" />\n\n=== Security and identity management ===\n;[https://github.com/NWebsec/NWebsec NWebsec]: Security headers for ASP.NET apps.\n;[https://github.com/IdentityManager/IdentityManager IdentityManager]: a tool for developers and/or administrators to manage the identity information for users of their applications\n;[https://github.com/IdentityServer/IdentityServer4 IdentityServer]: a free, open source OpenID Connect and OAuth 2.0 framework for ASP.NET Core\n;[https://skgl.codeplex.com/ Serial Key Generating Library (SKGL)]: a very simple licensing system that might be used to protect .NET Apps\n;[https://github.com/sshnet/SSH.NET SSH.NET]: client-side library for [[Secure Shell|SSH]], [[Secure copy|SCP]] and [[SSH File Transfer Protocol|SFTP]]. It does not contain third party dependencies and is released under the [[BSD License]].\n\n=== Quality assurance ===\n;[https://github.com/fscheck/FsCheck FsCheck]: a random testing framework for testing .NET programs automatically. It is a port of Haskell's [[QuickCheck]].\n;[[NUnit]]: an [[Open-source software|open source]] [[unit testing]] [[software framework|framework]] for .NET, written in C# and thus cross-platform. It is one of many programs in the [[xUnit]] family. Licensed under [[MIT License]].\n\n;[https://msdn.microsoft.com/en-us/library/ms243147%28vs.80%29.aspx Microsoft Unit Testing Framework]: part of  Visual Studio, only available on Windows platforms.\n\n=== Object-relational mapping ===\n.NET Framework natively provides utilities for object-relational mapping<ref name=\"OrmAmbler\">{{cite web | url=http://www.agiledata.org/essays/mappingObjects.html | title=Mapping Objects to Relational Databases: O/R Mapping In Detail | last=Ambler | first=Scott | work= | publisher=Agile Data | date= | archive-url=https://web.archive.org/web/20181103222615/http://www.agiledata.org/essays/mappingObjects.html | archive-date=2018-11-03 |access-date=2018-11-03 }}</ref> through [[ADO.NET]], a part of .NET stack since .NET 1.0. In addition, a number of third-party object-relational libraries have emerged, especially in earlier years of the .NET development, in order to fill some perceived gaps of the framework.<ref name=\"OrmMaksimovic\">{{cite web | url=https://www.agile-code.com/blog/microsoft-net-or-mapper-choose-your-own/ | title=Microsoft.NET O/R mapper: choose your own! | last=Maksimovic | first=Zoran | work=| publisher=agile-code.com  | date=November 2, 2017 | archive-url=https://web.archive.org/web/20181103220259/https://www.agile-code.com/blog/microsoft-net-or-mapper-choose-your-own/ | archive-date=2018-11-03 |access-date=2018-11-03 }}</ref><ref name=\"OrmBala\">{{cite web | url=https://baladotnettips.wordpress.com/2014/02/28/list-of-orms-available-for-net/ | title=List of ORM’s available for .NET | last= | first= | work=Bala.NET Tips | publisher=WordPress | date=February 28, 2014 | archive-url=https://baladotnettips.wordpress.com/2014/02/28/list-of-orms-available-for-net/ | archive-date=2018-11-03 |access-date=2018-11-03 }}</ref><ref name=\"OrmComparision\">{{cite web | url=http://wiki.c2.com/?ObjectRelationalToolComparisonDotNet | title=Object Relational Tool Comparison Dot Net | last= | first= | work= | publisher=WikiWikiWeb | date=April 10, 2014 | archive-url=https://web.archive.org/web/20181103222039/http://wiki.c2.com/?ObjectRelationalToolComparisonDotNet | archive-date=2018-11-03 |access-date=2018-11-03 }}</ref>\n\nAs the framework has evolved, additional object-relational tools were added, such as the [[Entity Framework]] included with the [[ .NET Framework 3.5]]. [[LINQ to SQL]] was also introduced with .NET 3.5.  This somehow reduced significance and popularity of third-party object-relational libraries. \n\n==== Open source object-relational mapping tools ====\n;[[Entity Framework]]: an open source<ref>{{cite news|last=Krill|first=Paul|url=http://www.infoworld.com/d/application-development/microsoft-open-sources-entity-framework-198213|title=Microsoft open-sources Entity Framework|accessdate=24 July 2012|newspaper=InfoWorld|date=20 July 2012}}</ref> [[Object-relational mapping|object-relational mapping (ORM)]] framework for [[ADO.NET]].  It was a part of [[.NET Framework]], but since Entity framework version 6 it is separated from .NET framework.\n;[http://www.brothersoft.com/nconstruct-lite-333381.html NConstruct Lite]: a desktop and web rapid application development tool and environment for [[.NET Framework]], containing an extensive library for [[Object-relational mapping|ORM]].<ref name=\"NConstructGitHub\">{{cite web | url=https://www.openhub.net/p/NConstruct-Lite | title=NConstruct Lite - Project summary on GitHub| last= | first= | work=| publisher= GitHub| date=| archive-url=https://web.archive.org/web/20160528112838/https://www.openhub.net/p/NConstruct-Lite | archive-date=2016-05-28|access-date=2016-05-28 }}</ref>\n;NHibernate: [[NHibernate]] is an object-relational mapper for the .NET platform.\n;SQLProvider:  an ORM-like-tool for F# language and SQL databases.\n\n==== Proprietary object-relational mapping tools ====\n;[http://dataobjects.net/ DataObjects.NET]: an object-relational mapper and business logic layer development framework for .NET projects. The framework focuses on non-trivial domain models with deep inheritance and composite objects,  and on code-first, test-driven development. It is a proprietary library that comes with source code, and community edition of the library is available for free.\n\n=== Serialization and data formats ===\n.NET Framework comes with a wide set of utilities for [[serialization]] of objects. The framework provides native object serialization to and from XML, JSON and binary streams. In spite of that, there are numerous third-party libraries that support serialization to target formats and working with these formats.\n\n;[https://www.newtonsoft.com/json Json.NET]: a JSON framework for the .NET platform. Beside serialization and deserialization of arbitrary objects, it features numerous utilities for working with JSON documents. One can compose the  object structures that map to JSON documents, save them to strings, streams or files, reload object structures from streams, traverse the structures, find parts by using JSON Path (an analogue to XPath in XML), convert JSON documents to XML documents, etc.\n\n== See also ==\n* [[.NET Framework]]\n* [[Library (computing)|Library]]\n* [[List of numerical libraries]]\n** [[List of numerical libraries#.NET Framework languages C.23.2C F.23.2C VB.NET and PowerShell|List of Numerical Libraries for .NET]]\n* [[Standard Libraries (CLI)]]\n** [[Base Class Library]] (BCL)\n* [[List of CLI languages]]\n\n== Notes ==\n{{Notelist}}\n{{reflist|group=notes}}\n\n== References ==\n{{Reflist|30em}}\n\n== External links ==\nGeneral:\n* [https://github.com/Microsoft/dotnet/blob/master/dotnet-developer-projects.md .NET Open Source Developer Projects], a list maintained at [[GitHub]]\n* [https://github.com/quozd/awesome-dotnet Awesome .NET], a collection of .NET libraries, tools, frameworks, and software, maintained at  [[GitHub]]\n* [http://scottge.net/2015/07/08/a-complete-list-of-net-open-source-developer-projects/ A Complete List of .NET Open Source Developer Projects], a comprehensive list of open source projects based on .NET.\nNumerical libraries:\n* [http://mathforum.org/library/topics/num_analysis/ The Math Forum - Math Libraries], an extensive list of mathematical libraries with short descriptions\n* [http://fsharp.org/guides/math-and-statistics/ Guide - Math and Statistics Programming with F#]\nData:\n* [http://c2.com/cgi/wiki?ObjectRelationalMapping Object Relational Mapping]\n* [http://www.dotnet-akademie.de/dotnet/Artikel/DOTNET_ORM_Comparison.pdf Comparison of Object Relational Mapping Tools for the .NET Framework]\n\n[[Category:.NET Framework software]]\n[[Category:Computer programming tools]]\n[[Category:Lists of software|.NET libraries and frameworks]]\n[[Category:Computer libraries]]\n[[Category:Numerical libraries]]\n[[Category:Graphics libraries]]\n[[Category:Free and open-source software]]"
    },
    {
      "title": "GNU MPFR",
      "url": "https://en.wikipedia.org/wiki/GNU_MPFR",
      "text": "{{Infobox software\n| name                   = GNU MPFR\n| title                  = GNU MPFR\n| logo                   = Mpfr.svg\n| logo size              = 180px\n| screenshot             = GNOME Calculator 3.32 screenshot.png\n| caption                = GNOME Calculator, which uses MPFR as of version 3.15.4\n| collapsible            = \n| author                 = \n| developer              = [[INRIA]] and others\n| released               = <!-- {{Start date|YYYY|MM|DD|df=yes/no}} -->\n| discontinued           = \n| latest release version = 4.0.2\n| latest release date    = {{Start date and age|2019|1|31}}\n| latest preview version = \n| latest preview date    = <!-- {{Start date and age|YYYY|MM|DD|df=yes/no}} -->\n| programming language   = \n| operating system       = \n| platform               = \n| size                   = \n| language               = \n| status                 = \n| genre                  = [[Mathematical software]]\n| license                = [[GNU Lesser General Public License|LGPL]]\n| website                = {{URL|https://www.mpfr.org/}}\n}}\n{{Portal|Free and open-source software}}\n'''GNU MPFR''' ('''GNU Multiple Precision Floating-Point Reliably'''<ref>{{cite journal\n|first1 = L. |last1 = Fousse\n|first2 = G. |last2 = Hanrot\n|first3 = V. |last3 = Lefèvre\n|first4 = P. |last4 = Pélissier\n|first5 = P. |last5 = Zimmermann\n|title = MPFR: A multiple-precision binary floating-point library with correct rounding\n|journal = ACM Transactions on Mathematical Software (TOMS)\n|year = 2007 |volume = 33 |number = 2 |pages = 13:1–15\n|doi = 10.1145/1236463.1236468\n}}\n</ref>) is a [[GNU]] portable [[C (programming language)|C]] [[Library (computing)|library]] for [[Arbitrary-precision arithmetic|arbitrary-precision]] binary [[Floating-point arithmetic|floating-point]] computation with [[rounding#Table-maker's dilemma|correct rounding]], based on [[GNU Multiple Precision Arithmetic Library|GNU Multi-Precision Library]]. The computation is both efficient and has a well-defined semantics: the functions are completely specified on all the possible operands and the results do not depend on the platform. This is done by copying the ideas from the [[IEEE 754|ANSI/IEEE-754]] standard for fixed-precision floating-point arithmetic (correct rounding and exceptions, in particular). More precisely, its main features are:\n* Support for special numbers: [[signed zero]]s (+0 and −0), [[Infinity#Computing|infinities]] and [[NaN|not-a-number]] (a single NaN is supported).\n* Each number has its own [[Precision (computer science)|precision]] (in bits since MPFR uses [[radix]] 2). The floating-point results are correctly rounded to the precision of the target variable, in one of the five supported rounding modes (including the four from [[IEEE 754-1985]]).\n* Supported functions: MPFR implements all mathematical functions from [[C99]] and other usual mathematical functions: the [[logarithm]] and [[Exponential function|exponential]] in natural base, base 2 and base 10, the log(1+x) and exp(x)−1 functions (<code>log1p</code> and <code>expm1</code>), the six [[Trigonometric functions|trigonometric]] and [[Hyperbolic function|hyperbolic]] functions and their inverses, the [[Gamma function|gamma]], [[Riemann zeta function|zeta]] and [[error function]]s, the [[arithmetic–geometric mean]], the [[Exponentiation|power]] (x<sup>y</sup>) function. All those functions are correctly rounded over their complete range.\n* [[Denormal number|Subnormals]] are not supported, but can be emulated with the <code>mpfr_subnormalize</code> function.\n\nMPFR is not able to track the [[Accuracy and precision|accuracy]] of numbers in a whole program or expression; this is not its goal. [[Interval arithmetic]] packages like [http://arblib.org/ Arb], [https://gforge.inria.fr/projects/mpfi/ MPFI], or [[Real RAM]] implementations like [http://irram.uni-trier.de/ iRRAM], which may be based on MPFR, can do that for the user.\n\nMPFR is needed to build the [[GNU Compiler Collection]] (GCC).<ref>{{cite web\n| url=https://gcc.gnu.org/gcc-4.3/changes.html#mpfropts\n| title=GCC 4.3 Release Series: Changes, New Features, and Fixes\n| date=2012-11-02\n| accessdate=2013-09-25}}</ref>\n\n==References==\n{{reflist}}\n\n==External links==\n* [https://www.mpfr.org/ Official MPFR web site]\n* [https://gforge.inria.fr/projects/mpfr/ MPFR project page]\n\n{{DEFAULTSORT:Mpfr}}\n[[Category:C libraries]]\n[[Category:Computer arithmetic]]\n[[Category:Free software programmed in C]]\n[[Category:GNU Project software]]\n[[Category:Numerical libraries]]\n[[Category:Software using the LGPL license]]"
    },
    {
      "title": "NAG Numerical Library",
      "url": "https://en.wikipedia.org/wiki/NAG_Numerical_Library",
      "text": "{{primary sources|date=April 2012}}\nThe '''NAG Numerical Library''' is a software product developed and sold by [[The Numerical Algorithms Group Ltd|The Numerical Algorithms Group]]. It is a [[library (computer science)|software library]] of [[numerical analysis]] routines, containing more than 1,700 mathematical and statistical algorithms.  Areas covered by the library include [[linear equations|linear algebra]], [[Optimization problem|optimization]], [[Numerical integration|quadrature]], the solution of [[ordinary differential equation|ordinary]] and [[partial differential equations]], [[regression analysis]], and [[time series analysis]].\n\nUsers of the NAG Library call its routines from within their applications in order to incorporate its mathematical or statistical functionality and to solve numerical problems - for example, [[Optimization problem|finding the minimum or maximum of a function]], [[Curve fitting|fitting a curve or surface to data]], or [[ordinary differential equation|solving a differential equation]].  The Library is available in the many forms, but namely the NAG C Library,<ref>[http://www.nag.co.uk/numeric/CL/CLdescription.asp NAG C Library]</ref> the NAG Fortran Library,<ref>[http://www.nag.co.uk/numeric/fl/FLdescription.asp NAG Fortran Library]</ref> and the NAG Library for .NET.<ref>[http://www.nag.co.uk/netdevelopers.asp NAG Library for .NET]</ref> Its contents are accessible from several computing environments, including standard languages such as [[C (programming language)|C]], [[C++]], [[Fortran]], [[Visual Basic]], [[Java (programming language)|Java]], Python and [[C Sharp (programming language)|C#]], as well as packages such as [[MATLAB]], [[R (programming language)|R]], [[LabVIEW]], [[Microsoft Excel|Excel]], [[Origin (data analysis software)|Origin]] and [[Ch (computer programming)|Ch]].<ref>[http://www.softintegration.com/products/package/statistics/ Ch NAG Statistics Package]</ref> \nSupported operating systems include the 32 bit and 64 bit versions of [[Windows (operating system)|Windows]],  [[Linux]] and [[macOS]], as well as [[Solaris (operating system)|Solaris]], [[AIX (operating system)|AIX]] and [[HP-UX]].\n\n== History ==\n{{See also|Numerical Algorithms Group#Origins}}\nThe original version of the NAG Library was written in [[Algol 60]] and [[Fortran]].  It contained 98 user-callable routines, and was released for the [[International Computers Limited|ICL]] [[ICT 1900 series#1900 A series|1906A]] and [[ICT 1900 series#The 1900 S series|1906S]] machines on October 1, 1971.  Three further Marks of the library appeared in the following five years; during this time the Algol version was ported to Algol 68, with the following platforms being supported: [[CDC 7600]]/[[CDC Cyber|CYBER]] ([[Control Data Corporation|CDC]] [[ALGOL 68]]), [[IBM 360]]/370/AMDAHL ([[FLACC]] [[ALGOL 68]]), [[ICT 1900 series|ICL 1900]] ([[ALGOL 68R]]), ICL 1906A/S ([[ALGOL 68R]]), ICL 2900 ([[ALGOL 68RS]]) and [[Telefunken]] TR440 ([[ALGOL 68C]]).\n\nThe first partially [[Vector processor|vectorized]] implementation of the NAG Fortran Library for the [[Cray-1]] was released in 1983, while the first release of the NAG Parallel Library<ref>[http://www.nag.co.uk/numeric/fd/FDdescription.asp NAG Parallel Library]</ref> (which is specially designed for [[distributed memory]] parallel computer architectures) was in the early 1990s.  Mark 1 of the NAG C Library was released in 1990.  In 1992, the Library incorporated [[LAPACK]] routines for the first time; NAG had been a collaborator in the LAPACK project since 1987.  The first release of the NAG Library for SMP & multicore,<ref>[http://www.nag.co.uk/numeric/FL/FSdescription.asp NAG Library for SMP & multicore]</ref> which takes advantage of the [[Shared memory architecture|shared memory]] parallelism of [[SMP - Symmetric Multiprocessor System|Symmetric Multi-Processors]] (SMP) and [[Multi-core processor|multicore processors]], appeared in 1997 for multiprocessor machines built using the [[DEC Alpha|Dec Alpha]] and [[SPARC]] architectures. The NAG Library for .NET, which is a [[Assembly (CLI)|CLI DLL assembly]] containing methods and objects that give [[Common Language Infrastructure]] (CLI) users access to NAG algorithms, was first released in 2010.\n\n== Current version ==\nThe NAG Library houses over 1,700 mathematical and statistical algorithms organised into Chapters.  \n\n== See also ==\n*[[List of numerical analysis software]]\n*[[List of numerical libraries]]\n\n==References==\n{{reflist}}\n\n==External links==\n*[http://www.nag.com/numeric/numerical_libraries.asp NAG Numerical Libraries]\n\n[[Category:Numerical libraries]]"
    },
    {
      "title": "Trilinos",
      "url": "https://en.wikipedia.org/wiki/Trilinos",
      "text": "{{Infobox software\n| name                   = Trilinos\n| logo                   = \n| screenshot             =\n| caption                =\n| author                 =\n| developer              = [[Sandia National Laboratories]]\n| released               =\n| latest release version = 12.14.1\n| latest release date    = {{Start date and age|2019|02|27}}\n| genre                  = \n| license                = [[BSD licences|Modified BSD license]], [[GNU Lesser General Public License]]\n| language               = [[C++]] and [[C (programming language)|C]]\n| website                = {{URL|trilinos.org}}\n}}\n'''Trilinos''' is a collection of [[open-source software|open-source]] [[software libraries]], called ''packages'', intended to be used as building blocks for the development of scientific applications. The word \"Trilinos\" is Greek and conveys the idea of \"a string of pearls\", suggesting a number of software packages linked together by a common infrastructure.  Trilinos was developed at [[Sandia National Laboratories]] from a core group of existing algorithms and utilizes the functionality of software interfaces such as the [[BLAS]], [[LAPACK]], and [[Message Passing Interface|MPI]] (the message-passing interface for distributed-memory parallel programming).<ref name=\"Sandia\">{{cite web\n  | title = The Trilinos Project\n  | publisher = Sandia National Laboratories\n  | url = http://trilinos.org/\n  | accessdate =  2014-06-24}}</ref><ref name=\"Trilinos ACM TOMS\">{{cite journal|last1=Heroux|first1=Michael A.|last2=Bartlett|first2=Roscoe A.|last3=Howle|first3=Vicki E.|last4=Hoekstra|first4=Robert J.|last5=Hu|first5=Jonathan J.|last6=Kolda|first6=Tamara G.|authorlink6=Tamara G. Kolda|last7=Lehoucq|first7=Richard B.|last8=Long|first8=Kevin R.|last9=Pawlowski|first9=Roger P.|last10=Phipps|first10=Eric T.|last11=Salinger|first11=Andrew G.|last12=Thornquist|first12=Heidi K.|last13=Tuminaro|first13=Ray S.|last14=Willenbring|first14=James M.|last15=Williams|first15=Alan|last16=Stanley|first16=Kendall S.|title=An overview of the Trilinos project|journal=ACM Trans. Math. Softw.|date=2005|volume=31|issue=3|pages=397–423|doi=10.1145/1089014.1089021|citeseerx=10.1.1.150.5502}}</ref><ref name=\"RCE 49: Trilinos\">{{cite web|last1=Palen|first1=Brock|last2=Squyres|first2=Jeff|last3=Heroux|first3=Mike|last4=Willenbring|first4=Jim|title=RCE 49: Trilinos|url=http://www.rce-cast.com/Podcast/rce-49-trilinos.html|website=Research, Computing, and Engineering (RCE) Podcast|accessdate=24 June 2014}}</ref>\n\nSeveral supercomputing facilities provide an installed version of Trilinos for their users.  These include the [[National Energy Research Scientific Computing Center]] (NERSC),<ref>{{cite web|title=Trilinos|url=http://www.nersc.gov/users/software/programming-libraries/math-libraries/trilinos/|website=National Energy Research Scientific Computing Center (NERSC)|accessdate=24 June 2014}}</ref> Blue Waters at the [[National Center for Supercomputing Applications]],<ref>{{cite web|title=Trilinos|url=https://bluewaters.ncsa.illinois.edu/trilinos|website=Blue Waters: Sustained Petascale Computing|publisher=National Center for Supercomputing Applications (NCSA)|accessdate=24 June 2014}}</ref> and the [[Titan (supercomputer)|Titan supercomputer]] at [[Oak Ridge National Laboratory]].<ref>{{cite web|title=Trilinos|url=https://www.olcf.ornl.gov/kb_articles/software-trilinos/|website=Oak Ridge Leadership Computing Facility|publisher=Oak Ridge National Laboratory|accessdate=24 June 2014}}</ref>  [[Cray]] supercomputers come with Trilinos installed as part of the Cray Scientific and Math Libraries.<ref name=\"Cray LibSci\">{{cite web|title=Cray Programming Environment User's Guide|url=http://docs.cray.com/cgi-bin/craydoc.cgi?mode=View;id=S-2529-116;idx=books_search;this_sort=release_date%20desc;q=Trilinos;type=books;title=Cray%20Programming%20Environment%20User%27s%20Guide|website=CRAYDOC: Customer Documentation|publisher=Cray Inc.|accessdate=24 June 2014}}</ref>\n\n== Features ==\n\nTrilinos contains packages for:\n* Constructing and using [[Sparse matrix|sparse graphs and matrices]], and dense matrices and vectors.\n* Iterative and direct solution of [[linear system]]s.\n* Parallel multilevel and algebraic [[preconditioning]].\n* Solution of non-linear, [[eigenvalue]] and time-dependent problems.\n* [[partial differential equation|PDE]]-constrained [[optimization problem]]s.\n* Partitioning and [[Load balancing (computing)|load balancing]] of distributed data structures.\n* Automatic differentiation.\n* Discretizing partial differential equations.\n\nTrilinos supports distributed-memory parallel computation through the [[Message Passing Interface]] (MPI).  In addition, some Trilinos packages have growing support for shared-memory parallel computation.  They do so by means of the Kokkos package in Trilinos, which provides a common C++ interface over various parallel programming models, including [[OpenMP]], [[POSIX Threads]], and [[CUDA]].\n\n== Programming languages ==\n\nMost Trilinos packages are written in [[C++]].  Trilinos version 12.0 and later requires C++11 support.  Some Trilinos packages, like ML and Zoltan, are written in [[C (programming language)|C]].  A few packages, like Epetra, have optional implementations of some computational kernels in [[Fortran]], but Fortran is not required to build these packages.\n\nSome Trilinos packages have bindings for other programming languages.  These include Python, C, Fortran, and Matlab.\n\n== Software licenses ==\n\nEach Trilinos package may have its own software license.  Most packages are [[Open-source software|Open-source]]; most of these have a [[BSD licences|Modified BSD license]], while a few packages are under the [[GNU Lesser General Public License]] (LGPL).  The [[Basic Linear Algebra Subprograms|BLAS]], and [[LAPACK]] libraries are required dependencies.<ref name=\"Sandia\"/>\n\n== See also ==\n{{Portal|Free and open-source software}}\n* [[BLAS]]\n* [[LAPACK]]\n* [[Message Passing Interface]]\n* [[List of numerical analysis software]]\n* [[Sandia National Laboratories]]\n\n== References ==\n{{Reflist}}\n\n== External links ==\n* {{official website|http://trilinos.org}}\n\n[[Category:Numerical libraries]]\n[[Category:Concurrent programming libraries]]\n[[Category:Free mathematics software]]\n[[Category:C++ numerical libraries]]"
    },
    {
      "title": "Adept (C++ library)",
      "url": "https://en.wikipedia.org/wiki/Adept_%28C%2B%2B_library%29",
      "text": "{{Infobox software\n| name = Adept C++ Library\n| logo = The Adept logo.png\n| developer = Robin Hogan\n| latest release version = 2.0.5\n| latest release date = {{start date and age|df=yes|paren=yes|2018|2|6}}\n| latest preview version = \n| latest preview date = \n| programming language = [[C++]]\n| operating system = [[Cross-platform]]\n| genre = [[Library (computing)|Library]]\n| license = [[Apache License|Apache 2.0]] ([[Open-source software|open source]])\n| website = {{URL|http://www.met.reading.ac.uk/clouds/adept/}}\n}}\n'''Adept''' is a combined [[automatic differentiation]] and [[Array programming|array]] software library for the [[C++|C++ programming language]]. The automatic differentiation capability facilitates the development of applications involving [[mathematical optimization]]. Adept is notable for having applied the [[template metaprogramming]] technique of [[expression templates]] to speed-up the differentiation of mathematical statements.<ref name=hogan2014>{{cite journal|last=Hogan|first=Robin J.|title=Fast reverse-mode automatic differentiation using expression templates in C++|journal=ACM Trans. Math. Softw.|year=2014|volume=40|issue=4|pages=26:1–26:16|url=http://www.met.reading.ac.uk/%7Eswrhgnrj/publications/adept.pdf}}</ref><ref>{{cite journal|first=Andreas|last=Griewank|year=2014|title=On automatic differentiation and algorithmic linearization|journal=Pesquisa Operacional|volume=34|issue=3|pages=621–645|doi=10.1590/0101-7438.2014.034.03.0621}}</ref> Along with the efficient way that it stores the differential information, this makes it significantly faster than most other C++ tools that provide similar functionality (e.g. ADOL-C, CppAD and FADBAD),<ref name=hogan2014/><ref name=carpenter>{{cite arXiv|first=Bob|last=Carpenter|title=The Stan Math Library: Reverse-Mode Automatic Differentiation in C++|eprint=1509.07164|class=cs.MS|year=2015}}</ref><ref>{{cite web|url=https://www.xcelerit.com/computing-benchmarks/software/aad/|title=Sensitivities in Quantitative Finance: Libor Swaption Portfolio Pricer (Monte-Carlo)|accessdate=2017-10-21|date=2016-12-02}}</ref><ref>{{cite thesis|title=Discrete controls and constraints in optimal control problems|type=PhD Thesis|first=Matthias|last=Rieck|publisher=Technical University of Munich|accessdate=2017-10-21|url=https://mediatum.ub.tum.de/doc/1316413/1316413.pdf}}</ref><ref name=zhao>{{cite thesis|title=Stochastic volatility models with applications in finance|url=http://ir.uiowa.edu/cgi/viewcontent.cgi?article=6780&context=etd|first=Ze|last=Zhao|accessdate=2017-10-27|publisher=University of Iowa}}</ref> although comparable performance has been reported for [[Stan (software)|Stan]] and in some cases Sacado.<ref name=carpenter/> Differentiation may be in forward mode, reverse mode (for use with a [[Quasi-Newton method|Quasi-Newton]] minimization scheme), or the full [[Jacobian matrix]] may be computed (for use with the [[Levenberg–Marquardt algorithm|Levenberg-Marquardt]] or [[Gauss-Newton algorithm|Gauss-Newton]] minimization schemes).\n\nApplications of Adept have included [[financial modeling]],<ref name=zhao/><ref>{{cite arXiv|first=Gilles|last=Pagès|first2=Olivier|last2=Pironneau|first3=Guillaume|last3=Sall|title=Vibrato and automatic differentiation for high order derivatives and sensitivities of financial options|eprint=1606.06143|class=q-fin.CP|year=2016}}</ref> [[computational fluid dynamics]],<ref>{{cite conference|first=T.|last=Albring|first2=M.|last2=Sagebaum|first3=N. R.|last3=Gauger|year=2016|title=A Consistent and Robust Discrete Adjoint Solver for the SU2 Framework—Validation and Application|editor-first=A.|editor-last=Dillmann|editor-first2=G.|editor-last2=Heller|editor-first3=E.|editor-last3=Krämer|editor-first4=C.|editor-last4=Wagner|editor-first5=C.|editor-last5=Breitsamter|series=New Results in Numerical and Experimental Fluid Mechanics X. Notes on Numerical Fluid Mechanics and Multidisciplinary Design|volume=132|publisher=Springer, Cham|doi=10.1007/978-3-319-27279-5_7}}</ref> [[physical chemistry]],<ref>{{cite journal|first=Kyle E.|last=Niemeyer|first2=Nicholas J.|last2=Curtis|first3=Chih-Jen|last3=Sung|title=pyJac: Analytical Jacobian generator for chemical kinetics|journal=Comput. Phys. Commun.|volume=215|year=2017|pages=188–203|arxiv=1605.03262|bibcode=2017CoPhC.215..188N|doi=10.1016/j.cpc.2017.02.004}}</ref> [[parameter estimation]]<ref>{{cite journal|title=Boosting Bayesian parameter inference of nonlinear stochastic differential equation models by Hamiltonian scale separation|first=Carlo|last=Albert|first2=Simone|last2=Ulzega|first3=Ruedi|last3=Stoop|journal=Phys. Rev. E|volume=93|issue=43313|pages=043313|year=2016|arxiv=1509.05305|doi=10.1103/PhysRevE.93.043313|pmid=27176434}}</ref> and [[meteorology]].<ref>{{cite journal|first=S.|last=Mason|first2=J.-C.|last2=Chiu|first3=R. J.|last3=Hogan|first4=D.|last4=Moisseev|first5=S.|last5=Kneifel|title=Retrievals of riming and snow particle density from vertically-pointing Doppler radars|journal=J. Geophys. Res.|volume=123|doi=10.1029/2018JD028603|year=2018}}</ref> Adept is [[free software]] distributed under the [[Apache License]].\n\n== Example ==\nAdept implements automatic differentiation using an [[operator overloading]] approach, in which scalars to be differentiated are written as <code>adouble</code>, indicating an \"active\" version of the normal <code>double</code>, and vectors to be differentiated are written as <code>aVector</code>. The following simple example uses these types to differentiate a [[Norm (mathematics)|3-norm]] calculation on a small vector:\n<source lang=\"cpp\">\n#include <iostream>\n#include <adept_arrays.h>                           \nint main(int argc, const char** argv) {\n  using namespace adept;\n  Stack stack;                           // Object to store differential statements\n  aVector x(3);                          // Independent variables: active vector with 3 elements\n  x << 1.0, 2.0, 3.0;                    // Fill vector x\n  stack.new_recording();                 // Clear any existing differential statements\n  adouble J = cbrt(sum(abs(x*x*x)));     // Compute dependent variable: 3-norm in this case\n  J.set_gradient(1.0);                   // Seed the dependent variable\n  stack.reverse();                       // Reverse-mode differentiation\n  std::cout << \"dJ/dx = \"\n            << x.get_gradient() << \"\\n\"; // Print the vector of partial derivatives dJ/dx\n  return 0;\n}\n</source>\nWhen compiled and executed, this program reports the derivative as:\n<source lang=\"cpp\">\ndJ/dx = {0.0917202, 0.366881, 0.825482}\n</source>\n\n== See also ==\n* [[List of numerical libraries]]\n* [[Automatic differentiation]]\n* [[Eigen (C++ library)]]\n* [[Armadillo (C++ library)]]\n\n== References ==\n{{Reflist}}\n\n== External links ==\n* [http://www.met.reading.ac.uk/clouds/adept/ Adept homepage]\n\n{{DEFAULTSORT:Adept (C++ library)}}\n[[Category:Articles with example C++ code]]\n[[Category:C++ numerical libraries]]\n[[Category:Free computer libraries]]\n[[Category:Free mathematics software]]\n[[Category:Free science software]]\n[[Category:Free software programmed in C++]]\n[[Category:Software using the Apache license]]"
    },
    {
      "title": "Blitz++",
      "url": "https://en.wikipedia.org/wiki/Blitz%2B%2B",
      "text": "{{Infobox software\n| name = Blitz++\n| logo = \n| screenshot = \n| caption = \n| collapsible = \n| author = Todd Veldhuizen\n| developer = \n| released = \n| latest release version = 1.0.1\n| latest release date = {{Start date and age|2017|10|02}}\n| latest preview version = \n| latest preview date = \n| status = \n| programming language = [[C++]]\n| operating system = \n| platform = \n| size = \n| language = <!-- Supported human languages (English, French, Italian, Arabic, ...) -->\n| genre = [[Library (computing)|Library]] and [[Software framework|framework]]\n| license = \n| website = {{URL|https://github.com/blitzpp/blitz}}\n}}\n'''Blitz++''' is a high-performance vector mathematics [[Library (computing)|library]] written in [[C++]]. This library is intended for use in scientific applications that might otherwise be implemented with [[Fortran]] or [[MATLAB]].\n\nBlitz++ utilizes advanced C++ [[template metaprogramming]] techniques, including [[expression templates]],<ref>{{cite journal |title=Scientific Computing: C++ Versus Fortran |first=Todd |last=Veldhuizen |year=1997 |journal=Dr Dobb's |url=http://www.drdobbs.com/cpp/scientific-computing-c-versus-fortran/184410315}}</ref> to provide speed-optimized mathematical operations on sequences of data without sacrificing the natural syntax provided by other mathematical programming systems. Indeed, it has been recognized as a pioneer in the area of C++ template metaprogramming.<ref>[[David Abrahams (computer programmer)|David Abrahams]], [[Aleksey Gurtovoy]]: ''C++ Template Metaprogramming: Concepts, Tools, and Techniques from Boost and Beyond'', Addison-Wesley, {{ISBN|0-321-22725-5}}</ref>\n\n==References==\n{{Reflist}}\n\n==External links==\n*{{Official website|https://github.com/blitzpp/blitz}}\n\n[[Category:C++ numerical libraries]]\n[[Category:Free software programmed in C++]]"
    },
    {
      "title": "Dlib",
      "url": "https://en.wikipedia.org/wiki/Dlib",
      "text": "{{Infobox software\n| logo                   = Dlib c++ library logo.png\n| author                 = Davis E. King\n| released               = {{Start date|2002}}\n| latest release version = 19.17\n| latest release date    = {{Start date and age|2019|3|10}}<ref>{{cite web |url=http://dlib.net/release_notes.html |title=Release notes |website=Dlib|accessdate=11 March 2019}}</ref>\n| programming language   = [[C++]]\n| operating system       = [[Cross-platform]]\n| genre                  = [[Library (computing)|Library]], [[machine learning]]\n| license                = [[Boost (C++ libraries)#License|Boost]]\n}}\n'''Dlib''' is a general purpose [[cross-platform]] software [[Library (computing)|library]] written in the programming language [[C++]]. Its design is heavily influenced by ideas from [[design by contract]] and [[component-based software engineering]]. Thus it is, first and foremost, a set of independent software components. It is [[open-source software]] released under a [[Boost (C++ libraries)#License|Boost Software License]].\n\nSince development began in 2002, Dlib has grown to include a wide variety of tools. As of 2016, it contains software components for dealing with [[Computer network|networking]], [[Thread (computing)|threads]], [[graphical user interface]]s, [[data structure]]s, [[linear algebra]], [[machine learning]], [[image processing]], [[data mining]], [[XML]] and text parsing, [[numerical optimization]], [[Bayesian network]]s, and many other tasks. In recent years, much of the development has been focused on creating a broad set of statistical machine learning tools and in 2009 Dlib was published in the ''[[Journal of Machine Learning Research]]''.<ref>{{cite journal |last1=King |first1=D. E. |year=2009 |title=Dlib-ml: A Machine Learning Toolkit |journal=[[Journal of Machine Learning Research|J. Mach. Learn. Res.]] |volume=10 |issue=Jul |pages=1755–1758 |url=http://www.jmlr.org/papers/volume10/king09a/king09a.pdf |citeseerx=10.1.1.156.3584}}</ref> Since then it has been used in a wide range of domains.<ref>[https://scholar.google.com/scholar?q=%22dlib.net%22+OR+%22dlib-ml%22+OR+%22dclib.sourceforge.net%22 Scholarly research using Dlib]</ref><ref>[http://mloss.org/software/downloads/ Dlib on mloss.org]</ref><ref>[https://books.google.com/books?id=DgkeBAAAQBAJ&dq=dlib+c%2B%2B Autonome Mobile Systeme 2009]</ref><ref>[http://www.codeproject.com/Articles/35715/ESS-Extremely-Simple-Serialization-for-C ESS: Extremely Simple Serialization for C++]</ref><ref>{{cite journal |last1=Gould |first1=S. |year=2012 |title=Darwin: A Framework for Machine Learning and Computer Vision Research and Development |journal=[[Journal of Machine Learning Research|J. Mach. Learn. Res.]] |volume=13 |issue=Dec |pages=3533–3537 |url=http://www.jmlr.org/papers/volume13/gould12a/gould12a.pdf |citeseerx=10.1.1.413.8518}}</ref><ref>Yan, Junchi, et al. \"Online incremental regression for electricity price prediction.\" Service Operations and Logistics, and Informatics (SOLI), 2012 IEEE International Conference on. IEEE, 2012. {{Cite book |doi= 10.1109/SOLI.2012.6273500| chapter= Online incremental regression for electricity price prediction| title= Proceedings of 2012 IEEE International Conference on Service Operations and Logistics, and Informatics| pages= 31| year= 2012| last1= Yan |first1= J. |last2= Tian |first2= C. |last3= Wang |first3= Y. |last4= Huang |first4= J. |isbn= 978-1-4673-2401-4}}</ref><ref>Kuijf, Hugo J., Max A. Viergever, and Koen L. Vincken. \"Automatic Extraction of the Curved Midsagittal Brain Surface on MR Images.\" Medical Computer Vision. Recognition Techniques and Applications in Medical Imaging. Springer Berlin Heidelberg, 2013. 225-232. {{Cite book |doi= 10.1007/978-3-642-36620-8_22| chapter= Automatic Extraction of the Curved Midsagittal Brain Surface on MR Images| title= Medical Computer Vision. Recognition Techniques and Applications in Medical Imaging| volume= 7766| pages= 225| series= Lecture Notes in Computer Science| year= 2013| last1= Kuijf |first1= H. J. |last2= Viergever |first2= M. A. |last3= Vincken |first3= K. L. |isbn= 978-3-642-36619-2}}</ref><ref>Bormann, Richard Klaus Eduard. \"Vision-based place categorization.\" (2010).</ref><ref>Brodu, Nicolas, and Dimitri Lague. \"3D terrestrial lidar data classification of complex natural scenes using a multi-scale dimensionality criterion: Applications in geomorphology.\" ISPRS Journal of Photogrammetry and Remote Sensing 68 (2012): 121–134.</ref><ref>Aung, Zeyar, et al. \"Towards accurate electricity load forecasting in smart grids.\" DBKDA 2012, The Fourth International Conference on Advances in Databases, Knowledge, and Data Applications. 2012.</ref><ref>Rodriguez, Alberto, et al. \"Abort and retry in grasping.\" Intelligent Robots and Systems (IROS), 2011 IEEE/RSJ International Conference on. IEEE, 2011. {{Cite book |doi= 10.1109/IROS.2011.6095100| chapter= Abort and retry in grasping| title= 2011 IEEE/RSJ International Conference on Intelligent Robots and Systems| pages= 1804| year= 2011| last1= Rodriguez |first1= A. |last2= Mason |first2= M. T. |last3= Srinivasa |first3= S. S. |last4= Bernstein |first4= M. |last5= Zirbel |first5= A. |isbn= 978-1-61284-456-5}}</ref><ref>Mohan, Vandana, et al. \"Intraoperative prediction of tumor cell concentration from Mass Spectrometry Imaging.\" Int. Symp. Math. Theo. Netw. Syst. 2010.</ref><ref>Nakashima, Yuta, Noboru Babaguchi, and Jianping Fan. \"Detecting intended human objects in human-captured videos.\" Computer Vision and Pattern Recognition Workshops (CVPRW), 2010 IEEE Computer Society Conference on. IEEE, 2010. {{Cite book |doi= 10.1109/CVPRW.2010.5543721| chapter= Detecting intended human objects in human-captured videos| title= 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition - Workshops| pages= 33| year= 2010| last1= Nakashima |first1= Y. |last2= Babaguchi |first2= N. |last3= Fan |first3= J. |isbn= 978-1-4244-7029-7}}</ref>\n\n==See also==\n* [[Comparison of deep learning software]]\n\n==References==\n{{Reflist|30em}}\n\n==External links==\n* {{Official website}}\n* [https://www.kdnuggets.com/2014/06/dlib-library-machine-learning.html DLib: Library for Machine Learning]\n\n{{Deep Learning Software}}\n\n{{DEFAULTSORT:dlib}}\n[[Category:C++ libraries]]\n[[Category:C++ numerical libraries]]\n[[Category:Computer vision software]]\n[[Category:Data mining and machine learning software]]\n[[Category:Free software programmed in C++]]\n[[Category:Free statistical software]]\n[[Category:Software using the Boost license]]"
    },
    {
      "title": "Eigen (C++ library)",
      "url": "https://en.wikipedia.org/wiki/Eigen_%28C%2B%2B_library%29",
      "text": "{{third-party|date=January 2016}}\n{{Infobox software\n| name = Eigen\n| logo = Eigen Silly Professor 135x135.png\n| developer = {{plainlist|\n* Benoît Jacob\n* Gaël Guennebaud\n}}\n| latest release version = 3.3.7\n| latest release date = {{start date and age|df=yes|paren=yes|2018|12|11}}\n| latest preview version = \n| latest preview date = \n| programming language = [[C++]]\n| operating system = [[Cross-platform]]\n| genre = [[Library (computing)|Library]]\n| license = [[Mozilla Public License|MPL 2.0]]\n| website = {{URL|http://eigen.tuxfamily.org/}}\n}}\n\n'''Eigen''' is a high-level  [[C++]] [[library (computing)|library]] of [[Template (C++)|template headers]] for [[linear algebra]], [[Matrix (mathematics)|matrix]] and [[Vector (mathematics and physics)|vector]] operations, geometrical transformations, [[Numerical analysis|numerical solvers]] and related  algorithms.\nEigen is [[open-source software]] licensed under the [[Mozilla Public License]] 2.0 since version 3.1.1. Earlier versions were licensed under the [[GNU Lesser General Public License]].<ref>{{cite web\n | title = Eigen License\n | url =  http://eigen.tuxfamily.org/index.php?title=Main_Page#License\n | publisher = tuxfamily.org\n | accessdate = 16 Jan 2016\n }}</ref>\n\nEigen is implemented using the [[expression templates]] [[Template metaprogramming|metaprogramming]] technique, meaning it builds expression trees at compile time and generates custom code to evaluate these. Using expression templates and a [[Analysis of algorithms#Cost models|cost model]] of [[floating point]] operations, the library performs its own [[loop unrolling]] and [[Automatic vectorization|vectorization]].<ref>{{cite conference |title=Eigen: A C++ linear algebra library |first=Gaël |last=Guennebaud |year=2013 |conference=Eurographics/CGLibs |url=http://downloads.tuxfamily.org/eigen/eigen_CGLibs_Giugno_Pisa_2013.pdf}}</ref>\n\n==See also==\n* [[List of numerical libraries]]\n* [[Numerical linear algebra]]\n\n==References==\n{{Reflist}}\n\n[[Category:C++ numerical libraries]]\n[[Category:Free computer libraries]]\n[[Category:Free software programmed in C++]]\n[[Category:Numerical analysis software for Linux]]\n[[Category:Software using the Mozilla license]]\n\n{{compu-prog-stub}}"
    },
    {
      "title": "IML++",
      "url": "https://en.wikipedia.org/wiki/IML%2B%2B",
      "text": "'''IML++''', or the '''Iterative Methods Library''', is a C++ library for solving linear systems of equations.  It is said to be \"templated\" in the sense that the same source code works for dense, sparse, and distributed matrices.\n\nSome of the supported solutions methods are:\n\n* [[Richardson iteration|Richardson Iteration]]\n* [[Chebyshev iteration|Chebyshev Iteration]]\n* [[Conjugate gradient method|Conjugate Gradient (CG)]]\n* Conjugate Gradient Squared (CGS)\n* [[Biconjugate gradient method|BiConjugate Gradient (BiCG)]]\n* [[Biconjugate gradient stabilized_method|BiConjugate Gradient Stabilized (BiCGSTAB)]]\n* [[Generalized minimal residual method|Generalized Minimum Residual (GMRES)]]\n* Quasi-Minimal Residual Without Lookahead (QMR)\n\n== Status ==\n\nIML++ was developed by the National Institute of Standards and Technology, and is in the public domain.  However, it is no longer being actively developed.  It has been largely superseded by the [[Template Numerical Toolkit]].\n\n==See also==\n* [[Iterative Template Library]]\n\n==External links==\n* [http://math.nist.gov/iml++/ The IML++ home page]\n\n[[Category:C++ numerical libraries]]"
    },
    {
      "title": "IT++",
      "url": "https://en.wikipedia.org/wiki/IT%2B%2B",
      "text": "{{Infobox software\n| name                   = IT++ C++ Library\n| logo                   =\n| screenshot             =\n| caption                =\n| developer              =\n| latest release version = 4.3.1\n| latest release date    = {{Start date and age|2013|07|06}}\n| programming language   = [[C++]]\n| operating system       = [[Cross-platform]]\n| language               = [[English language|English]]\n| genre                  = [[library (computing)|Software library]]\n| license                = [[GNU General Public License|GPL]] [[open source software|open source]]\n| website                = {{URL|http://itpp.sourceforge.net}}\n}}\n'''IT++''' is a [[C++]] library of [[C++ classes|classes]] and functions for [[linear algebra]], [[numerical optimization]], [[signal processing]], communications, and [[statistics]].<ref>IT++, [[Free Software Directory]], [[Free Software Foundation]], http://directory.fsf.org</ref> It is being developed by researchers in these areas and is widely used by researchers, both in the communications industry and universities.<ref>Bogdan Cristea. 2009. Turbo receivers with IT++. In Proceedings of the 2nd International Conference on Simulation Tools and Techniques (Simutools '09). ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering), ICST, Brussels, Belgium, Belgium, {{DOI|10.4108/ICST.SIMUTOOLS2009.5564}}</ref><ref>de Lima, C.H.M.; Stancanelli, E.M.G.; Rodrigues, E.B.; da S. Maciel, J.M.; Cavalcanti, F.R.P., A software development framework based on C++ OOP language for link-level simulation tools, Telecommunications Symposium, 2006 International, Fortaleza, Brazil, {{DOI|10.1109/ITS.2006.4433344}}</ref> The IT++ library originates from the former Department of Information Theory at the Chalmers University of Technology, Gothenburg, Sweden.\n\nThe kernel of the IT++ library is [[Template (C++)|templated]] vector and matrix classes, and a set of accompanying functions. Such a kernel makes IT++ library similar to [[Matlab]]/[[GNU Octave|Octave]]. For increased functionality, speed and accuracy, IT++ can make extensive use of existing [[FLOSS|free and open source]] libraries, especially [[Basic Linear Algebra Subprograms|BLAS]], [[LAPACK]] and [[FFTW]] libraries. Instead of BLAS and LAPACK, some optimized platform-specific libraries can be used as well, i.e.:\n* [[Automatically Tuned Linear Algebra Software|ATLAS]] (Automatically Tuned Linear Algebra Software) - includes optimised BLAS, CBLAS and a limited set of LAPACK routines;\n* [[Math Kernel Library|MKL]] (Intel Math Kernel Library) - includes all required BLAS, CBLAS, LAPACK and FFT routines (FFTW not required);\n* [[AMD Core Math Library|ACML]] (AMD Core Math Library) - includes BLAS, LAPACK and FFT routines (FFTW not required).\n\nIt is possible to compile and use IT++ without any of the above-listed libraries, but the functionality will be reduced. IT++ works on [[Linux]], [[Solaris (operating system)|Solaris]], [[Windows (operating system)|Windows]] (with [[Cygwin]], MinGW/MSYS, or [[Microsoft Visual C++]]) and [[OS X]] operating systems.\n\n== Example ==\nHere is a trivial example demonstrating the IT++ functionality similar to Matlab/Octave,\n<source lang=\"cpp\">\n#include <iostream>\n#include <itpp/itbase.h>\nusing namespace std;\nusing namespace itpp;\n\nint main()\n{\n  vec a = linspace(0.0, 2.0, 2);\n  vec b = \"1.0 2.0\";\n  vec c = 2*a + 3*b;\n  cout << \"c =\\n\" << c << endl;\n\n  mat A = \"1.0 2.0; 3.0 4.0\";\n  mat B = \"0.0 1.0; 1.0 0.0\";\n  mat C = A*B + 2*A;\n  cout << \"C =\\n\" << C << endl;\n  cout << \"inverse of B =\\n\" << inv(B) << endl;\n\n  return 0;\n}\n</source>\n\n==See also==\n{{Portal|Free and open-source software}}\n* [[List of numerical analysis software]]\n* [[List of numerical libraries]]\n* [[Numerical linear algebra]]\n* [[Scientific computing]]\n\n==References==\n{{reflist}}\n\n==External links==\n* {{Official website|http://itpp.sourceforge.net}}\n\n{{Projects at Chalmers University of Technology}}\n\n[[Category:C++ numerical libraries]]\n[[Category:Chalmers University of Technology]]\n[[Category:Free science software]]\n[[Category:Software using the GPL license]]"
    },
    {
      "title": "LAPACK++",
      "url": "https://en.wikipedia.org/wiki/LAPACK%2B%2B",
      "text": "{{Infobox software\n| name                   = LAPACK++\n| title                  = LAPACK++\n| logo                   = <!-- [[File: ]] -->\n| screenshot             = <!-- [[File: ]] -->\n| caption                = \n| collapsible            = \n| author                 = \n| developer              = \n| released               = <!-- {{Start date|YYYY|MM|DD|df=yes/no}} -->\n| discontinued           = \n| latest release version = 2.5.4\n| latest release date    = {{Start date and age|2010|11|10|df=yes/no}}\n| latest preview version = \n| latest preview date    = <!-- {{Start date and age|YYYY|MM|DD|df=yes/no}} -->\n| frequently updated     = <!-- DO NOT include this parameter unless you know what it does -->\n| programming language   = [[C++]]\n| operating system       = \n| platform               = \n| size                   = \n| language               = \n| status                 = \n| genre                  = [[Library (computing)|Software library]]\n| license                = [[GNU Lesser General Public License]] (LGPL)\n| website                = {{URL|http://sourceforge.net/projects/lapackpp/}}\n}}\n{{Portal|Free and open-source software}}\n'''LAPACK++''', the '''Linear Algebra PACKage in C++''', is a computer [[software library]] of algorithms for numerical [[linear algebra]] that solves systems of [[linear equation]]s and [[eigenvalue]] problems.\n\nIt supports various [[matrix (mathematics)|matrix]] classes for vectors, non-symmetric matrices, [[Positive-definite matrix|SPD matrices]], symmetric matrices, banded, triangular, and tridiagonal matrices. However, it does not include all of the capabilities of original [[LAPACK]] library. \n\n==History==\nThe original LAPACK++ (up to v1.1a) was written by R. Pozo et al. at the [[University of Tennessee]] and [[Oak Ridge National Laboratory]].\nIn 2000, R. Pozo et al. left the project, with the projects' web page stating LAPACK++ would be superseded by the [[Template Numerical Toolkit]] (TNT).\n\nThe current LAPACK++ (versions 1.9 onwards) started off as a fork from the original LAPACK++. There are extensive fixes and changes, such as more wrapper functions for [[LAPACK]] and [[BLAS]] routines.\n\n==See also==\n* [[List of numerical analysis software]]\n* [[List of numerical libraries]]\n\n==External links==\n* old [http://math.nist.gov/lapack++/ LAPACK++ Homepage]  (version 1.1a)\n* new [http://lapackpp.sourceforge.net/ LAPACK++ Homepage] (versions 1.9 onwards)\n\n[[Category:C++ numerical libraries]]"
    },
    {
      "title": "Matrix Template Library",
      "url": "https://en.wikipedia.org/wiki/Matrix_Template_Library",
      "text": "{{ Infobox Software\n| name                   = Matrix Template Library\n| operating_system       = [[Linux]], [[Unix]], [[Mac OS X]], [[Microsoft Windows|Windows]]\n| license                = [http://www.boost.org/LICENSE_1_0.txt Boost Software License]\n| language               = [[C++]]\n| genre                  = Scientific software [[library (computing)|library]]\n| website                = http://www.mtl4.org\n}}\n\nThe '''Matrix Template Library''' (MTL) is a [[linear algebra]] library for [[C++]] programs.\n\nThe MTL uses [[template (programming)|template programming]], which considerably reduces the code length. All matrices and vectors are available in all classical numerical formats: <code>float</code>, <code>double</code>, <code>complex<float></code> or <code>complex<double></code>. \n\nFurthermore, [[generic programming]] allows the usage of arbitrary types as long as they provide the necessary operations. For instance one can use arbitrary integer formats (e.g. <code>unsigned short</code>), types for interval arithmetic (e.g. boost::interval) from the [[Boost C++ Libraries]], [[quaternion]]s (e.g. boost::quaternion), types of higher precision (e.g. [[GNU Multi-Precision Library]]) and appropriate user-defined types. \n\nThe MTL supports several implementations of [[dense matrix|dense matrices]] and [[sparse matrix|sparse matrices]]. MTL2 has been developed by Jeremy Siek and Andrew Lumsdaine.<ref name=SiekLumsdaine98>[http://www.osl.iu.edu/download/research/mtl/papers/iscope_final.pdf J.G. Siek and A. Lumsdaine: ''The Matrix Template Library: A Generic Programming Approach to High Performance Numerical Linear Algebra''. ISCOPE 1998.] {{webarchive|url=https://web.archive.org/web/20080512092609/http://www.osl.iu.edu/download/research/mtl/papers/iscope_final.pdf |date=2008-05-12 }}</ref>\n\nThe latest version, MTL4, is developed by Peter Gottschling and Andrew Lumsdaine. It contains most of MTL2's functionality and adds new optimization techniques as meta-tuning, e.g. [[loop unwinding|loop unrolling]] of dynamically sized containers can be specified in the function call. Platform-independent performance scalability is reached by recursive data structures and algorithms.<ref name=Gottschlingetal07>[http://www.osl.iu.edu/download/research/mtl/papers/ics07.pdf P. Gottschling, D.S. Wise, and M.D. Adams: ''Representation-transparent matrix algorithms with scalable performance.'' ICS '07: Proc. 21st intern. conf. on Supercomputing, pp. 116--125, ACM Press, New York, 2007.] {{webarchive|url=https://web.archive.org/web/20080720143453/http://osl.iu.edu/download/research/mtl/papers/ics07.pdf |date=2008-07-20 }}</ref>  \n\nGeneric applications can be written in a natural notation, e.g. <code>v += A*q - w;</code>, while the library dispatches to the appropriate algorithms: matrix vector products vs. matrix products vs. vector scalar products etcetera. The goal is to encapsulate performance issues inside the library and provide scientists an intuitive interface. MTL4 is used in different [[finite element method|finite element]] and [[finite volume method|finite volume]] packages, e.g. the [[FEniCS Project]].<ref name=Dolfin>[http://www.fenics.org/wiki/DOLFIN Dolfin web page within the FEniCS project.] {{webarchive|url=https://web.archive.org/web/20090104084613/http://www.fenics.org/wiki/DOLFIN |date=2009-01-04 }}</ref>\n\n== References ==\n\n{{reflist}}\n\n== See also ==\n* [[List of numerical libraries]]\n\n== External links ==\n* [http://www.osl.iu.edu/research/mtl/ MTL] homepage\n* [http://www.mtl4.org MTL4] homepage\n\n[[Category:C++ numerical libraries]]"
    },
    {
      "title": "Template Numerical Toolkit",
      "url": "https://en.wikipedia.org/wiki/Template_Numerical_Toolkit",
      "text": "{{Infobox software\n| name                   = Template Numerical Toolkit\n| title                  = Template Numerical Toolkit\n| logo                   = <!-- [[File: ]] -->\n| screenshot             = <!-- [[File: ]] -->\n| caption                = \n| collapsible            = \n| author                 = \n| developer              = [[National Institute of Standards and Technology]]\n| released               = <!-- {{Start date|YYYY|MM|DD|df=yes/no}} -->\n| discontinued           = \n| latest release version = \n| latest release date    = <!-- {{Start date and age|YYYY|MM|DD|df=yes/no}} -->\n| latest preview version = \n| latest preview date    = <!-- {{Start date and age|YYYY|MM|DD|df=yes/no}} -->\n| frequently updated     = <!-- DO NOT include this parameter unless you know what it does -->\n| programming language   = [[C++]]\n| operating system       = \n| platform               = \n| size                   = \n| language               = \n| status                 = \n| genre                  = [[Library (computing)|Software library]]\n| license                = [[Public domain software]] with the source\n| website                = {{URL|http://math.nist.gov/tnt/}}\n}}\n[[File:Row_and_column_major_order.svg|thumb|upright|Illustration of row- and column-major order]]\n{{Portal|Free and open-source software}}\nThe '''Template Numerical Toolkit''' (or '''TNT''') is a [[software library]] for manipulating [[Vector (geometric)|vectors]] and [[Matrix (computer science)|matrices]] in [[C++]] created by the U.S. [[National Institute of Standards and Technology]].  \nTNT provides the fundamental linear algebra operations (for example, [[matrix multiplication]]).  TNT is analogous to the [[BLAS]] library used by [[LAPACK]].  Higher level algorithms, such as [[LU decomposition]] and [[singular value decomposition]], are provided by [[JAMA (numerical linear algebra library)|JAMA]], also developed at NIST, which uses TNT.\n\nThe major features of TNT are:\n* All classes are template classes, and, therefore, work with float, double, or other user-defined number types.\n* Matrices can be stored in [[row-major order]] or [[column-major order]] for [[Fortran]] compatibility.\n* The library is simply a collection of header files, and so, does not need to be independently compiled.\n* Some support for [[sparse matrix]] storage is provided.\n* The [[source code]] is in the [[public domain]].\n\nTNT is mature and NIST classifies its development status as [http://math.nist.gov/mcsd/project-status.html active maintenance].\n\nThe principal designer of TNT is [[Roldan Pozo]].\n\n==See also==\n* [[Iterative Template Library]] (ITL)\n* [[List of numerical libraries]]\n\n== External links ==\n* [http://math.nist.gov/tnt/ Template Numerical Toolkit homepage] at NIST\n\n[[Category:C++ numerical libraries]]\n[[Category:Free mathematics software]]\n[[Category:Free software programmed in C++]]\n[[Category:Public-domain software with source code]]"
    },
    {
      "title": "OpenCL",
      "url": "https://en.wikipedia.org/wiki/OpenCL",
      "text": "{{distinguish|OpenGL}}\n{{For|the cryptographic library initially known as OpenCL|Botan (programming library)}}\n{{Infobox software\n| name = OpenCL API\n| title = OpenCL API\n| logo = OpenCL Logo.svg\n| logo caption = \n| logo size = 200px\n| logo alt = OpenCL logo\n| screenshot = <!-- Image name is enough. -->\n| caption = \n| screenshot size = \n| screenshot alt = \n| collapsible = \n| author = [[Apple Inc.]]\n| developer = [[Khronos Group]]\n| released = {{Start date and age|2009|08|28}}\n| discontinued = \n| latest release version = 2.2-10<ref>{{cite web|title=The OpenCL Specification|url=https://www.khronos.org/registry/OpenCL/specs/opencl-2.2.html|publisher=Khronos Group|accessdate=May 14, 2018|language=en|date=May 12, 2018}}</ref>\n| latest release date = {{Start date and age|2019|02|05}}\n| latest preview version = \n| latest preview date = \n| programming language = C with C++ bindings\n| operating system = [[Android (operating system)|Android]] (vendor dependent),<ref>{{cite web |title=Android Devices With OpenCL support |url=https://docs.google.com/a/arrayfire.com/spreadsheets/d/1Mpzfl2NmLUVSAjIph77-FOsJeuyD9Xjha89r5iHw1hI/edit?pli=1#gid=0 |website=Google Docs |publisher=ArrayFire |accessdate=April 28, 2015}}</ref> [[FreeBSD]],<ref>{{cite web |title=FreeBSD Graphics/OpenCL |url=https://wiki.freebsd.org/Graphics/OpenCL |publisher=FreeBSD |accessdate=December 23, 2015}}</ref> [[Linux]], [[macOS]], [[Windows]]\n| platform = [[ARMv7]], [[ARMv8]],<ref name=\"conformant-products\">{{cite web |title=Conformant Products |url=https://www.khronos.org/conformance/adopters/conformant-products/opencl |publisher=Khronos Group |accessdate=May 9, 2015}}</ref> [[Cell (microprocessor)|Cell]], [[IA-32]], [[IBM POWER microprocessors|POWER]], [[x86-64]]\n| size = \n| language = \n| language count = <!-- Number only -->\n| language footnote = \n| genre = [[Heterogeneous computing]] [[API]]\n| license = OpenCL specification license\n| alexa = \n| website = {{URL|https://www.khronos.org/opencl/}}\n| standard = \n}}\n{{Infobox programming language\n| name                   = OpenCL C/C++\n| logo                   = \n| logo caption           = \n| paradigm               = [[Imperative programming|Imperative]] ([[Procedural programming|procedural]]), [[structured programming|structured]], [[Object oriented programming|object-oriented]] (C++ only)\n| family                 = [[List of C-based programming languages|C]]\n| designer               = \n| developer              = \n| released               = \n| latest release version = \nOpenCL C++ 1.0 revision V2.2-10<ref>{{cite web|last1=Sochacki|first1=Bartosz|title=The OpenCL C++ 1.0 Specification|url=https://www.khronos.org/registry/OpenCL/specs/opencl-2.2-cplusplus.pdf|publisher=Khronos OpenCL Working Group|accessdate=May 17, 2017|date=May 12, 2017}}</ref>\nOpenCL C 2.0 revision V2.2-10<ref>{{cite web |last1=Munshi |first1=Aaftab |last2=Howes |first2=Lee |last3=Sochaki |first3=Barosz |title=The OpenCL C Specification Version: 2.0 Document Revision: 33 |url=https://www.khronos.org/registry/cl/specs/opencl-2.0-openclc.pdf |publisher=Khronos OpenCL Working Group |accessdate=April 29, 2016 |date=April 13, 2016}}</ref>\n| latest release date    = {{Start date and age|2019|02|05}}\n| latest preview version = \n| latest preview date    =\n| typing                 = [[Type system|Static]], [[Weak typing|weak]], [[manifest typing|manifest]], [[Nominative type system|nominal]]\n| scope                  = \n| programming language   = Implementation specific\n| platform               = \n| operating_system       = \n| license                = \n| file_ext               = .cl\n| file format            = \n| website                = \n| implementations        = AMD, Apple, freeocl, Gallium Compute, IBM, Intel Beignet, Intel SDK, Nvidia, pocl\n| dialects               = \n| influenced_by          = [[C99]], [[CUDA]], [[C++14]]\n| influenced             = \n}}\n\n'''OpenCL''' ('''Open Computing Language''') is a [[software framework|framework]] for writing programs that execute across [[heterogeneous computing|heterogeneous]] platforms consisting of [[central processing unit]]s (CPUs), [[graphics processing unit]]s (GPUs), [[digital signal processor]]s (DSPs), [[field-programmable gate array]]s (FPGAs) and other processors or [[hardware accelerator]]s. OpenCL specifies [[programming language]]s (based on [[C99]] and [[C++11]]) for programming these [[Personal computer hardware|devices]] and [[application programming interface]]s (APIs) to control the platform and execute programs on the [[OpenCL compute devices|compute devices]]. OpenCL provides a standard interface for [[parallel computing]] using [[Task parallelism|task-]] and [[Data parallelism|data-based parallelism]].\n\nOpenCL is an open standard maintained by the [[Non-profit organization|non-profit]] technology consortium [[Khronos Group]]. Conformant implementations are available from [[Altera]], [[Advanced Micro Devices|AMD]], [[Apple Inc|Apple]] (OpenCL along with [[OpenGL]] is [[deprecation|deprecated]] for Apple hardware, in favor of [[Metal (API)|Metal]] 2<ref>{{Cite web|url=https://appleinsider.com/articles/18/06/04/opengl-opencl-deprecated-in-favor-of-metal-2-in-macos-1014-mojave|title=OpenGL, OpenCL deprecated in favor of Metal 2 in macOS 10.14 Mojave|website=AppleInsider|language=en-US|access-date=July 3, 2018}}</ref>), [[ARM Holdings|ARM]], [[Creative Technology|Creative]], [[IBM]], [[Imagination Technologies|Imagination]], [[Intel]], [[Nvidia]], [[Qualcomm]], [[Samsung]], [[Vivante]], [[Xilinx]], and [[ZiiLABS]].<ref>{{cite web |title=Conformant Companies |url=https://www.khronos.org/conformance/adopters/conformant-companies#opencl |publisher=Khronos Group |accessdate=April 8, 2015}}</ref><ref>{{cite web |last1=Gianelli |first1=Silvia E. |title=Xilinx SDAccel Development Environment for OpenCL, C, and C++, Achieves Khronos Conformance |url=http://www.prnewswire.com/news-releases/xilinx-sdaccel-development-environment-for-opencl-c-and-c-achieves-khronos-conformance-300020285.html |website=PR Newswire |publisher=Xilinx |accessdate=April 27, 2015 |date=January 14, 2015}}</ref>\n\n== Overview ==\nOpenCL views a computing system as consisting of a number of ''compute devices'', which might be [[central processing unit]]s (CPUs) or \"accelerators\" such as graphics processing units (GPUs), attached to a ''host'' processor (a CPU). It defines a [[#OpenCL C language|C-like language]] for writing programs. Functions executed on an OpenCL device are called \"[[compute kernel|kernel]]s\".<ref name=specification>{{cite web |last1=Howes |first1=Lee |title=The OpenCL Specification Version: 2.1 Document Revision: 23 |url=https://www.khronos.org/registry/cl/specs/opencl-2.1.pdf |publisher=Khronos OpenCL Working Group |accessdate=November 16, 2015 |date=November 11, 2015}}</ref>{{rp|17}} A single compute device typically consists of several ''compute units'', which in turn comprise multiple ''[[processing element]]s'' (PEs). A single kernel execution can run on all or many of the PEs in parallel. How a compute device is subdivided into compute units and PEs is up to the vendor; a compute unit can be thought of as a \"[[Processor core|core]]\", but the notion of core is hard to define across all the types of devices supported by OpenCL (or even within the category of \"CPUs\"),{{r|Gaster}}{{rp|49–50}} and the number of compute units may not correspond to the number of cores claimed in vendors' marketing literature (which may actually be counting [[SIMD lanes]]).<ref>{{Cite web |title=An Introduction to the OpenCL Programming Model |first1=Jonathan |last1=Tompson |first2=Kristofer |last2=Schlachter |url=http://www.cs.nyu.edu/~lerner/spring12/Preso07-OpenCL.pdf |year=2012 |accessdate=July 6, 2015 |publisher=New York University Media Research Lab}}</ref>\n\nIn addition to its C-like programming language, OpenCL defines an [[application programming interface]] (API) that allows programs running on the host to launch kernels on the compute devices and manage device memory, which is (at least conceptually) separate from host memory. Programs in the OpenCL language are intended to be [[just-in-time compilation|compiled at run-time]], so that OpenCL-using applications are portable between implementations for various host devices.<ref name=\"CiSE\">{{cite journal |first1=John E. |last1=Stone |first2=David |last2=Gohara |first3=Guochin |last3=Shi |year=2010 |title=OpenCL: a parallel programming standard for heterogeneous computing systems |journal=Computing in Science & Engineering |doi=10.1109/MCSE.2010.69 |pmid=21037981 |volume=12 |issue=3 |pages=66–73|pmc=2964860 |bibcode=2010CSE....12c..66S }}</ref> The OpenCL standard defines host APIs for [[C (programming language)|C]] and [[C++]]; third-party APIs exist for other programming languages and platforms such as [[Python (programming language)|Python]],<ref name=\"pyopencl\">{{Cite journal | last1 = Klöckner | first1 = Andreas | last2 = Pinto | first2 = Nicolas | last3 = Lee | first3 = Yunsup | last4 = Catanzaro | first4 = Bryan | last5 = Ivanov | first5 = Paul | last6 = Fasih | first6 = Ahmed | year = 2012 | title = PyCUDA and PyOpenCL: A scripting-based approach to GPU run-time code generation | journal = Parallel Computing | volume = 38 | issue = 3 | pages = 157–174 | jstor = | doi = 10.1016/j.parco.2011.09.001 | arxiv = 0911.3456 }}</ref> [[Java (programming language)|Java]], [[Perl]]<ref name=\"perl-opencl\">{{cite web|url = https://metacpan.org/pod/OpenCL |title = OpenCL - Open Computing Language Bindings |accessdate = August 18, 2018 |publisher = metacpan.org }}</ref> and [[.NET Framework|.NET]].<ref name=\"Gaster\">{{cite book |title=Heterogeneous Computing with OpenCL: Revised OpenCL 1.2 Edition |first1=Benedict |last1=Gaster |first2=Lee |last2=Howes |first3=David R. |last3=Kaeli |first4=Perhaad |last4=Mistry |first5=Dana |last5=Schaa |year=2012 |publisher=Morgan Kaufmann}}</ref>{{rp|15}} An [[#Implementations|implementation]] of the OpenCL standard consists of a [[library (computing)|library]] that implements the API for C and C++, and an OpenCL C [[compiler]] for the compute device(s) targeted.\n\nIn order to open the OpenCL programming model to other languages or to protect the kernel source from inspection, the [[Standard Portable Intermediate Representation]] (SPIR)<ref>{{cite web |url=https://www.khronos.org/spir/ |title=SPIR - The first open standard intermediate language for parallel compute and graphics |publisher=[[Khronos Group]] |date=2014-01-21 }}</ref> can be used as a target-independent way to ship kernels between a front-end compiler and the OpenCL back-end.\n\nMore recently [[Khronos Group]] has ratified [[SYCL]],<ref>{{cite web |url=https://www.khronos.org/sycl/ |title=SYCL - C++ Single-source Heterogeneous Programming for OpenCL |publisher=[[Khronos Group]] |date=2014-01-21 }}</ref> a higher-level programming model for OpenCL as single-source [[DSEL]] based on pure [[C++11]] to improve [[programming productivity]].\n\n=== Memory hierarchy ===\nOpenCL defines a four-level [[memory hierarchy]] for the compute device:<ref name=\"CiSE\" />\n\n* global memory: shared by all processing elements, but has high access latency ({{mono|__global}});\n* read-only memory: smaller, low latency, writable by the host CPU but not the compute devices ({{mono|__constant}});\n* local memory: shared by a group of processing elements ({{mono|__local}});\n* per-element private memory ([[Processor register|registers]]; {{mono|__private}}).\n\nNot every device needs to implement each level of this hierarchy in hardware. [[Consistency model|Consistency]] between the various levels in the hierarchy is relaxed, and only enforced by explicit [[Synchronization (computer science)|synchronization]] constructs, notably [[Memory barrier|barriers]].\n\nDevices may or may not share memory with the host CPU.<ref name=\"CiSE\" /> The host API provides [[Handle (computing)|handles]] on device memory buffers and functions to transfer data back and forth between host and devices.\n\n== OpenCL C language ==\nThe programming language that is used to write [[compute kernel]]s is called OpenCL C and is based on [[C99]],<ref name=\"openclc\">{{cite web |title=The OpenCL C Specification, Version 2.0 |editor=Aaftab Munshi |year=2014 |url=https://www.khronos.org/registry/cl/specs/opencl-2.0-openclc.pdf |accessdate=June 24, 2014}}</ref> but adapted to fit the device model in OpenCL. Memory buffers reside in specific levels of the [[#Memory hierarchy|memory hierarchy]], and [[Pointer (computer programming)|pointers]] are annotated with the region qualifiers {{mono|__global}}, {{mono|__local}}, {{mono|__constant}}, and {{mono|__private}}, reflecting this. Instead of a device program having a {{mono|main}} function, OpenCL C functions are marked {{mono|__kernel}} to signal that they are [[entry point]]s into the program to be called from the host program. [[Function pointer]]s, [[bit field]]s and [[variable-length array]]s are omitted, [[recursion (computer science)|recursion]] is forbidden.<ref name=AMD>{{cite web|url=http://developer.amd.com/zones/OpenCLZone/courses/Documents/Introduction_to_OpenCL_Programming%20(201005).pdf|title=Introduction to OpenCL Programming 201005|publisher=AMD|pages=89–90|archive-url=https://web.archive.org/web/20110516092008/http://developer.amd.com/zones/OpenCLZone/courses/Documents/Introduction_to_OpenCL_Programming%20(201005).pdf|archive-date=May 16, 2011|dead-url=yes|accessdate=August 8, 2017}}</ref> The [[C standard library]] is replaced by a custom set of standard functions, geared toward math programming.\n\nOpenCL C is extended to facilitate use of [[parallel computing|parallelism]] with vector types and operations, synchronization, and functions to work with work-items and work-groups.<ref name=AMD /> In particular, besides scalar types such as {{mono|float}} and {{mono|double}}, which behave similarly to the corresponding types in C, OpenCL provides fixed-length vector types such as {{mono|float4}} (4-vector of single-precision floats); such vector types are available in lengths two, three, four, eight and sixteen for various base types.<ref name=\"openclc\" />{{rp|§&nbsp;6.1.2}} [[Array programming|Vectorized]] operations on these types are intended to map onto [[SIMD]] instructions sets, e.g., [[Streaming SIMD Extensions|SSE]] or [[AltiVec|VMX]], when running OpenCL programs on CPUs.<ref name=\"CiSE\" /> Other specialized types include 2-d and 3-d image types.{{r|openclc}}{{rp|10–11}}\n\n=== Example: matrix-vector multiplication ===\n[[File:Matrix multiplication qtl5.svg|thumb|Each invocation (''work-item'') of the kernel takes a row of the green matrix ({{mono|A}} in the code), multiplies this row with the red vector ({{mono|x}}) and places the result in an entry of the blue vector ({{mono|y}}). The number of columns {{mvar|n}} is passed to the kernel as {{mono|ncols}}; the number of rows is implicit in the number of work-items produced by the host program.]]\n\nThe following is a [[matrix-vector multiplication]] algorithm in OpenCL C.\n\n<syntaxhighlight lang=\"c\">\n// Multiplies A*x, leaving the result in y.\n// A is a row-major matrix, meaning the (i,j) element is at A[i*ncols+j].\n__kernel void matvec(__global const float *A, __global const float *x,\n                     uint ncols, __global float *y)\n{\n    size_t i = get_global_id(0);              // Global id, used as the row index\n    __global float const *a = &A[i*ncols];    // Pointer to the i'th row\n    float sum = 0.f;                          // Accumulator for dot product\n    for (size_t j = 0; j < ncols; j++) {\n        sum += a[j] * x[j];\n    }\n    y[i] = sum;\n}\n</syntaxhighlight>\n\nThe kernel function {{mono|matvec}} computes, in each invocation, the [[dot product]] of a single row of a matrix {{mvar|A}} and a vector {{mvar|x}}:\n\n:<math>y_i = a_{i,:} \\cdot x = \\sum_j a_{i,j} x_j</math>.\n\nTo extend this into a full matrix-vector multiplication, the OpenCL runtime [[Map (parallel pattern)|maps]] the kernel over the rows of the matrix. On the host side, the {{mono|clEnqueueNDRangeKernel}} function does this; it takes as arguments the kernel to execute, its arguments, and a number of work-items, corresponding to the number of rows in the matrix {{mvar|A}}.\n\n=== Example: computing the FFT ===\nThis example will load a [[fast Fourier transform]] (FFT) implementation and execute it. The implementation is shown below.<ref name=siggraph>{{cite web |url=http://s08.idav.ucdavis.edu/munshi-opencl.pdf |title=OpenCL |accessdate=August 14, 2008 |publisher=SIGGRAPH2008 |date=August 14, 2008}}</ref> The code asks the OpenCL library for the first available graphics card, creates memory buffers for reading and writing (from the perspective of the graphics card), [[Just-in-time compilation|JIT-compiles]] the FFT-kernel and then finally asynchronously runs the kernel. The result from the transform is not read in this example.\n\n<syntaxhighlight lang=\"c\">\n#include <stdio.h>\n#include <time.h>\n#include \"CL/opencl.h\"\n\n#define NUM_ENTRIES 1024\n\nint main() // (int argc, const char* argv[])\n{\n\t// CONSTANTS\n\t// The source code of the kernel is represented as a string\n\t// located inside file: \"fft1D_1024_kernel_src.cl\". For the details see the next listing.\n\tconst char *KernelSource =\n\t\t#include \"fft1D_1024_kernel_src.cl\"\n\t\t\t;\n\n\t// Looking up the available GPUs\n\tconst cl_uint num = 1;\n\tclGetDeviceIDs(NULL, CL_DEVICE_TYPE_GPU, 0, NULL, (cl_uint*)&num);\n\n\tcl_device_id devices[1];\n\tclGetDeviceIDs(NULL, CL_DEVICE_TYPE_GPU, num, devices, NULL);\n\n\t// create a compute context with GPU device\n\tcl_context context = clCreateContextFromType(NULL, CL_DEVICE_TYPE_GPU, NULL, NULL, NULL);\n\n\t// create a command queue\n\tclGetDeviceIDs(NULL, CL_DEVICE_TYPE_DEFAULT, 1, devices, NULL);\n\tcl_command_queue queue = clCreateCommandQueue(context, devices[0], 0, NULL);\n\n\t// allocate the buffer memory objects\n\tcl_mem memobjs[] = { clCreateBuffer(context, CL_MEM_READ_ONLY | CL_MEM_COPY_HOST_PTR, sizeof(float) * 2 * NUM_ENTRIES, NULL, NULL),\n\t\t\t\t\t\t clCreateBuffer(context, CL_MEM_READ_WRITE, sizeof(float) * 2 * NUM_ENTRIES, NULL, NULL) };\n\t// cl_mem memobjs[0] = // FIXED, SEE ABOVE\n\t// cl_mem memobjs[1] = // FIXED, SEE ABOVE\n\n\t// create the compute program\n\t// const char* fft1D_1024_kernel_src[1] = {  };\n\tcl_program program = clCreateProgramWithSource(context, 1, (const char **)& KernelSource, NULL, NULL);\n\n\t// build the compute program executable\n\tclBuildProgram(program, 0, NULL, NULL, NULL, NULL);\n\n\t// create the compute kernel\n\tcl_kernel kernel = clCreateKernel(program, \"fft1D_1024\", NULL);\n\n\t// set the args values\n\n\tsize_t local_work_size[1] = { 256 };\n\n\tclSetKernelArg(kernel, 0, sizeof(cl_mem), (void *)&memobjs[0]);\n\tclSetKernelArg(kernel, 1, sizeof(cl_mem), (void *)&memobjs[1]);\n\tclSetKernelArg(kernel, 2, sizeof(float)*(local_work_size[0] + 1) * 16, NULL);\n\tclSetKernelArg(kernel, 3, sizeof(float)*(local_work_size[0] + 1) * 16, NULL);\n\n\t// create N-D range object with work-item dimensions and execute kernel\n\tsize_t global_work_size[1] = { 256 };\n\t\n\tglobal_work_size[0] = NUM_ENTRIES;\n\tlocal_work_size[0] = 64; //Nvidia: 192 or 256\n\tclEnqueueNDRangeKernel(queue, kernel, 1, NULL, global_work_size, local_work_size, 0, NULL, NULL);\n}\n</syntaxhighlight>\n\nThe actual calculation inside file \"fft1D_1024_kernel_src.cl\" (based on [http://www.cs.berkeley.edu/~kubitron/courses/cs258-S08/projects/reports/project6_report.pdf Fitting FFT onto the G80 Architecture]):<ref name=VolkovKazianFFTG80>{{cite web | url=http://www.cs.berkeley.edu/~kubitron/courses/cs258-S08/projects/reports/project6_report.pdf | title=Fitting FFT onto G80 Architecture | accessdate=November 14, 2008 | publisher=Vasily Volkov and Brian Kazian, UC Berkeley CS258 project report |date=May 2008}}</ref>\n<syntaxhighlight lang=\"c\">\nR\"(\n  // This kernel computes FFT of length 1024. The 1024 length FFT is decomposed into\n  // calls to a radix 16 function, another radix 16 function and then a radix 4 function\n\n  __kernel void fft1D_1024 (__global float2 *in, __global float2 *out,\n                          __local float *sMemx, __local float *sMemy) {\n    int tid = get_local_id(0);\n    int blockIdx = get_group_id(0) * 1024 + tid;\n    float2 data[16];\n\n    // starting index of data to/from global memory\n    in = in + blockIdx;  out = out + blockIdx;\n\n    globalLoads(data, in, 64); // coalesced global reads\n    fftRadix16Pass(data);      // in-place radix-16 pass\n    twiddleFactorMul(data, tid, 1024, 0);\n\n    // local shuffle using local memory\n    localShuffle(data, sMemx, sMemy, tid, (((tid & 15) * 65) + (tid >> 4)));\n    fftRadix16Pass(data);               // in-place radix-16 pass\n    twiddleFactorMul(data, tid, 64, 4); // twiddle factor multiplication\n\n    localShuffle(data, sMemx, sMemy, tid, (((tid >> 4) * 64) + (tid & 15)));\n\n    // four radix-4 function calls\n    fftRadix4Pass(data);      // radix-4 function number 1\n    fftRadix4Pass(data + 4);  // radix-4 function number 2\n    fftRadix4Pass(data + 8);  // radix-4 function number 3\n    fftRadix4Pass(data + 12); // radix-4 function number 4\n\n    // coalesced global writes\n    globalStores(data, out, 64);\n  }\n)\"\n</syntaxhighlight>\nA full, open source implementation of an OpenCL FFT can be found on Apple's website.<ref name=AppleOpenCLFFT>{{cite web | url=https://developer.apple.com/mac/library/samplecode/OpenCL_FFT/index.html | title=OpenCL on FFT | accessdate=December 7, 2009 | publisher=Apple | date=November 16, 2009}}</ref>\n\n== History ==\nOpenCL was initially developed by [[Apple Inc.]], which holds [[trademark]] rights, and refined into an initial proposal in collaboration with technical teams at [[Advanced Micro Devices|AMD]], [[IBM]], [[Qualcomm]], [[Intel Corporation|Intel]], and [[Nvidia]]. Apple submitted this initial proposal to the [[Khronos Group]]. On June 16, 2008, the Khronos Compute Working Group was formed<ref>{{cite press release |url=https://www.khronos.org/news/press/releases/khronos_launches_heterogeneous_computing_initiative/ |title=Khronos Launches Heterogeneous Computing Initiative |accessdate=June 18, 2008 |publisher=Khronos Group |date=June 16, 2008 |deadurl=yes |archiveurl=https://web.archive.org/web/20080620123431/http://www.khronos.org/news/press/releases/khronos_launches_heterogeneous_computing_initiative/ |archivedate=June 20, 2008 |df=mdy-all }}</ref> with representatives from CPU, GPU, embedded-processor, and software companies. This group worked for five months to finish the technical details of the specification for OpenCL 1.0 by November 18, 2008.<ref name=macWorld>{{cite web |url=http://www.macworld.com/article/136921/2008/11/opencl.html?lsrc=top_2 |title=OpenCL gets touted in Texas |publisher=MacWorld |date=November 20, 2008 |accessdate=June 12, 2009}}</ref> This technical specification was reviewed by the Khronos members and approved for public release on December 8, 2008.<ref>{{cite press release|title=The Khronos Group Releases OpenCL 1.0 Specification|date=December 8, 2008|publisher=Khronos Group|url=https://www.khronos.org/news/press/the_khronos_group_releases_opencl_1.0_specification|accessdate=December 4, 2016}}</ref>\n\n=== OpenCL 1.0 ===\nOpenCL 1.0 released with [[Mac OS X Snow Leopard]] on August 28, 2009. According to an Apple press release:<ref name=pressrelease>{{cite press release |url=https://www.apple.com/pr/library/2008/06/09snowleopard.html |title=Apple Previews Mac OS X Snow Leopard to Developers |accessdate=June 9, 2008 |publisher=Apple Inc. |date=June 9, 2008 |deadurl=yes |archiveurl=https://www.webcitation.org/66GmLMR6B?url=http://www.apple.com/pr/library/2008/06/09Apple-Previews-Mac-OS-X-Snow-Leopard-to-Developers.html |archivedate=March 19, 2012 |df=mdy-all }}</ref>\n<blockquote>\nSnow Leopard further extends support for modern hardware with Open Computing Language (OpenCL), which lets any application tap into the vast gigaflops of GPU computing power previously available only to graphics applications. OpenCL is based on the C programming language and has been proposed as an open standard.\n</blockquote>\n\nAMD decided to support OpenCL instead of the now deprecated [[Close to Metal]] in its [[AMD Stream SDK|Stream framework]].<ref name=AMDpressrelease>{{cite press release |url=https://www.amd.com/us-en/Corporate/VirtualPressRoom/0,,51_104_543~127451,00.html |title=AMD Drives Adoption of Industry Standards in GPGPU Software Development |accessdate=August 14, 2008 |publisher=AMD |date=August 6, 2008}}</ref><ref name=eweekAMD>{{cite web |url=http://www.eweek.com/c/a/Desktops-and-Notebooks/AMD-Backing-OpenCL-and-Microsoft-DirectX-11/ |title=AMD Backs OpenCL, Microsoft DirectX 11 |accessdate=August 14, 2008 |publisher=eWeek |date=August 6, 2008}}</ref> [[RapidMind]] announced their adoption of OpenCL underneath their development platform to support GPUs from multiple vendors with one interface.<ref name=RapidMindHPCWire>{{cite web |url=http://www.hpcwire.com/topic/applications/RapidMind_Embraces_Open_Source_and_Standards_Projects.html |title=HPCWire: RapidMind Embraces Open Source and Standards Projects |accessdate=November 11, 2008 |publisher=HPCWire |date=November 10, 2008 |deadurl=yes |archiveurl=https://web.archive.org/web/20081218113648/http://www.hpcwire.com/topic/applications/RapidMind_Embraces_Open_Source_and_Standards_Projects.html |archivedate=December 18, 2008}}</ref> On December 9, 2008, Nvidia announced its intention to add full support for the OpenCL 1.0 specification to its GPU Computing Toolkit.<ref name=\"Nvidia Press Release 2008-12-09\">{{cite press release |url=http://www.nvidia.com/object/io_1228825271885.html |title=Nvidia Adds OpenCL To Its Industry Leading GPU Computing Toolkit |accessdate=December 10, 2008 |publisher=Nvidia |date=December 9, 2008}}</ref> On October 30, 2009, IBM released its first OpenCL implementation as a part of the [[XL compilers]].<ref name=openclIBM>{{cite web |url=http://www.alphaworks.ibm.com/tech/opencl |title=OpenCL Development Kit for Linux on Power |accessdate=October 30, 2009 |publisher=alphaWorks |date=October 30, 2009}}</ref>\n\n=== OpenCL 1.1 ===\nOpenCL 1.1 was ratified by the Khronos Group on June 14, 2010<ref>{{cite web |url=https://www.khronos.org/news/press/releases/khronos-group-releases-opencl-1-1-parallel-computing-standard/ |title=Khronos Drives Momentum of Parallel Computing Standard with Release of OpenCL 1.1 Specification |accessdate=February 24, 2016}}</ref> and adds significant functionality for enhanced parallel programming flexibility, functionality, and performance including:\n* New data types including 3-component vectors and additional image formats;\n* Handling commands from multiple host threads and processing buffers across multiple devices;\n* Operations on regions of a buffer including read, write and copy of 1D, 2D, or 3D rectangular regions;\n* Enhanced use of events to drive and control command execution;\n* Additional OpenCL built-in C functions such as integer clamp, shuffle, and asynchronous strided copies;\n* Improved OpenGL interoperability through efficient sharing of images and buffers by linking OpenCL and OpenGL events.\n\n=== OpenCL 1.2 ===\nOn November 15, 2011, the Khronos Group announced the OpenCL 1.2 specification,<ref>{{cite web |url=https://www.khronos.org/news/press/khronos-releases-opencl-1.2-specification |title=Khronos Releases OpenCL 1.2 Specification |publisher=Khronos Group |date=November 15, 2011 |accessdate=June 23, 2015}}</ref> which added significant functionality over the previous versions in terms of performance and features for parallel programming. Most notable features include:\n* Device partitioning: the ability to partition a device into sub-devices so that work assignments can be allocated to individual compute units. This is useful for reserving areas of the device to reduce latency for time-critical tasks.\n* Separate compilation and linking of objects: the functionality to compile OpenCL into external libraries for inclusion into other programs.\n* Enhanced image support: 1.2 adds support for 1D images and 1D/2D image arrays. Furthermore, the OpenGL sharing extensions now allow for OpenGL 1D textures and 1D/2D texture arrays to be used to create OpenCL images.\n* Built-in kernels: custom devices that contain specific unique functionality are now integrated more closely into the OpenCL framework. Kernels can be called to use specialised or non-programmable aspects of underlying hardware. Examples include video encoding/decoding and digital signal processors.\n* DirectX functionality: DX9 media surface sharing allows for efficient sharing between OpenCL and DX9 or [[DirectX Video Acceleration|DXVA]] media surfaces. Equally, for DX11, seamless sharing between OpenCL and DX11 surfaces is enabled.\n* The ability to force [[IEEE floating point|IEEE 754]] compliance for single precision floating point math: OpenCL by default allows the single precision versions of the division, reciprocal, and square root operation to be less accurate than the correctly rounded values that IEEE 754 requires.<ref name=\"OpenCL1.2\">{{cite web |url=https://www.khronos.org/registry/cl/specs/opencl-1.2.pdf |title=OpenCL 1.2 Specification |publisher=Khronos Group |accessdate=June 23, 2015}}</ref> If the programmer passes the \"-cl-fp32-correctly-rounded-divide-sqrt\" command line argument to the compiler, these three operations will be computed to IEEE 754 requirements if the OpenCL implementation supports this, and will fail to compile if the OpenCL implementation does not support computing these operations to their correctly-rounded values as defined by the IEEE 754 specification.<ref name=\"OpenCL1.2\" /> This ability is supplemented by the ability to query the OpenCL implementation to determine if it can perform these operations to IEEE 754 accuracy.<ref name=\"OpenCL1.2\" />\n\n=== OpenCL 2.0 ===\nOn November 18, 2013, the Khronos Group announced the ratification and public release of the finalized OpenCL 2.0 specification.<ref>{{cite web |url=https://www.khronos.org/news/press/khronos-finalizes-opencl-2.0-specification-for-heterogeneous-computing |title=Khronos Finalizes OpenCL 2.0 Specification for Heterogeneous Computing |date=November 18, 2013 |accessdate=February 10, 2014 |publisher=Khronos Group}}</ref> Updates and additions to OpenCL 2.0 include:\n* Shared virtual memory\n* Nested parallelism\n* Generic address space\n* Images\n* [[C11 (C standard revision)|C11]] atomics\n* Pipes\n* [[Android (operating system)|Android]] installable client driver extension\n\n=== OpenCL 2.1 ===\nThe ratification and release of the OpenCL 2.1 provisional specification was announced on March 3, 2015 at the Game Developer Conference in San Francisco. It was released on November 16, 2015.<ref>{{cite web |title=Khronos Releases OpenCL 2.1 and SPIR-V 1.0 Specifications for Heterogeneous Parallel Programming |url=https://www.khronos.org/news/press/khronos-releases-opencl-2.1-and-spir-v-1.0-specifications-for-heterogeneous |publisher=Khronos Group |accessdate=November 16, 2015 |date=November 16, 2015}}</ref> It introduced the OpenCL C++ kernel language, based on a subset of [[C++14]], while maintaining support for the preexisting OpenCL C kernel language. [[Vulkan API|Vulkan]] and OpenCL 2.1 share [[SPIR-V]] as an [[intermediate representation]] allowing high-level language front-ends to share a common compilation target. Updates to the OpenCL API include:\n* Additional subgroup functionality\n* Copying of kernel objects and states\n* Low-latency device timer queries\n* Ingestion of SPIR-V code by runtime\n* Execution priority hints for queues\n* Zero-sized dispatches from host\n\nAMD, ARM, Intel, HPC, and [[YetiWare]] have declared support for OpenCL 2.1.<ref>{{cite web |title=Khronos Announces OpenCL 2.1: C++ Comes to OpenCL |url=http://www.anandtech.com/show/9039/khronos-announces-opencl-21-c-comes-to-opencl |publisher=AnandTech |accessdate=April 8, 2015 |date=March 3, 2015}}</ref><ref>{{cite web |title=Khronos Releases OpenCL 2.1 Provisional Specification for Public Review |url=https://www.khronos.org/news/press/khronos-releases-opencl-2.1-provisional-specification-for-public-review |publisher=Kronos Group |accessdate=April 8, 2015 |date=March 3, 2015}}</ref>\n\n=== OpenCL 2.2 ===\nOpenCL 2.2 brings the OpenCL C++ kernel language into the core specification for significantly enhanced parallel programming productivity.<ref>{{cite web |url= https://www.khronos.org/opencl/ |title= OpenCL Overview |publisher= Khronos Group|date= 2013-07-21 }}</ref><ref name=\"opencl2.2-provisional\">{{cite web |url= https://www.khronos.org/news/press/khronos-releases-opencl-2.2-provisional-spec-opencl-c-kernel-language |title= Khronos Releases OpenCL 2.2 Provisional Specification with OpenCL C++ Kernel Language for Parallel Programming |date=April 18, 2016 |publisher= [[Khronos Group]] }}</ref><ref>{{cite web |title= OpenCL – A State of the Union |url= http://www.iwocl.org/wp-content/uploads/iwocl-2016-opencl-state-union.pdf|first=Neil|last=Trevett|website=IWOCL|publisher=[[Khronos Group]] |location=[[Vienna]] |date= April 2016 |accessdate= January 2, 2017 }}</ref> It was released on May 16, 2017.<ref>{{cite web |url=https://www.khronos.org/news/press/khronos-releases-opencl-2.2-with-spir-v-1.2 |title=Khronos Releases OpenCL 2.2 With SPIR-V 1.2 |date=May 16, 2017 |publisher=[[Khronos Group]] }}</ref> Maintenance Update released in May 2018 with bugfixes.<ref name=\"auto\">{{Cite web|url=https://www.khronos.org/blog/opencl-2.2-maintenance-update-released|title=OpenCL 2.2 Maintenance Update Released|date=May 14, 2018|website=The Khronos Group}}</ref>\n* The OpenCL C++ kernel language is a static subset of the [[C++14]] standard and includes classes, templates, lambda expressions, function overloads and many other constructs for generic and meta-programming.\n* Uses the new Khronos [[SPIR-V]] 1.1 intermediate language which fully supports the OpenCL C++ kernel language.\n* OpenCL library functions can now use the C++ language to provide increased safety and reduced undefined behavior while accessing features such as atomics, iterators, images, samplers, pipes, and device queue built-in types and address spaces.\n* Pipe storage is a new device-side type in OpenCL 2.2 that is useful for FPGA implementations by making connectivity size and type known at compile time, enabling efficient device-scope communication between kernels.\n* OpenCL 2.2 also includes features for enhanced optimization of generated code: applications can provide the value of specialization constant at SPIR-V compilation time, a new query can detect non-trivial constructors and destructors of program scope global objects, and user callbacks can be set at program release time.\n* Runs on any OpenCL 2.0-capable hardware (only driver update required)\n\n==Future==\n[[File:IWOCL2017.jpg|thumb|The [[IWOCL|International Workshop on OpenCL]] (IWOCL) held by the Khronos Group.]]\nWhen releasing OpenCL version 2.2, the Khronos Group announced that OpenCL would be merging into [[Vulkan (API)|Vulkan]] in the future.<ref>{{Cite web|url=https://www.pcper.com/reviews/General-Tech/Breaking-OpenCL-Merging-Roadmap-Vulkan|title=Breaking: OpenCL Merging Roadmap into Vulkan &#124; PC Perspective|website=www.pcper.com}}</ref> OpenCL Next will come in 2019 with new System of Features.<ref>{{Cite web|url=https://www.phoronix.com/scan.php?page=article&item=siggraph-2018-khr&num=2|title=SIGGRAPH 2018: OpenCL-Next Taking Shape, Vulkan Continues Evolving - Phoronix|website=www.phoronix.com}}</ref>\n\n==Implementations ==\nOpenCL consists of a set of headers and a [[shared object]] that is loaded at runtime. An installable client driver (ICD) must be installed on the platform for every class of vendor for which the runtime would need to support. That is, for example, in order to support Nvidia devices on a Linux platform, the Nvidia ICD would need to be installed such that the OpenCL runtime (the ICD loader) would be able to locate the ICD for the vendor and redirect the calls appropriately. The standard OpenCL header is used by the consumer application; calls to each function are then proxied by the OpenCL runtime to the appropriate driver using the ICD. Each vendor must implement each OpenCL call in their driver.<ref>{{cite web |url=https://www.khronos.org/registry/cl/extensions/khr/cl_khr_icd.txt |title=OpenCL ICD Specification |accessdate=June 23, 2015}}</ref>\n\nThe Apple,<ref>{{cite web|url=http://llvm.org/Users.html#Apple|title=Apple entry on LLVM Users page|accessdate=August 29, 2009}}</ref> Nvidia,<ref>{{cite web|url=http://llvm.org/Users.html|title=Nvidia entry on LLVM Users page|accessdate=August 6, 2009}}</ref> [[RapidMind]]<ref>{{cite web|url=http://llvm.org/Users.html|title=Rapidmind entry on LLVM Users page|accessdate=October 1, 2009}}</ref> and [[Gallium3D]]<ref>{{cite web|url=http://zrusin.blogspot.com/2009/02/opencl.html|title=Zack Rusin's blog post about the Gallium3D OpenCL implementation|accessdate=October 1, 2009|date=February 2009}}</ref> implementations of OpenCL are all based on the [[LLVM]] Compiler technology and use the [[Clang]] compiler as its frontend.\n\n; MESA Gallium Compute : An implementation of OpenCL (actual 1.1 incomplete, mostly done AMD Radeon GCN) for a number of platforms is maintained as part of the Gallium Compute Project,<ref>{{cite web |url=http://dri.freedesktop.org/wiki/GalliumCompute/ |title=GalliumCompute |publisher=dri.freedesktop.org |accessdate=June 23, 2015}}</ref> which builds on the work of the [[Mesa (computer graphics)|Mesa project]] to support multiple platforms. Formerly this was known as CLOVER.,<ref>{{Cite web|url=https://www.x.org/wiki/Events/XDC2013/XDC2013TomStellardCloverStatus/XDC2013TomStellardCloverStatus.pdf|title=Clover Status Update}}</ref> actual development: mostly support for running incomplete framework with actual LLVM and CLANG, some new features like fp16 in 17.3,<ref>{{Cite web|url=https://cgit.freedesktop.org/mesa/mesa/log/?qt=grep&q=clover|title=mesa/mesa - The Mesa 3D Graphics Library|website=cgit.freedesktop.org}}</ref> Target complete OpenCL 1.0, 1.1 and 1.2 for AMD and Nvidia. New Basic Development is done by [[Red Hat]] with SPIR-V also for Clover.<ref>{{Cite web|url=https://www.phoronix.com/scan.php?page=news_item&px=Gallium-Clover-NIR-SPIR-V-XDC18|title=Gallium Clover With SPIR-V & NIR Opening Up New Compute Options Inside Mesa - Phoronix|website=www.phoronix.com}}</ref><ref>https://xdc2018.x.org/slides/clover.pdf</ref>\n; BEIGNET : An implementation by Intel for its [[Ivy Bridge (microarchitecture)|Ivy Bridge +]] hardware was released in 2013.<ref>{{cite web |first=Michael |last=Larabel |authorlink=Michael Larabel |date=January 10, 2013 |title=Beignet: OpenCL/GPGPU Comes For Ivy Bridge On Linux |website=Phoronix |url=https://www.phoronix.com/scan.php?page=news_item&px=MTI3MTU}}</ref> This software from Intel's China Team, has attracted criticism from developers at AMD and [[Red Hat]],<ref>{{cite web |first=Michael |last=Larabel |authorlink=Michael Larabel |date=April 16, 2013 |title=More Criticism Comes Towards Intel's Beignet OpenCL |website=Phoronix |url=https://www.phoronix.com/scan.php?page=news_item&px=MTM1MzM}}</ref> as well as [[Michael Larabel]] of [[Phoronix]].<ref>{{cite web |last=Larabel |first=Michael |date=December 24, 2013 |title=Intel's Beignet OpenCL Is Still Slowly Baking |website=Phoronix |url=https://www.phoronix.com/scan.php?page=news_item&px=MTU1MjA}}</ref> Actual Version 1.3.2 support OpenCL 1.2 complete (Ivy Bridge and higher) and OpenCL 2.0 optional for Skylake and newer.<ref>{{cite web |url= https://freedesktop.org/wiki/Software/Beignet/ |title= Beignet |publisher= freedesktop.org}}</ref><ref>{{Cite web|url=https://cgit.freedesktop.org/beignet/|title=beignet - Beignet OpenCL Library for Intel Ivy Bridge and newer GPUs|website=cgit.freedesktop.org}}</ref> support for Android has been added to Beignet.,<ref>{{Cite web|url=https://www.phoronix.com/scan.php?page=news_item&px=Intel-Beignet-Android|title=Intel Brings Beignet To Android For OpenCL Compute - Phoronix|website=www.phoronix.com}}</ref> actual development targets: only support for 1.2 and 2.0, road to OpenCL 2.1 and 2.2 is gone to NEO.\n; NEO: An implementation by Intel for Gen. 8 [[Broadwell (microarchitecture)|Broadwell]] + Gen. 9 hardware released in 2018.<ref>{{Cite web|url=https://01.org/compute-runtime|title=01.org Intel Open Source - Compute Runtime|last=|first=|date=2018-02-07|website=|access-date=}}</ref> This driver replaces Beignet implementation for supported platforms. NEO provides OpenCL 2.1 support on Core platforms and OpenCL 1.2 on Atom platforms.<ref>{{Cite web|url=https://github.com/intel/compute-runtime/blob/master/README.md|title=NEO GitHub README|last=|first=|date=2019-03-21|website=|access-date=}}</ref> \n; ROCm \n: Created as part of AMD's [[GPUOpen]], ROCm (Radeon Open Compute) is an open source Linux project built on OpenCL 1.2 with language support for 2.0. The system is compatible with all modern AMD CPUs and APUs (GFX 8+), as well as Intel Gen7.5+ CPUs (only with PCI 3.0).<ref>{{cite web|url=https://radeonopencompute.github.io/|title=ROCm|last=|first=|date=|website=GitHub|archive-url=https://web.archive.org/web/20161008220038/https://radeonopencompute.github.io/|archive-date=October 8, 2016|dead-url=yes|access-date=}}</ref><ref>{{cite web|url=https://github.com/RadeonOpenCompute/ROCm|title=RadeonOpenCompute/ROCm: ROCm - Open Source Platform for HPC and Ultrascale GPU Computing|publisher=GitHub|date=2019-03-21}}</ref> With version 1.9 support is in some points extended experimental to Hardware with PCIe 2.0 and without atomics. An overview of actual work is done on XDC2018.<ref>{{Cite web|url=https://www.phoronix.com/scan.php?page=news_item&px=ROCm-Compute-Stack-Overview|title=A Nice Overview Of The ROCm Linux Compute Stack - Phoronix|website=www.phoronix.com}}</ref><ref>{{Cite web|url=https://drive.google.com/file/d/1ePlNzxYryveh6iFL-cqJO7ycSsYJ4LbC/view?usp=embed_facebook|title=XDC Lightning.pdf|website=Google Docs}}</ref> Actual ROCm Version 2.0 supports Full OpenCL 2.0, but some errors and limitations are on the todo list.<ref>{{Cite web|url=https://www.phoronix.com/scan.php?page=news_item&px=Radeon-ROCm-2.0-Arrives|title=Radeon ROCm 2.0 Officially Out With OpenCL 2.0 Support, TensorFlow 1.12, Vega 48-bit VA - Phoronix|website=www.phoronix.com}}</ref><ref>{{Cite web|url=https://www.phoronix.com/scan.php?page=article&item=radeon-rocm-20&num=1|title=Taking Radeon ROCm 2.0 OpenCL For A Benchmarking Test Drive - Phoronix|website=www.phoronix.com}}</ref>\n; POCL: A portable implementation supporting CPUs and some GPUs (via CUDA and [[Heterogeneous System Architecture|HSA]]). Building on [[Clang]] and [[LLVM]].<ref>{{Cite journal |journal=Int'l J. Parallel Programming |doi=10.1007/s10766-014-0320-y |year=2016 |title=pocl: A Performance-Portable OpenCL Implementation |first1=Pekka |last1=Jääskeläinen |first2=Carlos |last2=Sánchez de La Lama |first3=Erik |last3=Schnetter |first4=Kalle |last4=Raiskila |first5=Jarmo |last5=Takala |first6=Heikki |last6=Berg |volume=43 |issue=5 |pages=752–785|arxiv=1611.07083|bibcode=2016arXiv161107083J }}</ref> With version 1.0 OpenCL 1.2 was nearly fully implemented along with some 2.x features.<ref name=\"auto1\">{{Cite web|url=http://portablecl.org/|title=pocl home page|website=pocl}}</ref> Actual is Version 1.2 with LLVM/CLANG 6.0, 7.0 and Full OpenCL 1.2 support with all closed tickets in Milestone 1.2.<ref name=\"auto1\"/><ref>{{Cite web|url=https://github.com/pocl/pocl|title=pocl: Portable Computing Language. Contribute to pocl/pocl development by creating an account on GitHub|date=March 14, 2019|via=GitHub}}</ref> OpenCL 2.0 is nearly full implemented.<ref>{{Cite web|url=http://portablecl.org/docs/html/hsa_status.html#opencl-2-0-atomics-and-hsa-memory-scope|title=HSA support implementation status as of 2016-05-17 — Portable Computing Language (pocl) 1.3-pre documentation|website=portablecl.org}}</ref>\n; Shamrock : A Port of Mesa Clover for ARM with full support of OpenCL 1.2,<ref>{{cite web|title=About|url=https://git.linaro.org/gpgpu/shamrock.git/about/|website=Git.Linaro.org}}</ref><ref>{{cite web|title=LCA14-412: GPGPU on ARM SoC|url=https://s3.amazonaws.com/connect.linaro.org/lca14/presentations/LCA14-412-%20GPGPU%20on%20ARM%20SoC%20session.pdf|first1=T.|last1=Gall|first2=G.|last2=Pitney|website=[[Amazon Web Services]]|date=March 6, 2014|accessdate=January 22, 2017}}</ref> no actual development for 2.0.\n; FreeOCL : A CPU focused implementation of OpenCL 1.2 that implements an external compiler to create a more reliable platform,<ref>{{Cite web|url=https://github.com/zuzuf/freeocl|title=zuzuf/freeocl|website=GitHub|language=en|access-date=April 13, 2017}}</ref> no actual development.\n; MOCL: An OpenCL implementation based on POCL by the NUDT researchers for Matrix-2000 was released in 2018. The Matrix-2000 architecture is designed to replace the Intel Xeon Phi accelerators of the TianHe-2 supercomputer. This programming framework is built on top of LLVM v5.0 and reuses some code pieces from POCL as well. To unlock the hardware potential, the device runtime uses a push-based task dispatching strategy and the performance of the kernel atomics is improved significantly. This framework has been deployed on the TH-2A system and is readily available to the public.<ref name=\"mtx2k_ocl\">{{cite conference |url=https://jianbinfang.github.io/files/2018-03-15-mocl.pdf |format=PDF |conference=Proc. Int'l Conf. on Computing Frontiers |doi=10.1145/3203217.3203244 |title=MOCL: An Efficient OpenCL Implementation for the Matrix-2000 Architecture |year=2018 |last1=Zhang |first1=Peng |last2=Fang |first2=Jianbin |last3=Yang |first3=Canqun |last4=Tang |first4=Tao |last5=Huang |first5=Chun |last6=Wang | first6=Zheng}}</ref> Some of the software will next ported to improve POCL.<ref name=\"auto1\"/>\n\n; Khronos Conformance Test Suite (CTS): CTS is for all developers and all actual OpenCL levels free (since 2017) available.<ref>{{cite web|url=https://github.com/KhronosGroup/OpenCL-CTS|title=KhronosGroup/OpenCL-CTL: The OpenCL Conformance Tests|publisher=GitHub|date=2019-03-21}}</ref>\n\n=== Timeline of vendor implementations ===\n* December 10, 2008: AMD and Nvidia held the first public OpenCL demonstration, a 75-minute presentation at [[Siggraph]] Asia 2008. AMD showed a CPU-accelerated OpenCL demo explaining the scalability of OpenCL on one or more cores while Nvidia showed a GPU-accelerated demo.<ref>{{cite web |url=https://www.youtube.com/watch?v=sLv_fhQlqis |title=OpenCL Demo, AMD CPU |date=December 10, 2008 |accessdate=March 28, 2009}}</ref><ref>{{cite web |url=https://www.youtube.com/watch?v=PJ1jydg8mLg |title=OpenCL Demo, Nvidia GPU |date=December 10, 2008 |accessdate=March 28, 2009}}</ref>\n* March 16, 2009: at the 4th Multicore Expo, Imagination Technologies announced the [[PowerVR]] SGX543MP, the first GPU of this company to feature OpenCL support.<ref>{{cite web |url=http://www.imgtec.com/News/Release/index.asp?NewsID=449 |title=Imagination Technologies launches advanced, highly-efficient POWERVR SGX543MP multi-processor graphics IP family |publisher=Imagination Technologies |date=March 19, 2009 |accessdate=January 30, 2011}}</ref>\n* March 26, 2009: at [[Game Developers Conference|GDC 2009]], AMD and [[Havok (company)|Havok]] demonstrated the first working implementation for OpenCL accelerating [[Havok (software)#Havok Cloth and Destruction|Havok Cloth]] on AMD [[Radeon R700#Radeon HD 4800|Radeon HD 4000 series]] GPU.<ref>{{cite web |url=http://www.pcper.com/comments.php?nid=6954 |title=AMD and Havok demo OpenCL accelerated physics |publisher=PC Perspective |date=March 26, 2009 |accessdate=March 28, 2009 |archiveurl=https://web.archive.org/web/20090405072046/http://www.pcper.com/comments.php?nid=6954 |archivedate=April 5, 2009}}</ref>\n* April 20, 2009: Nvidia announced the release of its OpenCL driver and [[Software development kit|SDK]] to developers participating in its OpenCL Early Access Program.<ref>{{cite web |url=http://www.nvidia.com/object/io_1240224603372.html |title=Nvidia Releases OpenCL Driver To Developers |publisher=Nvidia |date=April 20, 2009 |accessdate=April 27, 2009}}</ref>\n* August 5, 2009: AMD unveiled the first development tools for its OpenCL platform as part of its [[ATI Stream]] SDK v2.0 Beta Program.<ref>{{cite web |url=http://arst.ch/5te |title=AMD does reverse GPGPU, announces OpenCL SDK for x86 |publisher=Ars Technica |date=August 5, 2009 |accessdate=August 6, 2009}}</ref>\n* August 28, 2009: Apple released [[Mac OS X Snow Leopard]], which contains a full implementation of OpenCL.<ref>{{cite web |first1=Dan |last1=Moren |first2=Jason |last2=Snell |url=http://www.macworld.com/article/140897/2009/06/keynote.html |title=Live Update: WWDC 2009 Keynote |website=MacWorld.com |publisher=MacWorld |date=June 8, 2009 |accessdate=June 12, 2009}}</ref>\n* September 28, 2009: Nvidia released its own OpenCL drivers and SDK implementation.\n* October 13, 2009: AMD released the fourth beta of the ATI Stream SDK 2.0, which provides a complete OpenCL implementation on both [[Radeon R700|R700]]/[[Radeon R800|R800]] GPUs and [[SSE3]] capable CPUs. The SDK is available for both Linux and Windows.<ref>{{cite web |url=http://developer.amd.com/GPU/ATISTREAMSDKBETAPROGRAM/Pages/default.aspx#one |title=ATI Stream Software Development Kit (SDK) v2.0 Beta Program |accessdate=October 14, 2009 |deadurl=yes |archiveurl=https://web.archive.org/web/20090809065559/http://developer.amd.com/GPU/ATISTREAMSDKBETAPROGRAM/Pages/default.aspx |archivedate=August 9, 2009}}</ref>\n* November 26, 2009: Nvidia released drivers for OpenCL 1.0 (rev 48).\n* October 27, 2009: [[S3 Graphics|S3]] released their first product supporting native OpenCL 1.0 – the Chrome 5400E embedded graphics processor.<ref>{{cite web |url=http://www.s3graphics.com/en/news/news_detail.aspx?id=44 |title=S3 Graphics launched the Chrome 5400E embedded graphics processor |accessdate=October 27, 2009 |deadurl=yes |archiveurl=https://web.archive.org/web/20091202065250/http://www.s3graphics.com/en/news/news_detail.aspx?id=44 |archivedate=December 2, 2009}}</ref>\n* December 10, 2009: [[VIA Technologies|VIA]] released their first product supporting OpenCL 1.0 – ChromotionHD 2.0 video processor included in VN1000 chipset.<ref>{{cite web |url=http://www.via.com.tw/en/resources/pressroom/pressrelease.jsp?press_release_no=4327 |title=VIA Brings Enhanced VN1000 Graphics Processor] |accessdate=December 10, 2009 |deadurl=yes |archiveurl=https://web.archive.org/web/20091215090119/http://www.via.com.tw/en/resources/pressroom/pressrelease.jsp?press_release_no=4327 |archivedate=December 15, 2009 |df=mdy-all }}</ref>\n* December 21, 2009: AMD released the production version of the ATI Stream SDK 2.0,<ref>{{cite web |url=http://developer.amd.com/gpu/ATIStreamSDK/Pages/default.aspx |title=ATI Stream SDK v2.0 with OpenCL 1.0 Support |accessdate=October 23, 2009 |deadurl=yes |archiveurl=https://web.archive.org/web/20091101061303/http://developer.amd.com/gpu/atistreamsdk/pages/default.aspx |archivedate=November 1, 2009 |df=mdy-all }}</ref> which provides OpenCL 1.0 support for [[Radeon R800|R800]] GPUs and beta support for [[Radeon R700|R700]] GPUs.\n* June 1, 2010: [[ZiiLABS]] released details of their first OpenCL implementation for the ZMS processor for handheld, embedded and digital home products.<ref>{{cite web |url=http://www.ziilabs.com/opencl |title=OpenCL |publisher=ZiiLABS |accessdate=June 23, 2015}}</ref>\n* June 30, 2010: IBM released a fully conformant version of OpenCL 1.0.<ref name=\"conformant-products\" />\n* September 13, 2010: [[Intel]] released details of their first OpenCL implementation for the Sandy Bridge chip architecture. Sandy Bridge will integrate Intel's newest graphics chip technology directly onto the central processing unit.<ref>{{cite web |url=http://news.cnet.com/8301-13924_3-20016302-64.html |title=Intel discloses new Sandy Bridge technical details |accessdate=September 13, 2010}}</ref>\n* November 15, 2010: [[Wolfram Research]] released [[Mathematica|Mathematica 8]] with [http://reference.wolfram.com/mathematica/OpenCLLink/tutorial/Overview.html OpenCLLink] package.\n* March 3, 2011: [[Khronos Group]] announces the formation of the [[WebCL]] working group to explore defining a [[JavaScript]] binding to OpenCL. This creates the potential to harness [[GPU]] and [[Multi-core processor|multi-core CPU]] parallel processing from a [[Web browser]].<ref>{{cite web |url=https://www.khronos.org/news/categories/C251 |title=WebCL related stories |publisher=Khronos Group |accessdate=June 23, 2015}}</ref><ref>{{cite web |url=https://www.khronos.org/news/press/releases/khronos-releases-final-webgl-1.0-specification |title=Khronos Releases Final WebGL 1.0 Specification |publisher=Khronos Group |accessdate=June 23, 2015 |deadurl=yes |archiveurl=https://web.archive.org/web/20150709134803/https://www.khronos.org/news/press/releases/khronos-releases-final-webgl-1.0-specification |archivedate=July 9, 2015 |df=mdy-all }}</ref>\n* March 31, 2011: IBM released a fully conformant version of OpenCL 1.1.<ref name=\"conformant-products\" /><ref>{{Cite web|url=https://developer.ibm.com/community/|title=Community}}</ref>\n* April 25, 2011: IBM released OpenCL Common Runtime v0.1 for Linux on x86 Architecture.<ref>{{Cite web|url=https://www.ibm.com/developerworks/mydeveloperworks/wikis/home?lang=en#/wiki/Wbf059a58a9b9_459d_aca4_493655c96370/page/OpenCL+Common+Runtime|title=Welcome to Wikis|date=October 20, 2009|website=www.ibm.com}}</ref>\n* May 4, 2011: Nokia Research releases an open source WebCL extension for the [[Firefox]] web browser, providing a JavaScript binding to OpenCL.<ref>{{cite web |url=https://www.khronos.org/news/permalink/nokia-research-releases-webcl-prototype |title=Nokia Research releases WebCL prototype |publisher=Khronos Group |date=May 4, 2011 |accessdate=June 23, 2015}}</ref>\n* July 1, 2011: Samsung Electronics releases an open source prototype implementation of WebCL for WebKit, providing a JavaScript binding to OpenCL.<ref>{{cite web |last=KamathK |first=Sharath |url=https://github.com/SRA-SiliconValley/webkit-webcl |title=Samsung's WebCL Prototype for WebKit |publisher=Github.com |accessdate=June 23, 2015 |deadurl=yes |archiveurl=https://web.archive.org/web/20150218105743/https://github.com/SRA-SiliconValley/webkit-webcl |archivedate=February 18, 2015 |df=mdy-all }}</ref>\n* August 8, 2011: AMD released the OpenCL-driven AMD Accelerated Parallel Processing (APP) Software Development Kit (SDK) v2.5, replacing the [[ATI Stream]] SDK as technology and concept.<ref>{{cite web |url=https://www.amd.com/us/press-releases/Pages/app-sdk-2011aug08.aspx |title=AMD Opens the Throttle on APU Performance with Updated OpenCL Software Development&nbsp; |publisher=Amd.com |date=August 8, 2011 |accessdate=June 16, 2013}}</ref>\n* December 12, 2011: AMD released AMD APP SDK v2.6<ref>{{cite web |url=http://forums.amd.com/forum/messageview.cfm?catid=390&threadid=157108 |title=AMD APP SDK v2.6 |publisher=Forums.amd.com |date=March 13, 2015 |accessdate=June 23, 2015}}</ref> which contains a preview of OpenCL 1.2.\n* February 27, 2012: [[The Portland Group]] released the PGI OpenCL compiler for multi-core [[ARM architecture|ARM]] CPUs.<ref>{{cite web |url=http://www.anandtech.com/show/5607/the-portland-group-announces-opencl-compiler-for-stericsson-armbased-novathor-socs |title=The Portland Group Announces OpenCL Compiler for ST-Ericsson ARM-Based NovaThor SoCs |accessdate=May 4, 2012}}</ref>\n* April 17, 2012: Khronos released a WebCL working draft.<ref>{{cite web |url=https://cvs.khronos.org/svn/repos/registry/trunk/public/webcl/spec/latest/index.html |title=WebCL Latest Spec |publisher=[[Khronos Group]] |date=November 7, 2013 |accessdate=June 23, 2015}}</ref>\n* May 6, 2013: Altera released the Altera SDK for OpenCL, version 13.0.<ref>{{cite web |url=http://newsroom.altera.com/press-releases/altera-opens-the-world-of-fpgas-to-software-programmers-with-broad-availability-of-sdk-and-off-the-shelf-boards-for-opencl.htm |title=Altera Opens the World of FPGAs to Software Programmers with Broad Availability of SDK and Off-the-Shelf Boards for OpenCL |publisher=Altera.com |accessdate=January 9, 2014}}</ref> It is conformant to OpenCL 1.0.<ref>{{cite web |url=http://newsroom.altera.com/press-releases/nr-altera-sdk-opencl-conformance.htm |title=Altera SDK for OpenCL is First in Industry to Achieve Khronos Conformance for FPGAs |publisher=Altera.com |accessdate=January 9, 2014}}</ref>\n* November 18, 2013: Khronos announced that the specification for OpenCL 2.0 had been finalized.<ref>{{cite web |url=https://www.khronos.org/news/press/khronos-finalizes-opencl-2.0-specification-for-heterogeneous-computing |title=Khronos Finalizes OpenCL 2.0 Specification for Heterogeneous Computing |publisher=Khronos Group |date=November 18, 2013 |accessdate=June 23, 2015}}</ref>\n* March 19, 2014: Khronos releases the WebCL 1.0 specification<ref>{{cite web |url=https://www.khronos.org/news/press/khronos-releases-webcl-1.0-specification |title=WebCL 1.0 Press Release |publisher=Khronos Group |date=March 19, 2014 |accessdate=June 23, 2015}}</ref><ref>{{cite web |url=https://www.khronos.org/registry/webcl/specs/1.0.0/ |title=WebCL 1.0 Specification |publisher=Khronos Group |date=March 14, 2014 |accessdate=June 23, 2015}}</ref>\n* August 29, 2014: Intel releases HD Graphics 5300 driver that supports OpenCL 2.0.<ref>{{Cite web|url=https://downloadcenter.intel.com/Detail_Desc.aspx?agr=Y&DwnldID=24245|title=Intel OpenCL 2.0 Driver}}</ref>\n* September 25, 2014: AMD releases Catalyst 14.41 RC1, which includes an OpenCL 2.0 driver.<ref>{{cite web |url=http://support.amd.com/en-us/kb-articles/Pages/OpenCL2-Driver.aspx |title=AMD OpenCL 2.0 Driver |website=Support.AMD.com |date=June 17, 2015 |accessdate=June 23, 2015}}</ref>\n* January 14, 2015: Xilinx Inc. announces SDAccel development environment for OpenCL, C, and C++, achieves Khronos Conformance<ref>{{Cite web|url=https://www.khronos.org/news/permalink/xilinx-sdaccel-development-environment-for-opencl-c-and-c-achieves-khronos|title=Xilinx SDAccel development environment for OpenCL, C, and C++, achieves Khronos Conformance - khronos.org news|website=The Khronos Group|language=en|access-date=June 26, 2017}}</ref>\n* April 13, 2015: Nvidia releases WHQL driver v350.12, which includes OpenCL 1.2 support for GPUs based on Kepler or later architectures.<ref>{{cite web |url=https://a248.e.akamai.net/f/248/10/10/us.download.nvidia.com/Windows/350.12/350.12-win8-win7-winvista-desktop-release-notes.pdf |title=Release 349 Graphics Drivers for Windows, Version 350.12 |date=April 13, 2015 |accessdate=February 4, 2016}}</ref> Driver 340+ support OpenCL 1.1 for Tesla and Fermi. \n* August 26, 2015: AMD released AMD APP SDK v3.0<ref>{{cite web |url=http://developer.amd.com/community/blog/2015/08/26/introducing-app-sdk-30-opencl-2/ |title=AMD APP SDK 3.0 Released |website=Developer.AMD.com |date=August 26, 2015 |accessdate=September 11, 2015}}</ref> which contains full support of OpenCL 2.0 and sample coding.\n* November 16, 2015: Khronos announced that the specification for OpenCL 2.1 had been finalized.<ref>{{cite web |url=https://www.khronos.org/news/press/khronos-releases-opencl-2.1-and-spir-v-1.0-specifications-for-heterogeneous |title=Khronos Releases OpenCL 2.1 and SPIR-V 1.0 Specifications for Heterogeneous Parallel Programming |date=November 16, 2015 |publisher=[[Khronos Group]] }}</ref>\n* April 18, 2016: Khronos announced that the specification for OpenCL 2.2 had been provisionally finalized.<ref name=\"opencl2.2-provisional\"/>\n* November 3, 2016 Intel support for Gen7+ of OpenCL 2.1 in SDK 2016 r3<ref>{{cite web|url=https://software.intel.com/en-us/whats-new-code-builder-2016-r3|title=What's new? Intel® SDK for OpenCL™ Applications 2016, R3|publisher=Intel Software}}</ref>\n* February 17, 2017: Nvidia begins evaluation support of OpenCL 2.0 with driver 378.66.<ref>{{cite web |url=https://www.khronos.org/news/permalink/nvidia-378.66-drivers-for-windows-offer-opencl-2.0-evaluation-support |title=NVIDIA 378.66 drivers for Windows offer OpenCL 2.0 evaluation support |date=February 17, 2017 |publisher=[[Khronos Group]] }}</ref><ref>{{Cite web|url=https://streamhpc.com/blog/2017-02-22/nvidia-enables-opencl-2-0-beta-support/|title=NVIDIA enables OpenCL 2.0 beta-support|first=Jakub|last=Szuppe|date=February 22, 2017}}</ref><ref>{{Cite web|url=https://streamhpc.com/blog/2017-03-06/nvidia-beta-support-opencl-2-0-linux/|title=NVIDIA beta-support for OpenCL 2.0 works on Linux too|first=Jakub|last=Szuppe|date=March 6, 2017}}</ref>\n* May 16, 2017: Khronos announced that the specification for OpenCL 2.2 had been finalized with Spir-V1.2.<ref>{{Cite web|url=https://www.khronos.org/news/permalink/khronos-releases-opencl-2.2-with-spir-v-1.2|title=The Khronos Group|date=March 21, 2019|website=The Khronos Group}}</ref>\n* May 14, 2018: Khronos announced Maintenance Update for OpenCL 2.2 with Bugfix and unified  headers.<ref name=\"auto\"/>\n\n== Devices ==\n\nAs of 2016 OpenCL runs on [[Graphics processing units]], [[Central processing unit|CPUs]] with [[SIMD]] instructions, [[Field-programmable gate array|FPGAs]], [[Movidius Myriad 2]], [[Adapteva epiphany]] and [[Digital signal processor|DSPs]].\n\n=== Conformant products ===\nThe [[Khronos Group]] maintains an extended list of OpenCL-conformant products.<ref name=\"conformant-products\" />\n\n{| class=\"wikitable sortable\" style=\"font-size: 85%; text-align: center\"\n|-\n!colspan=5|[[wikt:synopsis|Synopsis]] of OpenCL conformant products<ref name=\"conformant-products\" />\n|-\n!style=\"text-align:left\"|[https://developer.amd.com/tools-and-sdks/ AMD SDKs] (supports OpenCL [[CPU]] and [[accelerated processing unit]] Devices), (GPU: Terascale 1: OpenCL 1.1, Terascale 2: 1.2, GCN 1: 1.2+, GCN 2+: 2.0+)\n|[[X86]] + [[SSE2]] (or higher) compatible CPUs [[64-bit#32-bit vs 64-bit|64-bit & 32-bit]],<ref>{{cite web |url=http://developer.amd.com/documentation/articles/pages/OpenCL-and-the-AMD-APP-SDK.aspx |title=OpenCL and the AMD APP SDK |work=AMD Developer Central |publisher=developer.amd.com |accessdate=August 11, 2011 |deadurl=yes |archiveurl=https://web.archive.org/web/20110804010819/http://developer.amd.com/documentation/articles/pages/OpenCL-and-the-AMD-APP-SDK.aspx |archivedate=August 4, 2011}}</ref> Linux 2.6 PC, Windows Vista/7/8.x/10 PC\n|[[AMD Fusion]] E-350, E-240, C-50, C-30 with HD 6310/HD 6250\n|AMD [[Radeon]]/Mobility HD 6800, HD 5x00 series GPU, iGPU HD 6310/HD 6250, HD 7xxx, HD 8xxx, R2xx, R3xx, RX 4xx, RX 5xx, Vega Series\n|AMD FirePro Vx800 series GPU and later, Radeon Pro \n|-\n!style=\"text-align:left\"|[http://software.intel.com/en-us/vcsource/tools/opencl-sdk Intel SDK for OpenCL Applications 2013]<ref name=intelsdk>{{cite web |url=http://software.intel.com/en-us/articles/opencl-sdk/ |work=software.intel.com |title=About Intel OpenCL SDK 1.1 |publisher=intel.com |accessdate=August 11, 2011}}</ref> (supports Intel Core processors and Intel HD Graphics 4000/2500) actual 2017 R2 with OpenCL 2.1 (Gen7+), SDK 2019 in Beta,<ref>{{Cite web|url=https://software.intel.com/en-us/articles/intel-sdk-for-opencl-applications-release-notes|title=Intel® SDK for OpenCL™ Applications - Release Notes|date=March 14, 2019|website=software.intel.com}}</ref>\n|[[Intel]] CPUs with [[Streaming SIMD Extensions|SSE]] 4.1, SSE 4.2 or [[Advanced Vector Extensions|AVX]] support.<ref>{{cite web |url=http://software.intel.com/en-us/articles/opencl-sdk-frequently-asked-questions/#12 |title=Product Support |accessdate=August 11, 2011}}</ref><ref>{{cite web |url=http://software.intel.com/en-us/articles/opencl-release-notes/ |title=Intel OpenCL SDK – Release Notes |accessdate=August 11, 2011 |deadurl=yes |archiveurl=https://web.archive.org/web/20110717054302/http://software.intel.com/en-us/articles/opencl-release-notes/ |archivedate=July 17, 2011}}</ref> [[Microsoft Windows]], [[Linux]]\n|[[Intel Core]] [[Intel Core i7|i7]], [[Intel Core i5|i5]], [[Intel Core i3|i3]]; 2nd Generation Intel Core i7/5/3, 3rd Generation Intel Core Processors with Intel HD Graphics 4000/2500 and newer\n|[[Intel Core (microarchitecture)|Intel Core 2]] [[Intel Core 2|Solo, Duo Quad, Extreme]] and newer\n|[[Xeon#Core-based Xeon|Intel Xeon]] 7x00,5x00,3x00 (Core based) and newer\n|-\n!style=\"text-align:left\"|[[IBM]] Servers with [http://www.alphaworks.ibm.com/tech/opencl OpenCL Development Kit] for Linux on Power running on [[AltiVec#VSX|Power VSX]]<ref>{{cite web |url=http://www.ibm.com/developerworks/forums/thread.jspa?messageID=14600651&tstart=0 |title=Announcing OpenCL Development Kit for Linux on Power v0.3 |accessdate=August 11, 2011}}</ref><ref>{{cite web |url=https://www.ibm.com/developerworks/mydeveloperworks/blogs/80367538-d04a-47cb-9463-428643140bf1/entry/ibm_releases_opencl_development_kit_for_linux_on_power_v0_3_opencl_1_1_conformant_release_available6?lang=en |title=IBM releases OpenCL Development Kit for Linux on Power v0.3 – OpenCL 1.1 conformant release available |work=OpenCL Lounge |publisher=ibm.com |accessdate=August 11, 2011}}</ref>\n|[[Power 775|IBM Power 775]] ([[PERCS]]), [[IBM Power Systems|750]]\n|IBM BladeCenter PS70x Express\n|IBM BladeCenter JS2x, JS43\n|IBM BladeCenter QS22\n|-\n!style=\"text-align:left\"|[[IBM]] [http://www.alphaworks.ibm.com/tech/ocr OpenCL Common Runtime (OCR)]\n<ref>{{cite web |url=https://www.ibm.com/developerworks/mydeveloperworks/blogs/80367538-d04a-47cb-9463-428643140bf1/entry/ibm_releases_opencl_common_runtime_for_linux_on_x86_architecture4?lang=en |title=IBM releases OpenCL Common Runtime for Linux on x86 Architecture |accessdate=September 10, 2011|date=October 20, 2009 }}</ref>\n|[[X86]] + [[SSE2]] (or higher) compatible CPUs 64-bit & 32-bit;<ref>{{cite web |url=http://developer.amd.com/documentation/articles/pages/OpenCL-and-the-AMD-APP-SDK.aspx |title=OpenCL and the AMD APP SDK |work=AMD Developer Central |publisher=developer.amd.com |accessdate=September 10, 2011 |deadurl=yes |archiveurl=https://web.archive.org/web/20110906045531/http://developer.amd.com/documentation/articles/pages/OpenCL-and-the-AMD-APP-SDK.aspx |archivedate=September 6, 2011}}</ref> Linux 2.6 PC\n|[[AMD Fusion]], [[Nvidia Ion]] and Intel Core i7, i5, i3; 2nd Generation Intel Core i7/5/3\n|AMD Radeon, Nvidia [[GeForce]] and Intel Core 2 [[Intel Core 2|Solo, Duo, Quad, Extreme]]\n|ATI FirePro, Nvidia [[Quadro]] and Intel Xeon 7x00,5x00,3x00 (Core based)\n|-\n!style=\"text-align:left\"|[http://developer.nvidia.com/opencl Nvidia OpenCL Driver and Tools],<ref>{{cite web |url=http://www.tomshardware.com/news/Nvidia-Cuda-OpenCL-SDK,7596.html |title=Nvidia Releases OpenCL Driver |accessdate=August 11, 2011|date=April 22, 2009 }}</ref> Chips: Tesla, Fermi : OpenCL 1.1(Driver 340+), Kepler, Maxwell, Pascal, Volta, Turing: OpenCL 1.2 (Driver 370+), OpenCL 2.0 beta (378.66)\n|[[Nvidia]] [[Nvidia Tesla|Tesla]] C/D/S\n|Nvidia GeForce GTS/GT/GTX, \n|Nvidia Ion\n|Nvidia Quadro FX/NVX/Plex, Quadro, Quadro K, Quadro M, Quadro P, Quadro with Volta, Quadro RTX with Turing\n|}\n\nAll standard-conformant implementations can be queried using one of the clinfo tools (there are multiple tools with the same name and similar feature set).<ref>{{cite web|title=clinfo by Simon Leblanc|url=https://github.com/simleb/clinfo|accessdate=January 27, 2017}}</ref><ref>{{cite web|title=clinfo by Oblomov|url=https://github.com/Oblomov/clinfo|accessdate=January 27, 2017}}</ref><ref>{{cite web|title=clinfo: openCL INFOrmation|url=https://sourceforge.net/projects/clinfo/|accessdate=January 27, 2017}}</ref>\n\n=== Version support ===\nProducts and their version of OpenCL support include:<ref>{{Cite web |url=https://www.khronos.org/conformance/adopters/conformant-products#opencl |title=Khronos Products |website=The Khronos Group |accessdate=May 15, 2017}}</ref>\n\n==== OpenCL 2.2 support ====\n''None yet'': Khronos Test Suite ready, with Driver Update all Hardware with 2.0 and 2.1 support possible\n\n*Intel NEO Compute: Work in Progress for actual products <ref>{{Cite web|url=https://01.org/compute-runtime|title=compute-runtime|date=February 7, 2018|website=01.org}}</ref>\n\n==== OpenCL 2.1 support ====\n* (2018+) Support backported to Intel 5th and 6th gen processors ([[Broadwell (microarchitecture)|Broadwell]], [[Skylake (microarchitecture)|Skylake]])\n* (2017+) Intel 7th and 8th gen processors ([[Kaby Lake]], Coffee Lake (Desktop) or Cannon Lake (mobile))\n* Khronos: with Driver Update all Hardware with 2.0 support possible\n\n==== OpenCL 2.0 support ====\n* (2011+) AMD GCN GPU's (HD 7700+/HD 8000/Rx 200/Rx 300/Rx 400/Rx 500-Series), some GCN 1st Gen only 1.2 with some Extensions\n* (2013+) AMD GCN APU's (Jaguar, Steamroller, Puma, Excavator & Zen-based)\n* (2014+) Intel 5th & 6th gen processors ([[Broadwell (microarchitecture)|Broadwell]], [[Skylake (microarchitecture)|Skylake]])\n* (2015+) Qualcomm Adreno 5xx series\n* (2018+) Qualcomm Adreno 6xx series\n* (2017+) ARM Mali (Bifrost) G51 and G71 in Android 7.1 and Linux\n* (2018+) ARM Mali (Bifrost) G31, G52, G72 and G76\n* (2017+) incomplete Evaluation support: Nvidia Kepler, Maxwell, Pascal, Volta and Turing GPU's (GeForce 600, 700, 800, 900 & 10-series, Quadro K-, M- & P-series, Tesla K-, M- & P-series) with Driver Version 378.66+\n\n==== OpenCL 1.2 support ====\n* (2011+) for some AMD GCN 1st Gen some OpenCL  2.0 Features not possible today, but many more Extensions than Terascale \n* (2009+) AMD TeraScale 2 & 3 GPU's (RV8xx, RV9xx in HD 5000, 6000 & 7000 Series)\n* (2011+) AMD TeraScale APU's (K10, Bobcat & Piledriver-based)\n* (2012+) Nvidia Kepler, Maxwell, Pascal, Volta and Turing GPU's (GeForce 600, 700, 800, 900 & 10-series, Quadro K-, M- & P-series, Tesla K-, M- & P-series)\n* (2012+) Intel 3rd & 4th gen processors ([[Ivy Bridge (microarchitecture)|Ivy Bridge]], [[Haswell (microarchitecture)|Haswell]])\n* (2013+) Qualcomm Adreno 4xx series\n* (2013+) ARM Mali Midgard 3rd gen (T760)\n* (2015+) ARM Mali Midgard 4th gen (T8xx)\n\n==== OpenCL 1.1 support ====\n* (2008+) some AMD TeraScale 1 GPU's (RV7xx in HD4000-series)\n* (2008+) Nvidia Tesla, Fermi GPU's (GeForce 9, 100, 200, 300, 400, 500-series, Quadro-series or Tesla-series with Tesla or Fermi GPU)\n* (2011+) Qualcomm Adreno 3xx series\n* (2012+) ARM Mali Midgard 1st and 2nd gen (T-6xx, T720)\n\n==== OpenCL 1.0 support ====\n* mostly updated to 1.1 and 1.2 after first Driver for 1.0 only\n\n== Portability, performance and alternatives ==\n\nA key feature of OpenCL is portability, via its abstracted memory and [[execution model]], and the programmer is not able to directly use hardware-specific technologies such as inline [[Parallel Thread Execution]] (PTX) for Nvidia GPUs unless they are willing to give up direct portability on other platforms. It is possible to run any OpenCL kernel on any conformant implementation.\n\nHowever, performance of the kernel is not necessarily portable across platforms. Existing implementations have been shown to be competitive when kernel code is properly tuned, though, and [[auto-tuning]] has been suggested as a solution to the performance portability problem,<ref name=\"comprehensive\" /> yielding \"acceptable levels of performance\" in experimental linear algebra kernels.<ref>{{Cite journal | doi = 10.1016/j.parco.2011.10.002| title = From CUDA to OpenCL: Towards a performance-portable solution for multi-platform GPU programming| journal = Parallel Computing| volume = 38| issue = 8| pages = 391–407| year = 2012| last1 = Du | first1 = Peng| last2 = Weber | first2 = Rick| last3 = Luszczek | first3 = Piotr| last4 = Tomov | first4 = Stanimire| last5 = Peterson | first5 = Gregory| last6 = Dongarra | first6 = Jack |authorlink6=Jack Dongarra| citeseerx = 10.1.1.193.7712}}</ref> Portability of an entire application containing multiple kernels with differing behaviors was also studied, and shows that portability only required limited tradeoffs.<ref>{{cite book |last1=Dolbeau |first1=Romain |title=2013 IEEE 6th International Workshop on Multi-/Many-core Computing Systems (MuCoCoS) |pages=1–6 |last2=Bodin |first2=François |last3=de Verdière |first3=Guillaume Colin |chapter-url=http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=6633603 |date=September 7, 2013 |chapter=One OpenCL to rule them all? |accessdate=January 14, 2014 |deadurl=yes |archiveurl=https://web.archive.org/web/20140116074408/http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=6633603 |archivedate=January 16, 2014|doi=10.1109/MuCoCoS.2013.6633603 |isbn=978-1-4799-1010-6 }}</ref>\n\nA study at [[Delft University]] from 2011 that compared [[CUDA]] programs and their straightforward translation into OpenCL C found CUDA to outperform OpenCL by at most 30% on the Nvidia implementation. The researchers noted that their comparison could be made fairer by applying manual optimizations to the OpenCL programs, in which case there was \"no reason for OpenCL to obtain worse performance than CUDA\". The performance differences could mostly be attributed to differences in the programming model (especially the memory model) and to NVIDIA's compiler optimizations for CUDA compared to those for OpenCL.<ref name=\"comprehensive\">{{cite conference |url=http://pds.twi.tudelft.nl/pubs/papers/icpp2011a.pdf |format=PDF |conference=Proc. Int'l Conf. on Parallel Processing |doi=10.1109/ICPP.2011.45 |title=A Comprehensive Performance Comparison of CUDA and OpenCL |year=2011 |last1=Fang |first1=Jianbin |last2=Varbanescu |first2=Ana Lucia |last3=Sips |first3=Henk}}</ref>\n\nAnother study at D-Wave Systems Inc. found that \"The OpenCL kernel’s performance is between about 13% and 63% slower, and the end-to-end time is between about 16% and 67% slower\" than CUDA's performance.<ref>{{cite arXiv |first1=Kamran |last1=Karimi |first2=Neil G. |last2=Dickson |first3=Firas |last3=Hamze |eprint=1005.2581v3 |year=2011 |title=A Performance Comparison of CUDA and OpenCL|class=cs.PF }}</ref>\n\nThe fact that OpenCL allows workloads to be shared by CPU and GPU, executing the same programs, means that programmers can exploit both by dividing work among the devices.<ref>A Survey of CPU-GPU Heterogeneous Computing Techniques, ACM Computing Surveys, 2015.</ref> This leads to the problem of deciding how to partition the work, because the relative speeds of operations differ among the devices. [[Machine learning]] has been suggested to solve this problem: Grewe and O'Boyle describe a system of [[support vector machine]]s trained on compile-time features of program that can decide the device partitioning problem statically, without actually running the programs to measure their performance.<ref>{{cite conference |title=A Static Task Partitioning Approach for Heterogeneous Systems Using OpenCL |first1=Dominik |last1=Grewe |first2=Michael F. P. |last2=O'Boyle |conference=Proc. Int'l Conf. on Compiler Construction |year=2011 |doi=10.1007/978-3-642-19861-8_16}}</ref>\n\n* Project Coriander: Conversion CUDA to OpenCL 1.2 with CUDA-on-CL<ref>{{cite web|url=http://www.phoronix.com/scan.php?page=news_item&px=CUDA-On-CL-Coriander|title=Coriander Project: Compile CUDA Codes To OpenCL, Run Everywhere|publisher=Phoronix}}</ref><ref>{{cite web|url=http://www.iwocl.org/wp-content/uploads/iwocl2017-hugh-perkins-cuda-cl.pdf|title=cuda-on-cl|last=Perkins|first=Hugh|publisher=IWOCL|date=2017|accessdate=August 8, 2017}}</ref><ref>{{cite web|url=https://github.com/hughperkins/coriander|title=hughperkins/coriander: Build NVIDIA® CUDA™ code for OpenCL™ 1.2 devices|publisher=GitHub|date=May 6, 2019}}</ref>\n\n== See also ==\n{{div col|colwidth=18em}}\n* [[Advanced Simulation Library]]\n* [[AMD FireStream]]\n* [[BrookGPU]]\n* [[C++ AMP]]\n* [[Close to Metal]]\n* [[CUDA]]\n* [[DirectCompute]]\n* [[GPGPU]]\n* [[Larrabee (microarchitecture)|Larrabee]]\n* [[Lib Sh]]\n* [[List of OpenCL applications]]\n* [[OpenACC]]\n* [[OpenGL]]\n* [[OpenHMPP]]\n* [[OpenMP]]\n* [[Metal (API)|Metal]]\n* [[Renderscript]]\n* [[SequenceL]]\n* [[SIMD]]\n* [[Vulkan (API)|Vulkan]]\n* [[WebCL]]\n{{div col end}}\n\n== References ==\n{{Reflist|30em}}\n\n== External links ==\n* {{Official website|https://www.khronos.org/opencl/|name=Official website for OpenCL}}\n* {{Official website|https://www.khronos.org/webcl/|name=Official website for WebCL}}\n*{{Official Website|https://www.iwocl.org/|name=Official website for the International Workshop on OpenCL sponsored by The Khronos Group}} ([[IWOCL]])\n\n{{Khronos Group standards}}\n{{Parallel computing}}\n{{Use mdy dates|date=October 2018}}\n\n[[Category:2009 software]]\n[[Category:Application programming interfaces]]\n[[Category:Cross-platform software]]\n[[Category:GPGPU]]\n[[Category:GPGPU libraries| OpenCL]]\n[[Category:Parallel computing]]"
    },
    {
      "title": "AMD APP SDK",
      "url": "https://en.wikipedia.org/wiki/AMD_APP_SDK",
      "text": "{{Infobox software\n| name                   = \n| title                  = AMD APP SDK\n| logo                   = <!-- Image name is enough -->\n| logo caption           = \n| logo_size              = \n| logo_alt               = \n| screenshot             = <!-- Image name is enough -->\n| caption                = \n| screenshot_size        = \n| screenshot_alt         = \n| collapsible            = \n| author                 = [[Advanced Micro Devices]]\n| developer              = \n| released               = <!-- {{Start date and age|YYYY|MM|DD|df=yes/no}} -->\n| discontinued           = yes\n| latest release version = 3.0 (3.0.130 Linux)\n| latest release date    = {{release date and age|2015|8|25}}\n| latest preview version = 3.0 Beta\n| latest preview date    = {{release date and age|2014|12|9}}\n| programming language   = \n| operating system       = [[Linux]], [[Microsoft Windows]]\n| platform               = \n| size                   = \n| language               = \n| language count         = <!-- DO NOT include this parameter unless you know what it does -->\n| language footnote      = \n| genre                  = software development kit\n| license                = \n| website                = {{URL|https://web.archive.org/web/20170628060105/https://developer.amd.com/amd-accelerated-parallel-processing-app-sdk}} (downloads do not function)\n}}\n[[File:AMD VCE hybrid mode.svg|thumb|The entropy encode from the [[Video Coding Engine|VCE]] ASIC can be utilized with the help of AMD APP SDK.]]\n'''AMD APP SDK''' is a [[software development kit]] by AMD for \"Accelerated Parallel Processing\" (APP).<ref>{{cite web |url=http://developer.amd.com/tools-and-sdks/opencl-zone/opencl-tools-sdks/amd-accelerated-parallel-processing-app-sdk/ |title=AMD APP SDK OpenCL&#x2122; Accelerated Parallel Processing |access-date=2016-02-19 |archive-url=https://web.archive.org/web/20140701140057/http://developer.amd.com/tools-and-sdks/opencl-zone/opencl-tools-sdks/amd-accelerated-parallel-processing-app-sdk/ |archive-date=2014-07-01 |dead-url=yes |df= }}</ref> AMD APP SDK also targets [[Heterogeneous System Architecture]] (not only GPU).<ref>https://stackoverflow.com/questions/9473420/whats-the-difference-between-amds-app-sdk-and-amd-atis-stream-technology</ref>\n\nAMD APP SDK was available for 32-bit and 64-bit versions of Microsoft Windows and Linux but was removed from AMD's official website.<ref>https://github.com/fireice-uk/xmr-stak/issues/1511</ref> A developer stated in a forum post that the SDK was discontinued as the required libraries are now included with the drivers.<ref>https://community.amd.com/thread/228059#comment-2866963</ref>\n\nAMD intends developers to employ AMD APP SDK to utilize [[Video Coding Engine]] hybrid mode to create hybrid encoders that pair custom motion estimation, inverse discrete cosine transform and motion compensation with the hardware entropy encoding to achieve faster than real-time encoding.\n\nAPP SDK 3.0 supports OpenCL™ 2.0 and Catalyst Omega 15.7 driver.\n\nThe AMD APP SDK v3.0 Beta includes samples for [[OpenCL]]™ as well as accelerated libraries such as [[Bolt (library)|Bolt]] (an open-source C++ template library) and the OpenCL™ accelerated [[OpenCV]] (Open Computer Vision) library.\n\n== History ==\nAMD APP SDK replaced AMD Stream SDK (formerly named ATI Stream SDK). AMD CAL (Compute Abstraction Layer) SDK was replaced by ATI Stream SDK, available for Microsoft Windows and Linux, 32-bit and 64-bit.\n\n== References ==\n{{Reflist}}\n\n== External links ==\n* [https://softpedia.com/get/Programming/SDK-DDK/ATI-Stream-SDK.shtml Unofficial Windows mirror]\n* [https://sourceforge.net/projects/nicehashsgminerv5viptools/files/APP%20SDK%20A%20Complete%20Development%20Platform Unofficial Linux mirror]\n* [https://rocm.github.io ROCm] - Radeon Open Compute, designed to be a successor to the AMD APP SDK\n\n{{AMD graphics}}\n\n[[Category:Advanced Micro Devices software]]\n[[Category:GPGPU libraries]]\n[[Category:Heterogeneous System Architecture]]"
    },
    {
      "title": "AMD Stream SDK",
      "url": "https://en.wikipedia.org/wiki/AMD_Stream_SDK",
      "text": "#REDIRECT [[AMD FireStream#Software Development Kit]] {{R to section}}\n\n[[Category:Advanced Micro Devices software]]\n[[Category:GPGPU libraries]]"
    },
    {
      "title": "BrookGPU",
      "url": "https://en.wikipedia.org/wiki/BrookGPU",
      "text": "{{Infobox software\n| name                       = BrookGPU\n| logo                       =\n| screenshot                 =\n| caption                    =\n| collapsible                =\n| author                     =\n| developer                  =\n| released                   =\n| latest release version     =\n| latest release date        =\n| latest preview version     =\n| latest preview date        =\n| programming language       =\n| operating system           = [[Linux]], [[Microsoft Windows|Windows]]\n| platform                   =\n| size                       =\n| language                   =\n| status                     =\n| genre                      = Compiler/runtime\n| license                    = [[BSD license]] (parts are under the [[GNU General Public License|GPL]])\n| website                    = http://graphics.stanford.edu/projects/brookgpu/\n}}\nThe '''Brook''' programming language and its implementation '''BrookGPU''' were early and influential attempts to enable [[general-purpose computing on graphics processing units]].<ref>{{cite journal |last1=Tarditi |first1=David |first2=Sidd |last2=Puri |first3=Jose |last3=Oglesby |title=Accelerator: using data parallelism to program GPUs for general-purpose uses |journal=ACM SIGARCH Computer Architecture News |volume=34 |issue=5 |year=2006}}</ref><ref>{{cite journal |last1=Che |first1=Shuai |last2=Boyer |first2=Michael |last3=Meng |first3=Jiayuan |last4=Tarjan |first4=D. |last5=Sheaffer |first5=Jeremy W. |last6=Skadron |first6=Kevin |title=A performance study of general-purpose applications on graphics processors using CUDA |journal=J. Parallel and Distributed Computing |volume=68 |issue=10 |year=2008 |pages=1370–1380}}</ref>\nBrook, developed at [[Stanford University]] graphics group, was a compiler and runtime implementation of a [[Stream processing|stream programming]] language targeting modern, highly parallel [[Graphics processing unit|GPU]]s such as those found on [[ATI Technologies|ATI]] or [[Nvidia]] graphics cards.\n\nBrookGPU compiled programs written using the Brook stream programming language, which is a variant of [[ANSI C]]. It could target [[OpenGL]] v1.3+, [[DirectX]] v9+ or AMD's [[Close to Metal]] for the computational backend and ran on both [[Microsoft Windows]] and [[Linux]]. For debugging, BrookGPU could also [[Computer architecture simulator|simulate]] a virtual graphics card on the CPU.\n\n==Status==\n[[Brook (programming language)|Brook]] has been in [[Development stage#Beta|beta]] for a long time. The last major beta release (v0.4) was in October 2004 but renewed development began and stopped again in November 2007 with a v0.5 beta 1 release.\n\nThe new features of v0.5 include a much upgraded and faster [[OpenGL]] backend which uses framebuffer objects instead of PBuffers and harmonised the code around standard OpenGL interfaces instead of using proprietary vendor extensions. [[GLSL]] support was added which brings all the functionality (complex branching and loops) previously only supported by DirectX 9 to OpenGL. In particular, this means that Brook is now just as capable on [[Linux]] as [[Microsoft Windows|Windows]].\n\nOther improvements in the v0.5 series include multi-backend usage whereby different threads can run different Brook programs concurrently (thus maximising use of a multi-GPU setup) and [[Streaming SIMD Extensions|SSE]] and [[OpenMP]] support for the CPU backend (this allows near maximal usage of modern CPUs).\n\n==Performance comparison==\n{{unreferenced section|date=July 2014}}\nA like for like comparison between desktop CPUs and GPGPUs is problematic because of algorithmic & structural differences.\n\nFor example, a 2.66&nbsp;GHz [[Intel Core 2 Duo]] can perform a maximum of 25 [[FLOPS|GFLOPs]] (25 billion single-precision floating-point operations per second) if optimally using SSE and streaming memory access so the prefetcher works perfectly. However, traditionally (due to shader program length limits) most GPGPU kernels tend to perform relatively small amounts of work on large amounts of data in parallel, so the big problem with directly executing GPGPU algorithms on desktop CPUs is vastly lower memory bandwidth as generally speaking the CPU spends most of its time waiting on [[Random-access memory|RAM]]. As an example, dual-channel PC2-6400 DDR2 RAM can throughput about 11&nbsp;Gbit/s which is around 1.5 GFLOPs maximum given that there is a total of 3 GFLOPs total bandwidth and one must both read and write. As a result, if memory bandwidth constrained, Brook's CPU backend won't exceed 2 GFLOPs. In practice, it's even lower than that most especially for anything other than float4 which is the only data type which can be SSE accelerated.\n\nOn an [[Radeon R600|ATI HD 2900 XT]] (740&nbsp;MHz core 1000&nbsp;MHz memory), Brook can perform a maximum of 410 GFLOPs via its DirectX 9 backend. OpenGL is currently (due to driver and [[Cg (programming language)|Cg]] compiler limitations) much less efficient as a GPGPU backend on that GPU, so Brook can only manage 210 GFLOPs when using OpenGL on that GPU. On paper, this looks like around twenty times faster than the CPU, but as just explained it isn't as easy as that. GPUs currently have major branch and read/write access penalties so expect a reasonable maximum of one third of the peak maximum in real world code - this still leaves that ATI card at around 125 GFLOPs some five times faster than the Intel Core 2 Duo.\n\nHowever this discounts the important part of transferring the data to be processed to and from the GPU. With a [[PCI Express]] 1.0 x8 interface, the memory of an ATI HD 2900 XT can be written to at about 730&nbsp;Mbit/s and read from at about 311&nbsp;Mbit/s which is significantly slower than normal PC memory. For large datasets, this can greatly diminish the speed increase of using a GPU over a well-tuned CPU implementation. Of course, as GPUs become faster far more quickly than CPUs and the PCI Express interface improves, it will make more sense to offload large processing to GPUs.\n\n==Applications and games that use BrookGPU==\n* [[Folding@home]]\n\n==See also==\n{{Portal|Free and open-source software}}\n* [[GPGPU]]\n* [[CUDA]]\n* [[Close to Metal]]\n* [[OpenCL]]\n* [[Lib Sh]]\n* [[Intel Ct]]\n\n==External links==\n* [http://graphics.stanford.edu/projects/brookgpu/ Official BrookGPU website] - Stanford University's BrookGPU website\n* [http://www.sf.net/projects/brook/ Link to download BrookGPU package]\n* [https://web.archive.org/web/20051214111850/http://www.gpgpu.org/ GPGPU] General Purpose computation using GPUs, a common use of BrookGPU.\n* [http://graphics.stanford.edu/papers/brookgpu/ Paper and Presentation on \"Brook for GPUs: Stream Computing on Graphics Hardware\" for SIGGRAPH 2004 by Ian Buck et al.]\n* [https://web.archive.org/web/20080513102533/http://ati.amd.com/technology/streamcomputing/AMD-Brookplus.pdf AMD Brook+ Presentation]\n\n==References==\n{{reflist}}\n\n[[Category:GPGPU]]\n[[Category:GPGPU libraries]]"
    },
    {
      "title": "C++ AMP",
      "url": "https://en.wikipedia.org/wiki/C%2B%2B_AMP",
      "text": "{{Refimprove|date=February 2012}}\n{{Infobox software\n| name                   = \n| title                  = \n| logo                   = <!-- Image name is enough -->\n| logo caption           = \n| logo_size              = \n| logo_alt               = \n| screenshot             = <!-- Image name is enough -->\n| caption                = \n| screenshot_size        = \n| screenshot_alt         = \n| collapsible            = \n| author                 = [[Microsoft]]\n| developer              = \n| released               = <!-- {{Start date and age|YYYY|MM|DD|df=yes/no}} -->\n| discontinued           = \n| latest release version = \n| latest release date    = <!-- {{Start date and age|YYYY|MM|DD|df=yes/no}} -->\n| latest preview version = \n| latest preview date    = <!-- {{Start date and age|YYYY|MM|DD|df=yes/no}} -->\n| status                 = \n| programming language   = \n| operating system       = \n| platform               = \n| size                   = \n| language               = \n| language count         = <!-- DO NOT include this parameter unless you know what it does -->\n| language footnote      = \n| genre                  = Library\n| license                = Inconclusive\n}}\n\n'''C++ Accelerated Massive Parallelism''' ('''C++ AMP''') is a native programming model that contains elements that span the [[C++]] [[programming language]] and its [[runtime library]]. It provides an easy way to write programs that compile and execute on data-parallel hardware, such as [[graphics card]]s ([[GPU]]s).\n\nC++ AMP is a [[library (computing)|library]] implemented on [[DirectX|DirectX 11]] and an [[open specification]] from [[Microsoft]] for implementing data parallelism directly in C++. It is intended to make programming GPUs easy for the developer by supporting a range of expertise from none (in which case the system does its best) to being more finely controllable, but still portable. In Microsoft's implementation, code that cannot be run on GPUs will fall back onto one or more CPUs instead and use SSE instructions.{{Citation needed|date=August 2014}}  The Microsoft implementation is included in Visual Studio 2012, including debugger and profiler support.\n\nThe initial C++ AMP release from Microsoft requires at least Windows 7 or Windows Server 2008 R2.<ref name=\"summary\">[http://blogs.msdn.com/cfs-file.ashx/__key/communityserver-components-postattachments/00-10-29-86-29/cppAMPv6_2D00_gen.pdf C++ AMP One-page summary]</ref> As C++ AMP is an open specification it is expected that in time implementations outside Microsoft will appear; one early example of this is Shevlin Park, Intel's experimental implementation of C++ AMP on Clang/LLVM and OpenCL.<ref name=\"shevlinPark\">[http://llvm.org/devmtg/2012-11/Sharlet-ShevlinPark.pdf Shevlin Park: Implementing C++ AMP with Clang/LLVM and OpenCL]</ref>\n\nOn November 12, 2013 the [[HSA Foundation]] announced a C++ AMP compiler that outputs to [[OpenCL]], [[Standard Portable Intermediate Representation]] (SPIR), and [[HSA Intermediate Language]] (HSAIL) supporting the current C++ AMP specification.<ref>{{cite web|url=http://hsafoundation.com/bringing-camp-beyond-windows-via-clang-llvm/ |title=Bringing C++AMP Beyond Windows via CLANG and LLVM |accessdate=January 9, 2014}}</ref>  The source is available at https://github.com/RadeonOpenCompute/hcc.  C++ AMP support is considered obsolete and the current ROCm 1.9 series will be the last to support it<ref>https://github.com/RadeonOpenCompute/hcc/wiki</ref>.\n\n==Features==\nMicrosoft added the <code>restrict(amp)</code> feature, which can be applied to any function (including lambdas) to declare that the function can be executed on a C++ AMP accelerator. The compiler will automatically generate a [[compute kernel]], saving the boilerplate of management and having to use a separate language. The restrict keyword instructs the compiler to statically check that the function uses only those language features that are supported by most GPUs, for example, <code>void myFunc() restrict(amp) {…}</code>\nMicrosoft or other implementer of the open C++ AMP specification could add other restrict specifiers for other purposes, including for purposes that are unrelated to C++ AMP.\n\nBeyond the new language feature, the rest of C++ AMP is available through the <code><amp.h></code> header file in the concurrency namespace. The key C++ AMP classes are: <code>array</code> (container for data on an accelerator), <code>array_view</code> (wrapper for data), <code>index</code> (N-dimensional point), <code>extent</code> (N-dimensional size), <code>accelerator</code> (computational resource, such as a GPU, on which to allocate memory and execute), and <code>accelerator_view</code> (view of an accelerator).\nThere is also a global function, <code>parallel_for_each</code>, which you use to write a C++ AMP parallel loop.\n\n== See also ==\n* [[OpenCL]]\n* [[CUDA]]\n* [[GPGPU]]\n* [[OpenACC]]\n* [[SYCL]] from [[Khronos Group]] extends some concepts from C++ AMP\n* [[Vulkan (API)|Vulkan]]\n* [[RaftLib]]\n\n== References ==\n{{Reflist}}\n\n== Further reading ==\n* Kate Gregory, Ade Miller. C++ Amp: Accelerated Massive Parallelism With Microsoft Visual C++ - Microsoft, 2012 - 326 pages - {{ISBN|9780735664739}}\n\n== External links ==\n* [http://download.microsoft.com/download/4/0/E/40EA02D8-23A7-4BD2-AD3A-0BFFFB640F28/CppAMPLanguageAndProgrammingModel.pdf C++ AMP : Language and Programming Model] — Version 1.0 : August 2012\n* [http://blogs.msdn.com/b/nativeconcurrency/ Parallel Programming in Native Code - C++ AMP Team Blog]\n* http://hsafoundation.com/bringing-camp-beyond-windows-via-clang-llvm/ C++ AMP Support in CLANG and LLVM compiler \n* https://github.com/RadeonOpenCompute/hcc C++ AMP Support in CLANG and LLVM compiler\n\n{{Parallel computing}}\n\n[[Category:C++ libraries]]\n[[Category:GPGPU libraries]]\n[[Category:Parallel computing]]"
    },
    {
      "title": "Close to Metal",
      "url": "https://en.wikipedia.org/wiki/Close_to_Metal",
      "text": "In [[computing]], '''Close To Metal''' (\"'''CTM'''\" in short, originally called ''Close-to-the-Metal'') is the name of a [[beta version]] of a [[Low-level programming language|low-level]] [[programming interface]] developed by [[ATI Technologies|ATI]], now the [[AMD Graphics Product Group]], aimed at enabling [[GPGPU]] computing. CTM was short-lived, and the first production version of AMD's GPGPU technology is now called [[AMD Stream SDK]], or rather the current [[AMD APP SDK]] for Windows and Linux 32-bit and 64-bit. APP stands for \"Accelerated Parallel Processing\".<ref>{{cite web |url=http://developer.amd.com/tools-and-sdks/opencl-zone/opencl-tools-sdks/amd-accelerated-parallel-processing-app-sdk/ |title=AMD APP SDK OpenCL™ Accelerated Parallel Processing |access-date=2014-07-06 |archive-url=https://web.archive.org/web/20140701140057/http://developer.amd.com/tools-and-sdks/opencl-zone/opencl-tools-sdks/amd-accelerated-parallel-processing-app-sdk/ |archive-date=2014-07-01 |dead-url=yes |df= }}</ref> and also targets [[Heterogeneous System Architecture]].\n\n==Overview==\nClose To Metal, originally called THIN (Thin Hardware INterface) and Data Parallel Virtual Machine, gave developers direct access to the native instruction set and memory of the massively [[parallel computing|parallel computational]] elements in modern AMD video cards.  CTM bypassed the graphics-centric DirectX and OpenGL APIs for the GPGPU programmer to expose previously unavailable low-level functionality, including direct control of the stream processors/ALUs and the memory controllers. R580 (ATI X1900) and later generations of AMD's GPU microarchitecture supported the CTM interface.\n\nCTM's commercial successor, AMD Stream SDK, was released under AMD [[End User License Agreement|EULA]] in December 2007 after the software stack was rewritten.<ref>[http://ati.amd.com/technology/streamcomputing/register.html AMD Stream SDK download page] {{webarchive |url=https://web.archive.org/web/20071223181400/http://ati.amd.com/technology/streamcomputing/register.html |date=December 23, 2007 }}, retrieved June 12, 2008</ref> Stream SDK provides high-level in addition to low-level tools for general-purpose access to AMD graphics hardware.\n\nUsing GPUs to perform computations holds a lot of potential for some applications because of the fundamental differences of GPU microarchitectures compared to CPUs. GPUs achieve much greater throughput (calculations per second) by executing many programs in parallel and restricting flow control (the ability of one program to execute instructions independently of another). Modern GPUs also have addressable on-die memory and extremely high performance multi-channel external memory.\n\nAMD subsequently switched from CTM to [[OpenCL]].<ref>{{cite news|last1=Valich|first1=Theo|title=AMD Ditches Close-To-Metal, Focuses On DX11 And OpenCL|url=http://www.tomshardware.com/news/AMD-stream-processor-GPGPU,6072.html|accessdate=13 September 2017|publisher=Tom's Hardware|date=7 August 2008}}</ref>\n\n== Open-source ==\nSome components of CTM and the Stream SDK are open source, such as the Brook+ C-like language and compiler.\n\n== See also ==\n*[[CUDA]]\n*[[BrookGPU]]\n*[[Lib Sh]]\n*[[Stream programming]]\n*[[Shader]]\n\n== References ==\n{{reflist}}\n;Notes\n{{refbegin}}\n*{{note|officialAMDAnnouncement}} [https://www.amd.com/us-en/Corporate/VirtualPressRoom/0,,51_104_543~114147,00.html AMD “Close to Metal” Technology Unleashes the Power of Stream Computing]: AMD Press Release, November 14, 2006.\n*{{note|anandTech}} [http://www.anandtech.com/video/showdoc.aspx?i=2849 AnandTech report]: ATI's Stream Processing & Folding@Home, September 30, 2006.\n*{{note|doublePrecisionOnGPU}} [https://web.archive.org/web/20070611113310/http://numod.ins.uni-bonn.de/research/papers/public/GoStTu05double.pdf Universität Dortmund, Fachbereich Mathematik research]: Accelerating Double precision on GPUs (Proceedings of ASIM 2005), Dominik Goddeke, Robert Strzodka, and Stefan Turek. 18th Symposium on Simulation Technique, 2005.{{dead link|date=July 2012}} \n*{{note|nvidiaCuda}} [https://web.archive.org/web/20070428101202/http://www.tgdaily.com/content/view/30988/135/ TGDaily report]: Nvidia activates a supercomputer in your PC, February 16, 2007.\n{{refend}}\n\n== External links ==\n* [https://web.archive.org/web/20070217182216/http://ati.amd.com/ ATI official site]\n* {{Official website|https://www.amd.com/|AMD official website}}\n* {{cite web |url=http://ati.amd.com/developer/techreports/2006/I3D2006/Peercy-Performance-Oriented_Data_Parallel_Virtual_Machine_for_GPUs(SIG06_Sketch).pdf |title=ATI DPVM SIGGRAPH 2006 sketch |deadurl=yes |archiveurl=https://web.archive.org/web/20070927060428/http://ati.amd.com/developer/techreports/2006/I3D2006/Peercy-Performance-Oriented_Data_Parallel_Virtual_Machine_for_GPUs%28SIG06_Sketch%29.pdf |archivedate=2007-09-27 |df= }}&nbsp;{{small|(134&nbsp;KiB)}}\n* {{cite web|url=http://ati.amd.com/developer/siggraph06/dpvm_sketch_siggraph.pdf |title=ATI DVPM SIGGRAPH 2006 Presentation |deadurl=yes |archiveurl=https://web.archive.org/web/20070927060433/http://ati.amd.com/developer/siggraph06/dpvm_sketch_siggraph.pdf |archivedate=2007-09-27 |df= }}&nbsp;{{small|(671&nbsp;KiB)}} \n* {{cite web |url=http://ati.amd.com/companyinfo/researcher/documents/ATI_CTM_Guide.pdf |title=CTM Guide - CTI Technical Reference Manual |deadurl=yes |archiveurl=https://web.archive.org/web/20070222162035/http://ati.amd.com/companyinfo/researcher/documents/ATI_CTM_Guide.pdf |archivedate=2007-02-22 |df= }}&nbsp;{{small|(866&nbsp;[[Kibibyte|KiB]])}}\n* [http://sourceforge.net/projects/amdctm/ AMD Close-to-the-Metal (CTM) open source project site]\n\n{{AMD graphics}}\n\n[[Category:ATI Technologies]]\n[[Category:Advanced Micro Devices software]]\n[[Category:GPGPU libraries]]"
    },
    {
      "title": "CUDA",
      "url": "https://en.wikipedia.org/wiki/CUDA",
      "text": "{{Infobox software\n| name                   = CUDA\n| screenshot             = Nvidia CUDA Logo.jpg\n| developer              = [[Nvidia]] Corporation\n| released               = {{Start date and age|2007|06|23}}\n| latest_release_version = 10.1.168\n| latest_release_date    = {{Start date and age|2019|05|07}}\n| operating_system       = [[Windows]], [[macOS]], [[Linux]]\n| platform               = [[#GPUs supported|Supported GPUs]]\n| genre                  = [[GPGPU]]\n| license                = [[Proprietary software|Proprietary]]\n| website                = {{URL|https://developer.nvidia.com/cuda-zone}}\n}}\n'''CUDA''' is a [[parallel computing]] platform and [[application programming interface]] (API) model created by [[Nvidia]].<ref>{{cite web|url=https://developer.nvidia.com/cuda-zone|title=Nvidia CUDA Home Page|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=}}</ref> It allows [[software developer]]s and [[software engineer]]s to use a CUDA-enabled [[graphics processing unit]] (GPU) for general purpose processing — an approach termed [[GPGPU]] (General-Purpose computing on Graphics Processing Units). The CUDA platform is a software layer that gives direct access to the GPU's virtual [[instruction set]] and parallel computational elements, for the execution of [[compute kernel]]s.<ref name=\"CUDA intro - TomsHardware\">{{cite web|url=https://www.tomshardware.com/reviews/nvidia-cuda-gpu,1954.html|title=Nvidia's CUDA: The End of the CPU?|last=Abi-Chahla|first=Fedy|date=June 18, 2008|website=|publisher=Tom's Hardware|archive-url=|archive-date=|dead-url=|accessdate=May 17, 2015}}</ref>\n\nThe CUDA platform is designed to work with programming languages such as [[C (programming language)|C]], [[C++]], and [[Fortran]]. This accessibility makes it easier for specialists in parallel programming to use GPU resources, in contrast to prior APIs like [[Direct3D]] and [[OpenGL]], which required advanced skills in graphics programming.<ref>{{Cite news|url=https://www.videomaker.com/article/c15/19313-cuda-vs-opencl-vs-opengl|title=CUDA vs. OpenCL vs. OpenGL|last=Zunitch|first=Peter|date=2018-01-24|work=Videomaker|access-date=2018-09-16|language=en-US}}</ref> Also, CUDA supports programming frameworks such as [[OpenACC]] and [[OpenCL]].<ref name=\"CUDA intro - TomsHardware\" /> When it was first introduced by Nvidia, the name CUDA was an acronym for '''Compute Unified Device Architecture''',<ref name=\"CUDA intro - AnandTech\">{{cite web|url=https://www.anandtech.com/show/2116/8|title=Nvidia's GeForce 8800 (G80): GPUs Re-architected for DirectX 10|last1=Shimpi|first1=Anand Lal|last2=Wilson|first2=Derek|date=November 8, 2006|publisher=AnandTech|accessdate=May 16, 2015}}</ref> but Nvidia subsequently dropped the use of the acronym.\n\n==Background==\n{{More information|Graphics processing unit}}\n\nThe graphics processing unit (GPU), as a specialized computer processor, addresses the demands of [[Real-time computer graphics|real-time]] high-resolution [[3D graphics]] compute-intensive tasks. By 2012, GPUs had evolved into highly parallel [[multi-core]] systems allowing very efficient manipulation of large blocks of data. This design is more effective than general-purpose [[central processing unit]] (CPUs) for [[algorithm]]s in situations where processing large blocks of data is done in parallel, such as:\n* [[push-relabel maximum flow algorithm]]\n* fast [[sort algorithm]]s of large [[List (computing)|lists]]\n* two-dimensional [[fast wavelet transform]]\n* [[molecular dynamics]] simulations\n* [[machine learning]]\n\n==Programming abilities==\n[[File:CUDA processing flow (En).PNG|thumb|300px|right|'''Example of CUDA processing flow''' {{ordered list |1=Copy data from main memory to GPU memory |2=CPU initiates the GPU [[compute kernel]] |3=GPU's CUDA cores execute the kernel in parallel |4=Copy the resulting data from GPU memory to main memory}}]]\n\nThe CUDA platform is accessible to software developers through CUDA-accelerated libraries, [[Directive (programming)|compiler directives]] such as [[OpenACC]], and extensions to industry-standard programming languages including [[C (programming language)|C]], [[C++]] and [[Fortran]]. C/C++ programmers can use 'CUDA C/C++', compiled with ''[[NVIDIA CUDA Compiler|nvcc]]'', Nvidia's [[LLVM]]-based C/C++ compiler.<ref>{{cite web|url=https://developer.nvidia.com/cuda-llvm-compiler|title=CUDA LLVM Compiler|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=}}</ref> Fortran programmers can use 'CUDA Fortran', compiled with the PGI CUDA Fortran compiler from [[The Portland Group]].\n\nIn addition to libraries, compiler directives, CUDA C/C++ and CUDA Fortran, the CUDA platform supports other computational interfaces, including the [[Khronos Group]]'s [[OpenCL]],<ref>{{YouTube|r1sN1ELJfNo|First OpenCL demo on a GPU}}</ref> Microsoft's [[DirectCompute]], [https://www.khronos.org/opengl/wiki/Compute_Shader OpenGL Compute Shaders] and [[C++ AMP]].<ref>{{YouTube|K1I4kts5mqc|DirectCompute Ocean Demo Running on Nvidia CUDA-enabled GPU}}</ref> Third party wrappers are also available for [[Python (programming language)|Python]], [[Perl]], [[Fortran]], [[Java (programming language)|Java]], [[Ruby (programming language)|Ruby]], [[Lua (programming language)|Lua]], [[Common Lisp (programming language)|Common Lisp]], [[Haskell (programming language)|Haskell]], [[R (programming language)|R]], [[MATLAB]], [[IDL (programming language)|IDL]], [[Julia (programming language)|Julia]], and native support in [[Mathematica]].\n\nIn the [[computer game]] industry, GPUs are used for graphics rendering, and for [[physics processing unit|game physics calculations]] (physical effects such as debris, smoke, fire, fluids); examples include [[PhysX]] and [[Bullet (software)|Bullet]]. CUDA has also been used to accelerate non-graphical applications in [[computational biology]], [[cryptography]] and other fields by an [[order of magnitude]] or more.<ref name=Ioannidis08>{{cite journal|last1=Vasiliadis |first1=Giorgos |last2=Antonatos |first2=Spiros |last3=Polychronakis |first3=Michalis |last4=Markatos |first4=Evangelos P. |last5=Ioannidis |first5=Sotiris |title= Gnort: High Performance Network Intrusion Detection Using Graphics Processors |journal= Proceedings of the 11th International Symposium on Recent Advances in Intrusion Detection (RAID) |date=September 2008 |url= http://www.ics.forth.gr/dcs/Activities/papers/gnort.raid08.pdf }}</ref><ref>{{cite journal |last1=Schatz |first1=Michael C. |last2=Trapnell |first2=Cole |last3=Delcher |first3=Arthur L. |last4=Varshney |first4=Amitabh |year= 2007 |title= High-throughput sequence alignment using Graphics Processing Units |journal= BMC Bioinformatics |volume= 8|doi= 10.1186/1471-2105-8-474 |pages= 474 |pmid= 18070356 |pmc= 2222658}}</ref><ref name=Manavski2008>{{cite journal|last1= Manavski |first1= Svetlin A. |last2=Giorgio |first2=Valle |title= CUDA compatible GPU cards as efficient hardware accelerators for Smith-Waterman sequence alignment |journal= BMC Bioinformatics |volume= 10 |year= 2008 |doi= 10.1186/1471-2105-9-S2-S10 |pages= S10 |pmid= 18387198 |pmc= 2323659}}</ref><ref>{{cite web|url=https://code.google.com/p/pyrit/|title=Pyrit – Google Code}}</ref><ref>{{cite web|url=http://boinc.berkeley.edu/cuda.php|title=Use your Nvidia GPU for scientific computing|archive-url=https://web.archive.org/web/20081228022142/http://boinc.berkeley.edu/cuda.php|archive-date=2008-12-28|dead-url=yes|access-date=2017-08-08|publisher=BOINC|date=2008-12-18}}</ref>\n\nCUDA provides both a low level [[API]] (CUDA '''Driver''' API, non single-source) and a higher level API (CUDA '''Runtime''' API, single-source). The initial CUDA [[Software development kit|SDK]] was made public on 15 February 2007, for [[Microsoft Windows]] and [[Linux]]. [[macOS|Mac OS X]] support was later added in version 2.0,<ref>{{cite web|url=http://developer.download.nvidia.com/compute/cuda/sdk/website/doc/CUDA_SDK_release_notes_macosx.txt|title=Nvidia CUDA Software Development Kit (CUDA SDK) – Release Notes Version 2.0 for MAC OS X|deadurl=yes|archiveurl=https://web.archive.org/web/20090106020401/http://developer.download.nvidia.com/compute/cuda/sdk/website/doc/CUDA_SDK_release_notes_macosx.txt|archivedate=2009-01-06|df=}}</ref> which supersedes the beta released February 14, 2008.<ref>{{cite web|url=http://news.developer.nvidia.com/2008/02/cuda-11---now-o.html|title=CUDA 1.1 – Now on Mac OS X|date=February 14, 2008|deadurl=yes|archiveurl=https://web.archive.org/web/20081122105633/http://news.developer.nvidia.com/2008/02/cuda-11---now-o.html|archivedate=November 22, 2008|df=}}</ref> CUDA works with all Nvidia GPUs from the G8x series onwards, including [[Nvidia GeForce|GeForce]], [[Nvidia Quadro|Quadro]] and the [[Nvidia Tesla|Tesla]] line. CUDA is compatible with most standard operating systems. Nvidia states that programs developed for the G8x series will also work without modification on all future Nvidia video cards, due to binary compatibility.{{Citation needed|date=January 2014}}\n\nCUDA 8.0 comes with the following libraries (for compilation & runtime, in alphabetical order):\n* cuBLAS – CUDA Basic Linear Algebra Subroutines library, see [https://developer.nvidia.com/cublas main] and [https://docs.nvidia.com/cuda/cublas/index.html docs]\n* CUDART – CUDA Runtime library, see [https://docs.nvidia.com/cuda/cuda-runtime-api/index.html docs]\n* cuFFT – CUDA Fast Fourier Transform library, see [https://developer.nvidia.com/cufft main] and [https://docs.nvidia.com/cuda/cufft/index.html docs]\n* cuRAND – CUDA Random Number Generation library, see [https://developer.nvidia.com/curand main] and [https://docs.nvidia.com/cuda/curand/index.html docs]\n* cuSOLVER – CUDA based collection of dense and sparse direct solvers, see [https://developer.nvidia.com/cusolver main] and [https://docs.nvidia.com/cuda/cusolver/index.html docs]\n* cuSPARSE – CUDA Sparse Matrix library, see [https://developer.nvidia.com/cusparse main] and [http://docs.nvidia.com/cuda/cusparse/index.html docs]\n* NPP – NVIDIA Performance Primitives library, see [https://developer.nvidia.com/npp main] and [https://docs.nvidia.com/cuda/npp/index.html docs]\n* nvGRAPH – NVIDIA Graph Analytics library, see [https://developer.nvidia.com/nvgraph main] and [http://docs.nvidia.com/cuda/nvgraph/index.html docs]\n* NVML – NVIDIA Management Library, see [https://developer.nvidia.com/nvidia-management-library-nvml main] and [http://docs.nvidia.com/deploy/nvml-api/index.html docs]\n* NVRTC – NVIDIA Runtime Compilation library for CUDA C++, see [https://docs.nvidia.com/cuda/nvrtc/index.html docs]\n\nCUDA 8.0 comes with these other software components:\n* nView – NVIDIA nView Desktop Management Software, see [https://www.nvidia.com/object/nview-driver.html main] and [https://www.nvidia.com/content/quadro/pdf/nViewDMGuide_v141-24.pdf docs] (pdf)\n* NVWMI – NVIDIA Enterprise Management Toolkit, see [https://developer.nvidia.com/nvwmi-sdk main] and [https://developer.nvidia.com/designworks/nvwmi/downloads/2.27.3/api-reference docs] (chm)\n* GameWorks [[PhysX]] – is a multi-platform game physics engine, see [https://developer.nvidia.com/gameworks-physx-overview main] and [https://docs.nvidia.com/gameworks/#gameworkslibrary/physx/physx.htm docs]\n\nCUDA 9.0-9.2 comes with these other components:\n* CUTLASS 1.0 – custom linear algebra algorithms, see [https://news.developer.nvidia.com/cuda-9-2-now-available/ CUDA 9.2 News], [https://news.developer.nvidia.com/cutlass-fast-linear-algebra-in-cuda-c/ Developer News] and [https://devblogs.nvidia.com/cutlass-linear-algebra-cuda/ dev blog]\n* <del>NVCUVID</del> – NVIDIA Video Decoder got deprecated in CUDA 9.2; it is now available in NVIDIA Video Codec SDK \n\nCUDA 10 comes with these other components:\n* nvJPEG – Hybrid JPEG Processing, see [https://developer.nvidia.com/cuda-toolkit/whatsnew CUDA 10 News] and [https://developer.nvidia.com/nvjpeg main] and [https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html actual Release Notes]\n\n==Advantages==\nCUDA has several advantages over traditional general-purpose computation on GPUs (GPGPU) using graphics APIs:\n* Scattered reads{{snd}} code can read from arbitrary addresses in memory\n* Unified virtual memory (CUDA&nbsp;4.0 and above)\n* Unified memory (CUDA&nbsp;6.0 and above)\n* [[Shared memory (interprocess communication)|Shared memory]]{{snd}} CUDA exposes a fast [[Scratchpad RAM|shared memory]] region that can be shared among threads. This can be used as a user-managed cache, enabling higher bandwidth than is possible using texture lookups.<ref>{{cite conference|doi=10.1145/1375527.1375572|title=Efficient computation of sum-products on GPUs through software-managed cache|conference=Proceedings of the 22nd annual international conference on Supercomputing  – ICS '08|year=2008|last1=Silberstein|first1=Mark|last2=Schuster|first2=Assaf|author2-link= Assaf Schuster\n |last3=Geiger|first3=Dan|last4=Patney|first4=Anjul|last5=Owens|first5=John D.|isbn=978-1-60558-158-3|pages=309–318}}</ref>\n* Faster downloads and readbacks to and from the GPU\n* Full support for integer and bitwise operations, including integer texture lookups\n\n==Limitations==\n* Whether for the host computer or the GPU device, all CUDA source code is now processed according to C++ syntax rules.<ref name=\"CUDA_Prog_v8\">{{cite web|<!--title=CUDA Toolkit Documentation-->|url=http://docs.nvidia.com/cuda/pdf/CUDA_C_Programming_Guide.pdf|website=nVidia Developer Zone |title=CUDA C Programming Guide v8.0|accessdate=22 March 2017|location=Section 3.1.5|page=19|date=January 2017}}</ref> This was not always the case. Earlier versions of CUDA were based on C syntax rules.<ref>{{cite web|url=https://devtalk.nvidia.com/default/topic/508479/cuda-programming-and-performance/nvcc-forces-c-compilation-of-cu-files/#entry1340190|title=NVCC forces c++ compilation of .cu files}}</ref> As with the more general case of compiling C code with a C++ compiler, it is therefore possible that old C-style CUDA source code will either fail to compile or will not behave as originally intended.\n* Interoperability with rendering languages such as OpenGL is one-way, with OpenGL having access to registered CUDA memory but CUDA not having access to OpenGL memory.\n* Copying between host and device memory may incur a performance hit due to system bus bandwidth and latency (this can be partly alleviated with asynchronous memory transfers, handled by the GPU's DMA engine)\n* Threads should be running in groups of at least 32 for best performance, with total number of threads numbering in the thousands. Branches in the program code do not affect performance significantly, provided that each of 32 threads takes the same execution path; the [[SIMD]] execution model becomes a significant limitation for any inherently divergent task (e.g. traversing a [[space partitioning]] data structure during [[ray tracing (graphics)|ray tracing]]).\n* Unlike [[OpenCL]], CUDA-enabled GPUs are only available from Nvidia.<ref name=\"CUDA_products\" >{{cite web |url=https://www.nvidia.com/object/cuda_learn_products.html |title=CUDA-Enabled Products |work=CUDA Zone |publisher=Nvidia Corporation |accessdate=2008-11-03}}</ref>\n* No emulator or fallback functionality is available for modern revisions.\n* Valid C++ may sometimes be flagged and prevent compilation due to the way the compiler approaches optimization for target GPU device limitations.{{citation needed|date=May 2016}}\n* C++ [[run-time type information]] (RTTI) and C++-style exception handling are only supported in host code, not in device code.\n* In [[Single precision floating-point format|single precision]] on first generation CUDA compute capability 1.x devices, [[denormal number]]s are unsupported and are instead flushed to zero, and the precisions of the division and square root operations are slightly lower than IEEE 754-compliant single precision math. Devices that support compute capability 2.0 and above support denormal numbers, and the division and square root operations are IEEE 754 compliant by default. However, users can obtain the prior faster gaming-grade math of compute capability 1.x devices if desired by setting compiler flags to disable accurate divisions and accurate square roots, and enable flushing denormal numbers to zero.<ref>{{Cite web|url=https://developer.nvidia.com/sites/default/files/akamai/cuda/files/NVIDIA-CUDA-Floating-Point.pdf |first1=Nathan |last1=Whitehead |first2=Alex |last2=Fit-Florea |title=Precision & Performance: Floating Point and IEEE 754 Compliance for Nvidia GPUs |accessdate=November 18, 2014 |publisher=[[Nvidia]]}}</ref>\n\n==GPUs supported==\nSupported CUDA level of GPU and card. See also at [http://developer.nvidia.com/cuda-gpus Nvidia]:\n* CUDA SDK 1.0 support for compute capability 1.0 – 1.1 (Tesla)<ref>{{cite web|url=http://developer.download.nvidia.com/compute/cuda/1.0/NVIDIA_CUDA_Programming_Guide_1.0.pdf|title=NVIDIA CUDA Programming Guide. Version 1.0|date=June 23, 2007}}</ref>\n* CUDA SDK 1.1 support for compute capability 1.0 – 1.1+x (Tesla)\n* CUDA SDK 2.0 support for compute capability 1.0 – 1.1+x (Tesla)\n* CUDA SDK 2.1 – 2.3.1 support for compute capability 1.0 – 1.3 (Tesla)<ref>{{cite web|url=http://developer.download.nvidia.com/compute/cuda/2_1/toolkit/docs/NVIDIA_CUDA_Programming_Guide_2.1.pdf|title=NVIDIA CUDA Programming Guide. Version 2.1|date=December 8, 2008}}</ref><ref>{{cite web|url=http://developer.download.nvidia.com/compute/cuda/2_2/toolkit/docs/NVIDIA_CUDA_Programming_Guide_2.2.pdf|title=NVIDIA CUDA Programming Guide. Version 2.2|date=April 2, 2009}}</ref><ref>{{cite web|url=http://developer.download.nvidia.com/compute/cuda/2_21/toolkit/docs/NVIDIA_CUDA_Programming_Guide_2.2.1.pdf|title=NVIDIA CUDA Programming Guide. Version 2.2.1|date=May 26, 2009}}</ref><ref>{{cite web|url=http://developer.download.nvidia.com/compute/cuda/2_3/toolkit/docs/NVIDIA_CUDA_Programming_Guide_2.3.pdf|title=NVIDIA CUDA Programming Guide. Version 2.3.1|date=August 26, 2009}}</ref>\n* CUDA SDK 3.0 – 3.1 support for compute capability 1.0 – 2.0 (Tesla, Fermi)<ref>{{cite web|url=http://developer.download.nvidia.com/compute/cuda/3_0/toolkit/docs/NVIDIA_CUDA_ProgrammingGuide.pdf|title=NVIDIA CUDA Programming Guide. Version 3.0|date=February 20, 2010}}</ref><ref>{{cite web|url=http://developer.download.nvidia.com/compute/cuda/3_1/toolkit/docs/NVIDIA_CUDA_C_ProgrammingGuide_3.1.pdf|title=NVIDIA CUDA C Programming Guide. Version 3.1.1|date=July 21, 2010}}</ref>\n* CUDA SDK 3.2 support for compute capability 1.0 – 2.1 (Tesla, Fermi)<ref>{{cite web|url=http://developer.download.nvidia.com/compute/cuda/3_2_prod/toolkit/docs/CUDA_C_Programming_Guide.pdf|title=NVIDIA CUDA C Programming Guide. Version 3.2|date=November 9, 2010}}</ref>\n* CUDA SDK 4.0 – 4.2 support for compute capability 1.0 – 2.1+x (Tesla, Fermi, more?)\n* CUDA SDK 5.0 – 5.5 support for compute capability 1.0 – 2.1+x (Tesla, Fermi, more?)\n* CUDA SDK 6.0 support for compute capability 1.0 – 3.5 (Tesla, Fermi, Kepler) \n* CUDA SDK 6.5 support for compute capability 1.1 – 5.x (Tesla, Fermi, Kepler, Maxwell). Last version with support for compute capability 1.x (Tesla)\n* CUDA SDK 7.0 – 7.5 support for compute capability 2.0 – 5.x (Fermi, Kepler, Maxwell)\n* CUDA SDK 8.0 support for compute capability 2.0 – 6.x (Fermi, Kepler, Maxwell, Pascal). Last version with support for compute capability 2.x (Fermi)\n* CUDA SDK 9.0 – 9.2 support for compute capability 3.0 – 7.2 (Kepler, Maxwell, Pascal, Volta)\n* CUDA SDK 10.0 – 10.1 support for compute capability 3.0 – 7.5 (Kepler, Maxwell, Pascal, Volta, Turing)\n<ref>{{cite web|url=https://developer.nvidia.com/cuda-toolkit-archive|title=CUDA Toolkit Archive|website=NVIDIA Developer}}</ref>\n\n{| class=\"wikitable\" style=\"font-size: 85%; text-align: center; width: auto;\"\n|-\n! Compute<br />capability<br />(version)\n! [[Microarchitecture|Micro-<br />architecture]]\n! GPUs\n! GeForce\n! Quadro, NVS\n! Tesla\n! Tegra,<br>Jetson,<br>DRIVE\n|-\n| 1.0\n| rowspan=\"4\" | [[Tesla (microarchitecture)|Tesla]]\n| G80\n|GeForce 8800 Ultra, GeForce 8800 GTX, GeForce 8800 GTS(G80)\n|Quadro FX 5600, Quadro FX 4600, Quadro Plex 2100 S4\n|Tesla C870, Tesla D870, Tesla S870\n|\n|-\n| 1.1\n|G92, G94, G96, G98, G84, G86\n|GeForce GTS 250, GeForce 9800 GX2, GeForce 9800 GTX, GeForce 9800 GT, GeForce 8800 GTS(G92), GeForce 8800 GT,  GeForce 9600 GT, GeForce 9500 GT, GeForce 9400 GT, GeForce 8600 GTS, GeForce 8600 GT, GeForce 8500 GT,<br>GeForce G110M, GeForce 9300M GS, GeForce 9200M GS, GeForce 9100M G, GeForce 8400M GT, GeForce G105M\n|Quadro FX 4700 X2, Quadro FX 3700, Quadro FX 1800, Quadro FX 1700, Quadro FX 580, Quadro FX 570, Quadro FX 470, Quadro FX 380, Quadro FX 370, Quadro FX 370 Low Profile, Quadro NVS 450, Quadro NVS 420, Quadro NVS 290, Quadro NVS 295, Quadro Plex 2100 D4,<br>Quadro FX 3800M, Quadro FX 3700M, Quadro FX 3600M, Quadro FX 2800M, Quadro FX 2700M, Quadro FX 1700M, Quadro FX 1600M, Quadro FX 770M, Quadro FX 570M, Quadro FX 370M, Quadro FX 360M, Quadro NVS 320M, Quadro NVS 160M, Quadro NVS 150M, Quadro NVS 140M, Quadro NVS 135M, Quadro NVS 130M, Quadro NVS 450, Quadro NVS 420,<ref>{{cite web|url=https://www.techpowerup.com/gpu-specs/quadro-nvs-420.c1448|title=NVIDIA Quadro NVS 420 Specs|website=TechPowerUp GPU Database}}</ref> Quadro NVS 295\n|\n|\n|-\n|1.2\n|GT218, GT216, GT215\n|GeForce GT 340*, GeForce GT 330*, GeForce GT 320*, GeForce 315*, GeForce 310*, GeForce GT 240, GeForce GT 220, GeForce 210,<br>GeForce GTS 360M, GeForce GTS 350M, GeForce GT 335M, GeForce GT 330M, GeForce GT 325M, GeForce GT 240M, GeForce G210M, GeForce 310M, GeForce 305M\n|Quadro FX 380 Low Profile, Quadro FX 1800M, Quadro FX 880M, Quadro FX 380M,<br>Nvidia NVS 300, NVS 5100M, NVS 3100M, NVS 2100M, ION\n|\n|\n|-\n|1.3\n|GT200, GT200b\n|GeForce GTX 295, GTX 285, GTX 280, GeForce GTX 275, GeForce GTX 260\n|Quadro FX 5800, Quadro FX 4800, Quadro FX 4800 for Mac, Quadro FX 3800, Quadro CX, Quadro Plex 2200 D2\n|Tesla C1060, Tesla S1070, Tesla M1060\n|\n|-\n|2.0\n|  rowspan=\"2\" | [[Fermi (microarchitecture)|Fermi]]\n|GF100, GF110\n|GeForce GTX 590, GeForce GTX 580, GeForce GTX 570, GeForce GTX 480, GeForce GTX 470, GeForce GTX 465,<br>GeForce GTX 480M\n|Quadro 6000, Quadro 5000, Quadro 4000, Quadro 4000 for Mac, Quadro Plex 7000,<br>Quadro 5010M, Quadro 5000M\n|Tesla C2075, Tesla C2050/C2070, Tesla M2050/M2070/M2075/M2090\n|\n|-\n|2.1\n|GF104, GF106 GF108, GF114, GF116, GF117, GF119\n|GeForce GTX 560 Ti, GeForce GTX 550 Ti, GeForce GTX 460, GeForce GTS 450, GeForce GTS 450*, GeForce GT 640 (GDDR3), GeForce GT 630, GeForce GT 620, GeForce GT 610, GeForce GT 520, GeForce GT 440, GeForce GT 440*, GeForce GT 430, GeForce GT 430*, GeForce GT 420*,<br>GeForce GTX 675M, GeForce GTX 670M, GeForce GT 635M, GeForce GT 630M, GeForce GT 625M, GeForce GT 720M, GeForce GT 620M, GeForce 710M, GeForce 610M, GeForce 820M, GeForce GTX 580M, GeForce GTX 570M, GeForce GTX 560M, GeForce GT 555M, GeForce GT 550M, GeForce GT 540M, GeForce GT 525M, GeForce GT 520MX, GeForce GT 520M, GeForce GTX 485M, GeForce GTX 470M, GeForce GTX 460M, GeForce GT 445M, GeForce GT 435M, GeForce GT 420M, GeForce GT 415M, GeForce 710M, GeForce 410M\n|Quadro 2000, Quadro 2000D, Quadro 600,<br>Quadro 4000M, Quadro 3000M, Quadro 2000M, Quadro 1000M,<br>NVS 310, NVS 315, NVS 5400M, NVS 5200M, NVS 4200M\n|\n|\n|-\n|3.0\n|  rowspan=\"4\" | [[Kepler (microarchitecture)|Kepler]]\n|GK104, GK106, GK107\n|GeForce GTX 770, GeForce GTX 760, GeForce GT 740, GeForce GTX 690, GeForce GTX 680, GeForce GTX 670, GeForce GTX 660 Ti, GeForce GTX 660, GeForce GTX 650 Ti BOOST, GeForce GTX 650 Ti, GeForce GTX 650,<br>GeForce GTX 880M, GeForce GTX 780M, GeForce GTX 770M, GeForce GTX 765M, GeForce GTX 760M, GeForce GTX 680MX, GeForce GTX 680M, GeForce GTX 675MX, GeForce GTX 670MX, GeForce GTX 660M, GeForce GT 750M, GeForce GT 650M, GeForce GT 745M, GeForce GT 645M, GeForce GT 740M, GeForce GT 730M, GeForce GT 640M, GeForce GT 640M LE, GeForce GT 735M, GeForce GT 730M\n|Quadro K5000, Quadro K4200, Quadro K4000, Quadro K2000, Quadro K2000D, Quadro K600, Quadro K420,<br>Quadro K500M, Quadro K510M, Quadro K610M, Quadro K1000M, Quadro K2000M, Quadro K1100M, Quadro K2100M, Quadro K3000M, Quadro K3100M, Quadro K4000M, Quadro K5000M, Quadro K4100M, Quadro K5100M,<br>NVS 510, Quadro 410\n|Tesla K10, GRID K340, GRID K520\n|\n|-\n|3.2\n|GK20A\n|\n|\n|\n|Tegra&nbsp;K1,<br>Jetson&nbsp;TK1\n|-\n|3.5\n|GK110, GK208\n|GeForce GTX Titan Z, GeForce GTX Titan Black, GeForce GTX Titan,  GeForce GTX 780 Ti, GeForce GTX 780, GeForce GT 640 (GDDR5), GeForce GT 630 v2, GeForce GT 730, GeForce GT 720, GeForce GT 710, GeForce GT 740M (64-bit, DDR3), GeForce GT 920M\n|Quadro K6000, Quadro K5200\n|Tesla K40, Tesla K20x, Tesla K20\n|\n|-\n|3.7\n|GK210\n|\n|\n| Tesla K80\n|\n|-\n|5.0\n| rowspan=\"3\" | [[Maxwell (microarchitecture)|Maxwell]]\n|GM107, GM108\n|GeForce GTX 750 Ti, GeForce GTX 750, GeForce GTX 960M, GeForce GTX 950M, GeForce 940M, GeForce 930M, GeForce GTX 860M, GeForce GTX 850M, GeForce 845M, GeForce 840M, GeForce 830M, GeForce GTX 870M\n|Quadro K1200, Quadro K2200, Quadro K620, Quadro M2000M, Quadro M1000M, Quadro M600M, Quadro K620M, NVS 810\n|Tesla M10\n|\n|-\n|5.2\n|GM200, GM204, GM206\n|GeForce GTX Titan X, GeForce GTX 980 Ti, GeForce GTX 980, GeForce GTX 970, GeForce GTX 960, GeForce GTX 950, GeForce GTX 750 SE,<br>GeForce GTX 980M, GeForce GTX 970M, GeForce GTX 965M\n|Quadro M6000 24GB, Quadro M6000, Quadro M5000, Quadro M4000, Quadro M2000, Quadro M5500,<br>Quadro M5000M, Quadro M4000M, Quadro M3000M\n|Tesla M4, Tesla M40, Tesla M6, Tesla M60\n|\n|-\n|5.3\n|GM20B\n|\n|\n|\n|Tegra&nbsp;X1,<br>Jetson&nbsp;TX1,<br>Jetson&nbsp;Nano,<br>DRIVE&nbsp;CX,<br>DRIVE&nbsp;PX\n|-\n|6.0\n| rowspan=\"3\" |[[Pascal (microarchitecture)|Pascal]]\n|GP100\n|\n| Quadro GP100\n| Tesla P100\n|\n|-\n|6.1\n|GP102, GP104, GP106, GP107, GP108\n|Nvidia TITAN Xp, Titan X,<br>GeForce GTX 1080 Ti, GTX 1080, GTX 1070 Ti, GTX 1070, GTX 1060, GTX 1050 Ti, GTX 1050,<br>GT 1030, MX150\n|Quadro P6000, Quadro P5000, Quadro P4000, Quadro P2000, Quadro P1000, Quadro P600, Quadro P400,<br>Quadro P5000(Mobile), Quadro P4000(Mobile), Quadro P3000(Mobile)\n|Tesla P40, Tesla P6, Tesla P4\n|\n|-\n|6.2\n|GP10B<ref>{{cite web|url=http://www.phoronix.com/scan.php?page=news_item&px=Tegra-X2-Nouveau-Support|title=NVIDIA Rolls Out Tegra X2 GPU Support In Nouveau|last=Larabel|first=Michael|author-link=Michael Larabel|publisher=[[Phoronix]]|date=March 29, 2017|access-date=August 8, 2017}}</ref>\n|\n|\n|\n|Tegra&nbsp;X2, Jetson&nbsp;TX2, DRIVE&nbsp;PX&nbsp;2\n|-\n|7.0\n| rowspan=\"2\" |[[Volta (microarchitecture)|Volta]]\n|GV100\n|NVIDIA TITAN V\n|Quadro GV100\n|Tesla V100\n|\n|-\n|7.2\n|GV10B<ref>[https://www.techpowerup.com/gpudb/3232/xavier Nvidia Xavier Specs] on TechPowerUp (preliminary)</ref>\n|\n|\n|\n|Tegra Xavier,<br/>Jetson AGX Xavier, DRIVE AGX Xavier, DRIVE AGX Pegasus\n|-\n|7.5\n||[[Turing (microarchitecture)|Turing]]\n|TU102, TU104, TU106, TU116, TU117\n|NVIDIA TITAN RTX,<br>GeForce RTX 2080 Ti, RTX 2080, RTX 2070, RTX 2060,<br>GeForce GTX 1660 Ti, GTX 1660, GTX 1650\n|Quadro RTX 8000, Quadro RTX 6000, Quadro RTX 5000, Quadro RTX 4000,<br>Quadro T2000, Quadro T1000\n|Tesla T4\n|\n|-\n|8.0\n|\n|\n|\n|\n|\n|\n|}\n'*' – [[Original equipment manufacturer|OEM]]-only products\n\n==Version features and specifications==\n{| class=\"wikitable\" style=\"font-size:85%;\"\n|-\n! rowspan=2  | Feature support (unlisted features are supported for all compute abilities)\n! colspan=13 | Compute capability (version)\n|-\n! 1.0 !! 1.1 !! 1.2 !! 1.3 !! 2.x !! 3.0 !! 3.2 !! 3.5, 3.7, 5.0, 5.2 !! 5.3 !! 6.x !! 7.x\n|-\n| Integer atomic functions operating on 32-bit words in global memory\n| colspan=\"1\" rowspan=\"2\" {{no}}\n| colspan=\"10\" rowspan=\"2\" {{yes}}\n|-\n| atomicExch() operating on 32-bit floating point values in global memory\n|-\n| Integer atomic functions operating on 32-bit words in shared memory\n| colspan=\"2\" rowspan=\"4\" {{no}}\n| colspan=\"9\" rowspan=\"4\" {{yes}}\n|-\n| atomicExch() operating on 32-bit floating point values in shared memory\n|-\n| Integer atomic functions operating on 64-bit words in global memory\n|-\n| Warp vote functions\n|-\n|Double-precision floating-point operations\n| colspan=\"3\" rowspan=\"1\" {{no}}\n| colspan=\"8\" rowspan=\"1\" {{yes}}\n|-\n| Atomic functions operating on 64-bit integer values in shared memory\n| colspan=\"4\" rowspan=\"7\" {{no}}\n| colspan=\"7\" rowspan=\"7\" {{yes}}\n|-\n| Floating-point atomic addition operating on 32-bit words in global and shared memory\n|-\n|  _ballot()\n|-\n| _threadfence_system()\n|-\n| _syncthreads_count(), _syncthreads_and(), _syncthreads_or()\n|-\n| Surface functions\n|-\n| 3D grid of thread block\n|-\n| Warp shuffle functions\n| colspan=\"5\" rowspan=\"1\" {{no}}\n| colspan=\"6\" rowspan=\"1\" {{yes}}\n|-\n| Funnel shift\n| colspan=\"6\" rowspan=\"1\" {{no}}\n| colspan=\"5\" rowspan=\"1\" {{yes}}\n|-\n| Dynamic parallelism\n| colspan=\"7\" rowspan=\"1\" {{no}}\n| colspan=\"4\" rowspan=\"1\" {{yes}}\n|-\n| Half-precision floating-point operations:<br>addition, subtraction, multiplication, comparison, warp shuffle functions, conversion\n| colspan=\"8\" rowspan=\"1\" {{no}}\n| colspan=\"3\" rowspan=\"1\" {{yes}}\n|-\n| Atomic addition operating on 64-bit floating point values in global memory and shared memory\n| colspan=\"9\" rowspan=\"1\" {{no}}\n| colspan=\"2\" rowspan=\"1\" {{yes}}\n|-\n| Tensor core\n| colspan=\"10\" rowspan=\"1\" {{no}}\n| colspan=\"1\" rowspan=\"1\" {{yes}}\n|}<ref>{{Cite web|url=https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#features-and-technical-specifications|title=<!--CUDA C Programming Guide-->H.1. Features and Technical Specifications{{snd}} Table 13. Feature Support per Compute Capability|website=docs.nvidia.com|language=en-us|access-date=2019-05-13}}</ref>\n\n{| class=\"wikitable\" style=\"font-size:85%;\"\n|-\n! Data Type\n! Operation\n! Supported since\n! Supported since<br>for global memory\n! Supported since<br>for shared memory\n|-\n| 16-bit integer\n| general operations\n|\n|\n|\n|-\n| 32-bit integer\n| atomic functions\n|\n| 1.1\n| 1.2\n|-\n| 64-bit integer\n| atomic functions\n|\n| 1.2\n| 2.0\n|-\n| 16-bit floating point\n| addition, subtraction,<br>multiplication, comparison,<br>warp shuffle functions, conversion\n| 5.3\n|\n|\n|-\n| 32-bit floating point\n| atomicExch()\n|\n| 1.1\n| 1.2\n|-\n| 32-bit floating point\n| atomic addition\n|\n| 2.0\n| 2.0\n|-\n| 64-bit floating point\n| general operations\n| 1.3\n|\n|\n|-\n| 64-bit floating point\n| atomic addition\n|\n| 6.0\n| 6.0\n|-\n| \n| tensor core\n| 7.0\n| \n|\n|}\nNote: Any missing lines or empty entries do reflect some lack of information on that exact item.<br>\n<ref>https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#features-and-technical-specifications</ref>\n\n{| class=\"wikitable\" style=\"font-size:85%;\"\n|-\n! rowspan=2 | Technical specifications\n! colspan=\"18\" | Compute capability (version)\n|-\n! 1.0\n! 1.1\n! 1.2\n! 1.3\n! 2.x\n! 3.0\n! 3.2\n! 3.5\n! 3.7\n! 5.0\n! 5.2\n! 5.3\n! 6.0\n! 6.1\n! 6.2\n! 7.0<br>(7.2?)\n! 7.5\n|-\n| Maximum number of resident grids per device<br>(concurrent kernel execution)\n| colspan=\"4\" {{n/a|t.b.d.}}\n| colspan=\"2\" {{yes|16}}\n| colspan=\"1\" {{yes|4}}\n| colspan=\"4\" {{yes|32}}\n| colspan=\"1\" {{yes|16}}\n| colspan=\"1\" {{yes|128}}\n| colspan=\"1\" {{yes|32}}\n| colspan=\"1\" {{yes|16}}\n| colspan=\"2\" {{yes|128}}\n|-\n| Maximum dimensionality of grid of thread blocks\n| colspan=\"4\" {{yes|2}}\n| colspan=\"13\" {{yes|3}}\n|-\n| Maximum x-dimension of a grid of thread blocks\n| colspan=\"5\" {{yes|65535}}\n| colspan=\"12\" {{yes|2<sup>31</sup> − 1}}\n|-\n| Maximum y-, or z-dimension of a grid of thread blocks\n| colspan=\"17\" {{yes|65535}}\n|-\n| Maximum dimensionality of thread block\n| colspan=\"17\" {{yes|3}}\n|-\n| Maximum x- or y-dimension of a block\n| colspan=\"4\" {{yes|512}}\n| colspan=\"13\" {{yes|1024}}\n|-\n| Maximum z-dimension of a block\n| colspan=\"17\" {{yes|64}}\n|-\n| Maximum number of threads per block\n| colspan=\"4\" {{yes|512}}\n| colspan=\"13\" {{yes|1024}}\n|-\n| Warp size\n| colspan=\"17\" {{yes|32}}\n|-\n| Maximum number of resident blocks per multiprocessor\n| colspan=\"5\" {{yes|8}}\n| colspan=\"4\" {{yes|16}}\n| colspan=\"7\" {{yes|32}}\n| colspan=\"1\" {{yes|16}}\n|-\n| Maximum number of resident warps per multiprocessor\n| colspan=\"2\" {{yes|24}}\n| colspan=\"2\" {{yes|32}}\n| {{yes|48}}\n| colspan=\"11\" {{yes|64}}\n| colspan=\"1\" {{yes|32}}\n|-\n| Maximum number of resident threads per multiprocessor\n| colspan=\"2\" {{yes|768}}\n| colspan=\"2\" {{yes|1024}}\n| {{yes|1536}}\n| colspan=\"11\" {{yes|2048}}\n| colspan=\"1\" {{yes|1024}}\n|-\n| Number of 32-bit registers per multiprocessor\n| colspan=\"2\" {{yes|8 K}}\n| colspan=\"2\" {{yes|16 K}}\n| {{yes|32 K}}\n| colspan=\"3\" {{yes|64 K}}\n| colspan=\"1\" {{yes|128 K}}\n| colspan=\"8\" {{yes|64 K}}\n|-\n| Maximum number of 32-bit registers per thread block\n| colspan=\"4\" {{n/a}}\n| colspan=\"1\" {{yes|32 K}}\n| colspan=\"1\" {{yes|64 K}}\n| colspan=\"1\" {{yes|32 K}}\n| colspan=\"4\" {{yes|64 K}}\n| colspan=\"1\" {{yes|32 K}}\n| colspan=\"2\" {{yes|64 K}}\n| colspan=\"1\" {{yes|32 K}}\n| colspan=\"2\" {{yes|64 K}}\n|-\n| Maximum number of 32-bit registers per thread\n| colspan=\"4\" {{yes|124}}\n| colspan=\"2\" {{yes|63}}\n| colspan=\"11\" {{yes|255}}\n|-\n| Maximum amount of shared memory per multiprocessor\n| colspan=\"4\" {{yes|16 KB}}\n| colspan=\"4\" {{yes|48 KB}}\n| colspan=\"1\" {{yes|112 KB}}\n| colspan=\"1\" {{yes|64 KB}}\n| colspan=\"1\" {{yes|96 KB}}\n| colspan=\"2\" {{yes|64 KB}}\n| colspan=\"1\" {{yes|96 KB}}\n| colspan=\"1\" {{yes|64 KB}}\n| colspan=\"1\" {{yes|96 KB<br>(of 128)}}\n| colspan=\"1\" {{yes|64 KB<br>(of 96)}}\n|-\n| Maximum amount of shared memory per thread block\n| colspan=\"15\" {{yes|48 KB}}\n| colspan=\"1\" {{yes|48/96 KB}}\n| colspan=\"1\" {{yes|64 KB}}\n|-\n| Number of shared memory banks\n| colspan=\"4\" {{yes|16}}\n| colspan=\"13\" {{yes|32}}\n|-\n| Amount of local memory per thread\n| colspan=\"4\" {{yes|16 KB}}\n| colspan=\"13\" {{yes|512 KB}}\n|-\n| Constant memory size\n| colspan=\"17\" {{yes|64 KB}}\n|-\n| Cache working set per multiprocessor for constant memory\n| colspan=\"12\" {{yes|8 KB}}\n| colspan=\"1\" {{yes|4 KB}}\n| colspan=\"4\" {{yes|8 KB}}\n|-\n| Cache working set per multiprocessor for texture memory\n| colspan=\"4\" {{yes| 6&nbsp;–&nbsp;8&nbsp;KB}}\n| colspan=\"2\" {{yes| 12&nbsp;KB}}\n| colspan=\"3\" {{yes| 12&nbsp;–&nbsp;48&nbsp;KB}}\n| colspan=\"1\" {{yes| 24&nbsp;KB}}\n| colspan=\"1\" {{yes| 48&nbsp;KB}}\n| colspan=\"1\" {{n/a}}\n| colspan=\"1\" {{yes| 24&nbsp;KB}}\n| colspan=\"1\" {{yes| 48&nbsp;KB}}\n| colspan=\"1\" {{yes| 24&nbsp;KB}}\n| colspan=\"1\" {{yes| 32&nbsp;–&nbsp;128&nbsp;KB}}\n| colspan=\"1\" {{yes| 32&nbsp;–&nbsp;64&nbsp;KB}}\n|-\n| Maximum width for 1D texture reference bound to a CUDA <br />array\n| colspan=\"4\" {{yes|8192}}\n| colspan=\"13\" {{yes|65536}}\n|-\n| Maximum width for 1D texture reference bound to linear <br />memory\n| colspan=\"17\" {{yes| 2<sup>27</sup>}}\n|-\n| Maximum width and number of layers for a 1D layered <br />texture reference\n| colspan=\"4\" {{yes|8192 × 512}}\n| colspan=\"13\" {{yes|16384 × 2048}}\n|-\n| Maximum width and height for 2D texture reference bound <br />to a CUDA array\n| colspan=\"4\" {{yes|65536 × 32768}}\n| colspan=\"13\" {{yes|65536 × 65535}}\n|-\n| Maximum width and height for 2D texture reference bound <br />to a linear memory\n| colspan=\"17\" {{yes|65000<sup>2</sup>}}\n|-\n| Maximum width and height for 2D texture reference bound <br />to a CUDA array supporting texture gather\n| colspan=\"4\" {{n/a}}\n| colspan=\"13\" {{yes|16384<sup>2</sup>}}\n|-\n| Maximum width, height, and number of layers for a 2D <br />layered texture reference\n| colspan=\"4\" {{yes|8192 × 8192 × 512}}\n| colspan=\"13\" {{yes|16384 × 16384 × 2048}}\n|-\n| Maximum width, height and depth for a 3D texture <br />reference bound to linear memory or a CUDA array\n| colspan=\"5\" {{yes|2048<sup>3</sup>}}\n| colspan=\"12\" {{yes|4096<sup>3</sup>}}\n|-\n| Maximum width and number of layers for a cubemap <br />layered texture reference\n| colspan=\"4\" {{n/a}}\n| colspan=\"13\" {{yes|16384 × 2046}}\n|-\n| Maximum number of textures that can be bound to a <br />kernel\n| colspan=\"5\" {{yes|128}}\n| colspan=\"12\" {{yes|256}}\n|-\n| Maximum width for a 1D surface reference bound to a <br />CUDA array\n| colspan=\"4\" rowspan=\"7\" {{no|Not<br />supported}}\n| colspan=\"13\" {{yes|65536}}\n|-\n| Maximum width and number of layers for a 1D layered <br />surface reference\n| colspan=\"13\" {{yes|65536 × 2048}}\n|-\n| Maximum width and height for a 2D surface reference <br />bound to a CUDA array\n| colspan=\"13\" {{yes|65536 × 32768}}\n|-\n| Maximum width, height, and number of layers for a 2D <br />layered surface reference\n| colspan=\"13\" {{yes|65536 × 32768 × 2048}}\n|-\n| Maximum width, height, and depth for a 3D surface <br />reference bound to a CUDA array\n| colspan=\"13\" {{yes|65536 × 32768 × 2048}}\n|-\n| Maximum width and number of layers for a cubemap <br />layered surface reference\n| colspan=\"13\" {{yes|32768 × 2046}}\n|-\n| Maximum number of surfaces that can be bound to a <br />kernel\n| colspan=\"1\" {{yes|8}}\n| colspan=\"12\" {{yes|16}}\n|-\n| Maximum number of instructions per kernel\n| colspan=\"4\" {{yes|2 million}}\n| colspan=\"13\" {{yes|512 million}}\n|}<ref>[https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#features-and-technical-specifications H.1. Features and Technical Specifications – Table 14. Technical Specifications per Compute Capability]</ref>\n\n{| class=\"wikitable\" style=\"font-size:85%;\"\n|-\n! rowspan= 2 | Architecture specifications\n! colspan=15 | Compute capability (version)\n|-\n! 1.0\n! 1.1\n! 1.2\n! 1.3\n! 2.0\n! 2.1\n! 3.0\n! 3.5\n! 3.7\n! 5.0\n! 5.2\n! 6.0\n! 6.1, 6.2\n! 7.0, 7.2\n! 7.5\n|-\n| Number of ALU lanes for integer and single-precision floating-point arithmetic operations\n| colspan=\"4\" {{yes|8}}<ref>ALUs perform only single-precision floating-point arithmetics. There is 1 double-precision floating-point unit.</ref>\n| colspan=\"1\" {{yes|32}}\n| colspan=\"1\" {{yes|48}}\n| colspan=\"3\" {{yes|192}}\n| colspan=\"2\" {{yes|128}}\n| colspan=\"1\" {{yes|64}}\n| colspan=\"1\" {{yes|128}}\n| colspan=\"2\" {{yes|64}}\n|-\n| Number of special function units for single-precision floating-point transcendental functions\n| colspan=\"4\" {{yes|2}}\n| colspan=\"1\" {{yes|4}}\n| colspan=\"1\" {{yes|8}}\n| colspan=\"5\" {{yes|32}}\n| colspan=\"1\" {{yes|16}}\n| colspan=\"1\" {{yes|32}}\n| colspan=\"2\" {{yes|16}}\n|-\n| Number of texture filtering units for every texture address unit or ''render output unit'' (ROP)\n| colspan=\"4\" {{yes|2}}\n| colspan=\"1\" {{yes|4}}\n| colspan=\"1\" {{yes|8}}\n| colspan=\"3\" {{yes|16}}\n| colspan=\"6\" {{yes|8}}<ref name=\"inside-volta\">{{cite web|url=https://devblogs.nvidia.com/inside-volta/|title=Inside Volta: The World’s Most Advanced Data Center GPU|first1=Luke|last1=Durant|first2=Olivier|last2=Giroux|first3=Mark|last3=Harris|first4=Nick|last4=Stam|date=May 10, 2017|website=Nvidia developer blog}}</ref>\n|-\n| Number of warp schedulers\n| colspan=\"4\" {{yes|1}}\n| colspan=\"2\" {{yes|2}}\n| colspan=\"5\" {{yes|4}}\n| colspan=\"1\" {{yes|2}}\n| colspan=\"3\" {{yes|4}}\n|-\n| Max number of instructions issued at once by a single scheduler\n| colspan=\"5\" {{yes|1}}\n| colspan=\"4\" {{yes|2}}<ref>No more than one scheduler can issue 2 instructions at once. The first scheduler is in charge of warps with odd IDs. The second scheduler is in charge of warps with even IDs.</ref>\n| colspan=\"6\" {{yes|1}}\n|-\n| Number of tensor cores\n| colspan=\"13\" {{n/a}}\n| colspan=\"2\" {{yes|8}}<ref name=\"inside-volta\"/>\n|-\n| Size in KB of unified memory for data cache and shared memory per multi processor\n| colspan=\"13\" | t.b.d.\n| {{yes|128}}\n| {{yes|96}}<ref>{{Cite web|url=https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#architecture-7-x|title=<!--CUDA C Programming Guide-->H.6.1. Architecture|website=docs.nvidia.com|language=en-us|access-date=2019-05-13}}</ref>\n|}<ref>{{Cite web|url=https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#compute-capability-7-x|title=<!--CUDA C Programming Guide -->H.6. Compute Capability 7.x|website=docs.nvidia.com|language=en-us|access-date=2019-05-13}}</ref>\n\nFor more information see the article: {{cite web|url=https://www.geeks3d.com/20100606/gpu-computing-nvidia-cuda-compute-capability-comparative-table/|title=NVIDIA CUDA Compute Capability Comparative Table |postscript=none<!--|author=JeGX|publisher=Geeks3D|date=2010-06-06|access-date=2017-08-08-->}} and read Nvidia CUDA programming guide.<ref>{{cite web|url= http://developer.download.nvidia.com/compute/DevZone/docs/html/C/doc/CUDA_C_Programming_Guide.pdf |title=Appendix F. Features and Technical Specifications }}&nbsp;{{small|(3.2 MiB)}}, page 148 of 175 (Version 5.0 October 2012).</ref>\n\n==Example==\nThis example code in [[C++]] loads a texture from an image into an array on the GPU:\n<source lang=\"cuda\">\ntexture<float, 2, cudaReadModeElementType> tex;\n\nvoid foo()\n{\n  cudaArray* cu_array;\n\n  // Allocate array\n  cudaChannelFormatDesc description = cudaCreateChannelDesc<float>();\n  cudaMallocArray(&cu_array, &description, width, height);\n\n  // Copy image data to array\n  cudaMemcpyToArray(cu_array, image, width*height*sizeof(float), cudaMemcpyHostToDevice);\n\n  // Set texture parameters (default)\n  tex.addressMode[0] = cudaAddressModeClamp;\n  tex.addressMode[1] = cudaAddressModeClamp;\n  tex.filterMode = cudaFilterModePoint;\n  tex.normalized = false; // do not normalize coordinates\n\n  // Bind the array to the texture\n  cudaBindTextureToArray(tex, cu_array);\n\n  // Run kernel\n  dim3 blockDim(16, 16, 1);\n  dim3 gridDim((width + blockDim.x - 1)/ blockDim.x, (height + blockDim.y - 1) / blockDim.y, 1);\n  kernel<<< gridDim, blockDim, 0 >>>(d_data, height, width);\n\n  // Unbind the array from the texture\n  cudaUnbindTexture(tex);\n} //end foo()\n\n__global__ void kernel(float* odata, int height, int width)\n{\n   unsigned int x = blockIdx.x*blockDim.x + threadIdx.x;\n   unsigned int y = blockIdx.y*blockDim.y + threadIdx.y;\n   if (x < width && y < height) {\n      float c = tex2D(tex, x, y);\n      odata[y*width+x] = c;\n   }\n}\n</source>\n\nBelow is an example given in [[Python (programming language)|Python]] that computes the product of two arrays on the GPU. The unofficial Python language bindings can be obtained from ''PyCUDA''.<ref>{{cite web|url=http://mathema.tician.de/software/pycuda|title=PyCUDA}}</ref>\n<source lang=\"numpy\">\nimport pycuda.compiler as comp\nimport pycuda.driver as drv\nimport numpy\nimport pycuda.autoinit\n\nmod = comp.SourceModule(\"\"\"\n__global__ void multiply_them(float *dest, float *a, float *b)\n{\n  const int i = threadIdx.x;\n  dest[i] = a[i] * b[i];\n}\n\"\"\")\n\nmultiply_them = mod.get_function(\"multiply_them\")\n\na = numpy.random.randn(400).astype(numpy.float32)\nb = numpy.random.randn(400).astype(numpy.float32)\n\ndest = numpy.zeros_like(a)\nmultiply_them(\n        drv.Out(dest), drv.In(a), drv.In(b),\n        block=(400,1,1))\n\nprint dest-a*b\n\n</source>\n\nAdditional Python bindings to simplify matrix multiplication operations can be found in the program ''pycublas''.<ref>{{cite web|url=http://kered.org/blog/2009-04-13/easy-python-numpy-cuda-cublas/|title=pycublas|archive-url=https://web.archive.org/web/20090420124748/http://kered.org/blog/2009-04-13/easy-python-numpy-cuda-cublas/|archive-date=2009-04-20|dead-url=yes|access-date=2017-08-08}}</ref>\n\n<source lang=\"numpy\"> \nimport numpy\nfrom pycublas import CUBLASMatrix\nA = CUBLASMatrix( numpy.mat([[1,2,3],[4,5,6]],numpy.float32) )\nB = CUBLASMatrix( numpy.mat([[2,3],[4,5],[6,7]],numpy.float32) )\nC = A*B\nprint C.np_mat()\n</source>\n\n==Benchmarks==\nThere are some open-source benchmarks containing CUDA codes\n* [https://github.com/yuhc/gpu-rodinia Rodinia benchmarks]\n* [https://github.com/vetter/shoc SHOC]\n* [http://eigen.tuxfamily.org/index.php Tensor module in Eigen 3.0 open-source C++ template library] for [[linear algebra]].\n* [https://github.com/bennylp/saxpy-benchmark SAXPY benchmark]\n\n==Language bindings==\n* [[Common Lisp]] – [https://github.com/takagi/cl-cuda cl-cuda]\n* [[Clojure]] – [https://clojurecuda.uncomplicate.org ClojureCUDA]\n* [[Fortran]] – [http://www.hoopoe-cloud.com/Solutions/Fortran/Default.aspx FORTRAN CUDA], [http://www.pgroup.com/resources/cudafortran.htm PGI CUDA Fortran Compiler]\n* [[F Sharp (programming language)|F#]] – [https://web.archive.org/web/20141010163529/https://www.quantalea.net/products/introduction/ Alea.CUDA]\n* [[Haskell (programming language)|Haskell]] – [http://hackage.haskell.org/package/accelerate Data.Array.Accelerate]\n* [[IDL (programming language)|IDL]] – [http://www.txcorp.com/products/GPULib/ GPULib]\n* [[Java (programming language)|Java]] – [http://www.cass-hpc.com/solutions/legacy/jcuda jCUDA], [http://www.jcuda.org/jcuda/JCuda.html JCuda], [http://www.jcuda.org/jcuda/jcublas/JCublas.html JCublas], [http://www.jcuda.org/jcuda/jcufft/JCufft.html JCufft], [http://www.ibm.com/support/knowledgecenter/SSYKE2_7.0.0/com.ibm.java.lnx.71.doc/user/gpu_developing_cuda4j.html CUDA4J]\n* [[Julia (programming language)|Julia]] – [https://juliagpu.github.io/CUDAnative.jl/stable/ CUDAnative.jl]<ref>{{cite web|url=https://devblogs.nvidia.com/gpu-computing-julia-programming-language/|title=High-Performance GPU Computing in the Julia Programming Language|first=Tim|last=Besard|date=October 25, 2017|website=Nvidia developer blog}}</ref>\n* [[Lua (programming language)|Lua]] – [https://web.archive.org/web/20160815110157/https://psilambda.com/download/kappa-extras/  KappaCUDA]\n* [[Mathematica]] – [http://reference.wolfram.com/mathematica/CUDALink/tutorial/Overview.html CUDALink]\n* [[MATLAB]] – Parallel Computing Toolbox, MATLAB Distributed Computing Server,<ref>{{cite web|title=MATLAB Adds GPGPU Support|url=http://www.hpcwire.com/features/MATLAB-Adds-GPGPU-Support-103307084.html|date=2010-09-20|deadurl=yes|archiveurl=https://web.archive.org/web/20100927155948/http://www.hpcwire.com/features/MATLAB-Adds-GPGPU-Support-103307084.html|archivedate=2010-09-27|df=}}</ref> and 3rd party packages like [[Jacket (software)|Jacket]].\n* [[.NET Framework|.NET]] – [http://www.cass-hpc.com/solutions/libraries/cuda-net CUDA.NET], [https://kunzmi.github.io/managedCuda/ Managed CUDA], [https://archive.codeplex.com/?p=cudafy CUDAfy.NET] .NET kernel and host code, CURAND, CUBLAS, CUFFT\n* [[Perl]] – [https://web.archive.org/web/20100825231711/http://psilambda.com/download/kappa-for-perl/ KappaCUDA], [https://github.com/run4flat/perl-CUDA-Minimal CUDA::Minimal], [https://metacpan.org/pod/AI::MXNet::CudaKernel AI::MXNet::CudaKernel]\n* [[Python (programming language)|Python]] – [http://numba.pydata.org/ Numba], NumbaPro, [http://mathema.tician.de/software/pycuda PyCUDA], [https://web.archive.org/web/20160815113344/https://psilambda.com/download/kappa-for-python/ KappaCUDA], [http://deeplearning.net/software/theano/ Theano]\n* [[Ruby (programming language)|Ruby]] – [https://web.archive.org/web/20160815110157/https://psilambda.com/download/kappa-extras/ KappaCUDA] (Broken link)\n* [[R (programming language)|R]] – [https://github.com/gpuRcore/gpuRcuda gpuRcuda]\n\n==Current and future usages of CUDA architecture==\n* Accelerated rendering of 3D graphics\n* Accelerated interconversion of video file formats\n* Accelerated [[encryption]], [[decryption]] and [[Data compression|compression]]\n* [https://www.nvidia.com/object/bio_info_life_sciences.html Bioinformatics], e.g. NGS DNA sequencing [http://sourceforge.net/projects/seqbarracuda/ BarraCUDA]\n* Distributed calculations, such as predicting the native conformation of [[proteins]]\n* Medical analysis simulations, for example [[virtual reality]] based on [[X-ray computed tomography|CT]] and [[Magnetic resonance imaging|MRI]] scan images\n* Physical simulations, in particular in [[fluid dynamics]]\n* [[Neural network]] training in [[machine learning]] problems\n* [[Face recognition]]\n* [[Distributed computing]]\n* [[Molecular dynamics]]\n* Mining [[cryptocurrencies]]\n* [[Structure from motion]] (SfM) software\n\n==See also==\n* [[OpenCL]] – an open standard from [[Khronos Group]] for programming a variety of platforms, including GPUs, similar to lower-level CUDA '''Driver''' API (''non single-source'')\n* [[SYCL]] – an open standard from [[Khronos Group]] for programming a variety of platforms, including GPUs, with ''single-source'' modern C++, similar to higher-level CUDA '''Runtime''' API (''single-source'')\n* [[BrookGPU]] – the Stanford University graphics group's compiler\n* [[Array programming]]\n* [[Parallel computing]]\n* [[Stream processing]]\n* [[rCUDA]] – an API for computing on remote computers\n* [[Molecular modeling on GPU]]\n* [[Vulkan (API)|Vulkan]]\n\n==References==\n{{Reflist|30em}}\n\n==External links==\n* {{Official website}}\n* [https://devtalk.nvidia.com/default/topic/726765/need-a-little-tool-to-adjust-the-vram-size/ A little tool to adjust the VRAM size]\n\n{{Nvidia}}\n{{CPU technologies}}\n{{Parallel computing}}\n\n{{Authority control}}\n\n{{DEFAULTSORT:Cuda}}\n[[Category:Computer physics engines]]\n[[Category:GPGPU]]\n[[Category:GPGPU libraries]]\n[[Category:Graphics hardware]]\n[[Category:Nvidia software]]\n[[Category:Parallel computing]]\n[[Category:Video cards]]\n[[Category:Video game hardware]]"
    },
    {
      "title": "DirectCompute",
      "url": "https://en.wikipedia.org/wiki/DirectCompute",
      "text": "'''Microsoft DirectCompute''' is an [[application programming interface]] (API) that supports running [[compute kernel]]s on  [[GPGPU|general-purpose computing on graphics processing units]] on Microsoft's [[Windows Vista]], [[Windows 7]] and later versions. DirectCompute is part of the [[Microsoft DirectX]] collection of APIs, and was initially released with the [[DirectX 11]] API but runs on graphics processing units that use either [[DirectX 10]] or DirectX 11.<ref>{{cite web |url=https://developer.nvidia.com/directcompute |title=DirectCompute |author=<!--Staff writer(s); no by-line.--> |date= |website=developer.nvidia.com |publisher=[[NVIDIA]] |access-date=22 March 2015}}</ref> The DirectCompute architecture shares a range of computational interfaces with its competitors: [[OpenCL]] from [[Khronos Group]], compute shaders in [[OpenGL]], and [[CUDA]] from [[NVIDIA]].\n\n==See also==\n* [[OpenCL]]\n* [[CUDA]]\n* [[C++ AMP]]\n{{clear}}\n\n==References==\n{{reflist}}\n\n==External links==\n*[http://msdn.microsoft.com/en-us/library/ff476331%28v=VS.85%29.aspx Compute Shader Overview]\n*[https://channel9.msdn.com/Tags/directcompute-lecture-series DirectCompute Lecture Series]\n*[http://www.gdcvault.com/play/1013698/Advanced-DirectX-11-DirectCompute-by Advanced DirectX 11: DirectCompute by Example]\n*[http://on-demand-gtc.gputechconf.com/gtcnew/on-demand-gtc.php?searchByKeyword=DirectCompute&searchItems=&sessionTopic=&sessionEvent=&sessionYear=&sessionFormat=&submit=&select=+ GTC On-Demand]\n\n{{DEFAULTSORT:Directcompute}}\n[[Category:DirectX]]\n[[Category:GPGPU libraries]]\n\n{{microsoft-stub}}"
    },
    {
      "title": "GPULib",
      "url": "https://en.wikipedia.org/wiki/GPULib",
      "text": "{{Update|reason=There are concerns this product and licenses for it are discontinued and may no longer be available.  However this concern is not supported by a source acceptable to Wikipedia.  Please update with reliable sources if applicable or add to the [[Talk:GPULib|talk page]]|inaccurate=yes|date=September 2018}}\n{{Orphan|date=June 2013}}\n{{Infobox software\n| name                   = GPULib\n| screenshot             =\n| caption                = A CUDA library for [[Interactive Data Language|IDL]]\n| developer              = Tech-X Corporation\n| latest_release_version = 1.6.2\n| latest_release_date    = {{Start date and age|2013|Oct|1|mf=yes}}\n| platform               = [[Microsoft Windows]], [[OS X]], and [[Linux]]\n| genre                  = [[GPGPU]]\n| license                = [[Proprietary software|Proprietary]] [[commercial software]]\n| website                = {{URL|http://www.txcorp.com/home/gpulib}}\n}}\n\n'''GPULib''' is a software library developed and marketed by Tech-X Corporation<ref name=\"TX-OLDHOME\"/> for accelerating general-purpose scientific computations from within the Interactive Data Language ([[Interactive Data Language|IDL]]) using [[NVIDIA|Nvidia]]'s [[CUDA]] platform for programming its [[graphics processing unit]]s (GPUs). GPULib provides basic arithmetic, array indexing, special functions, Fast Fourier Transforms (FFT), interpolation, [[Basic Linear Algebra Subprograms|BLAS]] matrix operations as well as [[Lapack|LAPACK]] routines provided by MAGMA,<ref>{{cite web|url=http://icl.cs.utk.edu/magma|title=MAGMA|publisher=}}</ref> and some image processing operations. All numeric data types provided by IDL are supported. GPULib is used in medical imaging, optics,<ref>Cheong, F. C., Krishnatreya, B. J., & Grier, D. G. (2010). Strategies for three-dimensional particle tracking with holographic video microscopy. ''Optics Express'', 18(13), 13563. doi:10.1364/OE.18.013563</ref><ref>Cheong, F., Sun, B., Dreyfus, R., Amato-Grill, J., Xiao, K., Dixon, L., & Grier, D. (2009). Flow visualization and flow cytometry with holographic video microscopy. Optics Express, 17(15), 13071–13079.</ref> astronomy, earth science,<ref>Fillmore, D., Messmer, P., Mullowney, P., & Amyx, K. (2008). Acceleration of Data Analysis Applications using GPUs. ''American Geophysical Union'', 23, 1099.</ref> remote sensing,<ref>[http://www.crcpress.com/product/isbn/9781420087130 Canty, Morton J. ''Image Analysis, Classification, and Change Detection in Remote Sensing: With Algorithms for ENVI/IDL, Second Edition''. CRC Press, 2009.]</ref><ref>[https://books.google.com/books?id=u1YdVRQlw7EC&pg=PA143&dq=GPULib+tech-x&hl=en&sa=X&ei=3WyhUd36OsaKjALg_4DgDQ&ved=0CC0Q6AEwAA#v=onepage&q=GPULib%20tech-x&f=false Rademakers, Lisa and Coleman, Daniel. ''Spinoff, 2011: NASA Technologies Benefit Society''. Government Printing Office, 2012.]</ref> and other scientific areas.<ref>[http://www.computer.org/csdl/mags/cs/2008/05/mcs2008050070-abs.html Messmer, P., & Mullowney, P. J. (2008). GPULib: GPU Computing in High-Level Languages. ''Computing in Science & Engineering'', 10, 70–73.]</ref>\n\nA [[CUDA]] enabled GPU is currently required<ref>{{cite web|url=http://developer.nvidia.com/cuda-gpus|title=CUDA GPUs|date=4 June 2012|publisher=}}</ref> to use this library, although there is an [[OpenCL]] prototype available. GPULib provides more capabilities depending on the capability of the graphics processing unit (GPU) being used. For example, double-precision calculations and the ability to transfer data concurrently with computations are not provided by all GPUs, but GPULib supports these operations on GPUs which are capable of performing them.\n\nGPULib is provided in the form of a Dynamically Loadable Module (DLM) along with [[Interactive Data Language|IDL]] code. Using GPULib does not require knowledge of [[C (programming language)|C]] or [[CUDA]], though it can be extended if the user is knowledgeable with [[CUDA]]. GPULib previously provided bindings for other languages including Matlab, Python,<ref>[https://books.google.com/books?id=9_AXCmGDiz8C&pg=PA273&dq=GPULib&hl=en&sa=X&ei=QWyhUZmVOOK5igLS6YDoCw&ved=0CDsQ6AEwAg#v=onepage&q=GPULib&f=false Hetlan, Magnus Lie. ''Python Algorithms: Mastering Basic Algorithms in the Python Language''. Apress, 2010.]</ref> and Java.\n\nThe GPULib API documentation is available online.<ref name=\"TX-OLDDOCS\"/>\n== See also ==\n\n*[[CUDA]] – a parallel computing platform and programming model created by [[NVIDIA|Nvidia]] and implemented by the graphics processing units (GPUs) that they produce\n*[[GPGPU]] – general purpose computation on GPUs\n*[[OpenCL]] – cross-platform standard supported by both [[NVIDIA|Nvidia]] and AMD/ATI as well as Intel and others\n\n== References ==\n{{reflist|refs=\n\n<ref name=\"TX-OLDHOME\">{{cite web|url=http://www.txcorp.com|title=Tech-X Products|website=Tech-X Corporation|id=GLULib|dead-url=yes|archive-url=https://web.archive.org/web/20171024040241/https://www.txcorp.com/|archive-date=24 October 2017|df=dmy-all}}</ref>\n\n<ref name=\"TX-OLDDOCS\">{{cite web|url=http://www.txcorp.com/images/docs/gpulib/1.6.2/html/index.html|title=GPULib 1.6.2 API|website=Tech-X Corporation|dead-url=yes|archive-url=https://web.archive.org/web/20161117092112/http://www.txcorp.com/images/docs/gpulib/1.6.2/html/index.html|archive-date=17 November 2016|df=dmy-all}}</ref>\n\n}}\n\n{{DEFAULTSORT:GPULib}}\n[[Category:GPGPU libraries]]"
    },
    {
      "title": "Lib Sh",
      "url": "https://en.wikipedia.org/wiki/Lib_Sh",
      "text": "'''Sh''' was an early [[metaprogramming]] language for [[GPGPU|programmable GPUs]]. It offered a general-purpose programming language, following a stream-processing model. Programs written in Sh could either run on [[CPU]]s or GPUs, obviating the need to write programs in a mix of two programming languages as was the case with earlier GPU programming systems such as [[Cg (programming language)|Cg]] or [[High-level shader language|HLSL]].<ref>{{cite journal |last1=Tarditi |first1=David |first2=Sidd |last2=Puri |first3=Jose |last3=Oglesby |title=Accelerator: using data parallelism to program GPUs for general-purpose uses |journal=ACM SIGARCH Computer Architecture News |volume=34 |issue=5 |year=2006}}</ref>\n\nAs of August 2006, it is no longer maintained. [[RapidMind|RapidMind Inc.]] was formed to commercialize the research behind Sh. RapidMind was then bought by Intel and ceased Sh development as well.\n\n==See also==\n*[[BrookGPU]]\n*[[CUDA]]\n*[[Close to Metal]]\n*[[OpenCL]]\n*[[RapidMind]]\n\n==External links==\n*[https://web.archive.org/web/20040725181641/http://libsh.org/ Official site]\n\n==References==\n{{reflist}}\n\n[[Category:GPGPU]]\n[[Category:GPGPU libraries]]\n\n{{Compu-graphics-stub}}"
    },
    {
      "title": "SYCL",
      "url": "https://en.wikipedia.org/wiki/SYCL",
      "text": "{{third-party|date=January 2019}}\n{{Infobox software\n| name = SYCL\n| logo = [[Image:Khronos Group SYCL logo.svg|SYCL logo|220px]]\n| author = [[Khronos Group]]\n| developer = [[Khronos Group]]\n| released = {{Start date|2014|03}}\n| latest release version = 1.2.1 revision 5\n| latest release date = {{start date and age|2019|04|18}}\n| operating_system = [[Cross-platform]]\n| platform = [[Cross-platform]]\n| genre = [[High-level programming language]]\n| website = {{URL|https://www.khronos.org/sycl/}}\n}}\n\n'''SYCL''' is a higher-level programming model for [[OpenCL]] as a single-source domain specific embedded language ([[DSEL]]) based on pure [[C++11]] for SYCL 1.2.1 to improve programming productivity. This is a standard developed by [[Khronos Group]], announced in March 2014.\n\n==Purpose==\n\nSYCL (pronounced ‘sickle’) is a royalty-free, cross-platform abstraction layer that builds on the underlying concepts, portability and efficiency of [[OpenCL]] that enables code for heterogeneous processors to be written in a “single-source” style using completely standard [[C++]].   SYCL enables single source development where [[Template (C++)|C++ template]] functions can contain both host and device code to construct complex algorithms that use [[OpenCL]] acceleration, and then re-use them throughout their source code on different types of data.\n\nWhile originally developed for use with [[OpenCL]] and [[Standard Portable Intermediate Representation|SPIR]], it is actually a more general heterogeneous framework able to target other systems. For example, the hipSYCL implementation targets [[CUDA]].\n\n==Versions==\n\nThe latest version is SYCL 1.2.1 revision 5 which was published on April 18, 2019 (the first version was published on December 6, 2017<ref name=\"sycl-ea-2017\">{{cite web|url = https://www.khronos.org/news/press/the-khronos-group-releases-finalized-sycl-1.2.1|title = The Khronos Group Releases Finalized SYCL 1.2.1|date = 6 December 2017|accessdate = 12 December 2017|website = Khronos|publisher = |last = Khronos Group}}</ref>).\n\nSYCL was introduced at GDC in March 2014 with\nprovisional version 1.2,<ref name=\"sycl-gdc-2014\">{{cite web|url = https://www.khronos.org/news/press/khronos-releases-sycl-1.2-provisional-specification|title = Khronos Releases SYCL 1.2 Provisional Specification|date = 19 March 2014|accessdate = 20 August 2017|website = Khronos|publisher = |last = Khronos Group}}</ref> then the SYCL 1.2 final version was\nintroduced at [[IWOCL]] 2015 in May 2015.<ref name=\"sycl-iwocl-2015\">{{cite web|url = https://www.khronos.org/news/press/khronos-releases-sycl-1.2-final-specification-c-single-source-heterogeneous|title = Khronos Releases SYCL 1.2 Final Specification|date = 11 May 2015|accessdate = 20 August 2017|website = Khronos|publisher = |last = Khronos Group}}</ref>\n\nSYCL 2.2 provisional was introduced at [[IWOCL]] 2016 in May 2016<ref name=\"sycl-iwocl-2016\">{{cite web|url = https://www.khronos.org/news/press/khronos-releases-opencl-2.2-provisional-spec-opencl-c-kernel-language|title = Khronos Releases OpenCL 2.2 Provisional Specification with OpenCL C++ Kernel Language|date = 18 April 2016|accessdate = 18 September 2017|website = Khronos|publisher = |last = Khronos Group}}</ref> targeting [[C++14]] and [[OpenCL]] 2.2. But the SYCL committee preferred not to finalize this version and is working on a more flexible SYCL specification to address the increasing diversity of current accelerators, including artificial-intelligence engines.\n\nThe public version is:\n* SYCL 1.2.1 targeting [[OpenCL]] 1.2 hardware features with an [[OpenCL]] 1.2 interoperability mode.\n\n==Example==\n\nThe following example shows the single-source pure [[C++]] programming model defining an implicit task graph of 3 kernels running on a default accelerator.\n\n<syntaxhighlight lang=\"C++\">\n#include <CL/sycl.hpp>\n#include <iostream>\n\nclass init_a;\nclass init_b;\nclass matrix_add;\n\nusing namespace cl::sycl;\n\n// Size of the matrices\nconstexpr size_t N = 2000;\nconstexpr size_t M = 3000;\n\nint main() {\n  // Create a queue to work on default device\n  queue q;\n  // Create some 2D buffers with N×M float values for our matrices\n  buffer<double, 2> a{{N, M}};\n  buffer<double, 2> b{{N, M}};\n  buffer<double, 2> c{{N, M}};\n  // First launch an asynchronous kernel to initialize buffer \"a\"\n  q.submit([&](handler &cgh) {\n    // The kernel writes \"a\", so get a write accessor to it\n    auto A = a.get_access<access::mode::write>(cgh);\n\n    // Enqueue parallel kernel on an N×M 2D iteration space\n    cgh.parallel_for<init_a>(range<2>{N, M}, [=](item<1> index) {\n      A[index] = index[0] * 2 + index[1];\n    });\n  });\n  // Launch an asynchronous kernel to initialize buffer \"b\"\n  q.submit([&](handler &cgh) {\n    // The kernel writes to \"b\", so get a write accessor on it\n    auto B = b.get_access<access::mode::write>(cgh);\n    // Enqueue a parallel kernel on an N×M 2D iteration space\n    cgh.parallel_for<init_b>(range<2>{N, M}, [=](item<1> index) {\n      B[index] = index[0] * 2014 + index[1] * 42;\n    });\n  });\n  // Launch an asynchronous kernel to compute matrix addition c = a + b\n  q.submit([&](handler &cgh) {\n    // In the kernel \"a\" and \"b\" are read, but \"c\" is written.\n    // Since the kernel reads \"a\" and \"b\", the runtime will implicitly add\n    // a producer-consumer dependency to the previous kernels producing them.\n    auto A = a.get_access<access::mode::read>(cgh);\n    auto B = b.get_access<access::mode::read>(cgh);\n    auto C = c.get_access<access::mode::write>(cgh);\n\n    // Enqueue a parallel kernel on an N×M 2D iteration space\n    cgh.parallel_for<matrix_add>(\n        range<2>{N, M}, [=](item<1> index) { C[index] = A[index] + B[index]; });\n  });\n  /* Request an access to read \"c\" from the host-side. The SYCL runtime\n     will wait for \"c\" to be ready available on the host side before\n     returning the accessor.\n     This means that there is no communication happening in the nested loop below.\n   */\n  auto C = c.get_access<access::mode::read>();\n  std::cout << \"\\nResult:\\n\";\n  for (size_t i = 0; i < N; i++)\n    for (size_t j = 0; j < M; j++)\n      // Compare the result to the analytic value\n      if (C[i][j] != i * (2 + 2014) + j * (1 + 42)) {\n        std::cout << \"Wrong value \" << C[i][j]\n                  << \" on element \" << i << ' ' << j << '\\n';\n        exit(EXIT_FAILURE);\n      }\n\n  std::cout << \"Good computation!\\n\";\n}\n</syntaxhighlight>\n\n==Tutorials==\n\nThere are a few tutorials in the ComputeCpp SYCL guides.<ref name=\"computecpp-sycl-guides\">{{cite web|url = https://developer.codeplay.com/computecppce/latest/sycl-guide-introduction|title = Introduction to GPGPU programming with SYCL|accessdate = 3 October 2017|website = Codeplay}}</ref>\n\n==Comparison with other APIs==\n\nThe open standards SYCL and [[OpenCL]] are similar to vendor-specific [[CUDA]] from [[Nvidia]].\n\nIn the [[Khronos Group]] realm, [[OpenCL]] is the low-level ''non-single source'' [[Application programming interface|API]] and SYCL is the high-level ''single-source'' [[C++]] [[DSEL|domain-specific embedded language]].\n\nBy comparison, the ''single-source'' [[C++]] [[DSEL|domain-specific embedded language]] version of [[CUDA]], which is actually named \"[[CUDA]] ''Runtime'' [[Application programming interface|API]]\", is somehow similar to SYCL.\nBut there is actually a less known ''non single-source'' version of [[CUDA]] which is called \"[[CUDA]] ''Driver'' [[Application programming interface|API]]\", similar to [[OpenCL]], and used for example by the [[CUDA]] ''Runtime'' [[Application programming interface|API]] implementation itself.\n\nSYCL extends the [[C++ AMP]] features relieving the programmer from explicitly transferring the data between the host and devices, by opposition to [[CUDA]].\n\nSYCL is higher-level than [[C++ AMP]] and [[CUDA]] since you do not need building an explicitly dependency graph between all the kernels and\nprovides you automatic asynchronous scheduling of the kernels with communication and computation overlap. This is\nall done by using the concept of accessors, without requiring any compiler support.\n\nBy opposition to [[C++ AMP]] and [[CUDA]], SYCL is a pure [[C++]] [[DSEL]] without any [[C++]] extension, allowing some basic CPU implementation relying on pure runtime without any specific compiler. This is very useful for debuging application or to prototype for a new architecture without having the architecture and compiler available yet.\n\nThe hipSYCL implementation adds SYCL higher-level programming to [[CUDA]].\n\n==See also==\n* [[C++]]\n* [[C++ AMP]]\n* [[CUDA]]\n* [[Metal (API)|Metal]]\n* [[OpenACC]]\n* [[OpenCL]]\n* [[OpenMP]]\n* [[Standard Portable Intermediate Representation|SPIR]]\n* [[Vulkan (API)|Vulkan]]\n\n==References==\n{{Reflist}}\n\n==External links==\n*[https://www.khronos.org/sycl/ Khronos SYCL webpage]\n* [https://www.khronos.org/registry/SYCL/ The SYCL specifications in Khronos registry]\n* [https://github.com/KhronosGroup/SyclParallelSTL C++17 ParallelSTL in SYCL]\n* [http://sycl.tech/ SYCL tech resources]\n* [https://www.codeplay.com/products/computesuite/computecpp Codeplay ComputeCpp SYCL implementation]\n* [https://github.com/intel/llvm/tree/sycl Implementation of SYCL started by Intel with the goal of Clang/LLVM up-streaming]\n* [https://github.com/illuhad/hipSYCL hipSYCL: implementation of SYCL 1.2.1 over AMD HIP/NVIDIA CUDA]\n* [https://github.com/triSYCL/triSYCL triSYCL open-source SYCL implementation]\n\n{{Khronos Group standards}}\n{{Parallel computing}}\n\n[[Category:Parallel computing]]\n[[Category:Heterogeneous computing]]\n[[Category:C++]]\n[[Category:Domain-specific programming languages]]\n[[Category:Application programming interfaces]]\n[[Category:Cross-platform software]]\n[[Category:GPGPU]]\n[[Category:GPGPU libraries|OpenCL]]"
    },
    {
      "title": "RenderScript",
      "url": "https://en.wikipedia.org/wiki/RenderScript",
      "text": "{{Infobox software\n| name                   = RenderScript\n| logo                   = <!-- Image name is enough -->\n| logo alt               = \n| screenshot             = <!-- Image name is enough -->\n| caption                = \n| screenshot alt         = \n| collapsible            = \n| author                 = \n| developer              = \n| released               = <!-- {{Start date and age|YYYY|MM|DD|df=yes/no}} -->\n| discontinued           = \n| latest release version = \n| latest release date    = <!-- {{Start date and age|YYYY|MM|DD|df=yes/no}} -->\n| latest preview version = \n| latest preview date    = <!-- {{Start date and age|YYYY|MM|DD|df=yes/no}} -->\n| status                 = \n| programming language   = \n| operating system       = \n| platform               = \n| size                   = \n| language               = \n| language count         = <!-- Number only -->\n| language footnote      = \n| genre                  = \n| license                = \n| alexa                  = \n| website                = {{URL|http://developer.android.com/guide/topics/renderscript/index.html}}\n| repo                   = <!-- {{URL|example.org}} -->\n| standard               = \n| AsOf                   = \n}}\n'''RenderScript''' is a component of the [[Android (operating system)|Android operating system]] for mobile devices that offers an [[Application programming interface|API]] for acceleration that takes advantage of [[heterogeneous computing|heterogeneous]] hardware. It allows developers to increase the performance of their applications at the cost of writing more complex (lower-level) code.\n\nIt provides the developer three primary tools: A simple 3D rendering API, a compute API similar to [[CUDA]], and a [[C99]]-derived language. \n\n== History ==\nRenderScript was added in Android 3.0 Honeycomb <ref>https://developer.android.com/about/versions/android-3.0-highlights.html#graphics</ref>\n\nAs of Android 4.1, Renderscipt's experimental [[3D rendering API]] has been deprecated, and now exists solely as a compute API.\n\nAndroid 4.2 added new capabilities to script intrinsics, such as ''Blend'' and ''Blur''; as well as ''ScriptGroups'' which allow you to chain together related RenderScript scripts and execute them with one call.\n\nMost recently, Google added ''FilterScript,'' which is a subset of RenderScript that allows developers to write their image processing operations in FilterScript using the standard RenderScript runtime API, but within stricter constraints that ensure wider compatibility and improved optimization across [[multi-core]] [[Central_processing_unit|CPUs]], [[Graphics_processing_unit|GPUs]], and [[Digital_signal_processor|DSPs]]. FilterScript is a less precise in terms of numeric datatype precision, and more cross device compatible subset of RenderScript &ndash; and should not be mistaken for a RenderScript replacement technology.<ref name=\"rs3d\">{{cite web | title = Android 4.2 APIs | url = http://developer.android.com/about/versions/android-4.2.html | accessdate = 2013-03-20}}</ref>\n\n== Features ==\n\n=== Portability ===\nRenderScript is designed to always run on the various Android platforms regardless of hardware type. Performance tuning is done at runtime.\n\nRenderScript portability depends upon device-specific drivers:<ref name=\"rsbookeasy\">{{cite book |last=Marchetti |first=Alberto |date=2016 |title=RenderScript: parallel computing on Android, the easy way |edition=1st |url=https://hydex11.net/rsbooked1.html}}</ref> a basic CPU-only driver is provided for every device, while there exist some specific chipset-provided RenderScript drivers that enable GPU usage (e.g. Qualcomm specific drivers, which are provided in the <code>libRSDriver_adreno.so</code> Android library).\n\n=== Performance ===\nRenderScript is designed to tune tasks at runtime that can be efficiently split and run concurrently on the underlying hardware.<ref>https://android-developers.googleblog.com/2011/03/renderscript.html</ref>\n\nAs of Android 4.2, RenderScript has been expanded to run on the GPU in addition to the CPU on supported systems.<ref name=\"rsjb\">{{cite web | title = Jelly Bean - Renderscipt Performance | author = | url = http://developer.android.com/about/versions/jelly-bean.html#42-performance | accessdate = 2012-11-27}}</ref>\n\n== Limitations ==\n* RenderScript cannot yet express on-chip inter-thread communication (known as local memory in OpenCL, and shared memory in CUDA). \n* RenderScript cannot yet express hardware-implemented 2D and 3D lookups with bilinear interpolation (known as texture in CUDA, and image read in OpenCL).\n\n==References==\n{{Reflist}}\n\n== External links ==\n* [http://developer.android.com/guide/topics/renderscript/index.html Google Developer page]\n* [http://android-developers.blogspot.com/2011/02/introducing-renderscript.html Introducing Renderscript]\n* [http://android-developers.blogspot.com/2011/03/renderscript.html Renderscript Part 2]\n* [https://www.engadget.com/2011/02/11/google-details-low-level-renderscript-api-for-honeycomb Google details low-level Renderscript API for Honeycomb]\n* [http://marakana.com/forums/android/general/381.html Video: Learn about RenderScript from Romain Guy and Chet Haase]\n* [http://www.independent-software.com/setting-up-android-renderscript-in-android-studio-1-3/ Guide to setting up Renderscript in Android Studio]\n\n{{Android}}\n\n[[Category:Android (operating system)]]\n[[Category:GPGPU libraries]]"
    },
    {
      "title": "ADMB",
      "url": "https://en.wikipedia.org/wiki/ADMB",
      "text": "{{Infobox programming language\n| name                   = ADMB\n| logo                   = ADMB logo.jpg\n| paradigm               =\n| designer               = [[David Fournier]]\n| developer              = ADMB Core Team\n| typing                 =\n| implementations        =\n| dialects               = [[C++]]\n| influenced             =\n| license                = [[BSD]]\n| website                = {{URL|http://admb-project.org/}}\n| year                   =\n| latest_release_version = 12.0<ref>[http://www.admb-project.org/2017/12/21/ADMB-12.0-Release.html]</ref>\n| latest_release_date    = {{Start date and age|2017|12|21|df=yes}}\n| latest_test_version    =\n| latest_test_date       =\n| influenced_by          = \n| operating_system       = [[Cross-platform]]\n}}\n\n'''ADMB''' or '''AD Model Builder''' is a [[free and open source software]] suite for [[non-linear]] [[statistical model]]ing.<ref>{{cite web | title = admb-project | publisher = ADMB Project | url = https://code.google.com/p/admb-project/ | accessdate = 2009-04-01| archiveurl= https://web.archive.org/web/20090303132743/https://code.google.com/p/admb-project/| archivedate= 3 March 2009 <!--DASHBot-->| deadurl= no}}</ref><ref>Fournier, D.A., H.J. Skaug, J. Ancheta, J. Ianelli, A. Magnusson, M.N. Maunder, A. Nielsen, and J. Sibert. 2012. AD Model Builder: using automatic differentiation for statistical inference of highly parameterized complex nonlinear models. Optim. Methods Softw. 27:233-249</ref> It was created by David Fournier and now being developed by the ADMB Project, a creation of the non-profit ADMB Foundation. The \"AD\" in AD Model Builder refers to the [[automatic differentiation]] capabilities that come from the '''AUTODIF Library''', a C++ language extension also created by David Fournier, which implements reverse mode automatic differentiation.<ref>{{cite web | title = AUTODIF: A C++ Array Language Extension with Automatic Differentiation For Use in Nonlinear Modeling and Statistics | publisher = ADMB Project | url = http://admb-project.googlecode.com/files/autodif.pdf | accessdate = 2008-12-03 | archive-url = https://web.archive.org/web/20110711111457/http://admb-project.googlecode.com/files/autodif.pdf | archive-date = 2011-07-11 | dead-url = yes | df =  }}</ref> A related software package, '''ADMB-RE''', provides additional support for modeling [[Random effects model|random effects]].<ref name=\"ADMB-RE user guide\">{{cite web | title = Random effects in AD Model Builder: ADMB-RE user guide | publisher = ADMB Project | url = http://admb-project.googlecode.com/files/admb-re.pdf | accessdate = 2008-12-03 | archive-url = https://web.archive.org/web/20110711111618/http://admb-project.googlecode.com/files/admb-re.pdf | archive-date = 2011-07-11 | dead-url = yes | df =  }}</ref>\n\n==Features and use==\n[[Markov chain Monte Carlo]] methods are integrated into the ADMB software, making it useful for [[Bayesian probability|Bayesian]] modeling.<ref>{{cite web | title = An Introduction to AD Model Builder Version 9.0.0 | publisher = ADMB Project | url = http://admb-project.googlecode.com/files/admb.pdf | accessdate = 2008-12-03 | archive-url = https://web.archive.org/web/20110104180301/http://admb-project.googlecode.com/files/admb.pdf | archive-date = 2011-01-04 | dead-url = yes | df =  }}</ref> In addition to Bayesian hierarchical models, ADMB provides support for modeling random effects in a frequentist framework using Laplace approximation and importance sampling.<ref name=\"ADMB-RE user guide\"/>\n\nADMB is widely used by scientists in academic institutions, government agencies, and international commissions,<ref>{{cite web\n |url          = http://admb-project.org/community/user-base\n |publisher    = ADMB Project\n |title        = ADMB User Base and Major Applications\n |accessdate   = 2008-12-02\n |archive-url  = https://web.archive.org/web/20110724224347/http://admb-project.org/community/user-base\n |archive-date = 2011-07-24\n |dead-url     = yes\n |df           = \n}}</ref> most commonly for ecological modeling. In particular, many [[fisheries]] [[stock assessment]] models have been built using this software.<ref>{{cite web\n |url          = http://admb-project.org/community/bibliography/stock-assessments\n |publisher    = ADMB Project\n |title        = Bibliography: Stock assessments\n |accessdate   = 2008-12-03\n |archive-url  = https://archive.is/20130226034837/http://admb-project.org/community/bibliography/stock-assessments\n |archive-date = 2013-02-26\n |dead-url     = yes\n |df           = \n}}</ref> ADMB is freely available under the [[New BSD License]],<ref name=downloads>{{cite web\n | url=http://admb-project.org/downloads\n | publisher=ADMB Project\n | title=ADMB Downloads\n | accessdate=2010-07-28\n}}</ref>\nwith versions available for [[Microsoft Windows|Windows]], [[Linux]], [[Mac OS X]], and [[OpenSolaris]] [[operating system]]s.<ref name=downloads /> Source code for ADMB was made publicly available in March 2009.<ref>{{cite web\n | url=http://www.ia.ucsb.edu/pa/display.aspx?pkey=1896\n | publisher=University of California, Santa Barbara\n | title=UCSB Press Release: \"Fisheries Stock Assessment Software Now Publicly Accessible\"\n | accessdate=2008-12-09\n}}</ref>\n<ref>{{cite web\n |url          = http://admb-project.org/news/admb-source-code-available\n |publisher    = ADMB Project\n |title        = ADMB Source Code Available\n |accessdate   = 2009-05-14\n |archive-url  = https://web.archive.org/web/20100418194627/http://admb-project.org/news/admb-source-code-available\n |archive-date = 2010-04-18\n |dead-url     = yes\n |df           = \n}}</ref>\n\n== History and background ==\n\n=== Implementation ===\n\nWork by David Fournier in the 1970s on development of highly parameterized \nintegrated statistical models in fisheries motivated the\ndevelopment of the AUTODIF Library, and ultimately ADMB.\nThe likelihood equations\nin these models are typically non-linear and estimates of the \nparameters are\nobtained by numerical methods.\n\nEarly in Fournier's work, it became clear that general numerical\nsolutions to these likelihood problems could only be reliably\nachieved using function minimization algorithms that\nincorporate accurate information about the gradients of the likelihood\nsurface. Computing the gradients (i.e. partial derivatives\nof the likelihood with respect to all model variables) must also be done with\nthe same accuracy as the likelihood computation itself.\n\nFournier developed a protocol for writing code to compute the required\nderivatives based on the chain rule of differential calculus. This\nprotocol is very similar to the suite of methods that came to be known\nas ``reverse mode automatic differentiation'' \n.<ref>A. Griewank and G. F.Corliss (eds). \n''Automatic differentiation of algorithms: theory, implementation, and application.''` \nSociety of Industrial and Applied Mathematics. 1992.\n</ref>\n\nThe statistical models using these methods\n<ref>D. Fournier and I. Doonan.\n''A length-based stock assessment method utilizing a generalized delay-difference model''.\nCanadian Journal of Fisheries and Aquatic Sciences, 44(2):422--437, 1987.\n</ref>\n<ref>D. Fournier and A. Warburton.\n''Evaluating fisheries management models by simulated adaptive control-introducing the composite model''.\nCanadian Journal of Fisheries and Aquatic Sciences.\n  46(6):1002--1012, 1989.\n</ref>\n<ref>D. Fournier, J. Sibert, J. Majkowski, and J. Hampton.\n''MULTIFAN a likelihood-based method for estimating growth parameters and age composition from multiple length frequency data sets illustrated using data for southern bluefin tuna (Thunnus maccoyii)''.\nCanadian Journal of Fisheries and Aquatic Sciences, 47(2):301--317, 1990.\n</ref>\n<ref>J. Sibert, J. Hampton, D. Fournier, and P. Bills.\n''An advection-diffusion-reaction model for the estimation of fishmovement parameters from tagging data, with application to skipjack tuna (Katsuwonus pelamis)''.\nCanadian Journal of Fisheries and Aquatic Sciences, 56(6):925--938, 1999.\n</ref>\ntypically included eight constituent code segments:\n# the objective function;\n# adjoint code to compute the partial derivatives of the objective function with respect to the parameters to be estimated;\n# dedicated memory to contain intermediate data for derivative computations, known as the \"gradient stack\", and the software to manage it;\n# a function minimizer;\n# an algorithm to check that the derivatives are correct with respect to finite difference approximations;\n# an algorithm to insert model parameters into a vector that can be manipulated by the function minimizer and the corresponding derivative code;\n# an algorithm to return the parameter values to the likelihood computation and the corresponding derivative code; and\n# an algorithm to compute the second [[partial derivative]]s of the objective unction with respect to the parameters to be estimated, the [[Hessian matrix]].\n\nModel developers are usually only interested in the first of these\nconstituents. Any programming tools that can reduce the overhead of\ndeveloping and maintaining the other seven will greatly increase their\nproductivity.\n\nBjarne Stroustrup began development of C++ in the 1970s at Bell Labs as an \nenhancement to the C programming language. C++ spread widely, and by\n1989, C++ compilers were available for personal computers.\nThe polymorphism of C++ makes it possible to envisage a programming\nsystem in which all mathematical operators and functions can be\noverloaded to automatically compute the derivative contributions of\nevery differentiable numerical operation in any computer program.\n\n=== Otter Research ===\n\nFournier formed Otter Research Ltd. in 1989, and\nby 1990 the AUTODIF Library included special classes for derivative computation and\nthe requisite overloaded functions for all C++ operators and\nall functions in the standard C++ math library.\nThe AUTODIF Library automatically computes the derivatives of the objective function\nwith the same accuracy as the objective function itself and thereby\nfrees the developer from the onerous task of writing\nand maintaining derivative code for statistical models.\nEqually important from the standpoint of model development,\nthe AUTODIF Library includes a \"gradient stack\", \na quasi-Newton function minimizer, a derivative checker, and\ncontainer classes for vectors and matrices. \nThe first application of the AUTODIF Library was published in 1992\n<ref>K. N. Holland, R. Brill, R. Chang, J. Sibert, and D. Fournier.\n''Physiological and behavioural thermogregulation in bigeye tuna (Thunnus obesus)''. Nature, 358:410--412, 1992.</ref>\n\nThe AUTODIF Library does not, however, completely liberate the developer from\nwriting all of the model constituents listed above. In 1993, Fournier further\nabstracted the writing of statistical models by creating ADMB, a special\n\"template\" language to simplify model specification by\ncreating the tools to\ntransform models written using the templates into the AUTODIF Library\napplications. ADMB produces code to manage the exchange of model\nparameters between the model and the function minimizer,\nautomatically computes the Hessian matrix and inverts it to provide\nan estimate the covariance of the estimated parameters. ADMB thus\ncompletes the liberation of the model developer from all of the tedious\noverhead of managing non-linear optimization, thereby freeing him or her to\nfocus on the more interesting aspects of the statistical model.\n\nBy the mid-1990s, ADMB had earned acceptance by researchers working on\nall aspects of resource management. Population models based on the\nADMB are used to monitor a range of both endangered\nspecies and commercially valuable fish populations including\nwhales, dolphins,\nsea lions, penguins, albatross, abalone, lobsters, tunas, marlins,\nsharks, rays, anchovy, and pollock. ADMB has also been\nused to reconstruct movements of many species of animals tracked with\nelectronic tags.\n\nIn 2002, Fournier teamed up with Hans Skaug to introduce random\neffects into ADMB. This\ndevelopment included automatic computation of second and third\nderivatives and the use of forward mode automatic differentiation followed by\ntwo sweeps of reverse model AD in certain cases.\n\n=== ADMB Project ===\n\nIn 2007, a group of ADMB users that included John Sibert, Mark\nMaunder and Anders Nielsen became concerned about ADMB's long-term \ndevelopment and maintenance. An agreement was reached with\nOtter Research to sell the copyright to ADMB for the purpose of\nmaking ADMB an open-source project and distributing it without\ncharge. The non-profit ADMB Foundation was created\nto coordinate development and promote use of ADMB.\nThe ADMB Foundation drafted a proposal to the Gordon and Betty Moore\nFoundation for the funds to purchase ADMB from Otter Research. \nThe Moore Foundation provided a grant to \nthe National Center of Ecological Analysis and Synthesis \nat the University of California at Santa Barbara \nin late 2007 so that the Regents of the University of California could\npurchase the rights to ADMB. \nThe purchase was completed in mid-2008, and the complete ADMB libraries were posted\non the ADMB Project website in December 2008. By May 2009, more\nthan 3000 downloads of the libraries had occurred. The\nsource code was made available in December 2009. In mid-2010,\nADMB was supported on all common operating systems (Windows,\nLinux, MacOS and Sun/SPARC), for all common C++ compilers\n(GCC, Visual Studio, Borland), and for both 32 and 64 bit\narchitectures.\n\nADMB Foundation efforts during the first two years of the ADMB \nProject have focused on\nautomating the building of ADMB for different platforms,\nstreamlining installation, and creation of\na user-friendly working environments. Planned technical\ndevelopments \ninclude parallelization of internal computations,\nimplementation of hybrid MCMC, and improvement of the large sparse matrix\nfor use in random effects models.\n\n== See also ==\n{{Portal|Free and open-source software}}\n\n* [[List of statistical packages]]\n* [[List of numerical analysis software]]\n* [[Comparison of numerical analysis software]]\n\n==References==\n{{Reflist|2}}\n\n==External links==\n* [http://admb-project.org/ The ADMB Project]\n* [http://admb-foundation.org/ The ADMB Foundation]\n* [http://www.otter-rsch.com/ Otter Research Ltd], the company which produced ADMB prior to the ADMB Foundation\n* [https://code.google.com/p/admb-project/ Google Code site for ADMB]\n\n{{Numerical analysis software}}\n{{Statistical software}}\n\n{{DEFAULTSORT:Admb}}\n[[Category:Array programming languages]]\n[[Category:Cross-platform free software]]\n[[Category:Free statistical software]]\n[[Category:Numerical analysis software for Linux]]\n[[Category:Numerical programming languages]]\n[[Category:Statistical programming languages]]"
    },
    {
      "title": "Astropy",
      "url": "https://en.wikipedia.org/wiki/Astropy",
      "text": "{{short description|Python language software}}\n{{Infobox software\n| name                   = Astropy\n| logo                   = [[File:Logo of the Astropy Project.png|The Astropy logo was designed by Kyle Barbary. The logo was updated in October 2012 by Thomas Robitaille to use an open source font (Source Sans Pro).]]\n| caption                = The Astropy logo was designed by Kyle Barbary. The logo was updated in October 2012 by Thomas Robitaille to use an open source font (Source Sans Pro).\n| latest release version = 3.2.1\n| latest release date    = {{Start date and age|2019|06|15|df=yes}}\n| latest preview version = 3.2rc2\n| latest preview date    = {{Start date and age|2019|05|30|df=yes}}\n| developer              = The Astropy Collaboration\n| programming language   = [[Python (programming language)|Python]], [[C (programming language)|C]]\n| operating system       = [[Cross-platform]]\n| genre                  = [[List of numerical analysis software|Technical computing]]\n| license                = [[BSD-new|BSD-new license]]\n| website                = {{URL|https://www.astropy.org/}}\n}}\n'''Astropy''' is a collection of software packages written in the [[Python (programming language)|Python programming language]] and designed for use in [[Portal:Astronomy|astronomy]].<ref name=\"astropy_A&A\">\n{{cite journal\n |author=Astropy Collaboration\n |coauthors=<!-- -->\n |year=2013\n |title=Astropy: A community Python package for astronomy\n |journal=[[Astronomy & Astrophysics]]\n |volume=558 |pages=A33\n |arxiv=1307.6212\n |bibcode=2013A&A...558A..33A\n |doi=10.1051/0004-6361/201322068\n}}</ref> The software is a single, [[Free software|free]], core package for astronomical utilities due to the increasingly widespread usage of Python by [[astronomer]]s, and to foster interoperability between various extant Python astronomy packages.<ref name=\".astronomy\">\n{{cite arXiv\n |last1=Simpson |first1=Robert A.\n |year=2013\n |title=Unproceedings of the Fourth .Astronomy Conference, Heidelberg, Germany, July 9–11 2012\n |eprint=1301.5193\n |class=astro-ph.IM\n|display-authors=etal}}</ref> Astropy is included in several large Python distributions; it is part of [[Package management system|package managers]] for [[Linux]] and [[macOS]],<ref name=\"python-astropy\">\n{{cite web\n |title=Package: python-astropy (0.2.4-3)\n |url=http://packages.debian.org/testing/python/python-astropy\n |publisher=[[Debian]]\n}}</ref><ref name=\"py-astropy\">\n{{cite web\n |title=py-astropy 0.2.5\n |url=https://trac.macports.org/browser/trunk/dports/python/py-astropy/Portfile\n |publisher=[[MacPorts]]\n}}</ref><ref name=\"astropy-py\">\n{{cite web\n |title=astropy-py33\n |url=http://pdb.finkproject.org/pdb/package.php/astropy-py33\n |publisher=[[Fink (software)|Fink]]\n}}</ref> the [[Anaconda (Python distribution)|Anaconda Python Distribution]], [[Enthought|Enthought Canopy]] and Ureka.<ref name=\"Ureka\">\n{{cite web\n|title=Ureka Sources\n|url=http://ssb.stsci.edu/ureka/source/\n|publisher=[[Gemini Observatory]]/[[Space Telescope Science Institute]]\n}}</ref>\n\n== Development ==\nAround the turn of the millennium the [[Space Telescope Science Institute]] (STScI) started development of Python-based utilities to extend or substitute existing astronomical data analysis tools on a modern, [[Object-oriented programming|object-oriented]] platform. Among the first projects were a replacement of the command language for the Image Reduction and Analysis Facility ([[IRAF]]) with a Python frontend,<ref>\n{{cite journal\n |last1=Greenfield |first1=P.\n |last2=White |first2=R. L.\n |year=2000\n |title=A New CL for IRAF Based On Python\n |url=http://www.adass.org/adass/proceedings/adass99/O3-03/\n |journal=[[ASP Conference Series]]\n |volume=216 |pages=59\n |bibcode=2000ASPC..216...59G\n |isbn=1-58381-047-1\n}}</ref>\nand the PyFITS interface to the [[Flexible Image Transport System]].<ref>\n{{cite journal\n |last1=Barrett |first1=P. E.\n |last2=Bridgman |first2=W. T.\n |year=2000\n |title=PyFITS, a Python FITS Module\n |url=http://www.adass.org/adass/proceedings/adass99/P1-55/\n |journal=[[ASP Conference Series]]\n |volume=216 |pages=67\n |bibcode=2000ASPC..216...67B\n |isbn=1-58381-047-1\n}}</ref>\nSince the existing ''Numeric'' module for handling vectors and arrays in Python turned out to be inadequate for large astronomical datasets, a new library better tuned for large array sizes was subsequently developed at STScI. Both libraries were merged into a new array package by [[Travis Oliphant]] in 2005–2006, creating [[NumPy]], now the de facto standard for numerical data handling in Python.<ref>{{cite web|title=History of SciPy |url=http://wiki.scipy.org/History_of_SciPy/ |publisher=scipy.org |deadurl=yes |archiveurl=https://web.archive.org/web/20131112154228/http://wiki.scipy.org/History_of_SciPy/ |archivedate=2013-11-12 |df= }}</ref> In the following years the existing software packages maintained by STScI as part of their stsci_python suite were ported to NumPy as well. This, together with the more extensive [[SciPy]] computing environment, provided a platform to develop customized scripts and applications for a variety of astronomical tasks.\n\nBy 2011, the use of Python in astronomy had reached significant levels. At the 2012 .Astronomy meeting, 42% of attendees preferred [[Python (programming language)|Python]] according to an informal survey.<ref name=\".astronomy\" /> Many astronomy-related Python packages have been developed over the years, albeit without cooperation or coordination, which led to duplication and difficult interoperability between packages. There was also no easy way install all the required packages needed in an astronomer’s toolkit. A number of smaller packages are sometimes no longer maintained or unavailable. The Astropy project started in 2011, motivated by these difficulties, and a desire to unite developers in astronomy to coordinate the development of a unified set of Python modules for astronomers, and reduce the confusion of available packages.<ref name=\"astropy_A&A\" />\n\nThe Space Telescope Science Institute, operators of the [[Hubble Space Telescope]], are merging the work on Astropy into stsci_python releases. PyFITS and PyWCS will be maintained solely within Astropy, with separate releases of these packages stopping, after the next release. PyFITS has been included as part of the Astropy project, and as a result, the next release of STScI_Python will depend on Astropy for the PyFITS library instead of using this standalone release.<ref>{{cite web |title=STScI_Python 2.14 Release Notes |url=http://www.stsci.edu/institute/software_hardware/pyraf/stsci_python/release-notes/releasenotes.2.14 |publisher=Space Telescope Science Institute}}</ref>\n\n== Use ==\n* The [[National Virtual Observatory]] Python integration includes support for the Astropy VOTable class<ref>\n{{cite journal\n |last1=Tody |first1=D.\n |last2=Fitzpatrick |first2=M. J.\n |last3=Graham  |first3=M.\n |last4=Young |first4=W.\n |year=2013\n |title=Scripting the Virtual Observatory in Python\n |url=http://www.usvao.org/documents/Papers/AASJan2013/Scripting-the-VO.pdf\n |journal=[[American Astronomical Society Meeting Abstracts]]\n |volume=221 |pages=#240.34\n |bibcode=2013AAS...22124034T\n}}</ref>\n* The [[Subaru Telescope]] Hyper Suprime-Cam, a 900-megapixel ultra-wide-field camera<ref>{{cite web | url=http://sumire.ipmu.jp/en/1648 | title=Subaru Telescope HSC Wide Field Corrector completed}}</ref>\n* A data mining toolkit for exploring large data cubes in radioastronomy from facilities like [[Atacama Large Millimeter Array|ALMA]] or [[Combined Array for Research in Millimeter-wave Astronomy|CARMA]].<ref>\n{{cite web\n | title=AStute\n | url=http://carma.astro.umd.edu/wiki/index.php/AStute\n}}</ref>\n* pcigale, the port to Python of [https://cigale.lam.fr/ CIGALE] (Code Investigating Galaxy Emission)<ref>\n{{cite arXiv\n |last1=Roehlly |first1=Y.\n |last2=Burgarella |first2=D.\n |last3=Buat |first3=V.\n |last4=Boquien |first4=M.\n |last5=Ciesla  |first5=L.\n |last6=Heinis |first6=S.\n |year=2013\n |title=pcigale: porting Code Investigating Galaxy Emission to Python\n |eprint=1309.6366\n |class=astro-ph.IM\n}}</ref>\n* Analyzing the optical afterglow of [[gamma-ray burst]]s<ref>\n{{cite journal\n |last1=Singer |first1=L. P.\n |year=2013\n |title=Discovery and redshift of an optical afterglow in 71 square degrees: iPTF13bxl and GRB 130702A\n |journal=[[The Astrophysical Journal Letters]]\n |volume=776 |issue=2 |pages=L34\n |arxiv=1307.5851\n |bibcode=2013ApJ...776L..34S\n |doi=10.1088/2041-8205/776/2/L34\n|display-authors=etal}}</ref>\n* The [[Goddard Space Flight Center#High Energy Astrophysics Science Archive Research Center|High Energy Astrophysics Science Archive Research Center]] (HEASARC) refers to Astropy as \"A single core package for Astronomy in Python\"\n* Project [https://projectpanoptes.org/ PANOPTES] \"makes extensive use of the Astropy package\"\n* Astropy has been accepted to the [http://asterisk.apod.com/viewtopic.php?f=35&t=31097 Astrophysics Source Code Library – Starship Asterisk*]<ref>\n{{cite journal\n |last1=Allen |first1=A.\n |year=2013\n |title=Using the Astrophysics Source Code Library\n |journal=[[American Astronomical Society Meeting Abstracts]]\n |volume=221 |pages=#240.01\n |bibcode=2013AAS...22124001A\n|display-authors=etal}}</ref>\n\n== Video sources ==\nThere are several videos recorded in seminars and conferences. These are intended to help beginners learn how Astropy works. The .Astronomy 4 meeting (9–11 July 2012) held a session on Astropy.<ref>{{cite web|title=.Astronomy 4 |url=http://dotastronomy.com/events/four/astropy-thomas-robitaille/ |accessdate=2012-07-11 |deadurl=yes |archiveurl=https://web.archive.org/web/20121209185606/http://dotastronomy.com/events/four/astropy-thomas-robitaille/ |archivedate=2012-12-09 }}</ref>\n\n== Core functionality ==\n{{prose|date=July 2017}}\nCore data structures and operations\n* Generalized container classes for representing gridded and tabular data as multidimensional arrays or tables<ref>{{cite web| title=ATPy | url=http://atpy.readthedocs.org/ | accessdate=2013-11-05}}</ref>\n* Unit and physical quantity conversions\n* Physical constants specific to astronomy\n* [[Celestial coordinate system|Celestial coordinate]] and time transformations\n* World coordinate system (WCS) support, implementing PyWCS, the Python wrapper to WCSLIB. WCSLIB is a C library which implements the WCS standard in the [[Flexible Image Transport System]] (FITS) standard.<ref>{{Cite journal | last1 = Greisen | first1 = E. W. | last2 = Calabretta | first2 = M. R. | doi = 10.1051/0004-6361:20021326 | title = Representations of world coordinates in FITS | journal = Astronomy and Astrophysics | volume = 395 | issue = 3 | pages = 1061 | year = 2002 | pmid =  | pmc = |arxiv = astro-ph/0207407 |bibcode = 2002A&A...395.1061G }}</ref><ref>{{cite web | url=http://www.atnf.csiro.au/people/mcalabre/WCS/wcslib/ | title=WCSLIB | author= Mark Calabretta | work=[[CSIRO]] Australia Telescope National Facility | accessdate=15 November 2013}}</ref>\nFile I/O\n* FITS files, implementing the former standalone PyFITS interface<ref>{{cite web|title=PyFITS|url=http://www.stsci.edu/institute/software_hardware/pyfits/|archive-url=https://wayback.archive-it.org/all/20150726152333/http://www.stsci.edu/institute/software_hardware/pyfits|dead-url=yes|archive-date=2015-07-26|publisher=Space Telescope Science Institute}}</ref>\n* [[Virtual Observatory]] (VO) tables\n* Common [[ASCII]] table formats, e.g. for online catalogues or data supplements of scientific publications\n* [[Hierarchical Data Format]] (HDF5) files\nComputational utilities\n* Framework for [[Cosmology|cosmological]] transformations and conversions\n* Toolset for [[Statistics|statistical]] analyses\n\n== Affiliated packages ==\nA major part of the Astropy project is the concept of \"affiliated packages”. An affiliated package is an astronomy-related Python package that is not part of the astropy core but has been suggested for inclusion as part of the project’s community. Such packages are intended to improve reuse, interoperability, and interface standards for Python astronomy and astrophysics packages.\nCurrent affiliated packages include:<ref>{{cite web | url= http://www.astropy.org/affiliated/index.html | title=About affiliated packages | work=astropy | year=2012 | accessdate=6 November 2013 | author=The Astropy collaboration}}</ref>\n* montage-wrapper\n* ginga\n* APLpy\n* astroML: tools for [[machine learning]] and [[data mining]] in astronomy\n* Astropysics: library of [[IDL (programming language)|IDL]] astronomy routines converted to Python.\n* astroplan: observation planning for astronomers\n\nA few additional affiliated packages are currently in development, including:\n* photutils: [[Photometry (astronomy)|photometry]] tools\n* astroquery: online [[database]] querying\n* specutils: [[Astronomical spectroscopy|spectroscopic]] analysis utilities\n* kcorrect: Python bindings to [[K correction|kcorrect]] code of Blanton et al. 2007\n* gammapy: A high level [[gamma-ray astronomy]] data analysis package\n\n== See also ==\n{{Portal|Free and open-source software}}\n* [[List of numerical analysis software]]\n\n== References ==\n{{Reflist}}\n\n== External links ==\n* {{Official website|https://www.astropy.org/}}\n* [https://github.com/astropy/astropy GitHub repository]\n* [http://conference.scipy.org/scipy2013/presentation_detail.php?id=212 Scipy2013 presentation video]\n* [http://adass2013.cfht.hawaii.edu/presenterdetails.php?id=221 ADASS Poster abstract]\n* [https://astropy4mpik.readthedocs.org/en/latest/index.html MPIK Astropy workshop]\n* [https://www.scipy.org/topical-software.html#astronomy Topical software – scipy.org]\n\n== Publications ==\nBooks and scientific publications citing Astropy\n*{{cite journal\n |last1=Tollerud |first1=E. J.\n |last2=Greenfield |first2=P. E.\n |last3=Robitaille |first3=T. P.\n |year= 2013\n |title=Astropy: A community Python package for astronomy\n |journal=[[ASP Conference Series]]\n |volume=475 |page=241\n |bibcode=2013ASPC..475..241T\n}}\n*{{cite arXiv\n |last1=Simpson |first1=Robert A.\n |year=2013\n |title=Unproceedings of the Fourth .Astronomy Conference, Heidelberg, Germany, July 9–11 2012\n |eprint=1301.5193\n |class=astro-ph.IM\n|display-authors=etal}}\n*{{cite journal\n |last=Allen |first=A.\n |year=2013\n |title=Bring out your codes! Bring out your codes! (Increasing Software Visibility and Re-use)\n |journal=[[ASP Conference Series]]\n |volume=475 |pages=383\n |arxiv=1212.1915\n |bibcode=2013ASPC..475..383A\n|display-authors=etal}}\n\n{{DEFAULTSORT:Astropy}}\n[[Category:Free astronomy software]]\n[[Category:Free software programmed in Python]]\n[[Category:Numerical analysis software for Linux]]\n[[Category:Numerical analysis software for MacOS]]\n[[Category:Numerical analysis software for Windows]]\n[[Category:Python scientific libraries]]\n[[Category:Software using the BSD license]]"
    },
    {
      "title": "Distributed R",
      "url": "https://en.wikipedia.org/wiki/Distributed_R",
      "text": "{{Orphan|date=February 2017}}\n\n{{Infobox software\n| name                   = Distributed R\n| logo                   = \n| caption                =\n| developer              = [[Hewlett-Packard|HP]]\n| status                 = Active\n| latest release version = v1.0.0\n| latest release date    = {{release date|2015|02|17}}\n| latest preview version = \n| latest preview date    = \n| operating system       = [[Linux]]\n| size                   = \n| programming language   = [[C++]], [[R (programming language)|R]]\n| genre                  = [[machine learning]] algorithms\n| license                = [[GNU General Public License]]\n| website                = {{URL|www.distributedr.org}}\n}}\n\n'''Distributed R''' is an open source, high-performance platform for the [[R (programming language)|R]] language. It splits tasks between multiple processing nodes to reduce execution time and analyze large data sets. Distributed R enhances R by adding distributed [[data structure]]s, parallelism primitives to run functions on distributed data, a task scheduler, and multiple data loaders.<ref>{{cite journal|last1=Venkataraman|first1=Shivaram|last2=Bodzsar|first2=Erik|last3=Roy|first3=Indrajit|last4=AuYoung|first4=Alvin|last5=Schreiber|first5=Robert S.|title=Presto: Distributed Machine Learning and Graph Processing with Sparse Matrices|journal=European Conference on Computer Systems (EuroSys)|date=2013|url=http://eurosys2013.tudos.org/wp-content/uploads/2013/paper/Venkataraman.pdf|deadurl=yes|archiveurl=https://web.archive.org/web/20150301102733/http://eurosys2013.tudos.org/wp-content/uploads/2013/paper/Venkataraman.pdf|archivedate=2015-03-01|df=}}</ref> It is mostly used to implement distributed versions of machine learning tasks. Distributed R is written in [[C++]] and [[R (programming language)|R]], and retains the familiar look and feel of R. {{as of|2015|February}}, [[Hewlett-Packard]] (HP) provides enterprise support for Distributed R with proprietary additions such as a fast data loader from the [[Vertica]] database.<ref>{{cite news|last1=Gagliordi|first1=Natalie|title=HP adds scale to open-source R in latest big data platform|url=http://www.zdnet.com/article/hp-adds-scale-to-open-source-r-in-latest-big-data-platform/|accessdate=17 February 2015|work=ZDNet}}</ref>\n\n==History==\nDistributed R was begun in 2011 by Indrajit Roy, Shivaram Venkataraman, Alvin AuYoung, and Robert S. Schreiber as a research project at HP Labs.<ref>{{cite journal|last1=Venkataraman|first1=Shivaram|last2=Roy|first2=Indrajit|last3=AuYoung|first3=Alvin|last4=Schreiber|first4=Robert S.|title=Using R for Iterative and Incremental Processing|journal=Workshop on Hot Topics in Cloud Computing (HotCloud)|date=2012}}</ref> It was open sourced in 2014 under the GPLv2 license and is available at [[GitHub]].\n\nIn February 2015, Distributed R reached its first stable version 1.0, along with enterprise support from HP.<ref>{{cite news|title=HP Delivers Predictive Analytics at Big Data Scale|url=http://www8.hp.com/us/en/hp-news/press-release.html?id=1912830&pageTitle=HP-Delivers-Predictive-Analytics-at-Big-Data-Scale|accessdate=17 February 2015|work=hp.com|date=17 February 2015}}</ref>\n\n==Components==\nDistributed R is a platform to implement and execute distributed applications in R. The goal is to extend R for distributed computing, while retaining the simplicity and look-and-feel of R. Distributed R consists of the following components:\n\n* ''Distributed data structures'': Distributed R extends R's common data structures such as array, data.frame, and list to store data across multiple nodes. The corresponding Distributed R data structures are darray, dframe, and dlist. Many of the common data structure operations in R, such as colSums, rowSums, nrow and others, are also available on distributed data structures.\n* ''Parallel loop'': Programmers can use the parallel loop, called foreach, to manipulate distributed data structures and execute tasks in parallel. Programmers only specify the data structure and function to express applications, while the runtime schedules tasks and, if required, moves around data.\n* ''Distributed algorithms'': Distributed versions of common machine learning and graph algorithms, such as clustering, classification, and regression.\n* ''Data loaders'': Users can leverage Distributed R constructs to implement parallel connectors that load data from different sources. Distributed R already provides implementations to load data from files and databases to distributed data structures.\n\n==Integration with databases==\nHP [[Vertica]] provides tight integration with their database and the open source Distributed R platform. HP Vertica 7.1 includes features that enable fast, parallel loading from the Vertica database to Distribute R. This parallel Vertica loader can be more than five times (5x) faster than using traditional ODBC based connectors. The Vertica database also supports deployment of machine learning models in the database. Distributed R users can call the distributed algorithms to create machine learning models, deploy them in the Vertica database, and use the model for in-database scoring and predictions. Architectural details of the Vertica database and Distributed R integration are described in the Sigmod 2015 paper.<ref>{{cite journal|last1=Prasad|first1=Shreya|last2=Fard|first2=Arash|last3=Gupta|first3=Vishrut|last4=Martinez|first4=Jorge|last5=LeFevre|first5=Jeff|last6=Xu|first6=Vincent|last7=Hsu|first7=Meichun|last8=Roy|first8=Indrajit|title=Enabling predictive analytics in Vertica: Fast data transfer, distributed model creation and in-database prediction|journal=ACM SIGMOD International Conference on Management of Data (SIGMOD)|date=2015}}</ref>\n\n==References==\n{{reflist}}\n\n==External links==\n* {{Official website|www.distributedr.org}}\n\n[[Category:R (programming language)| ]]\n[[Category:Software using the GPL license]]\n[[Category:Free statistical software]]\n[[Category:Data mining and machine learning software]]\n[[Category:Numerical analysis software for Linux]]\n[[Category:Cluster computing]]\n[[Category:Parallel computing]]"
    },
    {
      "title": "EICASLAB",
      "url": "https://en.wikipedia.org/wiki/EICASLAB",
      "text": "{{Notability|Products|date=June 2010}}\n{{primary sources|date=August 2014}}\n{{Infobox software\n| name = EICASLAB\n| developer = EICAS Automazione S.p.A.\n| operating_system = Windows/Linux\n| genre = [[List of numerical analysis software|Technical computing]]\n| license = [[Proprietary software|Proprietary]]\n| website = [http://www.eicaslab.com/ www.eicaslab.com]\n}}\n'''EICASLAB''' is a [[software suite]] providing a laboratory for [[automatic control]] design and time-series [[forecasting]] developed as final output of the European ACODUASIS Project IPS-2001-42068<ref>ACODUASIS IPS-2001-42068 : [http://ids.fzi.de/acoduasis/ ACODUASIS Project web-site]</ref><ref>CORDIS   Issue n. 44 – September 2003, ''Technology opportunities today'', page 16:  \"''EICASLAB: A family of CAE tools using automated algorithm generation to design control systems''\". Published by European Commission – Innovation, [ftp://ftp.cordis.europa.eu/pub/focus/docs/res44.pdf on line]</ref><ref>EVCA Barometer April 2006, page 5: \"''An easy to use tool for automated control systems''\", [http://www.evca.com/images/attachments/tmpl_27_art_41_att_952.pdf on line]</ref><ref>CORDIS - ICT results: Results that lead the way: \"''An easy-to-use tool for automated control systems''\", Published by European Commission, [http://cordis.europa.eu/ictresults/index.cfm/section/news/tpl/article/BrowsingType/Features/ID/81262 on line]</ref> funded by the European Community within the Innovation Programme. The Project - during its lifetime - aimed at delivering in the robotic field the scientific breakthrough of a new methodology for the automatic control design.<ref>Prof. Francesco Donati (Politecnico of Torino, Italy): ''\"The innovative methodology and the ACODUASIS Project\"'', ACODUASIS Workshop \"One Step further in Automatic Control Design\", Torino (Italy), 3 October 2005, [http://ids.fzi.de/acoduasis/workshop/aco_ws-prog.htm on line]</ref>\n\nTo facilitate such a knowledge transfer, EICASLAB was equipped with an “automated algorithm and code generation” software engine,<ref>Gabriella Caporaletti (EICAS Automazione, Italy): ''\"The ACODUASIS Project: A professional software tool supporting the control design in robotics\"'',  6th International Conference on Climbing and Walking Robots And the Support Technologies for Mobile Machines. CLAWAR 2003 September 17–19, 2003, Catania, Italy</ref> that allows to obtain a control algorithm algorithm even without a deep knowledge of the theory and the methodology that are otherwise normally required with traditional control design methodologies.\n\nEICASLAB has been and is actually adopted in other European Research Projects dealing with robotics  (ARFLEX IST-NMP2-016880<ref>ARFLEX Project IST-NMP2-016880 : [http://www.arflexproject.eu ARFLEX Project web-site]/</ref> and PISA Project NMP2-CT-2006-026697)<ref>PISA Project NMP2-CT-2006-026697 [http://www.pisa-ip.org/ PISA Project web-site]</ref> and automotive (HI-CEPS  Project TIP5-CT-2006-031373<ref>HI-CEPS Project TIP5-CT-2006-031373: [http://www.hi-ceps.eu HI-CEPS Project web-site]</ref> and ERSEC Project FP7 247955).<ref>ERSEC Project FP7 247955: [http://www.ersecproject.eu/ ERSEC Project web-site]:</ref> EICASLAB is used in European industries, research institutes and academia to design control systems and time series forecasting documented in the scientific and technical literature.<ref>Gabriella Caporaletti (EICAS Automazione, Italy), Rui Neves da Silva and Maria Marques (UNINOVA, Portugal): \"''Advanced Automated Algorithm Generation Software in the Control of Solar Plant''\" - MIC 2004 Twenty-Third IASTED International Conference on Modelling, Identification and Control, [http://www.actapress.com/PaperInfo.aspx?PaperID=16008&reason=500 abstract on line]</ref><ref>Kerscher, Zoellner and Dillman (University of Karlsruhe, Germany), Stella and Caporaletti (EICAS Automazione, Italy):\"''Model and Control of joints driven by fluidic muscles with the help of advanced automatic algorithm generation software''\"- CLAWAR 2005 8th International Conference on Climbing and Walking Robots and the Support Technologies for Mobile Machines</ref><ref>Kay Ch. Fuerstenberg (IBEO Automobile Sensor GmbH, Germany), Pierre Baraud (Peugeot Citroën Automobile, France), Gabriella Caporaletti (EICAS Automazione,Italy), Silvia Citelli (Fiat Research Center,Italy), Zafrir Eitan (TAMAM/IAI, Israel), Ulrich Lages (IBEO Automobile Sensor GmbH, Germany), Christophe Lavergne (Renault SA, France) ''Development of a Pre-crash sensorial system: The CHAMELEON Project'', [http://ibeo-as.de/english/downloads/publications/VDI_2001_Fuerstenberg_Wolfsburg.pdf  on line]</ref><ref>A. Bottero and D. Martinello (COMAU Robotics, Italy):''Industrial robot simulation models for control design and analysis purposes'', ACODUASIS Workshop \"One Step further in Automatic Control Design\", Torino (Italy), 3 October 2005, [http://ids.fzi.de/acoduasis/workshop/aco_ws-prog.htm on line]</ref><ref>F. Motto and A. Ramoino (EICAS Automazione, Italy), A. Bottero and D. Martinello (COMAU Robotics,Italy: ''Industrial robots control with EICASLAB approach: industrial prototyping and experimentation results'',  ACODUASIS Workshop \"One Step further in Automatic Control Design\", Torino (Italy), 3 October 2005, [http://ids.fzi.de/acoduasis/workshop/aco_ws-prog.htm on line]</ref><ref>J. Fottner (MIAS, Germany), T. Kerscher (University of Karlsruhe, Germany), G. di Gropello and A. Stella (EICAS Automazione, Italy): ''Modelling and Control of Automated Guided Vehicles (AGVs) for the transport of meals, laundry and waste in the healthcare domain'', ACODUASIS Workshop \"One Step further in Automatic Control Design\", Torino (Italy), 3 October 2005, [http://ids.fzi.de/acoduasis/workshop/aco_ws-prog.htm on line]</ref><ref>G. Caporaletti and A. Stella (EICAS Automazione, Italy), P. Pina (UNINOVA,Portugal), V. Abadie (CYBERNETIX, France):''\"Control of a hydraulic servoactuator using an automated algorithm generator\"'', ACODUASIS Workshop \"One Step further in Automatic Control Design\", Torino (Italy), 3 October 2005, [http://ids.fzi.de/acoduasis/workshop/aco_ws-prog.htm on line]</ref><ref>Y. Dodeman and N. Moisan (IPSIS, France), G. di Gropello (EICAS Automazione, Italy):''\"Synthesis of multivariable control of a thermic power plant\"'', ACODUASIS Workshop \"One Step further in Automatic Control Design\", Torino (Italy), 3 October 2005, [http://ids.fzi.de/acoduasis/workshop/aco_ws-prog.htm on line]</ref><ref>Prof. R. Bucher and K.Kaufmann – (SUPSI, Switzerland):\"''Rapid Control Prototyping with EICASLAB and Linux RTAI''\", ACODUASIS Workshop \"One Step further in Automatic Control Design\", Torino (Italy), 3 October 2005, [http://ids.fzi.de/acoduasis/workshop/aco_ws-prog.htm on line]</ref><ref>Prof. Silvano Balemi (University of Applied Sciences of Southern Switzerland, Lugano-Manno, Switzerland): \"''Rapid Controller Prototyping Platform for Precision Applications''\", Proceedings of the 6th euspen International Conference – Baden bei Wien - May 2006, [http://web.dti.supsi.ch/~balemi/ps/EUSPEN06_Balemi.pdf on line]</ref><ref>Paola Donati and Francesco Donati:” Modelling and Forecasting the Yield Curve under Model uncertainty, by Paola Donati and Francesco Donati”, Working Paper Series 917, [[European Central Bank]] (ECB), [http://www.ecb.int/pub/pdf/scpwps/ecbwp917.pdf on line]</ref><ref>Paola Donati:” Monetary Policy Effectiveness in Times of Crisis: Evidence from the Euro Area Money Market”, [[European Central Bank]] (ECB) workshop December 2009, [http://www.ecb.int/events/pdf/conferences/20091130_ecb_workshop/20091130_session6_donati.pdf?48195010a2fe3086bea2240acd5f9544 on line]</ref>\n\nEICASLAB includes tools for modelling plants, designing and testing [[Embedded system|embedded]] [[control systems]], assisting the phases of the design process of the control strategy, from system concept to generation of the control software code for the final target.\n\n==Software organisation==\nEICASLAB is a software suite composed by a main program,  called MASTER, able to assist and manage all the control design steps by means a set of tools, respectively:\n*the SIMBUILDER tool, devoted to program the simulation models of the plant and of the control algorithms;\n*the SIM tool, devoted to the simulation and the evaluation of performances of the control algorithms;\n*the POST tool, devoted to the analysis of results through post-processing of recorded simulation data;\n*the MPI/CPO tool, devoted to model parameter identification and control parameter optimization;\n*the RCP Manager tool, devoted to manage the Rapid Control Prototyping activities;\n*the SLOW MOTION tool, devoted to the offline repetition of experimental trials executed on field for advanced debugging and tuning purposes.\n\n==Features to support to control design phases ==\n\n===Support to system concept===\n\nEICASLAB includes the following features to support the system concept:\n* Design of multiprocessor control architectures\n* Design of multilevel hierarchical control algorithms\nHardware architectures including multi-processors and software architectures including multi-level hierarchical control are considered. The control software is subdivided into functions allocated by the designer to the different processors. Each control function has its own sampling frequency and a time window for its execution, which are scheduled by the designer by means of the EICASLAB [[Scheduling (computing)|scheduler]].\n\nData can be exchanged among the control functions allocated to the same processor and among the different processors belonging to the plant control system. The delay time in the data transmission is considered.\n\nThe final “application software” generated in [[C (programming language)|C]] is subdivided into files each one related to a specific processor.\n\n===Support to system simulation===\nEICASLAB includes specific working areas for developing, optimizing and testing algorithms and software  related to the  “plant controller”, including both the “[[automatic control]]” and the “trajectory generation” and the \"[[Disturbance (ecology)|disturbances]]\" acting on the plant. To perform such a task three different working areas are available as follows. \n*The plant area to be used to simulate the plant dynamic behaviour by means of the “plant fine model”,\n*The control area to be used to design the functions related to the automatic control and the trajectory generation,\n*The mission area to be used in order to plan the simulated trials. It is split in two sections, respectively, the plant mission  and the control mission. The first one generates the disturbance acting on the plant during the simulated trials and schedules any other event concerning the plant performance, such as plant parameters' variations. The second one generates the host command to be sent to the plant control during the simulated trials.\n\n===Support to control algorithm design===\nEICASLAB includes the following tools and features to support the control algorithm design:\n* AAG: Automatic Algorithm Generation\n* MPI: Model Parameter Identification\n* CPO: Control Parameter Optimisation\nThe Automatic Algorithm Generation tool, starting from the “plant simplified model” and from the \"control required performance\" generates the control algorithm. On the basis of the plant design data, the applied control design methodology allows design of controllers with guaranteed performance without requiring any tuning in field in spite of the unavoidable uncertainty which always exists between any mathematical model built on the basis of plant design data and the plant actual performance (for fundamentals on control in presence of uncertainty see <ref>Prof. F. Donati , Prof. D. Carlucci: \"''Control of norm of uncertain systems''\", IEEE Transactions on Automatic Control, vol.20-AC, 1975, pp.792- 795</ref><ref>Prof. F. Donati , Prof. M. Vallauri: \"''Guaranteed control of almost-linear plants''\", IEEE Transactions on Automatic Control, vol. 29- AC, 1984, pp. 34-41</ref>).\nThe designer can choose among three control basic schemes and for each one he has the option of selecting control algorithms at different level of complexity. \nIn synthesis, the automatically generated control is performed by the resultant of three actions:\n* the open loop action, which is given by the commands necessary to track the reference signals computed on the basis of the plant simplified model;\n* the plant disturbance compensation, which is computed on the basis of the disturbance predicted by the plant state observer;\n* the [[Feedback|closed loop]] action, which is computed as the action necessary to correct the plant state error with respect to the reference one.\nThe plant's [[state observer]] task may be extended to estimate and predict the disturbance acting on the plant. The plant disturbance prediction and compensation is an original control feature, which allows significant reduction of control error. \nModel Parameter Identification is a tool which allows the identification of the most appropriate values of the simplified model parameters from recorded experimental data or simulated trials performed by using the “plant fine model”. The parameter's \"true\" value does not exist: the model is an approximated description of the plant and then, the parameter's \"best\" value depends on the cost function adopted to evaluate the difference between model and plant. The identification method estimates the best values of the simplified model parameters from the point of view of the closed loop control design.\nControl Parameter Optimization is a tool which performs control parameter tuning in simulated environment. The optimization is performed numerically over a predefined simulated trial, that is for a given mission (host command sequence and disturbance acting on the plant and any other potential event related to the plant performance) and for a given functional cost associated to the plant control performance.\n\n===Support to code generation for the final target===\nThe EICASLAB Automatic Code Generation tool provides the [[ANSI C]] source code related to the control algorithm developed.\nThe final result of the designer work is the “application software” in [[ANSI C]], debugged and tested, ready to be compiled and linked in the plant control processors. The “application software” includes the software related to the “automatic control” and the “trajectory generation” functions. The simulated control functions are strictly the same one that the designer can transfer in field in the actual plant controller.\n\n===Support to control tuning===\nEICASLAB includes the following tools to support the control tuning:\n* Slow-Motion View\n* [[Rapid Prototyping]] (precisely called Rapid Control Prototyping, RCP)\n* [[Hardware-in-the-loop]]\n\nSlow Motion View is a tool to be used in the phase of setting up of the plant control, providing a variable by variable analysis of the control software performance during experimental trials performed by means of the actual plant.\n\nThe plant input and output and the host commands sent to the controller are recorded during experimental trials and then they can be processed by EICASLAB as follows. The recorded plant input and output variables are used in the Plant Area inside of the input and output variables obtained by the plant simulation. The recorded host commands are used in the Control Mission area inside of the host command generated by the Control Mission function.\n\nThen, when a simulated trial is performed, the control function receives the recorded outputs of the actual plant and the related recorded host commands inside of the simulated ones. Because the control function running in the EICASLAB is strictly the same one, which is running in the actual plant controller, then, the commands resulting from the simulated control function and sent from the simulated control to the simulated plant should be strictly the same of the recorded plant inputs (unless there are numerical errors depending on the differences between the processor where the EICASLAB is running and the one used in the actual plant controller, but the experience has shown that the effects of such differences are negligible).\nThen, the recorded experimental trial performed by the actual plant controller is completely repeated in the EICASLAB, with the difference that now the process can be performed in slow-motion and, if useful, step by step by using a debugger program.\n\nAutomatic Code Generation tool can be used to insert the controller code in a [[Linux]] [[Real-time operating system]] (RTOS) (in two available versions, namely, Linux [[RTAI]] and Linux RT with [[kernel preemption]]), in order to test the control algorithm in the PC environment instead of the final target hardware, performing Rapid Control Prototyping (RCP) tests.  EICASLAB RCP includes a real-time scheduler based on [[Thread (computer science)|multithreading]] programming techniques and able to run on a [[multi-core processor]].\n\nAutomatic Code Generation tool can be used to insert the controller code in the final Hardware Target.\nOnce performed such operation, '''Hardware In the Loop''' (HIL) tests may be performed, consisting in piloting – instead of the actual plant - the plant simulated in EICASLAB and running on your PC, suitable configured and connected through the necessary hardware interfaces with the final Hardware Target.\n\n==References==\n{{Reflist}}\n\n[[Category:Simulation programming languages]]\n[[Category:Visual programming languages]]\n[[Category:Numerical analysis software for Linux]]\n[[Category:Data analysis software]]"
    },
    {
      "title": "Euler (software)",
      "url": "https://en.wikipedia.org/wiki/Euler_%28software%29",
      "text": "{{Infobox software|\n| screenshot             = [[File:Knot.svg|200px|A Trefoil knot, drawn by Euler]] \n| caption                = A [[trefoil knot]], drawn by Euler\n| developer              = René Grothmann\n| released               = {{Start date and age|1988|df=yes}}\n| latest release version = 2019-06-27\n| latest release date    = {{Start date and age|2019|06|27|df=yes}}\n| language               = [[English language|English]]\n| programming language   = [[C (programming language)|C]]/[[C++]]\n| operating system       = [[Microsoft Windows|Windows]], [[Linux]]\n| genre                  = [[Numerical analysis]]\n| license                = [[General Public License]]\n| website                = {{URL|http://www.euler-math-toolbox.de/}}\n}}\n\n'''Euler''' (now '''Euler Mathematical Toolbox''' or '''EuMathT''') is a [[free software|free]] and [[Open-source software|open-source]] [[numerical software]] package. It contains a [[matrix (mathematics)|matrix]] language, a graphical [[Notebook interface|notebook style interface]], and a plot window.  Euler is designed for higher level math such as [[calculus]], [[Optimization (mathematics)|optimization]], and [[statistics]].\n\nThe software can handle [[real number|real]], [[complex number|complex]] and [[interval arithmetic|interval]] numbers, [[Euclidean vector|vector]]s and [[matrix (mathematics)|matrices]], it can produce [[Cartesian plane|2D]]/[[Three-dimensional space|3D]] [[Plot (graphics)|plots]], and uses [[Maxima (software)|Maxima]] for symbolic operations.\nThe software is compilable with [[Microsoft Windows|Windows]]. The [[Unix]] and [[Linux]] versions do not contain a [[computer algebra system|computer algebra subsystem]].\n\n==History==\nEuler Math Toolbox originated in 1988 as a program for [[Atari ST]]. At that time, the title of the program was simply Euler, but it turned out to be too unspecific for the Internet. The main aim of the program was to create a tool for testing numerical algorithms, to visualize results, and to demonstrate mathematical content in the classroom. Euler Math Toolbox uses a matrix language similar to [[MATLAB]], a system that had been under development since the 1970s. Then and now the main developer of Euler is René Grothmann, a mathematician at the [[Catholic University of Eichstätt-Ingolstadt]], Germany. In 2007, Euler was married with the Maxima computer algebra system. Symbolic expressions and other functions were added to communicate with Maxima, and to reach a good degree of integration into the numerical Euler core.\n\n==Overview==\nThe Euler core is a numerical system written in [[C (programming language)|C]]/[[C++]]. It handles real, complex, and interval values, and matrices of these types. Other available data types are sparse, compressed matrices, a long accumulator for an exact [[Dot product|scalar product]], and [[String (computer science)|strings]]. Strings are used for expressions, file names etc. Based on this core, additional functions are implemented in the Euler matrix language, which is an interpreted programming language in the style of an advanced [[BASIC]] dialect. Euler contains libraries for statistics, exact numerical computations with interval inclusions, differential equations and stiff equations, astronomical functions, geometry, and more.\n\nThe clean interface consists of a text window, and a graphics window. The text window contains fully editable notebooks, and the graphics window the graphics output. Graphics can be added to the notebook window too, or can be exported in various formats ([[Portable Network Graphics|PNG]], [[SVG]], [[Windows Metafile|WMF]], Clipboard). Graphic types include line, bar or point plots in 2D and 3D, including [[Anaglyph 3D|anaglyph]] plots of 3D surfaces and other 3D plots. Euler has an API to use the open raytracer [[POV-Ray]].\n\nEuler handles symbolic computations via Maxima, which is loaded as a separate process, communicating with Euler through pipes. The two programs can exchange variables and values. Indeed, Maxima is used in various Euler functions (e.g. [[Newton's method]]) to assist in the computation of derivatives, Taylor expansions and integrals. Moreover, Maxima can be called at definition time of an Euler function.\n\n[[LaTeX]] can be used from within Euler to display formulas. For export of formulas to [[HTML]], either the generated LaTeX images or [[MathJax]] can be used. A special export option exports all graphics to SVG.\n\nEuler also includes the [[Tiny C Compiler]], which allows subroutines in C to be compiled, and included via a Windows DLL.\n\nEuler has a lot of similarity to MATLAB and its free clones ([[GNU Octave]]), but it is not compatible.\n\n==See also==\n{{Portal|Free and open-source software}}\n*[[Comparison of numerical analysis software]]\n\n==External links==\n*{{Official website|http://www.euler-math-toolbox.de/}}\n*[https://sourceforge.net/p/eumat/discussion/ Official forum]\n*[http://euler.sourceforge.net/ Old GTK+ version of Euler for Unix/Linux]\n\n{{Numerical analysis software}}\n\n[[Category:C software]]\n[[Category:Data analysis software]]\n[[Category:Free mathematics software]]\n[[Category:Numerical analysis software for Linux]]\n[[Category:Numerical programming languages]]\n[[Category:Plotting software]]\n[[Category:Science software for Windows]]\n[[Category:Science software that uses GTK]]"
    },
    {
      "title": "FreeMat",
      "url": "https://en.wikipedia.org/wiki/FreeMat",
      "text": "{{Infobox software\n| name                   = FreeMat\n| logo                   = [[Image:FreeMat.png|48px|FreeMat icon]]\n| screenshot             = FreeMat screenshot Linux.png\n| caption                = Screenshot of FreeMat in [[Fedora (operating system)|Fedora]]\n| developer              = Samit Basu\n| latest release version = 4.2\n| latest release date    = {{Start date and age|2013|06|30}}\n| programming language   = [[Assembly language]], [[C (programming language)|C]], [[C++]], [[Fortran]], [[Qt (software)|Qt]]\n| operating system       = [[Cross-platform]] ([[Linux]], [[macOS]], [[Microsoft Windows|Windows]])\n| genre                  = [[List of numerical analysis software|Technical computing]]\n| license                = [[GNU General Public License|GPL]], older: [[MIT License|MIT]]\n| website                = {{URL|freemat.sourceforge.net}}\n}}\n'''FreeMat''' is a [[free software|free]] [[open-source software|open-source]] [[numerical analysis|numerical computing]] environment and [[programming language]],<ref>\n{{cite web\n|url=http://freemat.sourceforge.net/\n|title=FreeMat - Home\n|publisher=freemat.sourceforge.net\n|accessdate=2009-01-25\n|last=\n|first=\n}}\n</ref> similar to [[MATLAB]] and [[GNU Octave]].<ref>\n{{cite web\n|url=http://berkeleyscience.com/freemat.htm\n|title=Berkeley Science Books - Freemat and Octave\n|publisher=berkeleyscience.com\n|accessdate=2009-01-25\n|last=\n|first=\n}}\n</ref> In addition to supporting many [[MATLAB]] functions and some [[IDL (programming language)|IDL]] functionality, it features a codeless interface to external [[C (programming language)|C]], [[C++]], and [[Fortran]] code, further [[Parallel distributed processing|parallel distributed algorithm development]] (via [[Message Passing Interface|MPI]]), and has plotting and [[3D computer graphics|3D]] visualization capabilities.<ref>It also features an intuitive GUI that is similar to that used in Matlab.\n{{cite web\n|url=http://www.linuxlinks.com/article/20080808050417963/FreeMat.html\n|title=FreeMat - LinuxLinks News\n|publisher=www.linuxlinks.com\n|accessdate=2009-01-25\n|last=\n|first=\n}}\n</ref> Community support takes place in [[Internet forum#Moderators|moderated]] [[Google Groups]].\n\n== See also ==\n{{Portal|Free and open-source software}}\n* [[Comparison of numerical analysis software]]\n\n== Notes ==\n{{Reflist}}\n\n{{Numerical analysis software}}\n\n{{DEFAULTSORT:Freemat}}\n[[Category:Array programming languages]]\n[[Category:Free mathematics software]]\n[[Category:Free software primarily written in assembly language]]\n[[Category:Free software programmed in C]]\n[[Category:Free software programmed in C++]]\n[[Category:Free software programmed in Fortran]]\n[[Category:Numerical analysis software for Linux]]\n[[Category:Numerical analysis software for MacOS]]\n[[Category:Numerical analysis software for Windows]]\n[[Category:Numerical programming languages]]\n[[Category:Science software that uses Qt]]\n[[Category:Unix programming tools]]"
    },
    {
      "title": "Genius (mathematics software)",
      "url": "https://en.wikipedia.org/wiki/Genius_%28mathematics_software%29",
      "text": "{{Infobox software\n| name = Genius\n| logo =\n| screenshot =\n| caption =\n| developer = Jiri Lebl\n| latest_release_version = v1.0.24\n| latest_release_date = {{Start date and age|2018|05|15}}\n| operating_system = [[Cross-platform]] ([[Linux]], [[macOS]])\n| programming language   = C\n| genre = [[List of numerical analysis software|Technical computing]]\n| license = [[GNU General Public License|GPL]]\n| website = {{URL|https://www.jirka.org/genius.html}}\n}}\n'''Genius'''  (also known as the Genius Math Tool) is a [[free software|free]] [[Open-source software|open-source]] [[numerical analysis|numerical computing]] environment and [[programming language]],<ref>\n{{cite web\n|url=https://www.jirka.org/genius.html\n|title=Genius\n|publisher=www.jirka.org\n|accessdate=2009-03-06\n|last=\n|first=\n}}\n</ref> similar in some aspects to [[MATLAB]], [[GNU Octave]], [[Mathematica]] and [[Maple (software)|Maple]].  Genius is aimed at mathematical experimentation rather than computationally intensive tasks.  It is also very useful as just a calculator.  The programming language is called GEL and aims to have a mathematically friendly syntax.  The software comes with a [[command-line interface]] and a [[GUI]], which uses the [[GTK+]] libraries.  The graphical version supports both 2D and 3D plotting.  The graphical version includes a set of tutorials originally aimed at in class demonstrations.\n\n== History ==\n\nGenius was the original calculator for the [[GNOME]] project started in 1997, but was split into a separate project soon after the 0.13 release of GNOME in 1998.  Because of this ancestry, it was also known as Genius Calculator or GNOME Genius.  There was an attempt to merge Genius and the [[Dr. Geo]] [[interactive geometry software]], but this merge never materialized.  Version 1.0 was released in 2007 almost 10 years after the initial release.\n\n== Example GEL source code ==\n\nHere is a sample definition of a function calculating the factorial recursively\n<pre>\nfunction f(x) = (\n  if x <= 1 then\n    1\n  else\n    (f(x-1)*x)\n)\n</pre>\nGEL contains primitives for writing the product iteratively and hence we can get the following iterative\nversion\n<pre>\nfunction f(x) = prod k=1 to x do k\n</pre>\n\n== See also ==\n{{Portal|Free and open-source software}}\n* [[Comparison of numerical analysis software]]\n\n== Notes ==\n{{Reflist}}\n\n{{Numerical analysis software}}\n\n[[Category:Array programming languages]]\n[[Category:Numerical programming languages]]\n[[Category:Free mathematics software]]\n[[Category:Free software programmed in C]]\n[[Category:Free educational software]]\n[[Category:Unix programming tools]]\n[[Category:Numerical analysis software for MacOS]]\n[[Category:Science software that uses GTK]]\n[[Category:Numerical analysis software for Linux]]"
    },
    {
      "title": "GNU Octave",
      "url": "https://en.wikipedia.org/wiki/GNU_Octave",
      "text": "{{Infobox software\n| name                 = GNU Octave\n| logo                 = [[File:Gnu-octave-logo.svg|100px]]\n| screenshot           = GNUOctave430.png\n| caption              = GNU Octave 4.3.0+ running on [[Linux]]\n| developer            = John W. Eaton and many others<ref>{{cite web|title=contributors.in|author=Rik|url=http://hg.savannah.gnu.org/hgweb/octave/file/tip/doc/interpreter/contributors.in|accessdate=14 June 2015|date=10 June 2015}}</ref>\n| released             = {{Start date and age|1988}}\n| latest release version = 5.1\n| latest release date = {{Start date and age|2019|02|23}}<ref>{{cite web|title=GNU Octave 4.4.1 Released|date=Aug 9, 2018|url=https://www.gnu.org/software/octave/news/release/2018/08/09/octave-4.4.1-released.html}}</ref>\n| programming language = [[C (programming language)|C]], [[C++]], [[Fortran]]<ref name=\"octave_building\">{{cite web|title=Building - Octave|url=https://wiki.octave.org/Building|website=wiki.octave.org|publisher=GNU|accessdate=1 May 2018|language=en}}</ref>\n| platform             = <!--List them all-->\n| language count       = 19\n| language footnote    = {{Citation needed|date=January 2016}}\n| genre                = [[List of numerical analysis software|Scientific computing]]\n| license              = [[GNU General Public License|GNU GPLv3]]\n| website              = {{URL|https://gnu.org/software/octave/}}\n}}\n'''GNU Octave''' is software featuring a [[High-level programming language|high-level]] [[programming language]], primarily intended for [[numerical analysis|numerical computations]]. Octave helps in solving linear and nonlinear problems numerically, and for performing other numerical experiments using a language that is mostly compatible with [[MATLAB]]. It may also be used as a [[Batch processing|batch-oriented]] language.\nSince it is part of the [[GNU Project]], it is [[free software]] under the terms of the [[GNU General Public License]].\n\nOctave is one of the major [[free software|free]] alternatives to MATLAB, others being [[Scilab]] and [[FreeMat]].<ref name=\"Trappenberg2010\">{{cite book|last=Trappenberg|first=Thomas|title=Fundamentals of Computational Neuroscience|year=2010|publisher=Oxford University Press|isbn=978-0-19-956841-3|page=361}}</ref><ref name=\"MuhammadZalizniak2011\">{{cite book|last1=Muhammad|first1=A|last2=Zalizniak|first2=V|title=Practical Scientific Computing|year=2011|publisher=[[Woodhead Publishing]]|isbn=978-0-85709-226-7|page=3}}</ref><ref name=\"MegreyMoksness2008\">{{cite book|last1=Megrey|first1=Bernard A.|last2=Moksness|first2=Erlend|title=Computers in Fisheries Research|year=2008|publisher=Springer Science & Business Media|isbn=978-1-4020-8636-6|page=345}}</ref><ref name=\"Kapuno2008\">{{cite book|last=Kapuno|first=Raul Raymond|title=Programming for Chemical Engineers Using C, C++, and MATLAB|year=2008|publisher=Jones & Bartlett Publishers|isbn=978-1-934015-09-4|page=365}}</ref> Scilab, however, puts less emphasis on (bidirectional) syntactic compatibility with MATLAB than Octave does.<ref name=\"Trappenberg2010\"/><ref name=\"Herman2013\">{{cite book|last=Herman|first=Russell L.|title=A Course in Mathematical Methods for Physicists|year=2013|publisher=CRC Press|isbn=978-1-4665-8467-9|page=42}}</ref><ref name=\"WouwerSaucez2014\">{{cite book|last1=Wouwer|first1=Alain Vande|last2=Saucez|first2=Philippe|last3=Vilas|first3=Carlos|title=Simulation of ODE/PDE Models with MATLAB, Octave and Scilab: Scientific and Engineering Applications|year=2014|publisher=Springer|isbn=978-3-319-06790-2|pages=114–115}}</ref>\n\n==History==\nThe project was conceived around 1988.<ref name=\"Octave_about\">{{cite web|title=About GNU Octave|url=https://www.gnu.org/software/octave/about.html|website=www.gnu.org|publisher=GNU|accessdate=1 May 2018}}</ref> At first it was intended to be a companion to a chemical reactor design course. Real development was started by John W. Eaton in 1992. The first alpha release dates back to January 4, 1993 and on February 17, 1994 version 1.0 was released. Version 4.0.0 was released on May 29, 2015.\n\nThe program is named after [[Octave Levenspiel]], a former professor of the principal author. Levenspiel was known for his ability to perform quick [[back-of-the-envelope calculation]]s.<ref name=\"about\">{{cite web\n| last = Eaton\n| first = John W\n| title = About Octave\n| url = https://www.gnu.org/software/octave/about.html\n| accessdate = 2009-06-28 }}</ref>\n\n== Development History ==\n{| class=\"wikitable\"\n|-\n! Time !! Action\n|-\n| 1988/1989 || 1st discussions (Book and Software)\n|-\n| February 1992 || Begin of Development \n|-\n| January 1993 || News in Web (Version 0.60)\n|-\n| February 1994 || 1st Publication (Version 1.0.0 to 1.1.1)<ref>https://www.gnu.org/software/octave/NEWS-1.html</ref>\n|-\n| December 1996 || 2nd Publication (Version 2.0.x) with Windows Port ([[Cygwin]]) <ref>https://www.gnu.org/software/octave/NEWS-2.html</ref>\n|-\n| March 1998 || Version 2.1 \n|-\n| November 2004 || Version 2.9 (DEV Version of 3.0) <ref>https://www.gnu.org/software/octave/news/2012/12/31/news-archive.html</ref>\n|-\n| December 2007 || Publication of Version 3.0 (Milestone)<ref>https://www.gnu.org/software/octave/NEWS-3.html</ref>\n|-\n| June 2009 || Publication of Version 3.2 (Milestone) <ref>https://www.gnu.org/software/octave/NEWS-3.2.html</ref>\n|-\n| 8. February 2011 || Version 3.4.0 (Milestone)<ref>https://www.gnu.org/software/octave/NEWS-3.4.html</ref>\n|-\n| 22. February 2012 || Publication of Octave 3.6.1 (Milestone)<ref>https://www.gnu.org/software/octave/NEWS-3.6.html</ref><ref>https://www.gnu.org/software/octave/news/release/2013/02/21/octave-3.6.4-released.html</ref>\n|-\n| 31. December 2013 || Publication of Octave 3.8.0 (experimentell GUI) <ref>https://www.gnu.org/software/octave/NEWS-3.8.html</ref><ref>https://www.gnu.org/software/octave/news/release/2013/12/31/octave-3.8.0-released.html</ref><ref>https://www.gnu.org/software/octave/news/release/2014/03/04/octave-3.8.1-released.html</ref>\n|-\n| 29. May 2015 || Version 4.0.0 (stable GUI und new Syntax for [[object oriented programming |OOP]]) <ref>https://www.gnu.org/software/octave/NEWS-4.0.html</ref><ref>https://www.gnu.org/software/octave/news/release/2015/05/29/octave-4.0.0-released.html</ref><ref>https://www.gnu.org/software/octave/news/release/2016/03/23/octave-4.0.1-released.html</ref><ref>https://www.gnu.org/software/octave/news/release/2016/07/02/octave-4.0.3-released.html</ref>\n|-\n| 14. November 2016 || Version 4.2.0 (gnuplot 4.4+)<ref>https://www.gnu.org/software/octave/news/2016/11/14/octave-4.2.0-released.html | text=Release Notes Version 4.2.0}}</ref><ref>https://www.gnu.org/software/octave/NEWS-4.2.html</ref><ref>https://www.gnu.org/software/octave/news/release/2017/02/24/octave-4.2.1-released.html</ref><ref>https://www.gnu.org/software/octave/news/release/2018/03/13/octave-4.2.2-released.html</ref>\n|-\n| 30. April 2018 || Version 4.4.0 (new Goal for GUI QT Toolkit, FLTK deprecating in future) <ref>https://www.gnu.org/software/octave/NEWS-4.4.html</ref><ref>https://www.gnu.org/software/octave/news/release/2018/04/30/octave-4.4.0-released.html</ref><ref>https://www.gnu.org/software/octave/news/release/2018/08/09/octave-4.4.1-released.html</ref>\n|-\n| 1. March 2019 || Publication of Octave 5.1.0 (QT5 preferred) <ref>https://www.gnu.org/software/octave/NEWS-5.1.html</ref>\n|}\n\n==Developments==\nIn addition to use on desktops for personal scientific computing, Octave is used in academia and industry. For example, Octave was used on a massive [[Parallel computing|parallel]] computer at [[Pittsburgh Supercomputing Center]] to find vulnerabilities related to guessing social security numbers.<ref>{{cite web\n|url=http://www.hpcwire.com/industry/government/Social-Security-Number-Vulnerability-Findings-Relied-on-Supercomputing-50292227.html\n|title=Social Security Number Vulnerability Findings Relied on Supercomputing\n|date=8 July 2009\n|archive-url=https://web.archive.org/web/20120229220547/http://www.hpcwire.com/hpcwire/2009-07-08/social_security_number_vulnerability_findings_relied_on_supercomputing.html\n|archive-date=29 February 2012\n}}</ref>\n\nDramatic acceleration with [[OpenCL]] or [[CUDA]] is also possible with use of GPUs.<ref>https://devblogs.nvidia.com/parallelforall/drop-in-acceleration-gnu-octave/</ref>\n\n==Technical details==\n* Octave is written in [[C++]] using the [[C++ standard library]].\n* Octave uses an [[Interpreter (computing)|interpreter]] to execute the Octave scripting language.\n* Octave is extensible using dynamically loadable modules.\n* Octave interpreter has an [[OpenGL]]-based graphics engine to create plots, graphs and charts and to save or print them. Alternatively, [[gnuplot]] can be used for the same purpose.\n* Octave includes a [[Graphical User Interface]] (GUI) in addition to the traditional [[Command Line Interface]] (CLI); see [[#User interfaces]] for details.\n\n==Octave, the language==\nThe Octave language is an interpreted programming language. It is a [[structured programming]] language (similar to [[C (programming language)|C]]) and supports many common [[C standard library]] functions, and also certain [[POSIX|UNIX]] system calls and functions.<ref>{{cite web\n| url        = http://www.network-theory.co.uk/docs/octave3/octave_269.html\n| title      = GNU Octave - Controlling subprocesses\n| accessdate = 2009-01-28\n| date       = 14 November 2008\n}}</ref> However, it does not support passing arguments by reference.<ref>{{cite web\n| url        = http://www.delorie.com/gnu/docs/octave/octave_105.html\n| title      = GNU Octave\n| accessdate = 2009-01-28\n}}</ref>\n\nOctave programs consist of a list of function calls or a [[Script (computer programming)|script]]. The syntax is [[Array programming|matrix]]-based and provides various functions for matrix operations. It supports various [[data structure]]s and allows [[object-oriented programming]].<!--Candidate for expansion--><ref>{{cite web\n| url        = https://www.gnu.org/software/octave/NEWS-3.2.html\n| title      = Summary of important user-visible changes for version 3.2\n| accessdate = 2012-01-05\n}}</ref>\n\nIts syntax is very similar to MATLAB, and careful programming of a script will allow it to run on both Octave and MATLAB.<ref>{{cite web\n| url        = http://www.octave.org/wiki/index.php?title=FAQ#Porting_programs_from_Matlab_to_Octave\n| title      = FAQ: MATLAB compatibility\n| accessdate = 2009-04-04\n}}</ref>\n\nBecause Octave is made available under the [[GNU General Public License]], it may be freely changed, copied and used.<ref name=\"about\" /> The program runs on [[Microsoft Windows]] and most [[Unix]] and [[Unix-like]] [[operating system]]s, including [[macOS]].<ref>{{cite web\n| url        = http://www.octave.org/wiki/index.php?title=FAQ#On_what_platforms_does_Octave_run.3F\n| title      = FAQ: Getting Octave\n| accessdate = 2009-04-04\n}}</ref><ref>https://octave.org/doc/interpreter/</ref>\n\n==Notable features==\n\n===Command and variable name completion===\nTyping a TAB character on the command line causes Octave to attempt to complete variable, function, and file names (similar to [[Bash (Unix shell)|Bash]]'s [[tab completion]]). Octave uses the text before the cursor as the initial portion of the name to complete.<ref>{{cite web|url=https://www.gnu.org/software/octave/doc/interpreter/Commands-For-Completion.html#Commands-For-Completion|title=Letting Readline Type For You|work=GNU Octave Reference Manual|last=Eaton|first=John W.}}</ref>\n\n===Command history===\nWhen running interactively, Octave saves the commands typed in an internal buffer so that they can be recalled and edited.\n\n===Data structures===\nOctave includes a limited amount of support for organizing data in structures. In this example, we see a structure \"x\" with elements \"a\", \"b\", and \"c\", (an integer, an array, and a string, respectively):\n<source lang=\"octave\">\noctave:1> x.a = 1; x.b = [1, 2; 3, 4]; x.c = \"string\";\noctave:2> x.a\nans =  1\noctave:3> x.b\nans =\n\n   1   2\n   3   4\n\noctave:4> x.c\nans = string\noctave:5> x\nx =\n{\n  a =  1\n  b =\n\n     1   2\n     3   4\n\n  c = string\n}\n</source>\n\n===Short-circuit boolean operators===\nOctave's '<code>&&</code>' and '<code>||</code>' logical [[Operator (programming)|operators]] are evaluated in a [[Short-circuit evaluation|short-circuit]] fashion (like the corresponding operators in the [[C (programming language)|C]] language), in contrast to the element-by-element operators '<code>&</code>' and '<code>|</code>'.\n\n===Increment and decrement operators===\n{{Main|Increment and decrement operators}}\nOctave includes the C-like [[increment and decrement operators]] '<code>++</code>' and '<code>--</code>' in both their prefix and postfix forms.\nOctave also does [[augmented assignment]], e.g.  '<code>x += 5</code>'.\n\n===Unwind-protect===\nOctave supports a limited form of [[exception handling]] modelled after the [http://www.lispworks.com/documentation/HyperSpec/Body/s_unwind.htm '<code>unwind_protect</code>'] of [[Lisp (programming language)|Lisp]]. The general form of an unwind_protect block looks like this:\n<source lang=\"octave\">\nunwind_protect\n   body\nunwind_protect_cleanup\n   cleanup\nend_unwind_protect\n</source>\n\nAs a general rule, GNU Octave recognizes as termination of a given '<code>''block''</code>' either the keyword '<code>end</code>' (which is compatible with the MATLAB language) or a more specific keyword '<code>end_''block''</code>'. As a consequence, an '<code>unwind_protect</code>' block can be terminated either with the keyword '<code>end_unwind_protect</code>' as in the example, or with the more portable keyword '<code>end</code>'.\n\nThe ''cleanup'' part of the block is always executed. In case an exception is raised by the ''body'' part, ''cleanup'' is executed immediately before propagating the exception outside the block '<code>unwind_protect</code>'.\n\nGNU Octave also supports another form of exception handling (compatible with the MATLAB language):\n<source lang=\"matlab\">\ntry\n   body\ncatch\n   exception_handling\nend\n</source>\n\nThis latter form differs from an '<code>unwind_protect</code>' block in two ways. First, ''exception_handling'' is only executed when an exception is raised by ''body''. Second, after the execution of ''exception_handling'' the exception is not propagated outside the block (unless a '<code>rethrow( lasterror )</code>' statement is explicitly inserted within the ''exception_handling'' code).\n\n===Variable-length argument lists===\nOctave has a mechanism for handling functions that take an unspecified number of arguments without explicit upper limit. To specify a list of zero or more arguments, use the special argument <code>varargin</code> as the last (or only) argument in the list.\n\n<source lang=\"octave\">\nfunction s = plus (varargin)\n   if (nargin==0)\n      s = 0;\n   else\n      s = varargin{1} + plus (varargin{2:nargin});\n   end\nend\n</source>\n\n===Variable-length return lists===\nA function can be set up to return any number of values by using the special return value <code>varargout</code>. For example:\n\n<source lang=\"octave\">\nfunction varargout = multiassign (data)\n   for k=1:nargout\n      varargout{k} = data(:,k);\n   end\nend\n</source>\n\n===C++ integration===\nIt is also possible to execute Octave code directly in a C++ program. For example, here is a code snippet for calling <code>rand([10,1])</code>:\n<source lang=\"cpp\">\n#include <octave/oct.h>\n...\nColumnVector NumRands(2);\nNumRands(0) = 10;\nNumRands(1) = 1;\noctave_value_list f_arg, f_ret;\nf_arg(0) = octave_value(NumRands);\nf_ret = feval(\"rand\", f_arg, 1);\nMatrix unis(f_ret(0).matrix_value());\n</source>\n\nC and C++ code can be integrated into GNU Octave by creating oct files, or using the MATLAB compatible [[MEX file]]s.\n\n=={{anchor|MATLAB}} MATLAB compatibility==\nOctave has been built with MATLAB compatibility in mind, and shares many features with MATLAB:\n\n# Matrices as fundamental data type.\n# Built-in support for complex numbers.\n# Powerful built-in math functions and extensive function libraries.\n# Extensibility in the form of user-defined functions.\n\nOctave treats incompatibility with MATLAB as a [[Bug (software)|bug]]; therefore, it could be considered a [[software clone]], which does not infringe [[software copyright]] as per ''[[Lotus v. Borland]]'' court case.\n\nMATLAB scripts from the [[MathWorks]]' FileExchange repository in principle are compatible with Octave. However, while they are often provided and uploaded by users under an Octave [[License compatibility|compatible]] and proper [[open-source license|open source]] [[BSD license]], the fileexchange's [[EULA|Terms of use]] prohibit any usage beside MathWorks' [[proprietary software|proprietary]] MATLAB.<ref>[http://wiki.octave.org/FAQ#Why_can.27t_I_use_code_from_File_Exchange_in_Octave.3F_It.27s_released_under_a_BSD_license.21 Why can't I use code from File Exchange in Octave? It's released under a BSD license!] on octave.org</ref><ref>[http://www.mathworks.com/matlabcentral/termsofuse.html#content terms of use] on mathworks.com ''\"Content that you submit must not directly compete with products offered by MathWorks. Content submitted to File Exchange may only be used with MathWorks products.\"''</ref><ref>[https://www.mathworks.com/matlabcentral/FX_transition_faq.html File Exchange Licensing Transition FAQ] on mathworks.com</ref>\n\n===Syntax compatibility===\nThere are a few purposeful, albeit minor, [http://octave.org/wiki/index.php?title=FAQ#Porting_programs_from_Matlab_to_Octave syntax additions]:\n\n# [[Comment (computer programming)|Comment]] lines can be prefixed with the # character as well as the % character;\n# Various [[C (programming language)|C-based]] operators [[Increment operator|++]], [[Decrement operator|--]], [[Augmented assignment|+=]], *=, /= are supported;\n# Elements can be referenced without creating a new variable by cascaded indexing, e.g. [1:10](3);\n# [[String (computer science)|String]]s can be defined with the double-quote \" character as well as the single-quote ' character;\n# When the variable type is [[Single-precision floating-point format|single]] (a single-precision floating-point number), Octave calculates the \"[[mean]]\" in the single-domain (MATLAB in [[Double-precision floating-point format|double-domain]]) which is faster but gives less accurate results;\n# Blocks can also be terminated with more specific [[Control structure]] keywords, i.e., endif, endfor, endwhile, etc.;\n# Functions can be defined within scripts and at the Octave prompt;\n# Presence of a do-until loop (similar to do-while in C).\n\n===Function compatibility===\nMany, but not all, of the numerous MATLAB functions are available in GNU Octave, some of them accessible through packages in [https://octave.sourceforge.io Octave Forge]. The functions available as part of either core Octave or Forge packages are listed [https://octave.sourceforge.io/list_functions.php?q=&sort=alphabetic online].\n\nA list of unavailable functions is included in the Octave function  [http://hg.savannah.gnu.org/hgweb/octave/file/d63878346099/scripts/help/__unimplemented__.m#l530 __unimplemented.m__]. Unimplemented functions are also listed under many Octave Forge packages in the [https://wiki.octave.org/Category:Octave_Forge Octave Wiki].\n\nWhen an unimplemented function is called the following error message is shown:\n<source lang=\"octave\">\n  octave:1> quad2d\n  warning: quad2d is not implemented. Consider using dblquad.\n\n  Please read <http://www.octave.org/missing.html> to learn how you can\n  contribute missing functionality.\n  warning: called from\n      __unimplemented__ at line 523 column 5\n  error: 'quad2d' undefined near line 1 column 1\n</source>\n\n==User interfaces==\nOctave comes with an official [[graphical user interface]] (GUI) and a [[integrated development environment]] (IDE) based on [[Qt (software)|Qt]]. It has been available since Octave 3.8,<ref>{{cite web|title=Summary of important user-visible changes for version 3.8|url=https://www.gnu.org/software/octave/NEWS-3.8.html}}</ref> and has become the default interface (over the [[command line interface]]) with the release of Octave 4.0.<ref>{{cite web|title=Summary of important user-visible changes for version 4.0|url=https://www.gnu.org/software/octave/NEWS-4.0.html}}</ref> \nIt was well-received by EDN contributor, who said \"[Octave] now has a very workable GUI.\"<ref>[http://www.edn.com/electronics-blogs/the-practicing-instrumentation-engineer/4428091/GNU-Octave-hits-a-high-note GNU Octave hits a high note, Steve Hageman - February 07, 2014]</ref>\n\nSeveral 3rd-party graphical front-ends have also been developed, like [[Toolbox (software)|ToolboX]] for coding education.\n\n== GUI applications ==\nWith Octave code, the user can create GUI applications [https://www.gnu.org/software/octave/doc/interpreter/GUI-Development.html]. Here are some examples.\n\nButton, edit control, checkbox<source lang=\"octave\">\n% create figure and panel on it\nf = figure;\n% create a button (default style)\nb1 = uicontrol (f, \"string\", \"A Button\", \"position\",[10 10 150 40]);\n% create an edit control\ne1 = uicontrol (f, \"style\", \"edit\", \"string\", \"editable text\", \"position\",[10 60 300 40]);\n% create a checkbox\nc1 = uicontrol (f, \"style\", \"checkbox\", \"string\", \"a checkbox\", \"position\",[10 120 150 40]);\n</source>Textbox<source lang=\"octave\">\nprompt = {\"Width\", \"Height\", \"Depth\"};\ndefaults = {\"1.10\", \"2.20\", \"3.30\"};\nrowscols = [1,10; 2,20; 3,30];\ndims = inputdlg (prompt, \"Enter Box Dimensions\", rowscols, defaults);\n</source>Listbox with message boxes.<source lang=\"octave\">\nmy_options = {\"An item\", \"another\", \"yet another\"};\n[sel, ok] = listdlg (\"ListString\", my_options, \"SelectionMode\", \"Multiple\");\nif (ok == 1)\n  msgbox (\"You selected:\");\n  for i = 1:numel (sel)\n    msgbox (sprintf (\"\\t%s\", my_options{sel(i)}));\n  endfor\nelse\n  msgbox (\"You cancelled.\");\nendif\n</source>Radiobuttons<source lang=\"octave\">\n% create figure and panel on it\nf = figure;\n% create a button group\ngp = uibuttongroup (f, \"Position\", [ 0 0.5 1 1])\n% create a buttons in the group\nb1 = uicontrol (gp, \"style\", \"radiobutton\", \"string\", \"Choice 1\", \"Position\", [ 10 150 100 50 ]);\nb2 = uicontrol (gp, \"style\", \"radiobutton\", \"string\", \"Choice 2\", \"Position\", [ 10 50 100 30 ]);\n% create a button not in the group\nb3 = uicontrol (f, \"style\", \"radiobutton\",\"string\", \"Not in the group\",\"Position\", [ 10 50 100 50 ]);\n</source>\n\n== Packages ==\nOctave also has packages available for free. Those packages are located at Octave-Forge [https://octave.sourceforge.io/packages.php]. Available packages are:\n* '''bim''' - Package for solving Diffusion Advection Reaction (DAR) Partial Differential Equations\n* '''bsltl''' - The BSLTL package is a free collection of OCTAVE/MATLAB routines for working with the biospeckle laser technique\n* '''cgi''' - Common Gateway Interface for Octave\n* '''communications''' - Digital Communications, Error Correcting Codes (Channel Code), Source Code functions, Modulation and Galois Fields\n* '''control''' - Computer-Aided Control System Design (CACSD) Tools for GNU Octave, based on the proven SLICOT Library\n* '''data-smoothing''' - Algorithms for smoothing noisy data\n* '''database''' - Interface to SQL databases, currently only postgresql using libpq\n* '''dataframe''' - Data manipulation toolbox similar to R data\n* '''dicom''' - Digital communications in medicine (DICOM) file io\n* '''divand''' - divand performs an n-dimensional variational analysis (interpolation) of arbitrarily located observations\n* '''doctest''' - The Octave-Forge Doctest package finds specially-formatted blocks of example code within documentation files\n* '''econometrics''' - Econometrics functions including MLE and GMM based techniques\n* '''fem-fenics''' - pkg for the resolution of partial differential equations based on fenics\n* '''financial''' - Monte Carlo simulation, options pricing routines,  financial manipulation, plotting functions and additional date manipulation tools\n* '''fits''' - The Octave-FITS package provides functions for reading, and writing FITS (Flexible Image Transport System) files\n* '''fpl''' - Collection of routines to export data produced by Finite Elements or Finite Volume Simulations in formats used by some visualization programs\n* '''fuzzy-logic toolkit''' - A mostly MATLAB-compatible fuzzy logic toolkit for Octave\n* '''ga''' - Genetic optimization code\n* '''general''' - General tools for Octave\n* '''generate_html''' - This package provides functions for generating HTML pages that contain the help texts for a set of functions\n* '''geometry''' - Library for geometric computing extending MatGeom functions\n* '''gsl''' - Octave bindings to the GNU Scientific Library\n* '''image''' - The Octave-forge Image package provides functions for processing images\n* '''image-acquisition''' - The Octave-forge Image Acquisition package provides functions to capture images from connected devices\n* '''instrument-control''' - Low level I/O functions for serial, i2c, parallel, tcp, gpib, vxi11, udp and usbtmc interfaces\n* '''interval''' - The interval package for real-valued interval arithmetic allows one to evaluate functions over subsets of their domain\n* '''io''' - Input/Output in external formats e.g. Excel\n* '''level-set''' - Routines for calculating the time-evolution of the level-set equation and extracting geometric information from the level-set function\n* '''linear-algebra''' - Additional linear algebra code, including general SVD and matrix functions\n* '''lssa''' - A package implementing tools to compute spectral decompositions of irregularly-spaced time series\n* '''ltfat''' - The Large Time/Frequency Analysis Toolbox (LTFAT) is a MATLAB/Octave toolbox for working with time-frequency analysis,  wavelets and signal processing\n* '''mapping''' - Simple mapping and GIS .shp and raster file functions\n* '''mataveid''' - System identification package for both MATLAB and GNU Octave\n* '''matavecontrol''' - Control toolbox for both MATLAB and GNU Octave\n* '''miscellaneous''' - Miscellaneous tools that would fit nowhere else\n* '''mpi''' - Octave bindings for basic Message Passing Interface (MPI) functions for parallel computing\n* '''msh''' - Create and manage triangular and tetrahedral meshes for Finite Element or Finite Volume PDE solvers\n* '''mvn''' - Multivariate normal distribution clustering and utility functions\n* '''nan''' - A statistics and machine learning toolbox for data with and w/o missing values\n* '''ncarray''' - Access a single or a collection of NetCDF files as a multi-dimensional array\n* '''netcdf''' - A MATLAB compatible NetCDF interface for Octave\n* '''nurbs''' - Collection of routines for the creation, and manipulation of Non-Uniform Rational B-Splines (NURBS), based on the NURBS toolbox by Mark Spink\n* '''ocs''' - Package for solving DC and transient electrical circuit equations\n* '''octclip''' - This package allows users to do boolean operations with polygons using the Greiner-Hormann algorithm\n* '''octproj''' - This package allows users to call functions of PROJ\n* '''optics''' - Functions covering various aspects of optics\n* '''optim''' - Non-linear optimization toolkit\n* '''optiminterp''' - An optimal interpolation toolbox for octave\n* '''parallel''' - Parallel execution package\n* '''quaternion''' - Quaternion package for GNU Octave, includes a quaternion class with overloaded operators\n* '''queueing''' - The queueing package provides functions for queueing networks and Markov chains analysis\n* '''secs1d''' - A Drift-Diffusion simulator for 1d semiconductor devices\n* '''secs2d''' - A Drift-Diffusion simulator for 2d semiconductor devices\n* '''secs3d''' - A Drift-Diffusion simulator for 3d semiconductor devices\n* '''signal''' - Signal processing tools, including filtering, windowing and display functions\n* '''sockets''' - Socket functions for networking from within octave\n* '''sparsersb''' - Interface to the librsb package implementing the RSB sparse matrix format for fast shared-memory sparse matrix computations\n* '''splines''' - Additional spline functions\n* '''statistics''' - Additional statistics functions for Octave\n* '''stk''' - The STK is a (not so) Small Toolbox for Kriging\n* '''strings''' - Additional functions for manipulation and analysis of strings\n* '''struct''' - Additional structure manipulation functions\n* '''symbolic''' - The Octave-Forge Symbolic package adds symbolic calculation features to GNU Octave\n* '''tisean''' - Port of TISEAN 3\n* '''tsa''' - Stochastic concepts and maximum entropy methods for time series analysis\n* '''vibes''' - The VIBes API allows one to easily display results (boxes, pavings)  from interval methods\n* '''video''' - A wrapper for ffmpeg's libavformat and libavcodec, implementing addframe, avifile, aviinfo and aviread\n* '''vrml''' - 3D graphics using VRML\n* '''windows''' - Provides COM interface and additional functionality on Windows\n* '''zeromq''' - ZeroMQ bindings for GNU Octave\n\n==See also==\n{{Portal|Mathematics|Computer programming|Free and open-source software}}\n*[[List of numerical analysis software]]\n*[[Comparison of numerical analysis software]]\n*[[List of statistical packages]]\n*[[List of numerical libraries]]\n\n==References==\n{{Reflist|30em}}\n\n==Further reading==\n*{{Citation|last=Hansen|first=Jesper Schmidt|title=GNU Octave. Beginner's Guide|date=June 2011|url=http://www.packtpub.com/gnu-octave-beginners-guide/book|publisher=[[Packt Publishing]]|isbn=978-1-849-51332-6|mode=cs1}}\n\n==External links==\n{{Commons category|GNU Octave}}\n{{Wikibooks|Octave Programming Tutorial}}\n\n* {{Official website}}\n\n\n{{GNU}}\n{{Numerical analysis software}}\n{{Statistical software}}\n{{Image processing software}}\n{{FOSS}}\n\n{{DEFAULTSORT:Gnu Octave}}\n[[Category:Array programming languages]]\n[[Category:Articles with example MATLAB/Octave code]]\n[[Category:Cross-platform free software]]\n[[Category:Data analysis software]]\n[[Category:Data mining and machine learning software]]\n[[Category:Free educational software]]\n[[Category:Free mathematics software]]\n[[Category:Free software programmed in C++]]\n[[Category:GNU Project software|Octave]]\n[[Category:High-priority free software projects]]\n[[Category:Numerical analysis software for Linux]]\n[[Category:Numerical analysis software for MacOS]]\n[[Category:Numerical analysis software for Windows]]\n[[Category:Numerical programming languages]]\n[[Category:Science software that uses Qt]]\n[[Category:Software that uses Qt]]"
    },
    {
      "title": "NumPy",
      "url": "https://en.wikipedia.org/wiki/NumPy",
      "text": "{{short description|Numerical programming library for the Python programming language}}\n{{Infobox software\n| title                  = \n| name                   = NumPy\n| logo                   = NumPy logo.svg\n| screenshot             = <!-- [[File: ]] -->\n| caption                = NumPy logo\n| collapsible            = \n| author                 = [[Travis Oliphant]]\n| developer              = Community project\n| released               = As Numeric, {{Start date|1995}}; as NumPy, {{Start date|2006}}\n| discontinued           = \n| latest release version = 1.16.4\n| latest release date    = {{Start date and age|2019|5|28|df=yes}}<ref>{{cite web|url=https://github.com/numpy/numpy/releases|title=Releases - numpy/numpy|via=[[GitHub]]|accessdate=28 May 2019}}</ref>\n| latest preview version = <!-- 1.14.0rc1 -->\n| latest preview date    = <!-- {{Start date and age|2017|12|13|df=yes}} -->\n| programming language   = [[Python (programming language)|Python]], [[C (programming language)|C]]\n| operating system       = [[Cross-platform]]\n| platform               = \n| size                   = \n| language               = \n| genre                  = [[Numerical analysis]]\n| license                = [[BSD licenses|BSD]]\n}}\n'''NumPy''' (pronounced {{IPAc-en|ˈ|n|ʌ|m|p|aɪ}} ({{respell|NUM|py}}) or sometimes {{IPAc-en|ˈ|n|ʌ|m|p|i}}<ref>{{cite web|url=http://www.physics.nyu.edu/pine/pymanual/html/apdx3/apdx3_resources.html|title=Python resources|first=David|last=Pine|publisher=Rutgers University|year=2014|accessdate=2017-04-07}}</ref><ref>{{cite web|url=https://www.reddit.com/r/Python/comments/2709pq/how_do_you_say_numpy/|title=How do you say numpy?|publisher=Reddit|year=2015|accessdate=2017-04-07}}</ref> ({{respell|NUM|pee}})) is a library for the [[Python (programming language)|Python programming language]], adding support for large, multi-dimensional [[Array data structure|arrays]] and [[matrix (math)|matrices]], along with a large collection of [[High-level programming language|high-level]] [[mathematics|mathematical]] [[function (mathematics)|functions]] to operate on these arrays. The ancestor of NumPy, Numeric, was originally created by [[Jim Hugunin]] with contributions from several other developers. In 2005, [[Travis Oliphant]] created NumPy by incorporating features of the competing Numarray into Numeric, with extensive modifications. NumPy is [[open-source software]] and has many contributors.\n\n== History ==\nThe Python programming language was not initially designed for numerical computing, but attracted the attention of the scientific and engineering community early on, so that a special interest group called matrix-sig was founded in 1995 with the aim of defining an array computing package. Among its members was Python designer and maintainer [[Guido van Rossum]], who implemented extensions to [[Python syntax and semantics|Python's syntax]] (in particular the indexing syntax) to make array computing easier.<ref name=\"millman\"/>\n\nAn implementation of a matrix package was completed by Jim Fulton, then generalized by [[Jim Hugunin]] to become ''Numeric'',<ref name=\"millman\">{{cite journal \n  |first1=K. Jarrod\n  |last1=Millman \n  |first2=Michael\n  |last2=Aivazis\n  |title=Python for Scientists and Engineers\n  |journal=Computing in Science and Engineering\n  |volume=13\n  |number=2\n  |pages=9–12\n  |year=2011\n  |url=http://www.computer.org/csdl/mags/cs/2011/02/mcs2011020009.html\n}}</ref> also variously called Numerical Python extensions or NumPy.<ref name=\"cise2\">{{cite journal |author=Travis Oliphant |title=Python for Scientific Computing |journal=Computing in Science and Engineering |year=2007 |url=http://www.vision.ime.usp.br/~thsant/pool/oliphant-python_scientific.pdf}}</ref><ref name=\"numerical\">{{cite web |author1=David Ascher |author2=Paul F. Dubois |author3=Konrad Hinsen |author4=Jim Hugunin |author5=Travis Oliphant |title=Numerical Python |url=http://www.cs.mcgill.ca/~hv/articles/Numerical/numpy.pdf |year=1999}}</ref>\nHugunin, a graduate student at [[Massachusetts Institute of Technology]] (MIT),<ref name=\"numerical\"/>{{rp|10}} joined the [[Corporation for National Research Initiatives]] (CNRI) to work on [[Jython|JPython]] in 1997<ref name=\"millman\"/> leaving Paul Dubois of [[Lawrence Livermore National Laboratory]] (LLNL) to take over as maintainer.<ref name=\"numerical\"/>{{rp|10}} Other early contributors include David Ascher, Konrad Hinsen and [[Travis Oliphant]].<ref name=\"numerical\"/>{{rp|10}}\n\nA new package called ''Numarray'' was written as a more flexible replacement for Numeric.<ref name=\"cise\"/><!--for sure not \"cise2\"? --> Like Numeric, it is now deprecated.<ref>{{cite web| title = Numarray Homepage | url = http://www.stsci.edu/resources/software_hardware/numarray | accessdate = 2006-06-24}}</ref><ref name=\"NumPyBook\">{{cite book\n  | title = Guide to NumPy\n  | author = Travis E. Oliphant\n  | date = 7 December 2006\n  | url = https://archive.org/details/NumPyBook\n  | access-date = 2 February 2017\n}}</ref> Numarray had faster operations for large arrays, but was slower than Numeric on small ones,<ref>{{cite web| title = <nowiki>[Numpy-discussion]</nowiki> Status of Numeric\n  | author = Travis Oliphant and other SciPy developers\n  | url = https://mail.scipy.org/pipermail/numpy-discussion/2004-January/002645.html\n  | access-date = 2 February 2017\n}}</ref> so for a time both packages were used for different use cases. The last version of Numeric v24.2 was released on 11 November 2005 and numarray v1.5.2 was released on 24 August 2006.<ref>{{cite web| title = NumPy Sourceforge Files | url = http://sourceforge.net/project/showfiles.php?group_id=1369 | accessdate = 2008-03-24}}</ref>\n\nThere was a desire to get Numeric into the Python standard library, but Guido van Rossum decided that the code was not maintainable in its state then.{{when|date=October 2013}}<ref>{{cite web|url=https://scipy.github.io/old-wiki/pages/History_of_SciPy.html|title=History_of_SciPy - SciPy wiki dump|website=scipy.github.io}}</ref>\n\nIn early 2005, NumPy developer Travis Oliphant wanted to unify the community around a single array package and ported Numarray's features to Numeric, releasing the result as NumPy 1.0 in 2006.<ref name=\"cise\"/><!--for sure not \"cise2\"? --> This new project was part of [[SciPy]]. To avoid installing the large SciPy package just to get an array object, this new package was separated and called NumPy. Support for Python 3 was added in 2011 with NumPy version 1.5.0.<ref>{{cite web| title = NumPy 1.5.0 Release Notes | url = http://sourceforge.net/projects/numpy/files//NumPy/1.5.0/NOTES.txt/view | accessdate = 2011-04-29 }}</ref>\n\nIn 2011, [[PyPy]] started development on an implementation of the NumPy API for PyPy.<ref>{{cite web| title=PyPy Status Blog: NumPy funding and status update | url = http://morepypy.blogspot.com/2011/10/numpy-funding-and-status-update.html | accessdate = 2011-12-22 }}</ref> It is not yet fully compatible with NumPy.<ref>{{cite web| title=NumPyPy Status | url = http://buildbot.pypy.org/numpy-status/latest.html | accessdate = 2013-10-14 }}</ref>\n\n== Traits ==\nNumPy targets the [[CPython]] reference [[Programming language implementation|implementation]] of Python, which is a non-optimizing [[bytecode]] interpreter. Mathematical algorithms written for this version of Python often run much slower than [[Compiler|compiled]] equivalents. NumPy addresses the slowness problem partly by providing multidimensional arrays and functions and operators that operate efficiently on arrays, requiring rewriting some code, mostly inner loops using NumPy.\n\nUsing NumPy in Python gives functionality comparable to [[MATLAB]] since they are both interpreted,<ref>{{cite web\n  | title = NumPy for Matlab users\n  | author = The SciPy Community\n  | url = https://docs.scipy.org/doc/numpy-dev/user/numpy-for-matlab-users.html\n  | access-date = 2 February 2017\n}}</ref> and they both allow the user to write fast programs as long as most operations work on arrays or matrices instead of [[scalar (computing)|scalars]]. In comparison, MATLAB boasts a large number of additional toolboxes, notably [[Simulink]], whereas NumPy is intrinsically integrated with Python, a more modern and complete programming language. Moreover, complementary Python packages are available; [[SciPy]] is a library that adds more MATLAB-like functionality and [[Matplotlib]] is a plotting package that provides MATLAB-like plotting functionality. Internally, both MATLAB and NumPy rely on [[Basic Linear Algebra Subprograms|BLAS]] and [[LAPACK]] for efficient linear algebra computations.\n\nPython [[Language binding|bindings]] of the widely used [[computer vision]] library [[OpenCV]] utilize NumPy arrays to store and operate on data.\nSince images with multiple channels are simply represented as three-dimensional arrays, indexing, [[Array slicing#1991: Python|slicing]] or [[Mask (computing)#Image masks|masking]] with other arrays are very efficient ways to access specific pixels of an image.\nThe NumPy array as universal data structure in OpenCV for images, extracted [[Interest point detection|feature points]], [[Kernel (image processing)|filter kernels]] and many more vastly simplifies the programming workflow and [[Debugger|debugging]].\n\n=== The ndarray data structure ===\nThe core functionality of NumPy is its \"ndarray\", for ''n''-dimensional array, data structure. These arrays are [[Stride of an array|strided]] views on memory.<ref name=\"cise\">{{cite journal |title=The NumPy array: a structure for efficient numerical computation |first=Stéfan |last=van der Walt |first2=S. Chris |last2=Colbert |first3=Gaël |last3=Varoquaux |year=2011 |journal=Computing in Science and Engineering |publisher=IEEE |arxiv=1102.1523|bibcode=2011arXiv1102.1523V }}</ref> In contrast to Python's built-in list data structure (which, despite the name, is a [[dynamic array]]), these arrays are homogeneously typed: all elements of a single array must be of the same type.\n\nSuch arrays can also be views into memory buffers allocated by [[C Programming Language|C]]/[[C++]], [[Cython]], and [[Fortran]] extensions to the CPython interpreter without the need to copy data around, giving a degree of compatibility with existing numerical libraries. This functionality is exploited by the [[SciPy]] package, which wraps a number of such libraries (notably [[BLAS]] and [[LAPACK]]). NumPy has built-in support for [[memory-mapped file|memory-mapped]] ndarrays.<ref name=\"cise\"/>\n\n===Limitations===\nInserting or appending entries to an array is not as trivially possible as it is with Python's lists.\nThe <tt>np.pad(...)</tt> routine to extend arrays actually creates new arrays of the desired shape and padding values, copies the given array into the new one and returns it.\nNumPy's <tt>np.concatenate([a1,a2])</tt> operation does not actually link the two arrays but returns a new one, filled with the entries from both given arrays in sequence.\nReshaping the dimensionality of an array with <tt>np.reshape(...)</tt> is only possible as long as the number of elements in the array does not change.\nThese circumstances originate from the fact that NumPy's arrays must be views on contiguous memory buffers. A replacement package called Blaze attempts to overcome this limitation.<ref>{{cite web |title=Blaze Ecosystem Docs |website=Read the Docs |url=https://blaze.readthedocs.io/ |accessdate=17 July 2016}}</ref>\n\nAlgorithms that are not expressible as a vectorized operation will typically run slowly because they must be implemented in \"pure Python\", while vectorization may increase memory complexity of some operations from constant to linear, because temporary arrays must be created that are as large as the inputs. Runtime compilation of numerical code has been implemented by several groups to avoid these problems; open source solutions that interoperate with NumPy include <code>scipy.weave</code>, numexpr<ref>{{cite web |title=numexpr |url=https://github.com/pydata/numexpr |author=Francesc Alted |accessdate=8 March 2014}}</ref> and [[Numba]].<ref>{{cite web |title=Numba |url=http://numba.pydata.org/ |accessdate=8 March 2014}}</ref> [[Cython]] and [[Pythran]] are static-compiling alternatives to these.\n\n== Examples ==\n;Array creation\n\n<source lang=\"numpy\">\n>>> import numpy as np\n>>> x = np.array([1, 2, 3])\n>>> x\narray([1, 2, 3])\n>>> y = np.arange(10)  # like Python's range, but returns an array\n>>> y\narray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n</source>\n\n;Basic operations\n<source lang=\"numpy\">\n>>> a = np.array([1, 2, 3, 6])\n>>> b = np.linspace(0, 2, 4)  # create an array with four equally spaced points starting with 0 and ending with 2.\n>>> c = a - b\n>>> c\narray([ 1.        ,  1.33333333,  1.66666667,  4.        ])\n>>> a**2\narray([ 1,  4,  9, 36])\n</source>\n\n;Universal functions\n<source lang=\"numpy\">\n>>> a = np.linspace(-np.pi, np.pi, 100) \n>>> b = np.sin(a)\n>>> c = np.cos(a)\n</source>\n\n;Linear algebra\n<source lang=\"numpy\">\n>>> from numpy.random import rand\n>>> from numpy.linalg import solve, inv\n>>> a = np.array([[1, 2, 3], [3, 4, 6.7], [5, 9.0, 5]])\n>>> a.transpose()\narray([[ 1. ,  3. ,  5. ],\n       [ 2. ,  4. ,  9. ],\n       [ 3. ,  6.7,  5. ]])\n>>> inv(a)\narray([[-2.27683616,  0.96045198,  0.07909605],\n       [ 1.04519774, -0.56497175,  0.1299435 ],\n       [ 0.39548023,  0.05649718, -0.11299435]])\n>>> b =  np.array([3, 2, 1])\n>>> solve(a, b)  # solve the equation ax = b\narray([-4.83050847,  2.13559322,  1.18644068])\n>>> c = rand(3, 3) * 20  # create a 3x3 random matrix of values within [0,1] scaled by 20\n>>> c\narray([[  3.98732789,   2.47702609,   4.71167924],\n       [  9.24410671,   5.5240412 ,  10.6468792 ],\n       [ 10.38136661,   8.44968437,  15.17639591]])\n>>> np.dot(a, c)  # matrix multiplication\narray([[  53.61964114,   38.8741616 ,   71.53462537],\n       [ 118.4935668 ,   86.14012835,  158.40440712],\n       [ 155.04043289,  104.3499231 ,  195.26228855]])\n>>> a @ c # Starting with Python 3.5 and NumPy 1.10\narray([[  53.61964114,   38.8741616 ,   71.53462537],\n       [ 118.4935668 ,   86.14012835,  158.40440712],\n       [ 155.04043289,  104.3499231 ,  195.26228855]])\n</source>\n\n;Incorporation with OpenCV\n<source lang=\"numpy\">\n>>> import numpy as np\n>>> import cv2\n>>> r = np.reshape(np.arange(256*256)%256,(256,256))  # 256x256 pixel array with a horizontal gradient from 0 to 255 for the red color channel\n>>> g = np.zeros_like(r)  # array of same size and type as r but filled with 0s for the green color channel\n>>> b = r.T # transposed r will give a vertical gradient for the blue color channel\n>>> cv2.imwrite('gradients.png', np.dstack([b,g,r]))  # OpenCV images are interpreted as BGR, the depth-stacked array will be written to an 8bit RGB PNG-file called 'gradients.png'\nTrue\n</source>\n\n;Nearest Neighbor Search - Iterative Python algorithm and vectorized NumPy version\n<source lang=\"numpy\">\n>>> # # # Pure iterative Python # # #\n>>> points = [[9,2,8],[4,7,2],[3,4,4],[5,6,9],[5,0,7],[8,2,7],[0,3,2],[7,3,0],[6,1,1],[2,9,6]]\n>>> qPoint = [4,5,3]\n>>> minIdx = -1\n>>> minDist = -1\n>>> for idx, point in enumerate(points):  # iterate over all points\n        dist = sum([(dp-dq)**2 for dp,dq in zip(point,qPoint)])**0.5  # compute the euclidean distance for each point to q\n        if dist < minDist or minDist < 0:  # if necessary, update minimum distance and index of the corresponding point\n            minDist = dist\n            minIdx = idx\n\n>>> print('Nearest point to q: {0}'.format(points[minIdx]))\nNearest point to q: [3, 4, 4]\n\n>>> # # # Equivalent NumPy vectorization # # #\n>>> import numpy as np\n>>> points = np.array([[9,2,8],[4,7,2],[3,4,4],[5,6,9],[5,0,7],[8,2,7],[0,3,2],[7,3,0],[6,1,1],[2,9,6]])\n>>> qPoint = np.array([4,5,3])\n>>> minIdx = np.argmin(np.linalg.norm(points-qPoint,axis=1))  # compute all euclidean distances at once and return the index of the smallest one\n>>> print('Nearest point to q: {0}'.format(points[minIdx]))\nNearest point to q: [3 4 4]\n</source>\n\n== See also ==\n* [[List of numerical analysis software]]\n* [[SciPy]]\n* [[matplotlib]]\n\n== References ==\n{{Reflist|2}}<ref>[https://www.codespeedy.com/how-to-create-matrix-of-random-numbers-in-python-numpy/ Random Matrix using NumPy]</ref>\n\n== Further reading ==\n* {{cite book|last=Bressert|first=Eli|title=Scipy and Numpy: An Overview for Developers.|year=2012|publisher=O'Reilly Media|isbn=978-1-4493-0546-8}}\n* {{cite book |first=Wes |last=McKinney |title=Python for Data Analysis : Data Wrangling with Pandas, NumPy, and IPython |location=Sebastopol |publisher=O'Reilly |year=2017 |edition=2nd |isbn=978-1-4919-5766-0 }}\n\n== External links ==\n{{Sister project links\n|commons=Category:NumPy\n|b=Python Programming/numpy\n|v=Python/Quizzes/NumPy & Co.\n|wikt=no|s=no|n=no|q=no}}\n* {{official website}}\n* [https://scipy.github.io/old-wiki/pages/History_of_SciPy History of NumPy]\n\n{{SciPy ecosystem}}\n\n{{DEFAULTSORT:Numpy}}\n[[Category:Array programming languages]]\n[[Category:Articles with example Python code]]\n[[Category:Free mathematics software]]\n[[Category:Free science software]]\n[[Category:Numerical analysis software for Linux]]\n[[Category:Numerical analysis software for MacOS]]\n[[Category:Numerical analysis software for Windows]]\n[[Category:Numerical programming languages]]\n[[Category:Python scientific libraries]]\n[[Category:Software using the BSD license]]"
    },
    {
      "title": "Programming with Big Data in R",
      "url": "https://en.wikipedia.org/wiki/Programming_with_Big_Data_in_R",
      "text": "{{multiple issues|\n{{notability|date=June 2013}}\n{{COI|date=June 2013}}\n{{Expert needed|Computer science|date=June 2013}}\n}}\n\n{{Infobox programming language\n| name                   = pbdR\n| logo                   =\n| paradigm               = [[SPMD]] and [[MPMD]]\n| released               = {{Start date and age|2012|09}}\n| designer               = Wei-Chen Chen, George Ostrouchov, Pragneshkumar Patel, and Drew Schmidt\n| developer              = pbdR Core Team\n| latest_test_version    = Through [[GitHub]] at [https://github.com/RBigData/ RBigData]\n| typing                 = [[dynamic typing|Dynamic]]\n| influenced_by          = [[R (programming language)|R]], [[C (programming language)|C]], [[Fortran]], [[Message Passing Interface|MPI]], and [[ZeroMQ|ØMQ]]\n| operating_system       = [[Cross-platform]]\n| license                = [[General Public License]] and [[Mozilla Public License]]\n| website                = {{URL|www.r-pbd.org}}\n}}\n'''Programming with Big Data in R''' (pbdR)<ref>{{cite web|author=Ostrouchov, G., Chen, W.-C., Schmidt, D., Patel, P.|title=Programming with Big Data in R|year=2012|url=http://r-pbd.org}}</ref> is a series of [[R (programming language)|R]] packages and an environment for [[statistical computing]] with [[big data]] by using high-performance statistical computation.<ref>{{cite web|author1=Chen, W.-C.  |author2=Ostrouchov, G. |lastauthoramp=yes |url=http://thirteen-01.stat.iastate.edu/snoweye/hpsc/|year=2011|title=HPSC -- High Performance Statistical Computing for Data Intensive Research}}</ref> The pbdR uses the same programming language as R with [[S (programming language)|S3/S4]] classes and methods which is used among [[statistician]]s and [[Data mining|data miners]] for developing [[statistical software]]. The significant difference between pbdR and R code is that pbdR mainly focuses on [[distributed memory]] systems, where data are distributed across several processors and analyzed in a [[Batch processing|batch mode]], while communications between processors are based on [[Message Passing Interface|MPI]] that is easily used in large [[High-performance computing|high-performance computing (HPC)]] systems. R system mainly focuses{{Citation needed|date=July 2013}} on single [[Multi-core processor|multi-core]] machines for data analysis via an interactive mode such as [[Graphical user interface|GUI interface]].\n\nTwo main implementations in [[R (programming language)|R]] using [[Message Passing Interface|MPI]] are Rmpi<ref name=rmpi>{{cite journal|author=Yu, H.|title=Rmpi: Parallel Statistical Computing in R|year=2002|url=https://cran.r-project.org/package=Rmpi|journal=R News}}</ref> and pbdMPI of pbdR.\n* The pbdR built on pbdMPI uses [[SPMD|SPMD parallelism]] where every processor is considered as worker and owns parts of data. The [[SPMD|SPMD parallelism]] introduced in mid 1980 is particularly efficient in homogeneous computing environments for large data, for example, performing [[singular value decomposition]] on a large matrix, or performing [[Mixture model|clustering analysis]] on high-dimensional large data. On the other hand, there is no restriction to use [[Master/slave (technology)|manager/workers parallelism]] in [[SPMD|SPMD parallelism]] environment.\n* The Rmpi<ref name=rmpi/> uses [[Master/slave (technology)|manager/workers parallelism]] where one main processor (manager) servers as the control of all other processors (workers). The [[Master/slave (technology)|manager/workers parallelism]] introduced around early 2000 is particularly efficient for large tasks in small [[Computer cluster|clusters]], for example, [[Bootstrapping (statistics)|bootstrap method]] and [[Monte Carlo method|Monte Carlo simulation]] in applied statistics since [[Independent and identically distributed random variables|i.i.d.]] assumption is commonly used in most [[Statistics|statistical analysis]]. In particular, task pull parallelism has better performance for Rmpi in heterogeneous computing environments.\nThe idea of [[SPMD|SPMD parallelism]] is to let every processor do the same amount of work, but on different parts of a large data set. For example, a modern [[Graphics processing unit|GPU]] is a large collection of slower co-processors that can simply apply the same computation on different parts of relatively smaller data, but the SPMD parallelism ends up with an efficient way to obtain final solutions (i.e. time to solution is shorter).<ref>{{cite web | url = http://graphics.stanford.edu/~mhouston/ | title = Folding@Home - GPGPU | author = Mike Houston | accessdate = 2007-10-04 }}</ref> It is clear that pbdR is not only suitable for small [[Computer cluster|clusters]], but is also more stable for analyzing [[big data]] and more scalable for [[supercomputer]]s.<ref>{{cite book|author=Schmidt, D., Ostrouchov, G., Chen, W.-C., and Patel, P.|title=Tight Coupling of R and Distributed Linear Algebra for High-Level Programming with Big Data|year=2012|pages=811–815|journal=High Performance Computing, Networking, Storage and Analysis (SCC), 2012 SC Companion:|url=http://dl.acm.org/citation.cfm?id=2477156|doi=10.1109/SC.Companion.2012.113|isbn=978-0-7695-4956-9}}</ref>{{third-party-inline|date=October 2014}} In short, pbdR\n* does ''not'' like Rmpi, {{clarify|text=snow, snowfall, do-like,|date=October 2014}} nor parallel packages in R,\n* does ''not'' focus on interactive computing nor master/workers,\n* but is able to use ''both'' SPMD and task parallelisms.\n\n== Package design ==\nProgramming with pbdR requires usage of various packages developed by pbdR core team. Packages developed are the following.\n{| class=\"wikitable\"\n|-\n! General !! I/O !! Computation !! Application !! Profiling !! Client/Server\n|-\n| pbdDEMO || pbdNCDF4 || pbdDMAT || pmclust  || pbdPROF || pbdZMQ\n|-\n| pbdMPI || pbdADIOS  || pbdBASE || pbdML    || pbdPAPI || remoter\n|-\n|        ||           || pbdSLAP ||          || hpcvis  || pbdCS\n|-\n|        ||           || kazaam  ||          ||         || pbdRPC\n|}\n[[File:Pbd overview.png|thumb|The images describes how various pbdr packages are correlated.]]\nAmong these packages, pbdMPI provides wrapper functions to [[Message Passing Interface|MPI]] library, and it also produces a [[Library (computing)|shared library]] and a configuration file for MPI environments. All other packages rely on this configuration for installation and library loading that avoids difficulty of library linking and compiling. All other packages can directly use MPI functions easily.\n\n* pbdMPI --- an efficient interface to MPI either [[Open MPI|OpenMPI]] or [[MPICH2]] with a focus on Single Program/Multiple Data ([[SPMD]]) parallel programming style\n* pbdSLAP --- bundles scalable dense linear algebra libraries in double precision for R, based on [[ScaLAPACK]] version 2.0.2 which includes several scalable linear algebra packages (namely [[BLACS]], [[PBLAS]], and [[ScaLAPACK]]).\n* pbdNCDF4 --- interface to Parallel Unidata [[NetCDF]]4 format data files\n* pbdBASE --- low-level [[ScaLAPACK]] codes and wrappers\n* pbdDMAT --- distributed matrix classes and computational methods, with a focus on linear algebra and statistics\n* pbdDEMO --- set of package demonstrations and examples, and this unifying vignette\n* pmclust --- parallel [[Mixture model|model-based clustering]] using pbdR\n* pbdPROF --- profiling package for MPI codes and visualization of parsed stats\n* pbdZMQ --- interface to [[ZeroMQ|ØMQ]]\n* remoter --- R client with remote R servers\n* pbdCS --- pbdR client with remote pbdR servers\n* pbdRPC --- remote procedure call\n* kazaam --- very tall and skinny distributed matrices\n* pbdML --- machine learning toolbox\n\nAmong those packages, the pbdDEMO package is a collection of 20+ package demos which offer example uses of the various pbdR packages, and contains a vignette that offers detailed explanations for the demos and provides some mathematical or statistical insight.\n\n== Examples ==\n\n=== Example 1 ===\nHello World! Save the following code in a file called \"demo.r\"\n<source lang=\"rsplus\">\n### Initial MPI\nlibrary(pbdMPI, quiet = TRUE)\ninit()\n\ncomm.cat(\"Hello World!\\n\")\n\n### Finish\nfinalize()\n</source>\nand use the command\n<source lang=\"bash\">\nmpiexec -np 2 Rscript demo.r\n</source>\nto execute the code where [[R]]script is one of command line executable program.\n\n=== Example 2 ===\nThe following example modified from pbdMPI illustrates the basic [[programming language syntax|syntax of the language]] of pbdR.\nSince pbdR is designed in [[SPMD]], all the R scripts are stored in files and executed from the command line via mpiexec, mpirun, etc. Save the following code in a file called \"demo.r\"\n<source lang=\"rsplus\">\n### Initial MPI\nlibrary(pbdMPI, quiet = TRUE)\ninit()\n.comm.size <- comm.size()\n.comm.rank <- comm.rank()\n\n### Set a vector x on all processors with different values\nN <- 5\nx <- (1:N) + N * .comm.rank\n\n### All reduce x using summation operation\ny <- allreduce(as.integer(x), op = \"sum\")\ncomm.print(y)\ny <- allreduce(as.double(x), op = \"sum\")\ncomm.print(y)\n\n### Finish\nfinalize()\n</source>\nand use the command\n<source lang=\"bash\">\nmpiexec -np 4 Rscript demo.r\n</source>\nto execute the code where [[R (programming language)|Rscript]] is one of command line executable program.\n\n=== Example 3 ===\nThe following example modified from pbdDEMO illustrates the basic ddmatrix computation of pbdR which performs [[singular value decomposition]] on a given matrix.\nSave the following code in a file called \"demo.r\"\n<source lang=\"rsplus\">\n# Initialize process grid\nlibrary(pbdDMAT, quiet=T)\nif(comm.size() != 2)\n  comm.stop(\"Exactly 2 processors are required for this demo.\")\ninit.grid()\n\n# Setup for the remainder\ncomm.set.seed(diff=TRUE)\nM <- N <- 16\nBL <- 2 # blocking --- passing single value BL assumes BLxBL blocking\ndA <- ddmatrix(\"rnorm\", nrow=M, ncol=N, mean=100, sd=10)\n\n# LA SVD\nsvd1 <- La.svd(dA)\ncomm.print(svd1$d)\n\n# Finish\nfinalize()\n</source>\nand use the command\n<source lang=\"bash\">\nmpiexec -np 2 Rscript demo.r\n</source>\nto execute the code where [[R (programming language)|Rscript]] is one of command line executable program.\n\n== Further reading ==\n* {{cite techreport|author=Raim, A.M.|year=2013|title=Introduction to distributed computing with pbdR at the UMBC High Performance Computing Facility|institution=UMBC High Performance Computing Facility, University of Maryland, Baltimore County|number=HPCF-2013-2|url=http://userpages.umbc.edu/~gobbert/papers/pbdRtara2013.pdf}}\n* {{cite techreport|author=Bachmann, M.G., Dyas, A.D., Kilmer, S.C. and Sass, J.|year=2013|title=Block Cyclic Distribution of Data in pbdR and its Effects on Computational Efficiency|institution=UMBC High Performance Computing Facility, University of Maryland, Baltimore County|number=HPCF-2013-11|url=http://userpages.umbc.edu/~gobbert/papers/REU2013Team1.pdf}}\n* {{cite techreport|author=Bailey, W.J., Chambless, C.A., Cho, B.M. and Smith, J.D.|year=2013|title=Identifying Nonlinear Correlations in High Dimensional Data with Application to Protein Molecular Dynamics Simulations|institution=UMBC High Performance Computing Facility, University of Maryland, Baltimore County|number=HPCF-2013-12|url=http://userpages.umbc.edu/~gobbert/papers/REU2013Team2.pdf}}\n* {{cite web|title=High-Performance and Parallel Computing with R|author=[[Dirk Eddelbuettel]]|url=https://cran.r-project.org/web/views/HighPerformanceComputing.html}}\n* {{cite news|title=R at 12,000 Cores|url=http://www.r-bloggers.com/r-at-12000-cores/}}<br />This article was read 22,584 times in 2012 since it posted on October 16, 2012 and ranked number 3<ref>{{cite news|url=http://www.r-bloggers.com/100-most-read-r-posts-for-2012-stats-from-r-bloggers-big-data-visualization-data-manipulation-and-other-languages/|title=100 most read R posts in 2012 (stats from R-bloggers) – big data, visualization, data manipulation, and other languages}}</ref>\n* {{cite web|url=http://rwiki.sciviews.org/doku.php?id=developers:projects:gsoc2013:mpiprofiler|title=Profiling Tools for Parallel Computing with R|author=Google Summer of Code - R 2013}}\n* {{cite web|url=http://rpubs.com/wush978/pbdMPI-linux-pilot|title=在雲端運算環境使用R和MPI|author=Wush Wu (2014)}}\n* {{cite web|url=https://www.youtube.com/watch?v=m1vtPESsFqM|title=快速在AWS建立R和pbdMPI的使用環境|author=Wush Wu (2013)}}\n\n== References ==\n{{Reflist|30em}}\n\n== External links ==\n* {{Official website|www.r-pbd.org}}\n\n{{DEFAULTSORT:PbdR}}\n[[Category:Cross-platform free software]]\n[[Category:Data mining and machine learning software]]\n[[Category:Data-centric programming languages]]\n[[Category:Free statistical software]]\n[[Category:Functional languages]]\n[[Category:Numerical analysis software for Linux]]\n[[Category:Numerical analysis software for MacOS]]\n[[Category:Numerical analysis software for Windows]]\n[[Category:Parallel computing]]"
    },
    {
      "title": "R (programming language)",
      "url": "https://en.wikipedia.org/wiki/R_%28programming_language%29",
      "text": "{{Use dmy dates|date=June 2018}}\n{{Infobox programming language\n| name = R\n| logo = R logo.svg\n| screenshot = R Terminal.png\n| screenshot caption = R terminal\n| released = {{Start date and age|1993|08}}<ref name=\"Interface98\">{{cite techreport |url=https://www.stat.auckland.ac.nz/~ihaka/downloads/Interface98.pdf |title=R : Past and Future History |first=Ross |last=Ihaka |institution=Statistics Department, The University of Auckland, Auckland, New Zealand |conference=Interface '98 |year=1998}}</ref>\n| designer = [[Ross Ihaka]] and [[Robert Gentleman (statistician)|Robert Gentleman]]\n| developer = R Core Team<ref>{{Cite web |url=https://cran.r-project.org/doc/FAQ/R-FAQ.html#What-is-R_003f |title=R FAQ |at=2.1 What is R? |date=November 26, 2015 |first=Kurt |last=Hornik |website=The  Comprehensive R Archive Network |accessdate=2018-08-05}}</ref>\n| typing = [[dynamic typing|Dynamic]]\n| influenced = [[Julia (programming language)|Julia]]<ref name=\"Introduction\">{{cite web |url=https://docs.julialang.org/en/stable/manual/introduction/#man-introduction-1 |title=Introduction |work=The Julia Manual |accessdate=2018-08-05 |archive-url=https://web.archive.org/web/20180620172516/https://docs.julialang.org/en/stable/manual/introduction/#man-introduction-1#man-introduction-1 |archive-date=20 June 2018 |dead-url=yes |df=dmy-all }}</ref>\n| license = [[GNU GPL#Version 2|GNU GPL v2]]<ref>{{cite web |url=https://www.r-project.org/COPYING |title=R license |publisher=r-project |access-date=2018-08-05}}</ref>\n| website = {{Official URL}}\n| wikibooks = R Programming\n| paradigms = [[Multi-paradigm programming language|Multi-paradigm]]: [[Array programming|Array]], [[Object-oriented programming|object-oriented]], [[Imperative programming|imperative]], [[Functional programming|functional]], [[Procedural programming|procedural]], [[Reflective programming|reflective]]\n| latest_release_version = 3.6.0 (\"Planting of a Tree\")<ref>{{cite web|url=https://CRAN.R-project.org/|title=The Comprehensive R Archive Network|access-date=2019-04-29}}</ref>\n| latest_release_date = {{Start date and age|2019|04|26}}\n| influenced_by = {{startflatlist}}\n* [[Common Lisp]]\n* [[S (programming language)|S]]\n* [[Scheme (programming language)|Scheme]]<ref name=\"Interface98\"/>\n* [[XLispStat]]\n{{endflatlist}}\n| file_ext = .r, .R, .RData, .rds, .rda\n}}\n'''R''' is a [[programming language]] and [[free software]] environment for [[statistical computing]] and graphics supported by the R Foundation for Statistical Computing.{{refn | R language and environment\n* {{Cite web |url=https://cran.r-project.org/doc/FAQ/R-FAQ.html#What-is-R_003f |title=R FAQ| at=2.1 What is R? |date=2017-10-04 |first=Kurt |last=Hornik |website=The Comprehensive R Archive Network |accessdate=2018-08-06}}\nR Foundation\n* {{Cite web |url=https://cran.r-project.org/doc/FAQ/R-FAQ.html#What-is-the-R-Foundation_003f |title=R FAQ |at=2.13 What is the R Foundation? |date=2017-10-04 |first=Kurt |last=Hornik |website=The Comprehensive R Archive Network |accessdate=2018-08-06}}\nThe R Core Team [https://cran.r-project.org/doc/FAQ/R-FAQ.html#Citing-R asks authors who use R in their data analysis] to cite the software using:\n* R Core Team (2016). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. URL http://www.R-project.org/.\n}} The R language is widely used among [[statistician]]s and [[Data mining|data miners]] for developing [[statistical software]]{{refn | widely used\n* {{cite journal |author1=Fox, John  |author2=Andersen, Robert  |lastauthoramp=yes | title = Using the R Statistical Computing Environment to Teach Social Statistics Courses | publisher = Department of Sociology, McMaster University | date = January 2005 | url = https://socialsciences.mcmaster.ca/jfox/Teaching-with-R.pdf | format = PDF | accessdate = 2018-08-06 }}\n* {{cite news | url=https://www.nytimes.com/2009/01/07/technology/business-computing/07program.html |title=Data Analysts Captivated by R's Power | date=2009-01-06 | accessdate=2018-08-06|last=Vance| first=Ashlee |work=[[New York Times]]| quote=R is also the name of a popular programming language used by a growing number of data analysts inside corporations and academia. It is becoming their lingua franca...}}\n}} and [[data analysis]].<ref>{{cite news | url=https://www.nytimes.com/2009/01/07/technology/business-computing/07program.html |title=Data Analysts Captivated by R's Power | date=2009-01-06 | accessdate=2018-08-06|last=Vance| first=Ashlee |work=[[New York Times]]| quote=R is also the name of a popular programming language used by a growing number of data analysts inside corporations and academia. It is becoming their lingua franca...}}</ref> Polls, [[Rexer's Annual Data Miner Survey|data mining surveys]], and studies of scholarly literature databases show substantial increases in popularity{{refn | R's popularity\n* David Smith (2012); [http://java.sys-con.com/node/2288420 ''R Tops Data Mining Software Poll''], Java Developers Journal, May 31, 2012.\n* Karl Rexer, Heather Allen, & Paul Gearan (2011); [http://www.rexeranalytics.com/Data-Miner-Survey-Results-2011.html ''2011 Data Miner Survey Summary''], presented at Predictive Analytics World, Oct. 2011.\n* {{cite web|author=Robert A. Muenchen|year=2012|url= http://r4stats.com/articles/popularity/|title=The Popularity of Data Analysis Software}}\n* {{cite journal|url=http://www.nature.com/news/programming-tools-adventures-with-r-1.16609|title=Programming tools: Adventures with R|first1=Sylvia|last1=Tippmann|journal=[[Nature (journal)|Nature]]|volume = 517| doi =  10.1038/517109a | pages = 109–110 | date = 29 December 2014}}}}; {{As of |June 2019||df=|lc=|since=|post=,}} R ranks 22nd in the [[TIOBE index]], a measure of popularity of programming languages.<ref name=\"TIOBE\">{{cite web | title=TIOBE Index  - The Software Quality Company | website=TIOBE | url=https://www.tiobe.com/tiobe-index/ | access-date=2019-03-04}}</ref>\n\nA [[List of GNU packages|GNU package]],{{refn | GNU project\n* {{cite web | url=http://directory.fsf.org/project/gnur/ | publisher=Free Software Foundation (FSF) Free Software Directory|title=GNU R |date=2018-04-23|accessdate=2018-08-07}}\n* {{cite web | author=R Project|date=n.d.|url=https://www.r-project.org/about.html | title=What is R? | accessdate=2018-08-07}}\n}} [[source code]] for the R software environment is written primarily in [[C (programming language)|C]], [[Fortran]] and [[Self-hosting (compilers)|R itself]],<ref>{{cite web | author=\"Wrathematics\"| url=http://librestats.com/2011/08/27/how-much-of-r-is-written-in-r/| archive-url=https://web.archive.org/web/20180612142342/http://librestats.com/2011/08/27/how-much-of-r-is-written-in-r/| dead-url=yes| archive-date=12 June 2018| title=How Much of R Is Written in R | date=27 August 2011|accessdate=2018-08-07|publisher=librestats}}</ref> and is freely available under the [[GNU General Public License]]. Pre-compiled binary versions are provided for various [[operating system]]s. Although R has a [[command line interface]], there are several [[graphical user interface]]s, such as [[RStudio]], an [[integrated development environment]].<ref name=\"R_gui\">{{cite web|title=7 of the Best Free Graphical User Interfaces for R|url=http://www.linuxlinks.com/article/20110306113701179/GUIsforR.html|website=linuxlinks.com|accessdate=9 February 2016}}</ref><ref>{{cite web|title=List of R Editors|url=https://r-dir.com/blog/2013/01/list-of-r-editors.html|website=r-dir|accessdate=2018-08-07}}</ref>\n\n== History ==\nR is an implementation of the [[S (programming language)|S programming language]] combined with [[lexical scoping]] semantics, inspired by [[Scheme (programming language)|Scheme]].<ref>{{cite journal|last2=Hill|first2=Brandon|last3=Osvald|first3=Leo|last4=Vitek|first4=Jan|year=2012|title=Evaluating the design of the R language: objects and functions for data analysis|url=http://r.cs.purdue.edu/pub/ecoop12.pdf|journal=ECOOP'12 Proceedings of the 26th European conference on Object-Oriented Programming|access-date=2016-05-17|first1=Frances|last1=Morandat}}</ref> [[S (programming language)|S]] was created by [[John Chambers (programmer)|John Chambers]] in 1976, while at [[Bell Laboratories|Bell Labs]]. There are some important differences, but much of the code written for S runs unaltered.<ref>{{cite web|url=https://www.r-project.org/about.html|title=R: What is R?|website=R-Project|accessdate=2018-08-07}}</ref>\n\nR was created by [[Ross Ihaka]] and [[Robert Gentleman (statistician)|Robert Gentleman]]<ref>{{cite web|url=http://myprofile.cos.com/rgentleman|title=Individual Expertise profile of Robert Gentleman|last=Gentleman|first=Robert|date=9 December 2006|accessdate=2009-07-20|archiveurl=https://web.archive.org/web/20110723215206/http://myprofile.cos.com/rgentleman|archivedate=23 July 2011}}</ref> at the [[University of Auckland]], New Zealand, and is currently developed by the ''R Development Core Team'' (of which Chambers is a member).<ref>{{cite journal |last1=Thieme |first1=Nick |title=R generation |journal=Significance |date=August 2018 |volume=15 |issue=4 |pages=14–19 |doi=10.1111/j.1740-9713.2018.01169.x}}</ref> R is named partly after the first names of the first two R authors and partly as a play on the name of [[S (programming language)|S]].<ref>{{cite book|url=https://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-is-R-named-R_003f|title=The R FAQ: Why R?|isbn=3-900051-08-9|author=Kurt Hornik|accessdate=2008-01-29}}</ref> The project was conceived in 1992, with an initial version released in 1995 and a stable beta version in 2000.<ref>{{Cite web|url=https://cran.r-project.org/doc/html/interface98-paper/paper_2.html|title=R : Past and Future History -- A Free Software Project|website=cran.r-project.org|access-date=2016-05-30}}</ref><ref>{{Cite web|url=http://blog.revolutionanalytics.com/2016/03/16-years-of-r-history.html|title=Over 16 years of R Project history|website=Revolutions|access-date=2016-05-30}}</ref><ref>{{Cite web|url=https://www.stat.auckland.ac.nz/~ihaka/downloads/Massey.pdf|title=The R Project: A Brief History and Thoughts About the Future|last=Ihaka|first=Ross|date=|website=stat.auckland.ac.nz|publisher=|access-date=}}</ref>\n\n== Statistical features ==\n<!-- Deleted image removed: [[Image:R gui on os x.png|thumb|right|The R [[gui]] running the general linear model demo on Mac OS X.]] -->\nR and its libraries implement a wide variety of statistical and [[graphical]] techniques, including [[linear]] and [[nonlinear]] modelling, classical statistical tests, [[time-series analysis]], classification, clustering, and others. R is easily extensible through functions and extensions, and the R community is noted for its active contributions in terms of packages. Many of R's standard functions are written in R itself, which makes it easy for users to follow the algorithmic choices made. For computationally intensive tasks, [[C (programming language)|C]], [[C++]], and [[Fortran]] code can be [[Linking (computing)|linked]] and called at run time. Advanced users can write C, C++,<ref>{{cite journal|url=http://www.jstatsoft.org/v40/i08|title= Rcpp: Seamless R and C++ Integration|first1=Dirk|last1= Eddelbuettel|first2=Romain|last2=Francois|journal=[[Journal of Statistical Software]]|volume=40|issue=8|year=2011|doi=10.18637/jss.v040.i08}}</ref> [[Java (programming language)|Java]],<ref>{{cite web|title=nution-j2r: Java library to invoke R native functions|url=https://gitlab.nuiton.org/nuiton/nuiton-j2r|accessdate=2018-09-13}}</ref> [[.NET Framework|.NET]]{{refn | .NET Framework\n* {{cite web  |title=Making GUIs using C# and R with the help of R.NET |url = http://psychwire.wordpress.com/2011/06/19/making-guis-using-c-and-r-with-the-help-of-r-net/|accessdate=2018-09-13}}\n* {{cite web  |title=R.NET homepage |url = http://rdotnet.codeplex.com/|accessdate=2018-09-13}}\n* {{cite conference |url=http://www.rinfinance.com/agenda/2011/OliverHaynold.pdf |title=An Rserve Client Implementation for CLI/.NET |last1=Haynold |first1=Oliver M. |date=April 2011 |conference=R/Finance 2011 |conference-url=http://www.rinfinance.com/RinFinance2011/agenda/ |publisher= |book-title= |pages= |location=Chicago, IL, USA |id= |deadurl=yes |archiveurl=https://web.archive.org/web/20151129223447/http://www.rinfinance.com/agenda/2011/OliverHaynold.pdf |archivedate=29 November 2015 |df=dmy-all|accessdate=2018-09-13}}\n}} or [[Python (programming language)|Python]] code to manipulate R objects directly.<ref name = RExtension>{{cite web|url=https://cran.r-project.org/doc/manuals/r-release/R-exts.html|title=Writing R Extensions|author=R manuals|work=r-project.org|accessdate=2018-09-13}}</ref> R is highly extensible through the use of user-submitted packages for specific functions or specific areas of study. Due to its [[S (programming language)|S]] heritage, R has stronger [[object-oriented programming]] facilities than most statistical computing languages. Extending R is also eased by its [[lexical scoping]] rules.<ref>{{cite journal  | last = Jackman | first = Simon | title = R For the Political Methodologist | journal = The Political Methodologist | volume = 11  | issue = 1 | pages = 20–22 | date = Spring 2003 | publisher = Political Methodology Section, [[American Political Science Association]] | url = http://polmeth.wustl.edu/tpm/tpm_v11_n2.pdf | format = PDF | accessdate = 2018-09-13 |archiveurl = https://web.archive.org/web/20060721143309/http://polmeth.wustl.edu/tpm/tpm_v11_n2.pdf |archivedate = 2006-07-21}}</ref>\n\nAnother strength of R is static graphics, which can produce publication-quality graphs, including mathematical symbols.  Dynamic and interactive graphics are available through additional packages.<ref>{{cite web\n| url=https://cran.r-project.org/web/views/Graphics.html\n| title=CRAN Task View: Graphic Displays & Dynamic Graphics & Graphic Devices & Visualization\n| publisher=The Comprehensive R Archive Network\n| accessdate=2018-09-13}}</ref>\n\nR has Rd, its own [[LaTeX]]-like documentation format, which is used to supply comprehensive documentation, both online in a number of formats and in hard copy.<ref name=\"R_Rd\">{{cite web|title=Rd format|url=http://www.hep.by/gnu/r-patched/r-exts/R-exts_49.html|website=hep.by|accessdate=2018-09-13}}</ref>\n\n== Programming features ==\nR is an [[interpreted language]]; users typically access it through a [[command-line interpreter]]. If a user types <code>2+2</code> at the R command prompt and presses enter, the computer replies with 4, as shown below:\n\n<source lang=\"rout\">\n> 2 + 2\n[1] 4\n</source>\n\nThis calculation is interpreted as the sum of two single-element vectors, resulting in a single-element vector. The prefix <code>[1]</code> indicates that the list of elements following it on the same line starts with the ''first'' element of the vector (a feature that is useful when the output extends over multiple lines).\n\nLike other similar languages such as [[APL (programming language)|APL]] and [[MATLAB]], R supports [[Matrix (mathematics)|matrix arithmetic]]. R's [[data structure]]s include [[Column vector|vectors]], [[Matrix (mathematics)|matrices]], arrays, data frames (similar to [[Table (database)|tables]] in a [[relational database]]) and [[List (computing)|lists]].<ref>\n{{cite book |last=Dalgaard |first=Peter |title=Introductory Statistics with R |year=2002 |publisher=Springer-Verlag |location=New York, Berlin, Heidelberg |isbn=0387954759 | pages=10–18, 34 }}\n</ref> Arrays are stored in [[column-major order]].<ref>''An Introduction to R'', Section 5.1: Arrays. Retrieved in 2010-03 from https://cran.r-project.org/doc/manuals/R-intro.html#Arrays.</ref> R's extensible object system includes objects for (among others): [[Regression analysis|regression models]], [[time-series]] and [[Spatial analysis|geo-spatial coordinates]]. The scalar data type was never a data structure of R.<ref>{{cite journal |last=Ihaka |first=Ross |last2=Gentlman |first2=Robert |date=Sep 1996 |title=R: A Language for Data Analysis and Graphics |url=https://www.stat.auckland.ac.nz/~ihaka/downloads/R-paper.pdf |journal=Journal of Computational and Graphical Statistics |publisher=American Statistical Association |volume=5 |issue=3 |pages=299–314 |doi=10.2307/1390807 |accessdate=2014-05-12}}</ref> Instead, a scalar is represented as a vector with length one.<ref>{{Cite web|url=http://adv-r.had.co.nz/Data-structures.html|title=Data structures · Advanced R.|website=adv-r.had.co.nz|access-date=2016-09-26}}</ref>\n\nMany features of R derive from [[Scheme (programming language)|Scheme]]. R uses [[S-expressions]] to represent both data and code. Functions are [[first-class functions|first-class]] and can be manipulated in the same way as data objects, facilitating [[meta-programming]], and allow [[multiple dispatch]]. Variables in R are [[lexical scope|lexically scoped]] and [[dynamic typing|dynamically typed]]. Function arguments are passed by value, and are [[lazy evaluation|lazy]] -- that is to say, they are only evaluated when they are used, not when the function is called.\n\nR supports [[procedural programming]] with [[Function (computer science)|functions]] and, for some functions, [[object-oriented programming]] with [[generic function]]s. A generic function acts differently depending on the [[Class (computer programming)|classes]] of arguments passed to it. In other words, the generic function [[Dynamic dispatch|dispatches]] the function ([[Method (computer science)|method]]) specific to that  [[Class (computer programming)|class]]  of [[Object (computer science)|object]]. For example, R has a [[Generic function|generic]] <code>print</code> function that can print almost every [[Class (computer programming)|class]] of [[Object (computer science)|object]] in R with a simple <code>print(objectname)</code> syntax.<ref name=\"help_print\">{{cite web|author=R Core Team|title=Print Values|url=https://stat.ethz.ch/R-manual/R-devel/library/base/html/print.html|website=R Documentation|publisher=R Foundation for Statistical Computing|accessdate=30 May 2016}}</ref>\n\nAlthough used mainly by statisticians and other practitioners requiring an environment for statistical computation and software development, R can also operate as a [[numerical linear algebra|general matrix calculation]] toolbox – with performance benchmarks comparable to [[GNU Octave]] or [[MATLAB]].<ref>{{cite web\n |url         = http://www.sciviews.org/benchmark\n |publisher   = SciView\n |title       = Speed comparison of various number crunching packages (version 2)\n |accessdate  = 2007-11-03\n |date        = 2003 <!--source ambiguously says \"Last update: 08/03/2003\"-->\n |deadurl     = yes\n |archiveurl  = https://web.archive.org/web/20071016130210/http://www.sciviews.org/benchmark/\n |archivedate = 16 October 2007\n |df          = dmy-all\n}}\n</ref>\n\n== {{Anchor|CRAN}}Packages ==\nThe capabilities of R are extended through user-created ''packages'', which allow specialised statistical techniques, graphical devices, import/export capabilities, reporting tools ([[knitr]], [[Sweave]]), etc. These packages are developed primarily in R, and sometimes in [[Java (programming language)|Java]], [[C (programming language)|C]], [[C++]], and [[Fortran]].{{citation needed|date=September 2018}} The R packaging system is also used by researchers to create compendia to organise research data, code and report files in a systematic way for sharing and public archiving.<ref>{{cite journal|last1=Marwick|first1=Ben|last2=Boettiger|first2=Carl|last3=Mullen|first3=Lincoln|title=Packaging data analytical work reproducibly using R (and friends)|journal=PeerJ Preprints|date=26 August 2017|doi=10.7287/peerj.preprints.3192v1|url=https://peerj.com/preprints/3192/?td=wk|language=en|issn=2167-9843}}</ref>\n\nA core set of packages is included with the installation of R, with more than 15,000 additional packages ({{as of|2018|9|lc=on}}) available at the Comprehensive R Archive Network (CRAN),<ref>{{cite web|url=https://cran.r-project.org/|title=The Comprehensive R Archive Network|publisher=|accessdate=2018-09-16}}</ref> [[Bioconductor]], Omegahat,<ref>{{cite web|url=http://www.omegahat.net/ |title=Omegahat.net |publisher=Omegahat.net |date= |accessdate=2018-09-16}}</ref> [[GitHub]], and other repositories.{{refn | packages available from repositories\n* {{cite web|author=Robert A. Muenchen|year=2012|url= http://r4stats.com/articles/popularity/|title=The Popularity of Data Analysis Software}}\n* {{cite journal|url=http://www.nature.com/news/programming-tools-adventures-with-r-1.16609|title=Programming tools: Adventures with R|first1=Sylvia|last1=Tippmann|journal=[[Nature (journal)|Nature]]|volume = 517| doi =  10.1038/517109a | pages = 109–110 | date = 29 December 2014}}\n* {{Cite web|url = http://www.rdocumentation.org/|title = <nowiki>Search all R packages and function manuals | Rdocumentation</nowiki>|date = 2014-06-16|accessdate = 2018-09-16|website = Rdocumentation|publisher = }}\n}}\n\nThe \"Task Views\" page (subject list) on the CRAN website<ref name=CRANTasks>{{cite web|title=CRAN Task Views|url=https://cran.r-project.org/web/views/|website=cran.r-project.org|accessdate=2018-09-16}}</ref> lists a wide range of tasks (in fields such as Finance, Genetics, High Performance Computing, Machine Learning, Medical Imaging, Social Sciences and Spatial Statistics) to which R has been applied and for which packages are available. R has also been identified by the FDA as suitable for interpreting data from clinical research.<ref>{{cite web|url=http://blog.revolutionanalytics.com/2012/06/fda-r-ok.html|title=FDA: R OK for drug trials|publisher=|accessdate=2018-09-16}}</ref>\n\nOther R package resources include Crantastic,<ref>{{cite web|url=http://crantastic.org/|title=It's crantastic!|publisher=|accessdate=2018-09-16}}</ref> a community site for rating and reviewing all CRAN packages, and R-Forge,<ref>{{cite web|url=https://r-forge.r-project.org/|title=R-Forge: Welcome|publisher=|accessdate=2018-09-16}}</ref> a central platform for the collaborative development of R packages, R-related software, and projects. R-Forge also hosts many unpublished beta packages, and development versions of CRAN packages.\n\nThe Bioconductor project provides R packages for the analysis of genomic data. This includes object-oriented data-handling and analysis tools for data from [[Affymetrix]], [[Complementary DNA|cDNA]] [[microarray]], and next-generation [[high-throughput sequencing]] methods.<ref>{{cite journal |date=2015 |title=Orchestrating high-throughput genomic analysis with Bioconductor |journal=Nature Methods |publisher=[[Nature Publishing Group]] |volume=12 |issue=2 |pages=115–121 |doi=10.1038/nmeth.3252 |pmid=25633503 |pmc=4509590 | last1 = Huber | first1 = W | last2 = Carey | first2 = VJ | last3 = Gentleman | first3 = R | last4 = Anders | first4 = S | last5 = Carlson | first5 = M | last6 = Carvalho | first6 = BS | last7 = Bravo | first7 = HC | last8 = Davis | first8 = S | last9 = Gatto | first9 = L | last10 = Girke | first10 = T | last11 = Gottardo | first11 = R | last12 = Hahne | first12 = F | last13 = Hansen | first13 = KD | last14 = Irizarry | first14 = RA | last15 = Lawrence | first15 = M | last16 = Love | first16 = MI | last17 = MacDonald | first17 = J | last18 = Obenchain | first18 = V | last19 = Oleś | first19 = AK | last20 = Pagès | first20 = H | last21 = Reyes | first21 = A | last22 = Shannon | first22 = P | last23 = Smyth | first23 = GK | last24 = Tenenbaum | first24 = D | last25 = Waldron | first25 = L | last26 = Morgan | first26 = M}}</ref>\n\n== Milestones ==\n<!-- List of notable changes only; ignore service/bug-fig releases -->\n\nA list of changes in R releases is maintained in various \"news\" files at CRAN.<ref name=RNews>Changes in versions 3.0.0 onward:\n*{{cite web|title=R News|url=https://cran.r-project.org/src/base/NEWS|website=cran.r-project.org|accessdate=2014-07-03}}\nChanges for earlier versions (by major release number):\n*{{cite web|title=NEWS.2|url=https://cran.r-project.org/src/base/NEWS.2|website=cran.r-project.org|accessdate=2017-04-08}}\n*{{cite web|title=NEWS.1|url=https://cran.r-project.org/src/base/NEWS.1|website=cran.r-project.org|accessdate=2017-04-08}}\n*{{cite web|title=NEWS.0|url=https://cran.r-project.org/src/base/NEWS.0|website=cran.r-project.org|accessdate=2017-04-08}}\n</ref> Some highlights are listed below for several major releases.\n\n{| class=\"wikitable\"\n|-\n! Release\n! Date\n! Description\n|-\n! 0.16\n|\n|This is the last [[Alpha test|alpha]] version developed primarily by Ihaka and Gentleman. Much of the basic functionality from the \"White Book\" (see [[S (programming language)#History|S history]]) was implemented. The mailing lists commenced on April 1, 1997.\n|-\n! 0.49\n| style=\"white-space:nowrap;\"|{{date|1997-04-23|iso}}\n| This is the oldest [[Source code|source]] release which is currently available on CRAN.<ref>{{cite web|url=https://cran.r-project.org/src/base/R-0/|title=Index of /src/base/R-0|publisher=}}</ref> CRAN is started on this date, with 3 mirrors that initially hosted 12 packages.<ref>{{cite web|url=https://stat.ethz.ch/pipermail/r-announce/1997/000001.html|title=ANNOUNCE:  CRAN|publisher=}}</ref> Alpha versions of R for Microsoft Windows and the [[classic Mac OS]] are made available shortly after this version.{{citation needed|reason=the CRAN announcement does not specifically mention Windows or Mac OS|date=October 2015}}\n|-\n! 0.60\n| {{date|1997-12-05|iso}}\n| R becomes an official part of the [[GNU Project]]. The code is hosted and maintained on [[Concurrent Versions System|CVS]].\n|-\n! 0.65.1\n| style=\"white-space:nowrap;\"|{{date|1999-10-07|iso}}\n| First versions of update.packages and install.packages functions for downloading and installing packages from CRAN.<ref>https://cran.r-project.org/src/base/NEWS.0</ref>\n|-\n! 1.0\n| {{date|2000-02-29|iso}}\n| Considered by its developers stable enough for production use.<ref>{{cite web|url=https://stat.ethz.ch/pipermail/r-announce/2000/000127.html|title=R-1.0.0 is released|author=Peter Dalgaard|accessdate=2009-06-06}}</ref>\n|-\n! 1.4\n| {{date|2001-12-19|iso}}\n| S4 methods are introduced and the first version for [[macOS|Mac OS X]] is made available soon after.\n|-\n! 1.8\n| {{date|2003-10-08|iso}}\n| Introduced a flexible condition handling mechanism for signalling and handling condition objects.\n|-\n! 2.0\n| {{date|2004-10-04|iso}}\n| Introduced [[lazy loading]], which enables fast loading of data with minimal expense of system memory.\n|-\n! 2.1\n| {{date|2005-04-18|iso}}\n| Support for [[UTF-8]] encoding, and the beginnings of [[internationalization and localization]] for different languages.\n|-\n! 2.11\n| {{date|2010-04-22|iso}}\n| Support for Windows 64 bit systems.\n|-\n! 2.13\n| {{date|2011-04-14|iso}}\n| Adding a new compiler function that allows speeding up functions by converting them to byte-code.\n|-\n! 2.14\n| {{date|2011-10-31|iso}}\n| Added mandatory namespaces for packages. Added a new parallel package.\n|-\n! 2.15\n| {{date|2012-03-30|iso}}\n| New load balancing functions. Improved serialisation speed for long vectors.\n|-\n! 3.0\n| {{date|2013-04-03|iso}}\n| Support for numeric index values 2<sup>31</sup> and larger on 64 bit systems.\n|-\n! 3.4\n| {{date|2017-04-21|iso}}\n| Just-in-time compilation (JIT) of functions and loops to byte-code enabled by default.\n|-\n! 3.5\n| {{date|2018-04-23|iso}}\n| Packages byte-compiled on installation by default. Compact internal representation of integer sequences. Added a new serialisation format to support compact internal representations.\n|}\n\n== Interfaces ==\nThe most specialized [[integrated development environment|integrated development environment (IDE)]] for R is [[RStudio]].<ref name=\"kdnuggets.com\">{{cite web|url=http://www.kdnuggets.com/polls/2011/r-gui-used.html|title=Poll: R GUIs you use frequently (2011)|website=kdnuggets.com|access-date=2018-09-18}}</ref> A similar development interface is [[R Tools for Visual Studio]]. Some generic IDEs like [[Eclipse (software)|Eclipse]],<ref>\n{{cite web|url=http://www.walware.de/goto/statet|title=StatET for R|author=Unknown}}</ref> also offer features to work with R.\n\nGraphical user interfaces with more of a point-and-click approach include [[Rattle GUI]], [[R Commander]], and [[RKWard]].\n\nSome of the more common editors with varying levels of support for R include  [[Emacs]] ([[Emacs Speaks Statistics]]), [[Vim (text editor)|Vim]] (Nvim-R plugin<ref name=\":0\">{{Cite web|url=https://www.vim.org/scripts/script.php?script_id=2628|title=Nvim-R - Plugin to work with R : vim online|website=www.vim.org|access-date=2019-03-06}}</ref>), [[Vim (text editor)#Neovim|Neovim]] (Nvim-R plugin<ref name=\":0\" />), [[Kate (text editor)|Kate]],<ref>\n{{cite web\n | url=http://kate-editor.org/downloads/syntax_highlighting\n | title=Syntax Highlighting\n | publisher=Kate Development Team\n | accessdate=2008-07-09\n | archiveurl = https://web.archive.org/web/20080707062903/http://www.kate-editor.org/downloads/syntax_highlighting <!-- Bot retrieved archive --> |archivedate = 2008-07-07}}\n</ref> [[LyX]],<ref>{{cite web\n | url=http://wiki.lyx.org/LyX/LyxWithRThroughSweave\n | title=LyX with R through Sweave\n | author= Paul E. Johnson\n | author2= Gregor Gorjanc\n | last-author-amp= yes\n | accessdate=2017-04-04\n}}</ref> [[Notepad++]],<ref>\n{{cite web\n|url=http://sourceforge.net/projects/npptor/\n|title=NppToR: R in Notepad++\n|publisher=sourceforge.net\n|accessdate=2013-09-18|date=8 May 2013\n}}</ref> [[Visual Studio Code]], [[WinEdt]],<ref>{{cite web\n | url=https://cran.r-project.org/web/packages/RWinEdt/index.html\n | title=RWinEdt: R Interface to 'WinEdt'\n| author=Uwe Ligges\n | accessdate=2017-04-04\n}}</ref> and Tinn-R.<ref>{{cite web|url=https://nbcgib.uesc.br/tinnr/en/|title=Tinn-R|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|accessdate=2019-03-05}}</ref>\n\nR functionality is accessible from several scripting languages such as [[Python (programming language)|Python]],<ref>{{cite web|url=http://rpy.sourceforge.net|title=A simple and efficient access to R from Python|accessdate=18 September 2013|date=21 October 2012|first=Laurent|last=Gautier }}</ref> [[Perl]],<ref>{{cite web|url=https://metacpan.org/module/Statistics::R|title=Statistics::R - Perl interface with the R statistical program - metacpan.org|author=Florent Angly|publisher=}}</ref> [[Ruby (programming language)|Ruby]],<ref>{{cite web|url=https://github.com/alexgutteridge/rsruby|title=GitHub - alexgutteridge/rsruby: Ruby - R bridge.|author=alexgutteridge|work=GitHub}}</ref> [[F Sharp (programming language)|F#]],<ref>{{cite web|url=https://bluemountaincapital.github.io/FSharpRProvider/|title=F# R Type Provider|author=BlueMountain Capital|publisher=}}</ref> and [[Julia (programming language)|Julia]].<ref>{{cite web|url=https://github.com/JuliaInterop/RCall.jl|title=Embedded R within Julia}}</ref> Interfaces to other, high-level programming languages, like [[Java (programming language)|Java]]<ref>{{cite web|url=https://www.rforge.net/Rserve/|title=Rserve TCP/IP server}}</ref> and [[C Sharp (programming language)|.NET C#]]<ref>{{cite web|url=https://github.com/konne/RserveCLI2|title=RserveCLI2 - a .NET/CLR client for Rserve}}</ref><ref>{{cite web|url=https://jmp75.github.io/rdotnet/|title=R.NET}}</ref> are available as well.\n\n== Implementations ==\nThe main R implementation is written in R, C, and Fortran, and there are several other implementations aimed at improving speed or increasing extensibility. A closely related implementation is pqR (pretty quick R) by [[Radford M. Neal]] with improved memory management and support for automatic multithreading. [[Renjin]] and FastR are [[Java (programming language)|Java]] implementations of R for use in a Java Virtual Machine.  CXXR, rho, and Riposte<ref>{{cite journal|last1=Talbot|first1=Justin|last2=DeVito|first2=Zachary|last3=Hanrahan|first3=Pat|title=Riposte: A Trace-driven Compiler and Parallel VM for Vector Code in R|journal=Proceedings of the 21st International Conference on Parallel Architectures and Compilation Techniques|date=1 January 2012|pages=43–52|doi=10.1145/2370816.2370825 |publisher=ACM}}</ref> are implementations of R in [[C++]].  Renjin, Riposte, and pqR attempt to improve performance by using multiple processor cores and some form of deferred evaluation.<ref>{{cite web|last1=Neal|first1=Radford|title=Deferred evaluation in Renjin, Riposte, and pqR|url=https://radfordneal.wordpress.com/2013/07/24/deferred-evaluation-in-renjin-riposte-and-pqr/|website=Radford Neal's blog|accessdate=6 March 2017|date=25 July 2013}}</ref> Most of these alternative implementations are experimental and incomplete, with relatively few users, compared to the main implementation maintained by the R Development Core Team.\n\nTIBCO built a [[runtime engine]] called TERR, which is part of Spotfire.<ref>Jackson, Joab (May 16, 2013). [http://www.pcworld.com/article/2038944/tibco-offers-free-r-to-the-enterprise.html TIBCO offers free R to the enterprise]. ''PC World''. Retrieved July 20, 2015.</ref>\n\nMicrosoft R Open is a fully compatible R distribution with modifications for multi-threaded computations.<ref>{{cite web |title=Microsoft R Open: The Enhanced R Distribution |accessdate=June 30, 2018 |work= |url=https://mran.microsoft.com/open }}</ref>\n\n== R communities ==\nR has vibrant and active local communities worldwide for users to network, share ideas, and learn.<ref>{{cite web|title=Local R User Group Directory|url=http://blog.revolutionanalytics.com/local-r-groups.html|website=Revolutions Blog|accessdate=12 May 2018}}</ref><ref>{{cite web|title=A list of R conferences and meetings|url=https://jumpingrivers.github.io/meetingsR/index.html|website=Jumping Rivers|accessdate=12 May 2018}}</ref>\n\nThere is a growing number of R events bringing its users together, such as conferences (e.g. useR!, WhyR?, conectaR, SatRdays)<ref>{{cite web|title=official website of WhyR? conference|url=http://whyr.pl/|website=WhyR?|accessdate=26 June 2019}}</ref><ref>{{cite web|title=SatRdays listing|url=https://satrdays.org/|website=SatRdays|accessdate=26 June 2019}}</ref>, meetups<ref>{{cite web|title=R Project for Statistical Computing|url=https://www.meetup.com/topics/r-project-for-statistical-computing/|website=Meetup|accessdate=12 May 2018}}</ref>, as well as R-Ladies<ref>{{cite web|title=R Ladies|url=https://rladies.org|website=R Ladies|accessdate=12 May 2018}}</ref> groups that promote gender diversity.\n\n== useR! conferences ==\nThe official annual gathering of R users is called \"useR!\".<ref name=\"user\">\"useR!\". Retrieved from https://www.r-project.org/conferences.html</ref>\nThe first such event was useR! 2004 in May 2004, [[Vienna]], Austria.<ref>{{cite web|url=http://www.ci.tuwien.ac.at/Conferences/useR-2004/|title=useR! 2004 - The R User Conference|accessdate=2018-09-09|date=27 May 2004}}</ref>  After skipping 2005, the useR! conference has been held annually, usually alternating between locations in Europe and North America.<ref>{{cite web|url=https://www.r-project.org/conferences.html|title=R-related Conferences|author=R Project|date=9 August 2013|accessdate=2018-09-09}}</ref>\nSubsequent conferences have included:<ref name=\"user\" />\n\n* useR! 2006, Vienna, Austria\n* useR! 2007, Ames, Iowa, USA\n* useR! 2008, Dortmund, Germany\n* useR! 2009, Rennes, France\n* useR! 2010, Gaithersburg, Maryland, USA\n* useR! 2011, Coventry, United Kingdom\n* useR! 2012, Nashville, Tennessee, USA\n* useR! 2013, Albacete, Spain\n* useR! 2014, Los Angeles, California, USA\n* useR! 2015, Aalborg, Denmark\n* useR! 2016, Stanford, California, USA\n* useR! 2017, Brussels, Belgium\n* useR! 2018, Brisbane, Australia\n\nFuture conferences planned are as follows:<ref name=\"user\" />\n\n* useR! 2019, Toulouse, France\n* useR! 2020, St. Louis, Missouri, USA\n\n== ''The R Journal'' ==\n''[[The R Journal]]'' is the [[open access]], [[Academic journal|refereed]] journal of the R project for statistical computing. It features short to medium length articles on the use, and development of R, including packages, programming tips, CRAN news, and foundation news.\n\n== Comparison with SAS, SPSS, and Stata ==\nR is comparable to popular commercial statistical packages, such as [[SAS (software)|SAS]], [[SPSS]], and [[Stata]], but R is available to users at no charge under a [[free software license]].<ref>{{cite web|url=http://www.burns-stat.com/pages/Tutor/R_relative_statpack.pdf|title= Comparison of R to SAS, Stata and SPSS|first=Patrick|last=Burns|date=27 February 2007|accessdate=2013-09-18}}</ref>\n\nIn January 2009, the ''[[New York Times]]'' ran an article charting the growth of R, the reasons for its popularity among data scientists and the threat it poses to commercial statistical packages such as SAS.{{refn | R as competition for commercial statistical packages\n* {{cite news| url=https://www.nytimes.com/2009/01/07/technology/business-computing/07program.html | work=The New York Times | first=Ashlee | last=Vance | title=Data Analysts Are Mesmerized by the Power of Program R: [Business/Financial Desk] | date=2009-01-07}}\n* {{cite news| url=http://bits.blogs.nytimes.com/2009/01/08/r-you-ready-for-r/ | work=The New York Times | first=Ashlee | last=Vance | title=R You Ready for R? | date=2009-01-08}}\n}}  In June 2017 data scientist Robert Muenchen published a more in-depth comparison between R and other software packages, \"The Popularity of Data Science Software\"<ref>{{cite web|url=http://r4stats.com/articles/popularity/|title= The Popularity of Data Science Software|first=Robert|last=Muenchen |date=19 June 2017|accessdate=2018-11-21}}</ref>.\n\n== Commercial support for R ==\n{{anchor|Commercialised versions of R}} <!--used in https://cran.r-project.org/doc/FAQ/R-FAQ.html#What-is-R_002dplus_003f-->\nAlthough R is an open-source project supported by the community developing it, some companies strive to provide commercial support and/or extensions for their customers. This section gives some examples of such companies.\n\nIn 2007, Richard Schultz, Martin Schultz, Steve Weston and Kirk Mettler founded [[Revolution Analytics]] to provide commercial support for Revolution R, their distribution of R, which also includes components developed by the company. Major additional components include: ParallelR, the R Productivity Environment IDE, RevoScaleR (for [[big data]] analysis), RevoDeployR, web services framework, and the ability for reading and writing data in the SAS file format.<ref name=\"prickett\">Morgan, Timothy Prickett (2011-02-07). \"'Red Hat for stats' goes toe-to-toe with SAS\". The Register, 7 February 2011. Retrieved from https://www.theregister.co.uk/2011/02/07/revolution_r_sas_challenge/.</ref> Revolution Analytics also offer a distribution of R designed to comply with established [[Verification and validation|IQ/OQ/PQ]] criteria which enables clients in the pharmaceutical sector to validate their installation of REvolution R.<ref>{{Cite web|url= http://blog.revolutionanalytics.com/2009/01/analyzing-clinical-trial-data-with-r.html|title= Analyzing clinical trial data for FDA submissions with R|date= January 14, 2009|website= |publisher= Revolution Analytics|access-date=2018-09-20}}</ref> In 2015, Microsoft Corporation completed the acquisition of Revolution Analytics.<ref name=\"Machine Learning Blog\">{{cite web|last1= Sirosh|first1= Joseph|title= Microsoft Closes Acquisition of Revolution Analytics|url= http://blogs.technet.com/b/machinelearning/archive/2015/04/06/microsoft-closes-acquisition-of-revolution-analytics.aspx|website= blogs.technet.com|publisher= Microsoft|accessdate=2018-09-20}}</ref> and has since integrated the R programming language into SQL Server 2016, SQL Server 2017, Power BI, Azure SQL Database, Azure Cortana Intelligence, Microsoft R Server and Visual Studio 2017.<ref>{{Cite news|url=https://blogs.msdn.microsoft.com/visualstudio/2016/03/22/introducing-r-tools-for-visual-studio-3/|title=Introducing R Tools for Visual Studio|access-date=2018-09-20|language=en-US}}</ref>\n\nIn October 2011, [[Oracle Corporation|Oracle]] announced the ''Big Data Appliance'', which integrates R, [[Apache Hadoop]], [[Oracle Linux]], and a [[NoSQL]] database with [[Exadata]] hardware.{{refn | Oracle Corporation's Big Data Appliance\n* Doug Henschen (2012); [http://www.informationweek.com/software/information-management/oracle-makes-big-data-appliance-move-wit/232400021 ''Oracle Makes Big Data Appliance Move With Cloudera''], InformationWeek, January 10, 2012.\n* Jaikumar Vijayan (2012); [http://www.computerworld.com/s/article/9223325/Oracle_s_Big_Data_Appliance_brings_focus_to_bundled_approach ''Oracle's Big Data Appliance brings focus to bundled approach''], ComputerWorld, January 11, 2012.\n* Timothy Prickett Morgan (2011); [https://www.theregister.co.uk/2011/10/03/oracle_big_data_appliance/ Oracle rolls its own NoSQL and Hadoop ''Oracle rolls its own NoSQL and Hadoop''], The Register, October 3, 2011.\n}} {{As of | 2012}}, [[Oracle R Enterprise]]<ref name=OracleRabc>Chris Kanaracus (2012); [http://www.pcworld.com/article/249509/oracle_stakes_claim_in_r_with_advanced_analytics_launch.html ''Oracle Stakes Claim in R With Advanced Analytics Launch''], PC World, February 8, 2012.</ref> became one of two components of the \"Oracle Advanced Analytics Option\"<ref name=OracleAAO>Doug Henschen (2012); [http://www.informationweek.com/software/business-intelligence/oracle-makes-its-big-play-for-analytics/232800252 ''Oracle Stakes Claim in R With Advanced Analytics Launch''], InformationWeek, April 4, 2012.</ref> (alongside [[Oracle Data Mining]]).{{citation needed|date= January 2016}}\n\n[[IBM]] offers support for in-[[Hadoop]] execution of R,<ref>{{cite web|title= What's New in IBM InfoSphere BigInsights v2.1.2|url= http://www-01.ibm.com/software/data/infosphere/biginsights/whats_new.html|publisher= IBM|accessdate= 8 May 2014|deadurl= yes|archiveurl= https://web.archive.org/web/20140906200802/http://www-01.ibm.com/software/data/infosphere/biginsights/whats_new.html|archivedate= 6 September 2014|df= dmy-all}}</ref> and provides a programming model for massively parallel in-database analytics in R.<ref>{{cite web|title= IBM PureData System for Analytics|url= http://mainline.com/_web/_shared/pdfs/brochures/IBM-PureData-System-Overview.pdf|publisher= IBM|accessdate= 2014-05-08|deadurl= yes|archiveurl= https://web.archive.org/web/20140517153029/http://mainline.com/_web/_shared/pdfs/brochures/IBM-PureData-System-Overview.pdf|archivedate= 17 May 2014|df= dmy-all}}</ref>\n\nTibco offers a runtime-version R as a part of [[Spotfire]].<ref>\n{{cite web\n|url= http://spotfire.tibco.com/discover-spotfire/what-does-spotfire-do/predictive-analytics/tibco-enterprise-runtime-for-r-terr\n|title= Unleash the agility of R for the Enterprise\n|author= Tibco|accessdate= 2014-05-15\n}}\n</ref>\n\nMango offers a validation package for R, ValidR,<ref>\n{{cite web\n|url= https://www.mango-solutions.com/data-science/products/valid-r/\n|title= ValidR on Mango website\n|accessdate=2018-09-24\n}}\n</ref><ref>\n{{cite web\n|url= https://www.lexjansen.com/phuse/2016/ad/AD12.pdf\n|title= ValidR Enterprise: Developing an R Validation Framework\n|author= Andy Nicholls at Mango Solutions|accessdate=2018-09-24\n}}\n</ref> to make it compliant with drug approval agencies, like FDA. These agencies allow for the use of any statistical software in submissions, if only the software is validated, either by the vendor or sponsor itself.<ref>{{cite web |url= https://www.fda.gov/downloads/ForIndustry/DataStandards/StudyDataStandards/UCM587506.pdf |title= Statistical Software Clarifying Statement |author= FDA |accessdate=2018-09-24}}</ref>\n\n== Examples ==\n\n=== Basic syntax ===\nThe following examples illustrate the basic [[programming language syntax|syntax of the language]] and use of the command-line interface.\n\nIn R, the generally preferred{{refn | most used assignment operator in R is <code><-</code>\n* {{cite web|title=Writing R Extensions|url=https://cran.r-project.org/doc/manuals/R-exts.html#Tidying-R-code|accessdate=2018-09-11|author=R Development Core Team|quote=[...] we recommend the consistent use of the preferred assignment operator ‘<-’ (rather than ‘=’) for assignment.}}\n* {{cite web|title=Google's R Style Guide|url=https://google.github.io/styleguide/Rguide.xml#assignment|accessdate=2018-09-11}}\n* {{cite web|last=Wickham|first=Hadley|title=Style Guide|url=http://stat405.had.co.nz/r-style.html|accessdate=2018-09-11}}\n* {{cite web|last=Bengtsson|first=Henrik|title=R Coding Conventions (RCC)  – a draft|url=https://docs.google.com/document/preview?id=1esDVxyWvH8AsX-VJa-8oqWaHLs4stGlIbk8kLc5VlII&pli=1|accessdate=2018-09-11|date=January 2009}}\n}} [[Assignment (computer science)|assignment operator]] is an arrow made from two characters <code><-</code>, although <code>=</code> can usually be used instead.<ref>{{cite web|author=R Development Core Team|title=Assignments with the = Operator|url=https://developer.r-project.org/equalAssign.html|accessdate=2018-09-11}}</ref>\n<source lang=\"rout\">\n> x <- 1:6  # Create vector.\n> y <- x^2  # Create vector by formula.\n> print(y)  # Print the vector’s contents.\n[1]  1  4  9 16 25 36\n\n> mean(y)  # Arithmetic mean of vector.\n[1] 15.16667\n\n> var(y)  # Sample variance of vector.\n[1] 178.9667\n\n> model <- lm(y ~ x)  # Linear regression model y = A + B * x.\n> print(model)  # Print the model’s results.\n\nCall:\nlm(formula = y ~ x)\n\nCoefficients:\n(Intercept)            x  \n     -9.333        7.000  \n\n> summary(model)  # Display an in-depth summary of the model.\n\nCall:\nlm(formula = y ~ x)\n\nResiduals:\n      1       2       3       4       5       6 \n 3.3333 -0.6667 -2.6667 -2.6667 -0.6667  3.3333 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -9.3333     2.8441  -3.282 0.030453 *  \nx             7.0000     0.7303   9.585 0.000662 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 3.055 on 4 degrees of freedom\nMultiple R-squared:  0.9583,\tAdjusted R-squared:  0.9478 \nF-statistic: 91.88 on 1 and 4 DF,  p-value: 0.000662\n\n> par(mfrow = c(2, 2))  # Create a 2 by 2 layout for figures.\n> plot(model)  # Output diagnostic plots of the model.\n</source>\n\n[[File:Plots from lm example.svg|Diagnostic plots from plotting “model” (q.v. “plot.lm()” function). Notice the mathematical notation allowed in labels (lower left plot).]]\n\n=== Structure of a function ===\nOne of R’s strengths is the ease of creating new functions. Objects in the function body remain local to the function, and any data type may be returned.<ref>{{cite web|url=http://www.statmethods.net/management/userfunctions.html|title=Quick-R: User-Defined Functions|first=Robert|last=Kabacoff|year=2012|accessdate=2018-09-28|website=statmethods.net}}</ref>\nHere is an example user-created function:\n<source lang=\"r\">\n# Declare function “f” with parameters “x”, “y“\n# that returns a linear combination of x and y.\nf <- function(x, y) {\n  z <- 3 * x + 4 * y\n  return(z)\n}\n</source>\n<source lang=\"rout\">\n> f(1, 2)\n[1] 11\n\n> f(c(1,2,3), c(5,3,4))\n[1] 23 18 25\n\n> f(1:3, 4)\n[1] 19 22 25\n</source>\n\n=== Mandelbrot set ===\nShort R code calculating [[Mandelbrot set]] through the first 20 iterations of equation ''z'' = ''z''<sup>2</sup> + ''c'' plotted for different complex constants ''c''.  This example demonstrates:\n\n* use of community-developed external libraries (called packages), in this case caTools package\n* handling of [[complex numbers]]\n* multidimensional arrays of numbers used as basic data type, see variables <code>C</code>, <code>Z</code> and <code>X</code>.\n\n<source lang=\"r\">\ninstall.packages(\"caTools\")  # install external package\nlibrary(caTools)             # external package providing write.gif function\njet.colors <- colorRampPalette(c(\"red\", \"blue\", \"#007FFF\", \"cyan\", \"#7FFF7F\",\n                                 \"yellow\", \"#FF7F00\", \"red\", \"#7F0000\"))\ndx <- 1500                    # define width\ndy <- 1400                    # define height\nC  <- complex(real = rep(seq(-2.2, 1.0, length.out = dx), each = dy),\n              imag = rep(seq(-1.2, 1.2, length.out = dy), dx))\nC <- matrix(C, dy, dx)       # reshape as square matrix of complex numbers\nZ <- 0                       # initialize Z to zero\nX <- array(0, c(dy, dx, 20)) # initialize output 3D array\nfor (k in 1:20) {            # loop with 20 iterations\n  Z <- Z^2 + C               # the central difference equation\n  X[, , k] <- exp(-abs(Z))   # capture results\n}\nwrite.gif(X, \"Mandelbrot.gif\", col = jet.colors, delay = 100)\n</source>\n\n[[File:Mandelbrot Creation Animation.gif|400px|\"Mandelbrot.gif\" – graphics created in R with 14 lines of code in Example 2]]\n\n== See also ==\n{{Portal|Free and open-source software|Computer programming}}\n\n* [[Comparison of numerical analysis software]]\n* [[Comparison of statistical packages]]\n* [[List of numerical analysis software]]\n* [[List of statistical packages]]\n* [[Rmetrics]]\n* [[RStudio]]\n* [[Statcheck]]\n{{Clear}}\n\n== References ==\n{{reflist|30em}}\n\n== External links ==\n{{Sister project links|b=R Programming|v=How to use R|commons=Category:GNU R|wikt=no|n=no|s=no|q=no}}\n* {{official website}} of the R project\n\n\n{{GNU}}\n{{Numerical analysis software}}\n{{Statistical software}}\n{{Programming languages}}\n\n{{Authority control}}\n\n[[Category:Array programming languages]]\n[[Category:Cross-platform free software]]\n[[Category:Data mining and machine learning software]]\n[[Category:Data-centric programming languages]]\n[[Category:Dynamically typed programming languages]]\n[[Category:Free plotting software]]\n[[Category:Free statistical software]]\n[[Category:Functional languages]]\n[[Category:GNU Project software]]\n[[Category:Literate programming]]\n[[Category:Numerical analysis software for Linux]]\n[[Category:Numerical analysis software for MacOS]]\n[[Category:Numerical analysis software for Windows]]\n[[Category:Programming languages created in 1993]]\n[[Category:R (programming language)| ]]\n[[Category:Science software]]\n\n[[Category:Statistical programming languages]]"
    },
    {
      "title": "Renjin",
      "url": "https://en.wikipedia.org/wiki/Renjin",
      "text": "{{more citations needed|date=January 2016}}\n\n{{Infobox software\n| name                   = Renjin\n| screenshot             =\n| caption                =\n| developer              = Alexander Bertram\n| released               = {{Start date and age|2010}}\n| latest release version = 0.8\n| latest release date    = {{release date|2015|11|13}}\n| latest preview version = \n| latest preview date    = \n| operating system       = [[Cross-platform]]\n| platform               = [[Java Virtual Machine]]\n| programming language   = [[R (programming language)|R]] and [[Java (programming language)|Java]]\n| genre                  = R programming language interpreter\n| license                = [[GNU General Public License|GPL]]\n| website                = {{url|http://www.renjin.org/}}\n|status = Active}}\n'''Renjin''' is an implementation of the [[R (programming language)|R programming language]] atop the [[Java Virtual Machine]]. It is [[free software]] released under  the [[GNU General Public License|GPL]]. Renjin is tightly integrated with [[Java (programming language)|Java]] to allow the embedding of the interpreter into any Java application with full two-way access between the Java and R code.\n\nRenjin's development is primarily supported by [[BeDataDriven]], but ultimately made possible by several current and past contributors including Mehmet Hakan Satman,\nHannes Mühleisen, and Ruslan Shevchenko.\n\n==History==\nRenjin's roots lie in an abortive 2010 attempt to compile the GNU R interpreter for the JVM via nestedvm,<ref>{{cite web\n| url=http://code.google.com/p/r4jvm/\n| title=R4JVM\n| date=2010-07-02\n| last=Bertram|first=Alex\n| accessdate=2016-01-22}}</ref> a toolchain which involves cross-compiling C and Fortran code to a static MIPS binary, which nestedvm\ncan then translate to JVM bytecode. This proved challenging as GNU R had grown to rely heavily on dynamic linking and the best C standard library\nimplementation available at the time for the MIPS architecture, [[Newlib]], was not fully compatible with the [[GNU C Library]], against which\nGNU R had been developed.\n\nThe experience with the R4JVM project provided the BeDataDriven team with in depth look at the GNU R codebase, and convinced them\nthat a new implementation, written in Java, was a feasible undertaking. Development on Renjin began in October 2010, and rapidly resulted in \na functional, if minimal, interpreter for the R language.\n\n==References==\n{{Reflist|colwidth=30em}}\n\n==External links==\n*{{official website|http://www.renjin.org}}\n\n[[Category:Free software programmed in Java (programming language)]]\n[[Category:JVM programming languages]]\n[[Category:Scripting languages]]\n[[Category:R (programming language)| ]]\n[[Category:Cross-platform free software]]\n[[Category:Array programming languages]]\n[[Category:Dynamically typed programming languages]]\n[[Category:Functional languages]]\n[[Category:Data-centric programming languages]]\n[[Category:Free statistical software]]\n[[Category:Literate programming]]\n[[Category:Numerical analysis software for Linux]]\n[[Category:Numerical analysis software for MacOS]]\n[[Category:Numerical analysis software for Windows]]\n[[Category:Data mining and machine learning software]]\n[[Category:Free data visualization software]]"
    },
    {
      "title": "Scilab",
      "url": "https://en.wikipedia.org/wiki/Scilab",
      "text": "{{More citations needed|date=April 2009}}\n\n{{Infobox software\n| name                   = Scilab\n| screenshot             = [[Image:Screenshot scilab 3.png|300px|A screenshot of Scilab running]]\n| caption                = A screenshot of Scilab running\n| developer              = Scilab Enterprises\n| latest release version = 6.0.2\n| latest release date    = {{release date and age|2019|02|14|df=yes}}<ref>{{cite web | url=http://www.scilab.org/index.php/en/community/news/scilab601 | title=Scilab 6.0.2 Release | date=Feb 14, 2019 }}</ref>\n| programming language   = Scilab, [[C (programming language)|C]], [[C++]], [[Java (programming language)|Java]], [[Fortran]]\n| operating system       = [[BSD]]s (e.g., [[FreeBSD]]), [[Linux]], [[macOS]], [[Microsoft Windows|Windows]]\n| language               = [[English language|English]], [[German language|German]], [[Spanish language|Spanish]], [[French language|French]], [[Italian language|Italian]], [[Japanese language|Japanese]], [[Portuguese language|Portuguese&nbsp;(Brazil)]], [[Russian language|Russian]], [[Ukrainian language|Ukrainian]], [[Chinese language|Chinese]], [[Czech language|Czech]], [[Polish language|Polish]]\n| genre                  = [[List of numerical analysis software|Technical computing]]\n| license                = [[GPLv2]], previously [[CeCILL]]\n| website                = {{URL|http://www.scilab.org}}, {{URL|https://scilab.io}}\n}}\n\n'''Scilab''' is a [[free and open-source]], cross-platform [[Numerical analysis|numerical computational]] package and a [[High-level programming language|high-level]], numerically oriented [[programming language]].  It\ncan be used for [[signal processing]], [[statistical analysis]], [[image processing|image enhancement]], [[fluid dynamics]] simulations, [[Optimization (mathematics)|numerical optimization]], and modeling, simulation of explicit and implicit [[dynamical system]]s and (if the corresponding toolbox is installed) symbolic manipulations.\n\nScilab is one of the two major open-source alternatives to [[MATLAB]], the other one being [[GNU Octave]].<ref name=\"Trappenberg2010\">{{cite book|author=Thomas Trappenberg|title=Fundamentals of Computational Neuroscience|year=2010|publisher=Oxford University Press|isbn=978-0-19-956841-3|page=361}}</ref><ref name=\"MuhammadZalizniak2011\">{{cite book|author1=A Muhammad|author2=V Zalizniak|title=Practical Scientific Computing|year=2011|publisher=[[Woodhead Publishing]]|isbn=978-0-85709-226-7|page=3}}</ref><ref name=\"MegreyMoksness2008\">{{cite book|author1=Bernard A. Megrey|author2=Erlend Moksness|title=Computers in Fisheries Research|year=2008|publisher=Springer Science & Business Media|isbn=978-1-4020-8636-6|page=345}}</ref><ref name=\"Kapuno2008\">{{cite book|author=Raul Raymond Kapuno|title=Programming for Chemical Engineers Using C, C++, and MATLAB|year=2008|publisher=Jones & Bartlett Publishers|isbn=978-1-934015-09-4|page=365}}</ref> Scilab puts less emphasis on syntactic compatibility with MATLAB than Octave does,<ref name=\"Trappenberg2010\"/><ref name=\"Herman2013\">{{cite book|author=Russell L. Herman|title=A Course in Mathematical Methods for Physicists|year=2013|publisher=CRC Press|isbn=978-1-4665-8467-9|page=42}}</ref><ref name=\"WouwerSaucez2014\">{{cite book|author1=Alain Vande Wouwer|author2=Philippe Saucez|author3=Carlos Vilas|title=Simulation of ODE/PDE Models with MATLAB®, OCTAVE and SCILAB: Scientific and Engineering Applications|year=2014|publisher=Springer|isbn=978-3-319-06790-2|pages=114–115}}</ref> but it is similar enough that some authors suggest that it is easy to transfer skills between the two systems.<ref name=\"Haidekker2013\">{{cite book|author=Mark A. Haidekker|title=Linear Feedback Controls: The Essentials|year=2013|publisher=Newnes|isbn=978-0-12-405513-1|page=3}}</ref>\n\n==Overview==\n\nScilab is a [[High-level programming language|high-level]], numerically oriented [[programming language]]. The language provides an [[interpreted language|interpreted]] programming environment, with [[matrix (mathematics)|matrices]] as the main [[data type]]. By using matrix-based computation, [[dynamic typing]], and [[Garbage collection (computer science)|automatic memory management]], many numerical problems may be expressed in a reduced number of code lines, as compared to similar solutions using traditional languages, such as [[Fortran]], [[C (programming language)|C]], or [[C++]]. This allows users to rapidly construct [[computer simulation|models]] for a range of mathematical problems. While the language provides simple matrix operations such as multiplication, the Scilab package also provides a library of high-level operations such as [[correlation]] and complex multidimensional arithmetic. The software can be used for [[signal processing]], [[statistical analysis]], [[image processing|image enhancement]], [[fluid dynamics]] simulations, and [[Optimization (mathematics)|numerical optimization]].<ref>{{cite web |title=Modelling and simulation of multitechnological machine systems|url=http://www.vtt.fi/inf/pdf/symposiums/2001/S209.pdf|last=Holopainen|first=Timo|year=2000 }}</ref><ref>{{cite book|title=An improved genetic algorithm for the multiconstrained 0-1 knapsackproblem|journal=Evolutionary Computation Proceedings|date=May 1998|first=Raidl|last=Guenther|isbn=978-0-7803-4869-1|doi=10.1109/ICEC.1998.699502|pages=207–211|citeseerx=10.1.1.20.6454}}</ref><ref>{{Cite book|title=Scilab : I. Fundamentals, from theory to practice|last=Philippe.|first=Roux|publisher=|isbn=9782822702935|location=Paris, France|pages=|oclc=1003630046|date = 2016-03-29}}</ref>\n\nScilab also includes a free package called [[Xcos]] (a fork of [[Scicos]] based on [[Modelica]] language) for modeling and simulation of explicit and implicit [[dynamical system]]s, including both continuous and discrete sub-systems. Xcos is the open source equivalent to [[Simulink]] from [[the MathWorks]].\n\nAs the [[syntax]] of Scilab is similar to [[MATLAB]], Scilab includes a source code translator for assisting the conversion of code from MATLAB to Scilab. Scilab is available free of cost under an [[open source license]]. Due to the open source nature of the software, some user contributions have been integrated into the main program.\n\n== License ==\nScilab family 5 & 6 are distributed under the [[GNU General Public License|GPL]]-compatible [[CeCILL]] license.\n\nPrior to version 5, Scilab was [[semi-free software]] according to the nomenclature of the [[Free Software Foundation]]. The reason for this is that earlier versions' licenses prohibited commercial distribution of modified versions of Scilab.\n\n== Syntax ==\nScilab [[syntax]] is largely based on the [[MATLAB]] language. The simplest way to execute Scilab code is to type it in at the [[command-line interface|prompt]], <code>--> </code>, in the graphical command window. In this way, Scilab can be used as an interactive mathematical [[command line interpreter|shell]].\n\n[[Hello World!]] in Scilab:\n<source lang=\"scilab\">\ndisp('Hello World');\n</source>\n\nPlotting a 3D surface function:\n<source lang=\"scilab\">\n// A simple plot of z = f(x,y)\nt=[0:0.3:2*%pi]';\nz=sin(t)*cos(t');\nplot3d(t,t',z)\n</source>\n\n== LaTeX engine ==\nScilab renders formulas in mathematical notation using its own Java-based rendering engine, [[JLaTeXMath]],<ref>[http://forge.scilab.org/index.php/p/jlatexmath/ JLaTeXMath project]</ref> a fork of the JMathTeX project.<ref>[http://jmathtex.sourceforge.net/ JMathTex SourceForge page]</ref>\n\n== Toolboxes ==\nScilab has many contributed toolboxes for different tasks, such as\n* [[Scilab Image Processing]] Toolbox (SIP) and its variants (such as SIVP)\n* Scilab Wavelet Toolbox\n* Scilab Java and .NET Module\n* Scilab Remote Access Module\n\nMore are available on ATOMS Portal or the Scilab forge.\n\n== History ==\n\nScilab was created in 1990 by researchers from [[Institut National de Recherche en Informatique et en Automatique|INRIA]] and [[École nationale des ponts et chaussées]] (ENPC). It was initially named '''Ψlab'''<ref>{{Cite web | url=http://raweb.inria.fr/rapportsactivite/RA94/meta2/META2.3.1.1.html | title=META2.3.1.1.html META2.3.1.1}}</ref> ''(Psilab)''. The Scilab Consortium was formed in May 2003 to broaden contributions and promote Scilab as worldwide reference software in academia and industry.<ref>{{cite web | title=SCILAB Consortium launched | url=http://www.ercim.org/publication/Ercim_News/enw54/gomez.html | year=2003 }}</ref> In July 2008, in order to improve the technology transfer, the Scilab Consortium joined the Digiteo Foundation.\n\nScilab 5.1, the first release compiled for Mac, was available in early 2009, and supported [[Mac OS X 10.5]], a.k.a. Leopard. Thus, OSX 10.4, Tiger, was never supported except by porting from sources. Linux and Windows builds had been released since the beginning, with Solaris support dropped with version 3.1.1, and HP-UX dropped with version 4.1.2 after spotty support.\n\nIn June 2010, the Consortium announced the creation of Scilab Enterprises.<ref>{{cite web |url=http://www.scilab.org/aboutus/pressroom/press_release/pr_20100602 |title=SCILAB Enterprises announced |year=2010 |deadurl=yes |archiveurl=https://archive.is/20100620181929/http://www.scilab.org/aboutus/pressroom/press_release/pr_20100602 |archivedate=2010-06-20 |df= }}</ref>  Scilab Enterprises develops and markets, directly or through an international network of affiliated services providers, a comprehensive set of services for Scilab users. Scilab Enterprises also develops and maintains the Scilab software. The ultimate goal of Scilab Enterprises is to help make the use of Scilab more effective and easy.\n\nIn February 2017 Scilab 6.0.0 was released which leveraged the latest C++ standards and lifted memory allocation limitations.\n\nSince July 2012, Scilab is developed and published by Scilab Enterprises and in early 2017 Scilab Enterprises was acquired by Virtual Prototyping pioneer [[ESI Group]]<ref>{{Cite web |url=https://finance.yahoo.com/news/esi-group-acquisition-scilab-enterprises-074500256.html |title=Archived copy |access-date=2017-08-24 |archive-url=https://web.archive.org/web/20170824181417/https://finance.yahoo.com/news/esi-group-acquisition-scilab-enterprises-074500256.html# |archive-date=2017-08-24 |dead-url=yes |df= }}</ref>\n\n== Scilab Cloud App & Scilab Cloud API ==\nSince 2016 Scilab can be embedded in a browser and be called via an interface written in Scilab or an API.\n\nThis new deployment method has the notable advantages of masking code & data as well as providing large computational power.<ref>{{Cite news|url=https://scilab.io/cloud/|title=Scilab Cloud|work=Scilab.io|access-date=2017-10-08|language=en-US}}</ref>\n\n== See also ==\n* [[SageMath]]\n* [[List of numerical analysis software]]\n* [[Comparison of numerical analysis software]]\n* [[SimulationX]]\n* [[ESI Group]]\n* [[Simulink]]\n* [[GNU Octave]]\n\n== References ==\n{{Reflist|30em}}\n\n=== Further reading ===\n* {{cite book | authors = Stephen L. Campbell, Jean-Philippe Chancelier, Ramine Nikoukhah| title = Modeling and Simulation in Scilab/Scicos | publisher = Springer | location = New York | year = 2006 | isbn = 978-0-387-27802-5 }}\n\n== External links ==\n* [http://www.scilab.org/ Scilab website]\n\n{{Commons}}\n\n{{Numerical analysis software}}\n\n{{Authority control}}\n\n[[Category:Array programming languages]]\n[[Category:Free educational software]]\n[[Category:Free mathematics software]]\n[[Category:Free software programmed in Fortran]]\n[[Category:Numerical analysis software for Linux]]\n[[Category:Numerical analysis software for MacOS]]\n[[Category:Numerical analysis software for Windows]]\n[[Category:Numerical programming languages]]\n[[Category:Science software that uses GTK]]"
    },
    {
      "title": "SciPy",
      "url": "https://en.wikipedia.org/wiki/SciPy",
      "text": "{{short description|Python library}}\n{{Distinguish|ScientificPython}}\n{{Infobox software\n| name = SciPy\n| logo = Scipylogo.png\n| logo size = 200px\n| screenshot = Psd scipy.png\n| caption = PSD of ECG using SciPy\n| author = Travis Oliphant, Pearu Peterson, Eric Jones\n| developer = Community library project\n| released = Around {{Start date|2001}}\n| latest release version = 1.3.0\n| latest release date = {{Start date and age|2019|5|17|df=yes}}<ref name=\"github-releases\">{{cite web|url=https://github.com/scipy/scipy/releases|title=Releases - scipy/scipy|via=[[GitHub]]|accessdate=17 May 2019}}</ref>\n| latest preview version = 1.3.0rc2\n| latest preview date = {{start date and age|2019|5|9|df=yes}}<ref name=\"github-releases\" />\n| programming language = [[Python (programming language)|Python]], [[Fortran]], [[C (programming language)|C]], [[C++]]<ref>{{cite web\n    | title        = How can SciPy be fast if it is written in an interpreted language like Python?\n    | author       = SciPy Team\n    | url          = https://www.scipy.org/scipylib/faq.html#how-can-scipy-be-fast-if-it-is-written-in-an-interpreted-language-like-python\n    | accessdate   = 2013-12-23}}</ref>\n| operating system = [[Cross-platform]]\n| genre = [[List of numerical analysis software|Technical computing]]\n| license = [[BSD-new|BSD-new license]]\n}}\n\n'''SciPy''' (pronounced /ˈsaɪpaɪ'/ \"Sigh Pie\"<ref>https://scipy.org/ \"SciPy (pronounced \"Sigh Pie\")\"</ref>) is a [[free and open-source]] [[Python (programming language)|Python]] library used for [[scientific computing]] and technical computing.\n\nSciPy contains modules for [[Optimization (mathematics)|optimization]], [[linear algebra]], [[Integral|integration]], [[interpolation]], [[special functions]], [[Fast Fourier transform|FFT]], [[signal processing|signal]] and [[image processing]], [[ordinary differential equation|ODE]] solvers and other tasks common in science and engineering.\n\nSciPy builds on the [[NumPy]] array object and is part of the NumPy stack which includes tools like [[Matplotlib]], [[pandas (software)|pandas]] and [[SymPy]], and an expanding set of scientific computing libraries. This NumPy stack has similar users to other applications such as [[MATLAB]], [[GNU Octave]], and [[Scilab]]. The NumPy stack is also sometimes referred to as the SciPy stack.<ref>{{cite web|url=https://www.scipy.org/about.html|title=Scientific Computing Tools for Python|publisher=SciPy.org}}</ref>\n\nSciPy is also a family of conferences for users and developers of these tools: SciPy (in the United States), EuroSciPy (in Europe) and SciPy.in (in India).<ref>{{cite web|url=https://conference.scipy.org/index.html|title=SciPy Conferences}}</ref> [[Enthought]] originated the SciPy conference in the United States and continues to sponsor many of the international conferences as well as host the SciPy website.\n\nThe SciPy library is currently distributed under the [[BSD license]], and its development is sponsored and supported by an open community of developers. It is also supported by NumFOCUS, a community foundation for supporting reproducible and accessible science.\n\n==The SciPy Library/Package==\nThe SciPy package of key algorithms and functions core to Python's scientific computing capabilities. Available sub-packages include:\n* '''constants''': physical constants and conversion factors (since version 0.7.0<ref>{{cite web|url=http://sourceforge.net/project/shownotes.php?release_id=660191&group_id=27747|title=SciPy: Scientific Library for Python|publisher=[[SourceForge]]}}</ref>)\n* '''cluster''': hierarchical clustering, vector quantization, K-means\n* '''fftpack''': Discrete Fourier Transform algorithms\n* '''integrate''': numerical integration routines\n* '''interpolate''': interpolation tools\n* '''io''': data input and output\n* '''lib''': Python wrappers to external libraries\n* '''linalg''': linear algebra routines\n* '''misc''': miscellaneous utilities (e.g. image reading/writing)\n* '''ndimage''': various functions for multi-dimensional image processing\n* '''optimize''': optimization algorithms including linear programming\n* '''signal''': signal processing tools\n* '''sparse''': sparse matrix and related algorithms\n* '''spatial''': KD-trees, nearest neighbors, distance functions\n* '''special''': special functions\n* '''stats''': statistical functions\n* '''weave''': tool for writing C/C++ code as Python multiline strings\n[[File:Scipy source.png|thumb|Snapshot showing SciPy ndimage source code]]\n\n==Data structures==\nThe basic data structure used by SciPy is a multidimensional [[Array data structure|array]] provided by the [[NumPy]] module. NumPy provides some functions for linear algebra, [[Fourier transform]]s, and [[random number generation]], but not with the generality of the equivalent functions in SciPy. NumPy can also be used as an efficient multidimensional container of data with arbitrary datatypes. This allows NumPy to seamlessly and speedily integrate with a wide variety of databases. Older versions of SciPy used Numeric as an array type, which is now deprecated in favor of the newer NumPy array code.<ref>{{cite web|url=http://www.numpy.org/|title=NumPy Homepage}}</ref>\n\n==History==\nIn the 1990s, Python was extended to include an array type for numerical computing called Numeric (This package was eventually replaced by [[Travis Oliphant]] who wrote NumPy in 2006 as a blending of Numeric and Numarray which had been started in 2001). As of 2000, there was a growing number of extension modules and increasing interest in creating a complete environment for scientific and technical computing. In 2001, Travis Oliphant, Eric Jones, and Pearu Peterson merged code they had written and called the resulting package SciPy. The newly created package provided a standard collection of common numerical operations on top of the Numeric array data structure. Shortly thereafter, Fernando Pérez released IPython, an enhanced interactive shell widely used in the technical computing community, and John Hunter released the first version of Matplotlib, the 2D plotting library for technical computing. Since then the SciPy environment has continued to grow with more packages and tools for technical computing.<ref>{{cite web|url=https://wiki.scipy.org/History_of_SciPy|title=History of SciPy}}</ref><ref>{{cite web|url=http://csc.ucdavis.edu/~chaos/courses/nlp/Software/NumPyBook.pdf|title=Guide to NumPy}}</ref><ref>{{cite web|url=http://www.computer.org/csdl/mags/cs/2011/02/mcs2011020009.html|title=Python for Scientists and Engineers}}</ref>\n\n==See also==\n{{Portal|Free and open-source software}}\n* [[Comparison of numerical analysis software]]\n* [[List of numerical analysis software]]\n* [[Comparison of statistical packages]]\n* [[SageMath]]\n\n==Notes==\n{{Reflist}}\n\n==Further reading==\n*{{cite book |first=Juan |last=Nunez-Iglesias |first2=Stéfan |last2=van der Walt |first3=Harriet |last3=Dashnow |title=Elegant SciPy: The Art of Scientific Python |location= |publisher=O'Reilly |year=2017 |isbn=978-1-4919-2287-3 }}\n\n==External links==\n* {{official website}}\n\n{{SciPy ecosystem}}\n\n{{DEFAULTSORT:Scipy}}\n[[Category:Cross-platform software]]\n[[Category:Free science software]]\n[[Category:Numerical analysis software for Linux]]\n[[Category:Numerical analysis software for MacOS]]\n[[Category:Numerical analysis software for Windows]]\n[[Category:Numerical programming languages]]\n[[Category:Python scientific libraries]]\n[[Category:Software using the BSD license]]"
    },
    {
      "title": "JMP (statistical software)",
      "url": "https://en.wikipedia.org/wiki/JMP_%28statistical_software%29",
      "text": "{{good article}}\n{{Infobox software\n| name = JMP\n| logo = জাম্প লোগো.png\n| logo size = 250px\n| screenshot = \n| caption = \n| developer = [[SAS Institute]]\n| latest_release_version = Version 14\n| latest_release_date = {{Start date|2018|03}}\n| operating_system = [[Microsoft Windows|Windows]], [[Macintosh]]\n| genre = [[Statistical package]], [[Information visualization|visualization]], [[multivariate analysis]], [[genomics]], [[biomarkers]], [[Clinical trials|clinical]]\n| license = [[Proprietary software|Proprietary]]\n| website = {{URL|jmp.com}}\n}}\n\n'''JMP''' (pronounced \"jump\") is a suite of [[computer program]]s for [[statistical analysis]] developed by the JMP business unit of [[SAS Institute]]. It was launched in 1989<ref>{{cite web|title=About JMP|url=http://www.jmp.com/en_us/about.html|author=SAS Institute Inc.|accessdate=2 July 2016}}</ref> to take advantage of the graphical user interface introduced by the Macintosh. It has since been significantly rewritten and made available for the [[Windows]] operating system. JMP is used in applications such as [[Six Sigma]], [[quality control]], and engineering, [[design of experiments]], as well as for research in science, engineering, and social sciences.\n\nThe software can be purchased in any of five configurations: JMP, JMP Pro, JMP Clinical, JMP Genomics and the JMP Graph Builder App for the iPad. JMP can be automated with its proprietary scripting language, JSL. The software is focused on exploratory [[visual analytics]], where users investigate and explore data. These explorations can also be verified by [[hypothesis testing]], [[data mining]], or other analytic methods. In addition, discoveries made through graphical exploration can lead to a designed experiment that can be both designed and analyzed with JMP.\n\n==History==\n[[File:Version 1.0 of JMP 1989.png|thumb|left|Version 1.0 of JMP from 1989]]JMP was developed in the mid- to late-1980s by [[John Sall]] and a team of developers to make use of the graphical user interface introduced by the [[Apple Macintosh]].<ref name=\"CoxGaudard2009\">{{cite book|author1=Ian Cox|author2=Marie A. Gaudard|author3=Philip J. Ramsey|author4=Mia L. Stephens |author5=Leo Wright|title=Visual Six Sigma: Making Data Analysis Lean|url=https://books.google.com/books?id=xdg9nkBFh1UC&pg=PA23|accessdate=16 November 2012|date=21 December 2009|publisher=John Wiley & Sons|isbn=978-0-470-50691-2|pages=23–}}</ref> It originally stood for \"John's Macintosh Project\"<ref>[http://www.computerworld.com/article/2527824/business-intelligence/billionaire-sas-co-founder-keeps-on-coding.html Billionaire SAS co-founder keeps on coding]</ref><ref name=\"seven\">{{cite news|title=Proficiency in JMP®Visualization|first=Charles|last=Shipp|year=2012|accessdate=November 27, 2013|url=http://support.sas.com/resources/papers/proceedings12/277-2012.pdf}}</ref> and was first released in October 1989.<ref name=\"CoxGaudard2009\"/> It was used mostly by scientists and engineers for design of experiments (DOE), quality and productivity support (Six Sigma), and reliability modeling.<ref name=\"userg\">{{citation|first=Barbara|last=Okerson|location=SESUG 2011|title=JMPing In: A SAS Programmer's Look at JMP|url=http://analytics.ncsu.edu/sesug/2011/JP03.Okerson.pdf|accessdate=December 30, 2012}}</ref> Semiconductor manufacturers were also among JMP’s early adopters.<ref name=\"forty\"/>\n\nInteractive graphics and other features were added in 1991<ref name=\"APICS, the Performance Advantage\">{{cite book|title=APICS, the Performance Advantage|url=https://books.google.com/books?id=k1QgAQAAMAAJ|accessdate=30 December 2012|year=1991|publisher=American Production and Inventory Control Society}}</ref><ref name=\"fortyeight\">{{cite journal | last =Goodman | first =Arnold | title =JCGS@20, Visual@40, Interface@45 & !!Challenges!! | journal =Journal of Computational and Graphical Statistics | volume =20 | issue =4 | pages =818–829 | date =January 24, 2012 | doi=10.1198/jcgs.2011.204c}}</ref> with version 2.0. Version 2 was twice the size as the original, though it was still delivered on a floppy disk. It required 2 MB of memory and came with 700 pages of documentation.<ref name=\"Kim1992\">{{cite journal|last1=Kim|first1=Ki|title=JMP, Version 2. Software for Statistical Visualization on the Apple Macintosh|journal=Journal of Chemical Information and Modeling|volume=32|issue=2|year=1992|pages=174–175|issn=1549-9596|doi=10.1021/ci00006a600}}</ref> Support for [[Microsoft Windows]] was added with version 3.1 in 1994.<ref name=\"seven\"/><ref name=\"six\">{{citation|title=John P. Sall|publisher=Northern Illinois University|accessdate=November 16, 2012|url=http://www.niu.edu/clas/awards/awards_2010/honorees/sall.shtml|deadurl=yes|archiveurl=https://web.archive.org/web/20121205173316/http://www.niu.edu/clas/awards/awards_2010/honorees/sall.shtml|archivedate=December 5, 2012|df=}}</ref>  Rewritten with Version 4 and released in 2002, JMP could import data from a wider variety of data sources<ref name=\"number\">{{cite journal|last1=Altman|first1=Micah|title=A Review of JMP 4.03 With Special Attention to its Numerical Accuracy|journal=The American Statistician|volume=56|issue=1|year=2002|pages=72–75|issn=0003-1305|doi=10.1198/000313002753631402}}</ref> and added support for surface plots.<ref name=\"fortyeight\"/> Version 4 also added time series forecasting and new smoothing models, such as the seasonal smoothing method, called Winter's Method, and ARIMA (Autoregressive Integrated Moving Average). It was also the first version to support JSL, JMP Scripting Language.<ref>{{citation|title=Using JMP Version 4 for Time Series Analysis\n|first=Bill|last=Gjertsen|url=http://analytics.ncsu.edu/sesug/2000/s-61.pdf|publisher=North Carolina State University|accessdate=December 30, 2012}}</ref>\n\nIn 2005, data mining tools like a decision tree and neural net were added with version 5<ref>{{cite news|title=What Is A Data Mining Product?|url=http://www.information-management.com/issues/20030601/6798-1.html|newspaper=Information Management}}</ref> as well as Linux support, which was later withdrawn in JMP 9.<ref name=\"userg\"/> Later in 2005, JMP 6 was introduced.<ref name=\"forty\">{{cite news|first=John|last=Collins|newspaper=The Irish Times|title=Software Innovator helps companies get the facts straight|pages=8|date=September 23, 2005}}</ref><ref>{{citation|title=JMP Version 6 Featuring Split Plots|first=John|last=Sall|url=http://www2.sas.com/proceedings/sugi30/210-30.pdf|location=SUGI 30|accessdate=December 30, 2012}}</ref> JMP began integrating with SAS in version 7.0 in 2007 and has strengthened this integration ever since. Users can write SAS code in JMP, connect to SAS servers, and retrieve and use data from SAS. Support for bubble plots was added in version 7.<ref name=\"userg\"/><ref name=\"clinical\"/> JMP 7 also improved data visualization and diagnostics.<ref>{{cite news|first=John|last=Wass|publisher=Scientific Computing|title=JMP7: One of the best just got better|url=http://www.scientificcomputing.com/jmp-7-one-of-the-best-just-got.aspx|accessdate=May 9, 2012}}</ref>\n\nJMP 8 was released in 2009 with new drag-and-drop features and a 64-bit version to take advantage of advances in the Mac operating system.<ref>{{cite news|url=http://www.google.com/translate?hl=en&ie=UTF8&sl=auto&tl=en&u=http%3A%2F%2Fwww.diarioti.com%2Fnoticia%2FSAS_lanza_JMP_8_para_Mac%2F24733|title=Launches SAS JMP 8 for Mac and Linux|date=April 11, 2009|accessdate=December 30, 2012|newspaper=Ti Journal}}</ref> It also added a new user interface for building graphs, tools for choice experiments and support for Life Distributions.<ref>{{citation|work=A Technical Publication for JMP Users|publisher=JMPer Cable|title=Introducing JMP Version 8|date=Winter 2009|issue=25|accessdate=December 30, 2012|url=http://www.jmp.com/about/newsletters/jmpercable/pdf/25_winter_2009.pdf}}</ref> According to ''Scientific Computing'', the software had improvements in \"graphics, QA, ease-of-use, SAS integration and data management areas.\"<ref>{{cite news|first=John|last=Wass|publisher=Scientific Computing|title=JMP 8: Continuous Improvement|url=http://www.scientificcomputing.com/article-da-JMP8-Continuous-Improvement-051509.aspx|accessdate=November 16, 2012}}</ref> JMP 9 in 2010 added a new interface for using the [[R (programming language)|R programming language]] from JMP and an add-in for Excel.<ref>{{citation|title=New Features in JMP 9|url=http://www.jmp.com/support/downloads/pdf/jmp9/jmp9_new_features.pdf|publisher=JMP|accessdate=December 30, 2012}}</ref><ref>{{cite news|first=Adriian|url=http://www.drdobbs.com/tools/228200027?queryText=SAS%2BJMP|last=Bridgewater|newspaper=Dr. Dobb's Journal|title=JMP Genomics 5: Data Visualization & Exploration|date=November 3, 2010|accessdate=May 31, 2012}}</ref> The main screen was rebuilt and enhancements were made to simulations, graphics and a new Degradation platform.<ref>{{cite news|first=John|last=Wass|publisher=Scientific Computing|title=JMP 9: A really new version|accessdate=May 9, 2012|url=http://scientificcomputing.com/articles-DA-JMP-9-A-Really-New-Version-051211.aspx}}</ref> In March 2012, version 10 made improvements in data mining, predictive analytics, and automated model building.<ref>{{citation|url=http://www.pharmasug.org/proceedings/2012/DG/PharmaSUG-2012-DG01.pdf|work=PharmaSUG 2012|title=Proficiency in JMP Visualization|first=Charles|last=Shipp|first2=Kirk Paul|last2=Lafler|accessdate=December 30, 2012}}</ref><ref name=\"thirtyeight\">{{cite news|first=James|last=Taylor|publisher=JTonEDM|title=First Look – JMP Pro|date=August 10, 2011|accessdate=May 31, 2012|url=http://jtonedm.com/2011/08/10/first-look-jmp-pro/}}</ref>\n\nVersion 11 was released in late 2014. It included new ease-of-use features, an Excel import wizard, and advanced features for [[design of experiments]].<ref>{{cite web | last=Wass| first=John | title=JMP 11: Remarkable Statistics, Graphics and Integration | website=Scientific Computing | date=November 7, 2014 | url=http://www.scientificcomputing.com/articles/2014/11/jmp-11-remarkable-statistics-graphics-and-integration | accessdate=May 11, 2016}}</ref> Two years later, version 12.0 was introduced. According to ''Scientific Computing'', it added a new \"Modeling Utilities\" submenu of tools, performance improvements and new technical features for statistical analysis.<ref>{{cite web | last=Wass| first=John | title=JMP Pro 12: The Best Keeps Getting Better! | website=Scientific Computing | date=January 27, 2016 | url=http://www.scientificcomputing.com/articles/2016/01/jmp-pro-12-best-keeps-getting-better | accessdate=May 11, 2016}}</ref> Version 13.0 was released in September 2016 and introduced various improvements to reporting, ease-of-use and its handling of large data sets in memory.<ref name=\"on 2016\">{{cite web | author=on | title=First Look: SAS JMP 13 and JMP Pro 13 | website=JT on EDM — James Taylor on Everything Decision Management | date=November 10, 2016 | url=http://jtonedm.com/2016/11/10/first-look-sas-jmp-13-and-jmp-pro-13/ | accessdate=November 28, 2016}}</ref><ref name=\"Report Roy\">{{cite web | last=Report | first=Impact | last2=Roy | first2=Krishna | title=SAS JMP gets self-service data and text prep and analysis makeover | website=451 Research | url=https://451research.com/report-short?entityId=90656 | accessdate=November 28, 2016}}</ref>\n\n==Software==\n[[File:JMP data displays.png|thumb|right|250px|Screenshot of different data displays in JMP]]\nJMP consists of JMP, JMP Pro, JMP Clinical and JMP Genomics,<ref name=\"thirtyeight\"/> as well as the Graph Builder iPad App.<ref>{{citation|url=http://www.jmp.com/software/jmp10/jmp-graph-builder-for-ipad.shtml|publisher=SAS Institute|title=JMP Graph Builder for iPad|accessdate=December 30, 2012}}</ref> JMP Clinical and JMP Genomics combine JMP with SAS software.<ref name=\"thirtyeight\"/>\n\nJMP software is partly focused on exploratory data analysis and visualization. It is designed for users to investigate data to learn something unexpected, as opposed to confirming a hypothesis.<ref name=\"seven\"/><ref name=\"thirtyeight\"/><ref name=\"twentyfour\">{{cite news|title=SAS JMP 8 for the Macintosh review|url=http://www.macstats.org/reviews/jmp.html|publisher=Macstats|accessdate=November 19, 2012}}</ref> JMP links statistical data to graphics representing them, so users can drill down or up to explore the data and various visual representations of it.<ref name=\"number\"/><ref name=\"doi10.1002/wics.162\">{{Cite journal | last1 = Jones | first1 = B. | last2 = Sall | first2 = J. | doi = 10.1002/wics.162 | title = JMP statistical discovery software | journal = Wiley Interdisciplinary Reviews: Computational Statistics | volume = 3 | issue = 3 | pages = 188–194| year = 2011 | pmid =  | pmc = }}</ref><ref>{{cite book|author=Robert H. Carver|title=Practical Data Analysis with Jmp|url=https://books.google.com/books?id=iCTlfWYOmzcC&pg=PA61|accessdate=16 November 2012|date=30 July 2010|publisher=SAS Institute|isbn=978-1-60764-475-0|pages=61–}}</ref> Its primary applications are for designed experiments and analyzing statistical data from industrial processes.<ref name=\"forty\"/>\n\nJMP is a desktop application with a [[Wizard (software)|wizard]]-based user interface, while SAS can be installed on servers. It runs in-memory, instead of on disk storage.<ref name=\"thirtyeight\"/> According to a review in ''Pharmaceutical Statistics'', JMP is often used as a graphical front-end for a SAS system, which performs the statistical analysis and tabulations.<ref name=\"Lovell2011\"/> JMP Genomics, used for analyzing and visualizing genomics data,<ref>{{cite news|title=Commercial Data Mining Software|first=Qingyu|last=Zhang|author2=Richard S. Segall|newspaper=Computational Statistics|doi=10.1007/978-0-387-09823-4_65}}</ref> requires a SAS component to operate and can access SAS/Genetics and SAS/STAT procedures or invoke SAS macros.<ref name=\"Lovell2011\">{{cite journal|last1=Lovell|first1=David P.|title=Review of JMP genomics|journal=Pharmaceutical Statistics|volume=10|issue=4|year=2011|pages=384–392|issn=1539-1604|doi=10.1002/pst.460}}</ref> JMP Clinical, used for analyzing clinical trial data, can package SAS code within the JSL scripting language and convert SAS code to JMP.<ref name=\"clinical\">{{citation|title=JMP Clinical for the Exploration of Legacy Studies|first=Robert|last=Huisden|year=2011|accessdate=December 30, 2012|url=http://www.phusewiki.org/docs/2011%20Papers/PP06%20paper.pdf }}</ref>\n\nJMP is also the name of the SAS Institute business unit that develops JMP. As of 2011 it had 180 employees and 250,000 users.<ref name=\"thirtyeight\"/>\n\n==JMP Scripting Language (JSL)==\nThe JMP Scripting Language (JSL) is an interpreted language for recreating analytic results and for automating or extending the functionality of JMP software.<ref name=\"Publishing2012\">{{cite book|author=SAS Publishing|title=Jmp 10 Scripting Guide|url=https://books.google.com/books?id=oOb3ejkFiIUC|accessdate=13 December 2012|date=1 March 2012|publisher=SAS Institute|isbn=978-1-61290-195-4}}</ref>{{rp|29}} JSL was first introduced in JMP version 4 in 2000.<ref name=\"MurphreyLucas2009\">{{cite book|author1=Wendy Murphrey|author2=Rosemary Lucas|title=Jump Into Jmp Scripting|url=https://books.google.com/books?id=Wd6p3YrbDi8C|accessdate=14 December 2012|date=26 August 2009|publisher=SAS Institute|isbn=978-1-59994-658-0}}</ref>{{rp|1}} JSL has a LISP-like syntax, structured as a series of expressions. All programming elements, including if-then statements and loops, are implemented as JSL functions. Data tables, display elements and analyses are represented by objects in JSL that are manipulated with named messages. Users may write JSL scripts to perform analyses and visualizations not available in the point-and-click interface or to automate a series of commands, such as weekly reports.<ref name=\"Publishing2012\"/> SAS, R, and Matlab code can also be executed using JSL.<ref name=\"PublishingInstitute2009\">{{cite book|author1=Publishing SAS Publishing|author2=SAS Institute|title=JMP Release 8 User Guide|url=https://books.google.com/books?id=T_mJXz7xzo8C&pg=PA392|accessdate=13 December 2012|date=December 11, 2009|publisher=SAS Institute|isbn=978-1-60764-301-2|pages=392–}}</ref>\n\n==Notable applications==\n[[File:Wildtrack FIT JMP.png|thumb|175px|JMP being used in the WildTrack FIT system]]\nIn 2007, a wildlife monitoring organization, WildTrack, started using JMP with the Footprint Identification Technology (FIT) system to identify individual endangered animals by their footprints.<ref>{{cite news|first=Mary|last=Hayes Weier|newspaper=InformationWeek|url=http://www.informationweek.com/news/200000512|archive-url=https://archive.is/20130126070615/http://www.informationweek.com/news/200000512|dead-url=yes|archive-date=January 26, 2013|title=Scientists use BI Software and Intuit Trackers to Gauge Polar Bear Populations|date=June 25, 2007|accessdate=May 25, 2012}}</ref> In 2009, the Chicago Botanic Garden used JMP to analyze DNA data from tropical breadfruit. Researchers determined that the seedless, starchy fruit was created by the deliberate hybridization of two fruits, the breadnut and the dugdug.<ref name=\"Lai 2009\">{{cite web | last=Lai | first=Eric | title=Billionaire SAS co-founder keeps on coding | website=Computerworld | date=September 18, 2009 | url=http://www.computerworld.com/article/2527824/business-intelligence/billionaire-sas-co-founder-keeps-on-coding.html | accessdate=May 13, 2016}}</ref> The Herzenberg Laboratory at Stanford has integrated JMP with the Fluorescence Activated Cell Sorter (FACS). The FACS system is used to study HIV, cancer, stem-cells and oceanography.<ref name=\"ten\">{{cite news|work=The Computerworld Honors Program|title=Advancements in FACS System for Clinical Studies|accessdate=December 15, 2011|url=http://cwhonors.org/viewCaseStudy2010.asp?NominationID=132&Username=hlsu|deadurl=yes|archiveurl=https://web.archive.org/web/20111105125748/http://cwhonors.org/viewCaseStudy2010.asp?NominationID=132&Username=hlsu|archivedate=November 5, 2011|df=}}</ref>\n\n==See also==\n* [[Comparison of statistical packages]]\n* [[Data mining]]\n* [[Data processing]]\n* [[Online analytical processing]] (OLAP)\n* [[SAS (software)]]\n* [[SQL]]\n\n== References ==\n{{Reflist}}\n\n==Further reading==\n* {{citation|title=JMP 6.0.3: interactive exploratory data and statistical analysis tool meets the statistical needs of virtually any user.|publisher=Operations Research Management Science Today|url=http://www.orms-today.org/orms-2-07/frswr.html|date=February 1, 2007|first=Wayne|last=Holland}}\n\n==External links==\n* [http://www.jmp.com/ JMP website]\n* [http://blogs.sas.com/jmp/ JMP Blog]\n* [http://www.sascommunity.org/wiki/Main_Page sasCommunity.org customer Wiki community]\n\n{{Statistical software}}\n\n[[Category:Data visualization software]]\n[[Category:Data analysis software]]\n[[Category:Time series software]]\n[[Category:Numerical analysis software for MacOS]]\n[[Category:Data-centric programming languages]]\n[[Category:High-level programming languages]]"
    },
    {
      "title": "H2O (software)",
      "url": "https://en.wikipedia.org/wiki/H2O_%28software%29",
      "text": "{{Advert|date=February 2016}}\n\n{{Infobox software\n| title                  = H2O\n| name                   = H2O (software)\n| logo                 =H2O_logo_from_H2O.ai.png <!-- FAIR USE. Not for use elsewhere -->\n| logo size              =\n| logo alt               = The corporate logo of H2O\n| logo caption           =\n| screenshot             = <!-- Image name is enough -->\n| screenshot size        =\n| screenshot alt         =\n| caption                =\n| collapsible            =\n| author                 = [[H2O.ai]]\n| developer              = [[H2O.ai]]\n| released               = {{Start date and age|2011}}\n| discontinued           =\n| latest release version = 3.20.0.8\n| latest release date    = {{Start date and age|2018|08|01}}\n| status                 = Active\n| programming language   = H2O (written in [[Java (programming language)|Java]], [[Python (programming language)|Python]], and [[R (programming language)|R]])<ref name=\"Harris\" >{{harvtxt|Harris|2012}}</ref><ref name=\"Novet\">{{harvtxt|Novet|2014}}</ref><ref name=\"Rec\">{{cite web|publisher=H2O.ai|website=0xdata.com|url=http://0xdata.com/product/recommended-systems-for-h2o/|title=Recommended systems for H2O|ref=harv|date=May 2015|access-date=2015-06-01|archive-url=https://web.archive.org/web/20150530010057/http://0xdata.com/product/recommended-systems-for-h2o/|archive-date=2015-05-30|dead-url=yes|df=}}</ref>\n| operating system       = [[Linux]], [[macOS]], and [[Microsoft Windows]]\n| platform               = [[Apache Hadoop]] [[Apache Hadoop#Hadoop distributed file system|Distributed File System]]; [[Amazon EC2]], [[Google Compute Engine]], and [[Microsoft Azure]].\n| size                   =\n| language               = English\n| language count         = <!-- Number only -->\n| language footnote      =\n| genre                  = [[big data|big]] [[data analytics]], [[machine learning]], [[statistical learning theory]]<ref name=\"Hardy\" >{{harvtxt|Hardy|2014}}</ref>\n| license                = [[Apache license]] 2.0<ref>https://github.com/h2oai/h2o-2/blob/master/LICENSE.txt</ref>\n| website                = {{URL|http://www.h2o.ai/}}\n| standard               = [[Databricks]] certified on [[Apache Spark|Spark]].<ref name=\"Rec\"/>\n| AsOf                   = 1 June 2015\n}}\n\n'''H2O''' is [[open-source software]] for [[big data|big-data]] [[data analysis|analysis]]. It is produced by the company H2O.ai. H2O allows users to fit thousands of potential models as part of discovering patterns in data.\n\nThe H2O software runs can be called from the [[R (programming language)|statistical package R]], [[Python (programming language)|Python]], and other environments. It is used for exploring and analyzing datasets held in [[cloud computing]] systems and in the [[Apache Hadoop|Apache]] [[Hadoop Distributed File System]] as well as in the conventional operating-systems [[Linux]], [[macOS]], and [[Microsoft Windows]]. The H2O software is written in [[Java (programming language)|Java]], [[Python (programming language)|Python]], and [[R (programming language)|R]]. Its graphical-user interface is compatible with four browsers: [[Chrome (browser)|Chrome]], [[Safari (browser)|Safari]], [[Firefox (browser)|Firefox]], and [[Internet Explorer]].\n\n==H2O==\n\nThe H2O project aims to develop an analytical interface for cloud computing, providing users with tools for data analysis.<ref name=\"Harris\" /> The software is open-source and freely distributed. The company receives fees for providing customer service and customized extensions.\n\n===Mining of big data===\n{{See also|Data mining|Machine learning}}{{machine learning bar}}[[Big data]]sets are too large to be analyzed using traditional software like [[R (programming language)|R]]. The H2O software provides data structures and methods suitable for big data. H2O allow users to analyze and visualize whole sets of data without using the [[Procrustean]] strategy of studying only a small subset with a conventional statistical package.<ref name=\"Novet\" /> H2O's statistical algorithms includes [[K-means clustering]], [[generalized linear model]]s, [[Random forest|distributed random forests]], [[Gradient boosting|gradient boosting machines]], [[Naive Bayes classifier|naive bayes]], [[principal component analysis]], and [[Low-rank approximation|generalized low rank models]].<ref name=\"CRAN\">{{citation|title =h2o: R Interface for H2O|author =Aiello, Spencer|author2 =Tom Kraljevic|author3 =Petr Maj|others=with contributions from the 0xdata team|year=2015|number=3.0.0.12\n|url=https://cran.r-project.org/web/packages/h2o/index.html\n|ref=harv|series=Contributed Packages|publisher=The R Project for Statistical Computing|website=The Comprehensive R Archive Network (CRAN)}}</ref>\n\nH2O is also able to run on Spark.<ref>{{Cite web|url=http://docs.h2o.ai/h2o/latest-stable/h2o-docs/faq.html#sparkling-water|title=FAQ — H2O 3.10.2.1 documentation|website=docs.h2o.ai|language=en|access-date=2017-01-28}}</ref>\n\n====Iterative methods for real-time problems====\n\nH2O uses [[iterative method]]s that provide quick answers using all of the client's data. When a client cannot wait for an optimal solution, the client can interrupt the computations and use an approximate solution.<ref name=\"Harris\" /> In its approach to [[deep learning]],<ref name=\"Novet\" /><ref name=\"CRAN\" /><ref>\"Prediction of IncRNA using Deep Learning Approach\". Tripathi, Rashmi; Kumari, Vandana; Patel, Sunil; Singh, Yashbir; Varadwaj, Pritish. ''International Conference on Advances in Biotechnology (BioTech)''. Proceedings: 138-142. Singapore: Global Science and Technology Forum. (2015)</ref> H2O divides all the data into subsets and then analyzing each subset simultaneously using the same method. These processes are combined to estimate parameters by using the Hogwild scheme,<ref>[http://h2o-release.s3.amazonaws.com/h2o/rel-shannon/12/docs-website/h2o-docs/index.html#Data%20Science%20Algorithms-GLM-GLM%20Algorithm Description of the iterative method for computing maximum-likelihood estimates for a generalized linear model].</ref> a parallel [[stochastic gradient descent|stochastic gradient]] method.<ref>{{cite journal|title=Hogwild: A Lock-Free Approach to Parallelizing Stochastic Gradient Descent|author =Benjamin Recht|author2 =Re, Christopher|author3 =Wright, Stephen|author4 =Feng Niu|last-author-amp =yes\n|journal=Advances in Neural Information Processing Systems|volume=24|editor=J. Shawe-Taylor|editor2=R.S. Zemel|editor3=P.L. Bartlett|editor4=F. Pereira|editor5=K.Q. Weinberger|pages=693–701|year=2011|publisher=Curran Associates, Inc.\n|url=http://papers.nips.cc/paper/4390-hogwild-a-lock-free-approach-to-parallelizing-stochastic-gradient-descent.pdf\n|ref=harv}} [https://www.eecs.berkeley.edu/~brecht/papers/hogwildTR.pdf Recht's PDF]</ref> These methods allow H2O to provide answers that use all the client's data, rather than throwing away most of it and analyzing a subset with conventional software.\n\n===Software===\n<!-- Following the guidelines of the article's WikiProjects and the software information-box template, this section provides the information requested by the template. Citations can be expanded to include facts from Novet and from Harris, but this would just clutter the article. It is simplest and cleanest to use H2O.ai's recommendations as the uniform source. -->\n\n====Programming languages====\n\nThe H2O software has an interface to the following programming languages: [[Java (programming language)|Java]] (6 or later), [[Python (programming language)|Python]] (2.7.x, 3.5.x), [[R (programming language)|R]] (3.0.0 or later) and [[Scala (programming language)|Scala]] (1.4-1.6).<ref name=\"Novet\" /><ref name=\"Rec\" />\n\n====Operating systems====\nThe H2O software can be run on conventional operating-systems: [[Microsoft Windows]] ([[Microsoft Windows 7|7]] or later), Mac [[OS X]] ([[OS X Mavericks|10.9]] or later), and [[Linux]] ([[Ubuntu 12.04]] <!-- not \"or later\" 1 June 2015 -->; [[RHEL]]/[[CentOS]] 6 or later),<ref name=\"Rec\"/> It also runs on big-data systems, particularly [[Apache Hadoop]] [[Apache Hadoop#Hadoop distributed file system|Distributed File System]] (HDFS), several popular versions: [[Cloudera]] (5.1 or later), [[MapR]] (3.0 or later), and [[Hortonworks]] (HDP 2.1 or later). It also operates on [[cloud computing]] environments, for example using [[Amazon EC2]], [[Google Compute Engine]], and [[Microsoft Azure]]. The H2O Sparkling Water software is [[Databricks]]-certified on [[Apache Spark]].<ref name=\"Rec\"/>\n\n====Graphical user interface and browsers====\n\nIts graphical user interface is compatible with four browsers (unless specified, in their latest versions {{as of|2015|June|1|lc=y}}): [[Chrome (browser)|Chrome]], [[Safari (browser)|Safari]], [[Firefox (browser)|Firefox]], [[Internet Explorer]] ([[Internet Explorer 10|IE10]]).<ref name=\"Rec\"/>\n\n==Notes==\n{{Reflist}}\n\n==References==\n* {{cite news|last=Gage|first=Deborah|title=Platfora founder goes in search of big-data answers|url=https://blogs.wsj.com/venturecapital/2013/04/15/platfora-founder-goes-in-search-of-big-data-answers/|date=15 April 2013|newspaper=Wall Street Journal|ref=harv|accessdate=2 June 2015}}\n* {{citation\n|url=http://fortune.com/2014/08/03/meet-fortunes-2014-big-data-all-stars/\n|journal=Fortune|first1=Robert|last1=Hackett\n|title=Arno Candel, physicist and hacker, 0xdata\n|editor-first2=Robert|editor-last2=Hackett|series=Meet Fortune's 2014 Big Data All-Stars|ref=harv|accessdate=2 June 2015|editor-last1=Nusca|editor-first1=Andrew|editor-last3=Gupta|editor-first3=Shalene|date=3 August 2014}}\n* {{cite news|title=Valuable humans in our digital future|first=Quentin|last=Hardy|date=3 May 2014|newspaper=New York Times\n|url=http://bits.blogs.nytimes.com/2014/05/03/valuable-humans-in-our-digital-future/?\n|ref=harv|accessdate=1 June 2015}}\n* {{cite journal|title=How 0xdata wants to help everyone become data scientists|first=Derrick|last=Harris|date=14 August 2012|ref=harv\n|url=https://gigaom.com/2012/08/14/how-0xdata-wants-to-help-everyone-become-data-scientists/|journal=Gigaom Research|accessdate=1 June 2015}}\n* {{cite journal|title=0xdata takes $8.9M and becomes H2O to match its open-source machine-learning project|date=7 November 2014|first=Jordan|last=Novet|journal=VentureBeat\n|url=https://venturebeat.com/2014/11/07/h2o-funding/|ref=harv|accessdate=1 June 2015}}\n\n==External links==\n* {{URL|https://www.h2o.ai/h2o/|H2O software}} at {{URL|http://0xdata.com/ |H2O.ai (formerly 0xdata)}}\n* {{URL|https://github.com/0xdata/h2o|Github repository of H2O software}}\n* {{URL|https://www.youtube.com/channel/UCk6ONJlPzjw3DohAeMSgsng|YouTube channel of H2O.ai}}\n\n{{Statistical software}}\n{{Data warehouse}}\n\n[[Category:Free data analysis software]]\n[[Category:Data mining and machine learning software]]\n[[Category:Open-source cloud applications]]\n[[Category:R (programming language)| ]]\n[[Category:Cross-platform free software]]\n[[Category:Data-centric programming languages]]\n[[Category:Free statistical software]]\n[[Category:Free data visualization software]]\n[[Category:Hadoop]]\n[[Category:Stanford University]]\n[[Category:Big data products]]"
    },
    {
      "title": "Bibliometrix",
      "url": "https://en.wikipedia.org/wiki/Bibliometrix",
      "text": "{{Orphan|date=October 2016}}\n\n'''Bibliometrix''' package is a [[R (programming language)|R]] tool (http://www.bibliometrix.org) providing a set of tools for quantitative research in [[scientometrics]] and [[bibliometrics]].<ref>{{Cite journal|last=Pritchard, A|year=1969|title=Statistical bibliography or bibliometrics|journal=Journal of Documentation|volume=25, 348}}</ref>\n\nBibliometrics is the application of quantitative analysis and statistics to publications such as journal articles and their accompanying citation counts. Quantitative evaluation of publication and citation data is now used in almost all science fields to evaluate growth, maturity, leading authors, conceptual and intellectual maps, trend of a scientific community. Bibliometrics is also used in research performance evaluation,<ref name=\":0\">{{Cite journal|last=Cuccurullo|first=Corrado|last2=Aria|first2=Massimo|last3=Sarto|first3=Fabrizia|date=2016-05-21|title=Foundations and trends in performance management. A twenty-five years bibliometric analysis in business and public administration domains|journal=Scientometrics|language=en|volume=108|issue=2|pages=595–611|doi=10.1007/s11192-016-1948-8|issn=0138-9130}}</ref> especially in university and government labs, and also by policymakers,<ref>{{Cite journal|last=Sarto|first=Fabrizia|last2=Cuccurullo|first2=Corrado|last3=Aria|first3=Massimo|title=Exploring healthcare governance literature: systematic review and paths for future research|journal=Mecosan|volume=|issue=91|pages=61–80|doi=10.3280/mesa2014-091004|year=2015}}</ref> research directors and administrators, information specialists and librarians, and scholars themselves.<ref name=\":0\" /><ref>Cuccurullo, C., Aria, M., & Sarto, F.  (2015). '''Twenty years of research on performance management in business and public administration domains'''. ''Presentation at the Correspondence Analysis and Related Methods conference (CARME 2015)'' in September 2015.</ref><ref>Cuccurullo, C., Aria, M., & Sarto, F. (2013). '''Twenty years of research on performance management in business and public administration domains'''. In ''Academy of Management Proceedings'' (Vol. 2013, No. 1, p.&nbsp;14270). Academy of Management.</ref><ref>{{Cite journal|last=Ramos-Rodríguez|first=Antonio-Rafael|last2=Ruíz-Navarro|first2=José|date=2004-10-01|title=Changes in the intellectual structure of strategic management research: a bibliometric study of the Strategic Management Journal, 1980–2000|journal=Strategic Management Journal|language=en|volume=25|issue=10|pages=981–1004|doi=10.1002/smj.397|issn=1097-0266}}</ref><ref>{{Cite book|title=The Oxford handbook of evidence-based management. .|last=Rousseau, D. M.|publisher=Oxford University Press|year=2012|isbn=|location=|pages=|quote=|via=}}</ref>\n\n'''Bibliometrix''' is written in [[R (programming language)|R-language]]. [[R (programming language)|R]] is an open-source environment and ecosystem. The existence of substantial of good statistical algorithms, access to high-quality numerical routines, and integrated data visualization tools are perhaps the strongest qualities to prefer R to other languages for scientific computation.\n\n'''Bibliometrix''' supports scholars in three key phases of analysis:\n# Data importing and conversion to R data-frame;\n# Descriptive analysis of a publication dataset;\n# Network extraction for co-citation, coupling, and collaboration analyses. Matrices are the input data for performing network analysis, factorial analysis or multidimensional scaling analysis;\n# Text mining of manuscripts (title, abstract, authors'  keywords, etc.);\n# Co-word analysis.g\n\n== Main functions of Bibliometrix package ==\nThe following table lists the main functions of bibliometrix package:\n{| class=\"wikitable\"\n|'''''Software assisted'''''\n\n'''''workflow steps'''''<ref>{{Cite journal|last=Cobo|first=M.j.|last2=López-Herrera|first2=A.g.|last3=Herrera-Viedma|first3=E.|last4=Herrera|first4=F.|date=2011-07-01|title=Science mapping software tools: Review, analysis, and cooperative study among tools|journal=Journal of the American Society for Information Science and Technology|language=en|volume=62|issue=7|pages=1382–1402|doi=10.1002/asi.21525|issn=1532-2890|citeseerx=10.1.1.492.1815}}</ref>\n|'''''Bibliometrix [https://cran.r-project.org/web/packages/bibliometrix/bibliometrix.pdf function]'''''\n|'''''Description'''''\n|-\n|''Data loading and converting''\n|•         ''Convert2df()''\n|•         ''It creates a bibliographic  data frame''\n|-\n|''Data Analysis''\n\n''Descriptive bibliometric analysis''\n|•         ''biblioAnalysis()''\n\n•         ''Summary() and plot()''\n\n•         ''citations()''\n\n•         ''localCitations()''\n\n•         ''dominance()''\n\n•         ''Hindex()''\n\n•         ''lotka()''\n|•         ''It returns an object of  class bibliometrix''\n\n•         ''They summarize the main  results of the bibliometric analysis''\n\n•         ''It identifies the most  cited references or authors''\n\n•         ''It identifies the most  cited local authors''\n\n•         ''It calculates the authors’  dominance ranking''\n\n•         ''It measures productivity  and citation impact of a scholar''\n\n•         ''It estimates Lotka’s law  coefficients for scientific productivity'' \n|-\n|''Data Analysis''\n''Term Extraction''\n|•         ''termExtraction()''\n|''•         it extracts terms from textual fields (abstracts, titles, author's keywords, etc.) of a bibliographic collection''\n|-\n|''Data Analysis''\n\n''Bi-partite networks''\n|•         ''cocMatrix()''\n|•         ''It computes a bipartite  network''\n|-\n|''Data Analysis''\n\n''Normalization''\n|•         ''couplingSimilarity()''\n|•         ''It calculates Jaccard or  Salton similarity coefficient among manuscripts of a coupling network''\n|-\n|''Data Analysis''\n\n''Data Reduction''\n|''External functions from other R packages''\n|''Other R packages suggested for bibliometric  analysis''\n\n•         ''factominer: for PCA and  MCA''\n\n•         ''cmdscale: for MDS''\n\n•         ''cluster: for clustering'' \n|-\n|''Data Analysis''\n\n''Similarity matrix''\n\n''(square network matrix)''\n|•         ''biblioNetwork()''\n|•         ''It calculates the most  frequently used coupling networks''\n|-\n|''Data visualization''\n\n''Mapping''\n|''External functions from other R packages''\n|''Other R packages suggested for mapping''\n\n•         [http://igraph.org/r/  ''igraph''] ''for social network''\n\n•         [http://igraph.org/r/  ''ggplot2''] ''for bi-dimensional  maps''\n\n•         [https://cran.r-project.org/web/packages/cluster/ ''cluster''] ''for dendrogram''\n|}\n\n== References ==\n<references />\n\n[[Category:R (programming language)]]\n[[Category:Quantitative research]]\n[[Category:Bibliometrics]]"
    },
    {
      "title": "Bio7",
      "url": "https://en.wikipedia.org/wiki/Bio7",
      "text": "{{multiple issues|\n{{COI|date=July 2014}}\n{{more footnotes|date=July 2014}}\n{{notability|Products|date=July 2014}}\n{{Orphan|date=July 2014}}\n}}\n\n{{Infobox programming language\n| name = Bio7\n| latest_release_version = 3.0\n| latest_release_date = April 18, 2019\n| operating_system = [[Windows]], [[Linux]], [[Macintosh]]\n| license = [[Eclipse Public License]]\n| website = http://bio7.org/\n}}\n\nThe OpenSource application '''Bio7''' is a software for ecological simulation models, image analysis and statistical analysis. Built upon the RCP framework of [[Eclipse (software)|Eclipse]] it embeds several tools and programming languages for the analysis of complex ecological systems. Several Java based scripting languages ([[Groovy (programming language)|Groovy]], [[BeanShell]], [[Jython]], [[JavaScript]], ImageJ Macro) and the [[Java (programming language)|Java]] language can be used from within Bio7 for the creation of simulation models and analysis tasks.\nIn addition Bio7 also contains a complete \"Graphical User Interface\" (GUI) for the statistical software [[R (programming language)]] <ref>Austenfeld, Marcel, und Wolfram Beyschlag. „A Graphical User Interface for R in a Rich Client Platform for Ecological Modeling\". Journal of Statistical Software 49, Nr. 4 (2012): 1–19. ([http://www.jstatsoft.org/v49/i04 pdf])</ref> and the scientific image analysis tool [[ImageJ]] <ref>Austenfeld M, Beyschlag W: The Use of ImageJ within an Ecological Modeling Platform, ImageJ User and Developer Conference 2010, Luxembourg, Conference Proceedings, 211-216.</ref> with special functions to send image data from ImageJ to R or R data to ImageJ.\n\n==History==\nDevelopment start: 2004<br />\nFirst release: 2007<br />\nCurrent release: April 2019\n\n==License==\nEPL ([[Eclipse Public License]])\n\n== References==\n{{Reflist}}\n\n[[Category:R (programming language)]]"
    },
    {
      "title": "John Chambers (statistician)",
      "url": "https://en.wikipedia.org/wiki/John_Chambers_%28statistician%29",
      "text": "{{Other people|John Chambers}}\n'''John McKinley Chambers''' is the creator of the [[S (programming language)|S programming language]], and core member of the [[R (programming language)|R programming language]] project. He was awarded the 1998 [[ACM Software System Award]] for developing S.<ref>[http://www.acm.org/announcements/ss99.html/ ACM honors Dr. John M. Chambers of Bell Labs with the 1998 ACM Software System Award for creating \"S System\" software], ACM press release, March 29, 1999. Accessed 8 December 2008.</ref> He donated his prize money (US$10,000) to the [[American Statistical Association]] to endow an award for novel statistical software.<ref>{{cite web |url=http://stat-computing.org/awards/jmc/history.html |title=John M. Chambers Statistical Software Award. ASA Statistics Computing and Graphics |work= |accessdate=}}</ref>\n\nChambers is a [[Fellow]] of the [[American Statistical Association]], the [[American Association for the Advancement of Science]] and the [[Institute of Mathematical Statistics]].<ref>{{cite web |url=http://stat.bell-labs.com/jmc/vitae.html |title=John M. Chambers - Vitae |publisher=[[Bell Laboratories]] |deadurl=yes |archiveurl=https://web.archive.org/web/20110707222829/http://stat.bell-labs.com/jmc/vitae.html |archivedate=2011-07-07 |df= }}</ref>\n\nHe was a Consulting Professor of Statistics at Stanford University.<ref>[https://statistics.stanford.edu/people/john-chambers Stanford University Department of Statistics Page for John M. Chambers.] Accessed January 16, 2010.</ref> He received a B.Sc. from the [[University of Toronto]] and M.A. and Ph.D. degrees in Statistics from [[Harvard University]].<ref>{{cite web |url=http://stat.bell-labs.com/jmc/vitae.html |title=John M. Chambers - Vitae |publisher=[[Bell Laboratories]] |deadurl=yes |archiveurl=https://web.archive.org/web/20110707222829/http://stat.bell-labs.com/jmc/vitae.html |archivedate=2011-07-07 |df= }}</ref>\n\n==Bibliography==\n* {{cite book |year=1977 |author=Chambers, John M. |title=Computational methods for data analysis |publisher=Wiley |location=New York |pages= |isbn=0-471-02772-3 |oclc= |doi= |accessdate=}}\n* {{cite book |year=1983 |author=Chambers, John M. |title=Graphical methods for data analysis |publisher=Wadsworth International Group |location=Belmont, Calif |pages= |isbn=0-534-98052-X |oclc= |doi= |accessdate=}}\n* {{cite book |year=1984 |author=Chambers, John M. |title=Compstat lectures: lectures in computational statistics |publisher=Physica |location=Heidelberg |pages= |isbn=3-7051-0006-8 |oclc= |doi= |accessdate=}}\n* {{cite book |year=1984 |last=Becker |first=R.A. |author2=Chambers, J.M. |title=S: An Interactive Environment for Data Analysis and Graphics |publisher=Wadsworth & Brooks/Cole |location=Pacific Grove, CA, USA |isbn=0-534-03313-X }}\n* {{cite book |year=1985 |last=Becker |first=R.A. |author2=Chambers, J.M. |title=Extending the S System |publisher=Wadsworth & Brooks/Cole |location=Pacific Grove, CA, USA |isbn=0-534-05016-6 }}\n* {{cite book |year=1988 |last=Becker |first=R.A. |authorlink= |author2=Chambers, J.M. |author3=Wilks, A.R.  |title=The New S Language: A Programming Environment for Data Analysis and Graphics |publisher=Wadsworth & Brooks/Cole |location=Pacific Grove, CA, USA |isbn=0-534-09192-X }}\n* {{cite book |year=1991 |last=Chambers |first=J.M. |author2=Hastie, T.J. |title=Statistical Models in S |publisher=Wadsworth & Brooks/Cole |location=Pacific Grove, CA, USA |isbn=0-412-05291-1 |page=624}}\n* {{cite book |year=1998 |author=Chambers, John M. |title=Programming with data: a guide to the S language |publisher=Springer |location=Berlin |pages= |isbn=0-387-98503-4 |oclc= |doi= |accessdate=}}\n* {{cite book |year=2008 |author=Chambers, John M. |title=Software for data analysis programming with R |publisher=Springer |location=Berlin |pages= |isbn=0-387-75935-2 |oclc= |doi= |accessdate=}}\n* {{cite book |year=2016 |author=Chambers, John M. |title=Extending R |publisher=Chapman and Hall/CRC |location=Florida |pages=382  |isbn=978-1498775717 |oclc= |doi= |accessdate=}}\n\n==References==\n{{reflist}}\n\n{{Authority control}}\n\n{{DEFAULTSORT:Chambers, John}}\n[[Category:Programming language designers]]\n[[Category:Scientists at Bell Labs]]\n[[Category:Living people]]\n[[Category:Fellows of the American Statistical Association]]\n[[Category:Fellows of the Institute of Mathematical Statistics]]\n[[Category:Fellows of the American Association for the Advancement of Science]]\n[[Category:Harvard University alumni]]\n[[Category:R (programming language)]]\n[[Category:University of Toronto alumni]]\n[[Category:Year of birth missing (living people)]]"
    },
    {
      "title": "Datasets.load",
      "url": "https://en.wikipedia.org/wiki/Datasets.load",
      "text": "{{Infobox software\n| title = datasets.load\n| name = datasets.load\n| logo = <!-- [[File: ]] -->\n| logo caption = \n| screenshot =\n| caption = \n| collapsible = \n| author = [[Bastiaan Quast]]\n| developer = \n| released = {{Start date|2016|12|14|df=yes}}\n| discontinued = \n| latest release version = 0.3.0\n| latest release date = {{Start date and age|2018|09|10|df=yes}}\n| latest preview version = \n| latest preview date = \n| programming language = [[R (programming language)|R]]\n| operating system = \n| platform = \n| size = 530.5 kB (v. 0.3.0)\n| language = \n| language count = \n| language footnote = \n| genre = \n| license = [[GPL v3]]\n| alexa = \n| website = {{URL|https://cran.r-project.org/}}\n}}\n'''datasets.load''' is an R package and RStudio plugin, that provides a both [[Graphical User Interface]] (GUI) as well as a [[Command Line Interface]] for loading datasets. Normally, R only makes datasets of loaded packages visible, '''datasets.load''' shows the list of all installed datasets on the local library, including datasets included with packages that haven't been loaded.\n\n== R datasets ==\nR functionality is extendible using extensions call R packages. The central place to store package is the Central R Archive network (CRAN). From CRAN, R packages can be installed using the command:\n install.packages()\nOnce installed, R packages can be loaded using the command:\n library()\nAfter a package has been loaded, objects available from the package - such as functions and datasets - can be accessed.\n\nThe available datasets can listed using the command:\n data()\nHowever, datasets from packages that are not loaded, are not listed. As a result, many R users have access to datasets on their local install that are never used. The '''datasets.load''' packages addresses this by listed all datasets that are in any packages installed (loaded or not loaded).\n\n== Usage ==\n\n\nA video demonstrating the GUI usage is available via the thumbnail on the right and on [https://www.youtube.com/watch?v=dl_bYlDLydI YouTube].\n\nThe usage of '''datasets.load''''s [[Command Line Interface]] is demonstrated in the code snippet below.\n\n<source lang=\"rsplus\">\n> # install the datasets.load package\n> install.packages('datasets.load')\n\n> # load the datasets.load package\n> library(datasets.load)\n\n> # list the objects in the package (all functions)\n> ls(\"package:datasets.load\")\n[1] \"alldata\"        \"browseDatasets\" \"datasets\"       \"datasets.load\"  \"getDatasetInfo\" \"printDatasets\" \n[7] \"promptDatasets\"\n\n> # show all datasets (in a new window)\n> datasets()\n</source>\n\n\n== Functionality ==\nThe basic functionality of '''datasets.load''' is to expose all installed datasets to the user, including those in packages that are not loaded. There is a [[Command Line Interface]] which can be user from any R terminal.\n\nIn addition to this, there is also a [[Graphical User Interface]] for the RStudio [[Integrated Development Environment]], using [[RStudio#Addins|RStudio Addins]].\n\n== Reception ==\nThe initial release of version 0.1.0 took place in December 2016, and averaged a download rate of 1,000 times per month, from the RStudio servers alone. With the release of version 0.3.0 in 2018, the download rate increased to 2,000 times per month, putting the package in the 9th percentile of most popular R packages.<ref>{{Cite web|url=https://github.com/bquast/datasets.load/releases/tag/0.3.0|title=bquast/datasets.load|website=GitHub|language=en|access-date=2018-09-16}}</ref> The package was reviewed in the 2017 article \"R Packages worth a look\" on Data Analytics & R<ref>{{Cite news|url=https://advanceddataanalytics.net/2017/01/05/r-packages-worth-a-look-667/|title=R Packages worth a look|date=2017-01-05|work=Data Analytics & R|access-date=2018-09-16|language=en-US}}</ref>, which further increased usage. It is also frequently preinstalled on university computers<ref>{{Cite web|url=https://wiki.carleton.edu/display/itskb/R+packages+installed|title=R packages installed - ITS - Carlpedia - Carleton College Wiki|website=wiki.carleton.edu|access-date=2018-09-16}}</ref>, in order to help make R more accessible to students. \n\nThe RStudio CRAN mirror download logs\n<ref>{{cite web|title=RStudio CRAN logs|url=http://cran-logs.rstudio.com/}}</ref> show that the package is downloaded on average about 2000 times per month from those servers\n<ref>{{cite web|title=CRANlogs datasets.load package|url=https://cranlogs.r-pkg.org/badges/datasets.load}}</ref>, with a total of over 30,000 downloads since the first release\n<ref>{{cite web|title=CRANlogs datasets.load package|url=https://cranlogs.r-pkg.org/badges/grand-total/datasets.load}}</ref>, according to RDocumentation.org, this puts the package in the 9th percentile of most popular R packages\n<ref>{{cite web|title=RDocumentation rnn|url=https://www.rdocumentation.org/packages/datasets.load}}</ref>.\n\n== References ==\n{{reflist}}\n\n==External links==\n*[https://github.com/bquast/datasets.load Repository] on [[GitHub]]\n*[https://cran.r-project.org/package=datasets.load datasets.load package] on [[R (programming language)#Packages|CRAN]]\n\n[[Category:Deep learning]]\n[[Category:Free science software]]\n[[Category:Free R (programming language) software]]\n[[Category:R (programming language)]]\n[[Category:2016 software]]"
    },
    {
      "title": "Robert Gentleman (statistician)",
      "url": "https://en.wikipedia.org/wiki/Robert_Gentleman_%28statistician%29",
      "text": "{{for|the British water polo player|Robert Gentleman}}\n{{Infobox scientist\n|name          = Robert Clifford Gentleman\n|image         = <!-- Freely licenced images only. Please do not put a fair-use image here, it will be deleted - see [[WP:NONFREE]] -->\n|image_size    = \n|caption       = Do you have a picture of Robert Gentleman? Please, post here.\n| birth_name  = \n| birth_date        = {{Birth year and age|1959}}{{citation needed|date=March 2013}}\n| birth_place = \n| other_names = \n| nationality = \n| workplaces = [[Genentech]]<br>[[University of Washington]]<br>[[Harvard University]]<br>[[The University of Auckland]]\n| alma_mater = [[University of Washington]]<br>[[University of British Columbia]]\n| thesis_title = Exploratory methods for censored data\n| thesis_url = http://search.proquest.com/docview/303589316\n| thesis_year = 1988\n| doctoral_advisor = John James Crowley<ref name=\"mathgene\">{{MathGenealogy|id=26386}}</ref>\n| doctoral_students = \n| known_for   = [[R (programming language)]]\n| occupation  = \n| prizes           = [[Benjamin Franklin Award (Bioinformatics)]]\n}}\n\n'''Robert Clifford Gentleman''' (born 1959) is a Canadian statistician and [[bioinformatician]]<ref>{{Cite journal | last1 = Gentleman | first1 = R. | title = Reproducible Research: A Bioinformatics Case Study | doi = 10.2202/1544-6115.1034 | journal = Statistical Applications in Genetics and Molecular Biology | volume = 4 | pages = Article2 | year = 2005 | pmid =  16646837| pmc = | url = http://biostats.bepress.com/cgi/viewcontent.cgi?article=1002&context=bioconductor }}</ref> currently vice president of computational biology at [[23andMe]].<ref name=23andme-pr>{{cite web|title=Bioinformatics Pioneer Robert Gentleman, Ph.D., Joins 23andMe Leadership Team|url=http://www.prnewswire.com/news-releases/bioinformatics-pioneer-robert-gentleman-phd-joins-23andme-leadership-team-300059876.html|accessdate=10 August 2015}}</ref><ref name=bioit-world-23andme>{{cite web|title=Robert Gentleman on His Goals for Drug Discovery at 23andMe|url=http://www.bio-itworld.com/2015/5/19/robert-gentleman-his-goals-drug-discovery-23andme.html|accessdate=10 August 2015}}</ref> He is recognized, along with [[Ross Ihaka]], as one of the originators of the [[R programming language]]<ref name=jstor1390807>{{Cite journal | last1 = Ihaka | first1 = R. | last2 = Gentleman | first2 = R. | title = R: A Language for Data Analysis and Graphics | journal = Journal of Computational and Graphical Statistics | volume = 5 | issue = 3 | pages = 299–314 | doi = 10.2307/1390807 | year = 1996 | jstor = 1390807| pmid =  | pmc = }}</ref><ref>{{cite web |url=https://www.nytimes.com/2009/01/07/technology/business-computing/07program.html  |title=R, the Software, Finds Fans in Data Analysts - NYTimes.com |author=Ashlee Vance |date=6 January 2009 |website= |publisher=New York Times |accessdate=17 April 2011}}</ref> and the [[Bioconductor]] project.<ref>{{Cite journal | last1 = Gentleman | first1 = R. C. | last2 = Carey | first2 = V. J. | last3 = Bates | first3 = D. M. | last4 = Bolstad | first4 = B. | last5 = Dettling | first5 = M. | last6 = Dudoit | first6 = S. | author6-link = Sandrine Dudoit | last7 = Ellis | first7 = B. | last8 = Gautier | first8 = L. | last9 = Ge | first9 = Y. | last10 = Gentry | first10 = J. | last11 = Hornik | first11 = K. | last12 = Hothorn | first12 = T. | last13 = Huber | first13 = W. | last14 = Iacus | first14 = S. | last15 = Irizarry | first15 = R. | last16 = Leisch | first16 = F. | last17 = Li | first17 = C. | last18 = Maechler | first18 = M. | last19 = Rossini | first19 = A. J. | last20 = Sawitzki | first20 = G. | last21 = Smith | first21 = C. | last22 = Smyth | first22 = G. | last23 = Tierney | first23 = L. | last24 = Yang | first24 = J. Y. | last25 = Zhang | first25 = J. | title = Bioconductor: Open software development for computational biology and bioinformatics | journal = Genome Biology | volume = 5 | issue = 10 | pages = R80 | doi = 10.1186/gb-2004-5-10-r80 | year = 2004 | pmid =  15461798| pmc =545600 }}</ref><ref name=\"dblp\">{{DBLP|name=Robert Gentleman}}</ref><ref name=\"microsoft\">{{AcademicSearch|1281996}}</ref>\n\n==Education==\nGentleman was awarded a Bachelor of Science degree in [[mathematics]] from the [[University of British Columbia]].<ref name=23andme-pr /> He was awarded a [[Ph.D.]] degree in [[Statistics]] from [[University of Washington]] in 1988; his thesis title was ''Exploratory methods for censored data''.<ref name=\"gentlemanphd\">{{cite thesis |degree=PhD |first=Robert Clifford|last=Gentleman |title=Exploratory methods for censored data |publisher=University of Washington |date=1988 |url=http://search.proquest.com/docview/303589316|authorlink =Robert Gentleman (statistician)}}</ref>\n\n==Research==\nGentleman worked as a statistics professor at [[The University of Auckland]] in the mid 1990s, where he developed the [[R programming language]] alongside [[Ross Ihaka]].<ref name=jstor1390807 /><ref name=bioit-chief-gentleman>{{cite web|last1=Wolfson|first1=Wendy|title=A Bioinformatics Chief and a Gentleman|url=http://www.bio-itworld.com/issues/2010/may-june/gentleman.html|accessdate=10 August 2015}}</ref> In 2001, he started work on the [[Bioconductor]] project to promote the development of open-source tools for bioinformatics and [[computational biology]]. In 2009, Gentleman joined the [[Genentech]] biotechnology corporation, where he worked as a senior director in bioinformatics and computational biology.<ref>{{Cite journal \n| last1 = Gaudet | first1 = P. \n| last2 = Bairoch | first2 = A. | authorlink2 = Amos Bairoch\n| last3 = Field | first3 = D. \n| last4 = Sansone | first4 = S. -A. \n| last5 = Taylor | first5 = C. \n| last6 = Attwood | first6 = T. K. | authorlink6 = Terri Attwood\n| last7 = Bateman | first7 = A. | authorlink7 = Alex Bateman\n| last8 = Blake | first8 = J. A. \n| last9 = Bult | first9 = C. J. \n| last10 = Cherry | first10 = J. M. \n| last11 = Chisholm | first11 = R. L. \n| last12 = Cochrane | first12 = G. \n| last13 = Cook | first13 = C. E. \n| last14 = Eppig | first14 = J. T. \n| last15 = Galperin | first15 = M. Y. \n| last16 = Gentleman | first16 = R. | authorlink16 = Robert Gentleman (statistician)\n| last17 = Goble | first17 = C. A. | authorlink17 = Carole Goble\n| last18 = Gojobori | first18 = T. | authorlink18 = Takashi Gojobori\n| last19 = Hancock | first19 = J. M. \n| last20 = Howe | first20 = D. G. \n| last21 = Imanishi | first21 = T. \n| last22 = Kelso | first22 = J. \n| last23 = Landsman | first23 = D. \n| last24 = Lewis | first24 = S. E. | authorlink24 = Suzanna Lewis\n| last25 = Karsch Mizrachi | first25 = I. \n| last26 = Orchard | first26 = S. \n| last27 = Ouellette | first27 = B. F. F. \n| last28 = Ranganathan | first28 = S. \n| last29 = Richardson | first29 = L. \n| last30 = Rocca-Serra | first30 = P. \n| title = Towards BioDBcore: A community-defined information specification for biological databases \n| doi = 10.1093/database/baq027 \n| journal = Database \n| volume = 2011 \n| pages = baq027 \n| year = 2011 \n| pmid = 21205783 \n| pmc =3017395 \n \n}}</ref><ref name=\"genentech\">{{cite web |url=http://www.gene.com/gene/research/sci-profiles/bioinfo/gentleman/profile.html |title=Archived copy |accessdate=2011-04-17 |deadurl=yes |archiveurl=https://web.archive.org/web/20110704153255/http://www.gene.com/gene/research/sci-profiles/bioinfo/gentleman/profile.html |archivedate=2011-07-04 |df= }} Robert C. Gentleman Senior Director: Bioinformatics & Computational Biology</ref> Gentleman joined [[personal genomics]] and [[biotechnology]] company 23andMe as vice president in April 2015,<ref name=23andme-pr /> with the goal of bringing expertise on bioinformatics and computational drug discovery to the company.<ref name=bioit-world-23andme /> Gentleman has also served on the board of the statistical software company [[Revolution Analytics]] (formerly known as REvolution Computing).<ref name=bioit-chief-gentleman />\n\n==Awards ==\nGentleman won the [[Benjamin Franklin Award (Bioinformatics)|Benjamin Franklin Award]] in 2008, recognising his work on the R programming language, the Bioconductor project and his commitment to data and methods sharing.<ref>{{cite web|url=http://www.bioinformatics.org/franklin/|title=Benjamin Franklin Award - Bioinformatics.org|publisher=|accessdate=10 December 2016}}</ref> He was made a Fellow of the [[International Society for Computational Biology]] in 2014 for his contribution to computational biology and bioinformatics.<ref name=iscb-fellows>{{cite web|title=ISCB Fellows|url=http://www.iscb.org/iscb-fellows-program|accessdate=10 August 2015}}</ref>\nHe became a fellow of the [[American Statistical Association]] in 2017.<ref>{{cite web|url=http://www.amstat.org/ASA/Your-Career/Awards/ASA-Fellows-list.aspx|title=ASA Fellows list|publisher=American Statistical Association|accessdate=2017-11-02}}</ref>\n\n==References==\n{{Reflist}}\n{{ISCB Fellows}}\n{{Authority control}}\n\n{{DEFAULTSORT:Gentleman, Robert}}\n[[Category:1959 births]]\n[[Category:Living people]]\n[[Category:Bioinformaticians]]\n[[Category:Canadian statisticians]]\n[[Category:University of Washington alumni]]\n[[Category:Fellows of the American Statistical Association]]\n[[Category:Fellows of the International Society for Computational Biology]]\n[[Category:R (programming language)]]"
    },
    {
      "title": "Ross Ihaka",
      "url": "https://en.wikipedia.org/wiki/Ross_Ihaka",
      "text": "{{Use dmy dates|date=October 2014}}\n{{Use New Zealand English|date=October 2014}}\n{{Infobox scientist\n| name              = Ross Ihaka\n| native_name       = \n| native_name_lang  = \n| image             = Ross Ihaka (5189180796).jpg\n| image_size        = \n| alt               = \n| caption           = Ihaka at the 2010 New Zealand Open Source Awards\n| birth_name        = \n| birth_date        = \n| birth_place       = \n| death_date        = <!-- {{Death date and age|YYYY|MM|DD|YYYY|MM|DD}} (death date then birth date) -->\n| death_place       = \n| resting_place     = \n| resting_place_coordinates = <!-- {{Coord|LAT|LONG|type:landmark|display=inline,title}} -->\n| other_names       = \n| fields            = Statistical Computing\n| workplaces        = [[University of Auckland]]\n| patrons           =\n| alma_mater        = [[University of Auckland]]<br>[[University of California, Berkeley]]\n| thesis_title      = Ruaumoko\n| thesis_url        = \n| thesis_year       = 1985\n| doctoral_advisor  = \n| academic_advisors = \n| doctoral_students = \n| notable_students  = \n| known_for         = [[R (programming language)|R programming language]]\n| author_abbrev_bot = \n| author_abbrev_zoo = \n| influences        = \n| influenced        = \n| awards            = Pickering Medal <small>(2008)</small>\n| signature         = <!--(filename only)-->\n| signature_alt     = \n| website           = <!-- {{URL|https://www.stat.auckland.ac.nz/~ihaka/}} -->\n| footnotes         = \n| spouse            = \n| children          = \n}}\n'''George Ross Ihaka''' is a New Zealand statistician who is recognized, along with [[Robert Gentleman (statistician)|Robert Gentleman]], as one of the originators of the [[R (programming language)|R programming language]].<ref>{{Cite journal | last1 = Ihaka | first1 = R. | last2 = Gentleman | first2 = R. | title = R: A Language for Data Analysis and Graphics | journal = Journal of Computational and Graphical Statistics | volume = 5 | issue = 3 | pages = 299–314 | doi = 10.2307/1390807 | year = 1996 | jstor = 1390807| pmid =  | pmc = }}</ref><ref>{{cite news |title=Data Analysts Captivated by R's Power | url=//www.nytimes.com/2009/01/07/technology/business-computing/07program.html|work=The New York Times|accessdate=2009-01-07 | first=Ashlee | last=Vance | date=7 January 2009}}</ref><ref name=\"nzh\">{{cite web|url=//www.nzherald.co.nz/nz/news/article.cfm?c_id=1&objectid=10551243| title=Academic unfazed by rock star status| newspaper=[[New Zealand Herald]] |date=10 January 2009}}</ref> He retired as an associate professor of statistics at the [[University of Auckland]] in 2017.<ref>{{Cite web|url=https://www.stat.auckland.ac.nz/en/about/news-and-events-5/news/news-2017/2017/12/ross-ihaka-retires.html|title=Ross Ihaka retires from the Department of Statistics - The University of Auckland|website=www.stat.auckland.ac.nz|access-date=2018-09-17}}</ref>\n\nIhaka obtained his doctorate in 1985 from the [[University of California, Berkeley]].<ref>{{cite web| url=http://www.stat.berkeley.edu/~brill/students.html| title=David's students| accessdate=14 August 2014| website=stat.berkeley.edu | publisher=Department of Statistics, University of California, Berkeley}}</ref> \nHe received the [[Royal Society of New Zealand]]'s Pickering Medal in 2008 for his work on R.<ref>[http://www.royalsociety.org.nz/programmes/awards/pickering-medal/recipients/ Pickering Medal: Recipients], Royal Society of New Zealand.</ref> As of 2010, he was working on a new statistical programming language based on [[Lisp (programming language)|Lisp]].<ref>{{cite conference|title=Back to the Future: Lisp as a Base for a Statistical Computing System|first1=Ross|last1=Ihaka|first2=Duncan|last2=Temple Lang|date=25 August 2008|conference=Compstat 2008|url=//www.stat.auckland.ac.nz/%7Eihaka/downloads/Compstat-2008.pdf}}</ref><ref>{{cite conference|title=R: Lessons Learned, Directions for the Future|first=Ross|last=Ihaka| url=//www.stat.auckland.ac.nz/%7Eihaka/downloads/JSM-2010.pdf|conference=Joint Statistical Meetings 2010, Statistical Computing Section|date=2010}}</ref> The Department of Statistics at the University of Auckland started a public lecture series in his honour in 2017.<ref>{{Cite web|url=https://www.stat.auckland.ac.nz/en/about/our-department/ihaka-lectures.html|title=Ihaka Lecture Series - The University of Auckland|website=www.stat.auckland.ac.nz|access-date=2018-09-17}}</ref>\n\n==References==\n{{reflist}}\n\n==External links==\n*[//www.stat.auckland.ac.nz/people/riha001 Ihaka's profile] at the University of Auckland\n*[//www.stat.auckland.ac.nz/~ihaka/ Ross Ihaka's Home Page]\n\n{{Authority control}}\n\n{{DEFAULTSORT:Ihaka, Ross}}\n[[Category:Living people]]\n[[Category:New Zealand statisticians]]\n[[Category:University of Auckland faculty]]\n[[Category:University of California, Berkeley alumni]]\n[[Category:New Zealand academics]]\n[[Category:R (programming language)]]\n[[Category:Year of birth missing (living people)]]\n\n\n{{NewZealand-academic-bio-stub}}"
    },
    {
      "title": "Journal of Statistical Software",
      "url": "https://en.wikipedia.org/wiki/Journal_of_Statistical_Software",
      "text": "{{Infobox Journal\n| discipline = [[Statistics]]\n| openaccess = Yes\n| editor = Achim Zeileis, Bettina Grün, Edzer Pebesma, and Torsten Hothorn\n| license = [[Creative Commons licenses|Creative Commons Attribution License]]; [[GNU General Public License|GNU GPL]] or other GPL compatible license<ref>{{cite web |title=GPL compatible licenses |url=https://www.gnu.org/licenses/license-list.html#GPLCompatibleLicenses |website=Journal of Statistical Software |publisher=Foundation for Open Access Statistics |accessdate=23 January 2019}}</ref>\n (for [[source code|code]])\n| website = http://www.jstatsoft.org/\n| publisher = Foundation for Open Access Statistics\n| country = [[United States]]\n| abbreviation = J. Stat. Softw.\n| history = 1996-present\n| impact = 3.801\n| impact-year = 2015\n| ISSN = 1548-7660\n| OCLC = 42456366\n}}\nThe '''''Journal of Statistical Software''''' is a [[Peer review|peer-reviewed]] [[Open access (publishing)|open access]] [[scientific journal]] that publishes papers related to [[list of statistical packages|statistical software]]. ''The Journal of Statistical Software'' was founded in 1996 by [[Jan de Leeuw]] of the Department of Statistics at the [[University of California, Los Angeles]]. Its current Editors-in-Chief are Achim Zeileis, Bettina Grün, Edzer Pebesma, and Torsten Hothorn. It is published by the Foundation for Open Access Statistics.  The journal charges no author fees or subscription fees.\n\nThe journal publishes peer-reviewed articles about statistical software, together with the [[source code]].\nIt also publishes reviews of statistical software and books (by invitation only). Articles are licensed under the [[Creative Commons licenses|Creative Commons Attribution License]], while the [[source code]]s distributed with articles are licensed under the [[GNU General Public License]].\n\nArticles are often about [[free statistical software]] and coverage includes packages for the [[R (programming language)|R programming language]].\n\n==Abstracting and indexing==\n\nThe ''Journal of Statistical Software'' is indexed in the [[Current Index to Statistics]] and the [[Science Citation Index|Science Citation Index Expanded]]. Its 2012 Impact Factor in [[Journal Citation Reports]] is 4.91.<ref name=sw>{{Cite journal|url=http://www.sciencewatch.com/inter/jou/2011/11decJofStatSoft/ |title=The Editors of The Journal of Statistical Software Comment on its Success| journal=Science Watch |date=December 2011|accessdate=28 April 2017|ref=harv}}</ref> The journal was named a ''Rising Star'' by Science Watch<ref>{{cite web|url= http://sciencewatch.com/dr/ne/11junne/ |title=Essential Science Indicators: New Entrants (June 2011)|accessdate=28 April 2017}}</ref> in 2011.\n\n==References==\n{{reflist}}\n\n==External links==\n* {{Official website|http://www.jstatsoft.org/}}\n* [http://www.foastat.org/ Foundation for Open Access Statistics]\n\n{{Statistics journals}}\n\n[[Category:Computational statistics journals]]\n[[Category:Creative Commons Attribution-licensed journals]]\n[[Category:R (programming language)]]\n[[Category:Statistics journals|Statistical Software]]\n[[Category:Publications established in 1996]]\n[[Category:Open access journals]]\n[[Category:Computer science journals]]\n[[Category:Online-only journals]]"
    },
    {
      "title": "Knitr",
      "url": "https://en.wikipedia.org/wiki/Knitr",
      "text": "{{Infobox software\n| title                  = knitr\n| name                   = knitr\n| logo                   = <!-- [[File: ]] -->\n| logo caption           = \n| screenshot             = Screenshot-knitr-RStudio.png\n| caption                = \n| collapsible            = \n| author                 = [[Yihui Xie]]\n| developer              = \n| released               = {{Start date|2012|01|17|df=yes}}\n| discontinued           = \n| latest release version = 1.18\n| latest release date    = {{Start date and age|2017|12|27|df=yes}}\n| latest preview version = \n| latest preview date    = <!-- {{Start date and age|YYYY|MM|DD|df=yes/no}} -->\n| status                 = \n| programming language   = [[R (programming language)|R]]\n| operating system       = \n| platform               = \n| size                   = \n| language               = \n| language count         = <!-- DO NOT include this parameter unless you know what it does -->\n| language footnote      = \n| genre                  = [[Cross-platform]]\n| license                = [[GNU GPL]]\n| alexa                  = \n| website                = {{URL|https://yihui.name/knitr}}\n}}\n'''knitr''' is an engine for dynamic report generation with R.<ref>{{cite book|last=Xie|first=Yihui|title=Dynamic Documents with R and knitr, 2nd Edition|year=2015|publisher=Chapman & Hall/CRC|isbn=9781498716963|url=http://www.crcpress.com/product/isbn/9781498716963}}</ref><ref>{{cite web|last=Xie|first=Yihui|title=knitr: A General-Purpose Tool for Dynamic Report Generation in R|url=https://github.com/yihui/knitr/releases/download/doc/knitr-manual.pdf}}</ref> It is a package in the [[statistical]] programming language [[R (programming language)|R]] that enables integration of R code into [[LaTeX]], [[LyX]], [[HTML]], [[Markdown]], [[AsciiDoc]], and [[reStructuredText]] documents. The purpose of knitr is to allow [[reproducible research]] in R through the means of [[Literate Programming]]. It is licensed under the [[GNU General Public License]].<ref>https://cran.r-project.org/package=knitr</ref>\n\nknitr was inspired by [[Sweave]] and written with a different design for better [[modularization]], so it is easier to maintain and extend. Sweave can be regarded as a subset of knitr in the sense that all features of Sweave are also available in knitr. Some of knitr's extensions include the R Markdown format<ref>{{cite web|last=RStudio, Inc|title=R Markdown — Dynamic Documents for R|url=http://rmarkdown.rstudio.com}}</ref> (used in reports published on RPubs<ref>{{cite web|last=RStudio, Inc|title=Easy web publishing from R|url=http://www.rpubs.com/}}</ref>), caching, [[TikZ]] graphics and support to other languages such as [[Python (programming language)|Python]], [[Perl]], [[C++]], [[Shell scripts]] and [[CoffeeScript]], and so on.\n\nknitr is officially supported in the [[RStudio]] [[Integrated development environment|IDE]] for R, [[LyX]], [[Emacs Speaks Statistics|Emacs/ESS]] and the [[Architect (software)|Architect]] [[Integrated development environment|IDE]] for data science.\n\n==Workflow of KnitR==\nKnitR consists of standard e.g. MarkDown document with R-code chunks integrated in the document. The code chunks can be regarded as R-scripts that\n* load data,\n* performs data processing and\n* creates output data (e.g. descriptive analysis) or output graphics (e.g. boxplot diagram).\nThe implementation of logical conditions in R can provide text elements for the dynamic report depended on the statistical analysis.\nThe following text is as stan\n    The Wilcoxon Sign test was applied as statistical comparison of the average of two dependent samples above. \n    In this case then, the calculated P-value was 0.56 and hence greater than the significance (0.05 by default).\n    This implies that \"H0: there is no difference between the    \n    results in data1 and data2\" must be accepted. \nDepending on the R results (here 0.56) the text fragments are determined by logical conditions in the R-script. If the P-value were 0.04, which is lower than the significance (0.05 by default), another appropriate text fragment would get inserted in the dynamic report. By this workflow the replacement of the input data of the statistical or numerical analysis in R creates a reproducible report which the same methodology.\n\n==See also==\n* [[b:R Programming/Publication Quality Ouput|The R Programming wikibook]]\n* [[Reproducible research]]\n\n==References==\n{{Reflist}}\n\n==External links==\n*{{Official website|http://yihui.name/knitr/}}\n*[https://github.com/yihui/knitr Repository] on [[GitHub]]\n*[https://github.com/yihui/knitr-examples/ Example code] on [[GitHub]]\n*[https://cran.r-project.org/package=knitr knitr package] on [[R (programming language)#Packages|CRAN]]\n\n{{LaTeX navbox}}\n\n[[Category:Free R (programming language) software]]\n[[Category:Free statistical software]]\n[[Category:Free TeX software]]\n[[Category:Literate programming]]\n[[Category:R (programming language)]]\n\n\n{{programming-software-stub}}"
    },
    {
      "title": "Revolution Analytics",
      "url": "https://en.wikipedia.org/wiki/Revolution_Analytics",
      "text": "{{Infobox company\n| name = Revolution Analytics\n| logo = Revolution Analytics logo.png\n| caption = \n| type = [[Subsidiary]]\n| traded_as = \n| genre = <!-- Only used with media and publishing companies -->\n| fate = \n| predecessor = Revolution Computing\n| successor = \n| foundation = 2007\n| founder = \n| defunct = <!-- {{End date|YYYY|MM|DD}} -->\n| location_city = Mountain View, CA\n| location_country = United States\n| location = \n| locations = \n| area_served = \n| key_people = David Rich, CEO\n| industry = Statistical software\n| products = Revolution R\n| services = \n| revenue = 8-11 Million in 2009\n| operating_income = \n| net_income = \n| aum = <!-- Only used with financial services companies -->\n| assets = \n| equity = \n| owner = [[Microsoft]]<ref name=WinBetaMicrosoftCompletion>{{cite news|last=Kniskern|first=Kip|title=Microsoft completes Revolution Analytics acquisition: bringing big data analytics \"to everyone\".|url=http://www.winbeta.org/news/microsoft-completes-revolution-analytics-acquisition-bringing-big-data-analytics-everyone|newspaper=WinBeta|date=6 April 2015}}</ref>\n| num_employees = \n| parent = [[Microsoft]]\n| divisions = \n| subsid = \n| footnotes = \n| intl = \n| website                = {{URL|http://revolutionanalytics.com}}\n}}\n\n'''Revolution Analytics''' (formerly '''REvolution Computing''') is a [[statistical software]] company focused on developing open source and \"open-core\"<ref>{{cite web|last=Blankenhorn|first=Dana|title=Revolution rebooting R with name change and new strategy|url=http://www.zdnet.com/blog/open-source/revolution-rebooting-r-with-name-change-and-new-strategy/6362|work=ZDNet|accessdate=14 July 2011}}</ref> versions of the [[free and open source software]] [[R (programming language)|R]] for enterprise, academic and analytics customers. Revolution Analytics was founded in 2007 as REvolution Computing providing support and services for R in a model similar to [[Red Hat]]'s approach with Linux in the 1990s as well as bolt-on additions for parallel processing. In 2009 the company received nine million in [[venture capital]] from [[Intel]] along with a [[private equity firm]] and named [[Norman H. Nie]] as their new CEO. In 2010 the company announced the name change as well as a change in focus. Their core product, Revolution R, would be offered free to academic users and their commercial software would focus on [[big data]], large scale multiprocessor (or \"[[High-performance computing|high performance]]\") computing, and multi-core functionality.\n\n[[Microsoft]] announced on January 23, 2015 that they had reached an agreement to [[List of mergers and acquisitions by Microsoft|purchase]] Revolution Analytics for an as yet undisclosed amount.<ref>{{cite web|title=Microsoft to acquire Revolution Analytics to help customers find big data value with advanced statistical analysis|url=http://blogs.microsoft.com/blog/2015/01/23/microsoft-acquire-revolution-analytics-help-customers-find-big-data-value-advanced-statistical-analysis/|work=Official Microsoft Blog Post|accessdate=24 January 2015}}</ref><ref>{{cite web|title=Revolution Analytics joins Microsoft|url=http://blog.revolutionanalytics.com/2015/01/revolution-acquired.html/|work=Official RA Announcement|accessdate=24 January 2015}}</ref>\n\n==Founding and venture capital==\nREvolution Computing was founded in [[New Haven, Connecticut]] in 2007 by Richard Schultz, Martin Schultz, Steve Weston and Kirk Mettler. At the time Martin Schultz was also the Watson Professor of Computer Science at [[Yale University]].<ref>{{cite web|last=Bogdon|first=Steve|title=One-on-One with David Smith|url=http://www.dashboardinsight.com/articles/one-on-one-with-dashboard-insight/one-on-one-with-david-smith.aspx|work=Dashboard Insight|accessdate=31 August 2011}}</ref><ref name=\"rww1\">{{cite web|last=Leidel|first=John|title=Revolution Analytics Defines The Future of R-Statistics|url=http://insidehpc.com/2010/05/06/revolution-analytics-defines-the-future-of-r-statistics/|work=InsideHPC|accessdate=31 August 2011}}</ref> Adding parallel computing to R allowed the company to net large gains in speed for many common analytics operations and early clients like [[Pfizer]] took advantage of REvolution R to see large performance gains using R on computing clusters.<ref name=\"cnet\">{{cite web|last=Shankland|first=Stephen|title=Intel open-source expert heads to start-up|url=http://news.cnet.com/8301-1001_3-10202355-92.html|work=cnet News|publisher=[[CBS Interactive]]|accessdate=14 July 2011}}</ref> While the improvements to core R were released under the [[GNU General Public License]] (GPL), REvolution provides support and services to customers of their commercial product and had considerable early success with life sciences and pharmaceutical companies.<ref>{{cite news|last=Vance|first=Ashlee|title=R You Ready for R?|url=http://bits.blogs.nytimes.com/2009/01/08/r-you-ready-for-r/|accessdate=14 July 2011|newspaper=The New York Times|date=8 January 2009}}</ref><ref>{{cite news|last=Davies|first=Kevin|title=The New England Computing Revolution|url=http://www.bio-itworld.com/issues/2008/july-august/parallel-r.html|accessdate=14 July 2011|newspaper=Bio-IT World Magazine|date=14 July 2008}}</ref> A year later the company opened an additional office in [[Seattle]].<ref>{{cite web|title=REvolution Computing expands senior management team, opens west coast headquarters in Seattle|url=http://www.revolutionanalytics.com/news-events/news-room/2008/revolution-expands-senior-management.php|work=Revolution Analytics press release|accessdate=31 August 2011}}</ref>\n\nIn 2009 REvolution Computing accepted nine million dollars in venture capital from Intel and North Bridge Venture Partners, a private equity firm. Intel had previously supported REvolution Computing with venture capital in 2008.<ref>{{cite web|title=Intel capital makes series a investment in REvolution Computing—investment highlights Intel capital’s open source incubator program|url=http://www.revolutionanalytics.com/news-events/news-room/2008/intel-capital-makes-series-a-investment-in-revolution-computing.php|work=Revolution Analytics press release|accessdate=31 August 2011}}</ref> A number of Intel employees also joined Revolution Analytics as employees or as advisors.<ref name=\"cnet\" /> Concurrently, the company changed their name to Revolution Analytics and invited Norman Nie, founder of [[SPSS]], to serve as CEO.<ref>{{cite web|last=Rao|first=Leena|title=REvolution Computing Raises $9 Million|url=https://techcrunch.com/2009/10/20/revolution-computing-raises-9-million/|work=TechCrunch|accessdate=14 July 2011}}</ref><ref>{{cite news|last=Higginbotham|first=Stacey|title=The Data Whisperer: Norman Nie of Revolution Analytics|url=https://www.nytimes.com/external/gigaom/2011/02/02/02gigaom-the-data-whisperer-norman-nie-of-revolution-analy-22582.html|accessdate=14 July 2011|newspaper=The New York Times|date=2 February 2011}}</ref> This change in management corresponded with a movement toward building a more complete set of software for commercial users; prior to 2009 Revolution had been focused on building parallel processing functionality into the then mostly single threaded R.<ref>{{cite web|last=Prickett Morgan|first=Timothy|title=Open source R in commercial Revolution|url=https://www.theregister.co.uk/2010/05/06/revolution_commercial_r/|work=The Register|accessdate=1 September 2011}}</ref> David Rich replaced Norman Nie as CEO in February 2012.<ref>{{cite web|title=Revolution Analytics Names David Rich New CEO|url=http://www.revolutionanalytics.com/news-events/revolution-analytics-names-david-rich-new-ceo}}</ref>\n\n==High performance computing, big data and the shift to analytics==\nUnlike analytics products offered by [[SAS Institute]], R does not natively handle datasets larger than main memory. In 2010 Revolution Analytics introduced ScaleR, a package for Revolution R Enterprise designed to handle big data through a high-performance disk-based data store called XDF (not related to IBM's [[Extensible Data Format]]) and high performance computing across large clusters.<ref name=ZDNet>{{cite web|last=Gardner|first=Dana|title=Revolution Analytics targets R language, platform at growing need to handle 'big data' crunching challenges|url=http://www.zdnet.com/blog/gardner/revolution-analytics-targets-r-language-platform-at-growing-need-to-handle-big-data-crunching-challenges/3791|work=ZDNet|accessdate=14 July 2011}}</ref> The release of ScaleR marked a push away from consulting and services alone to custom code and [[a la carte]] package pricing.<ref>{{cite news|last=Morgan|first=Timothy Prickett|title=Revolution lets R to stats on big data|url=https://www.theregister.co.uk/2010/08/03/revolution_r_enterprise_v4/|accessdate=14 July 2011|newspaper=The Register|date=3 August 2010}}</ref> ScaleR also works with [[Apache Hadoop]] and other distributed file systems and Revolution Analytics has partnered with IBM to further integrate Hadoop into Revolution R.<ref>{{cite news|last=Harris|first=Derrick|title=IBM Creates Big Data Frankenstein With Netezza-R Fusion|url=https://www.nytimes.com/external/gigaom/2011/03/14/14gigaom-ibm-creates-big-data-frankenstein-with-netezza-r-78261.html|accessdate=14 July 2011|newspaper=The New York Times|date=14 March 2011}}</ref><ref>{{cite web|last=Rosenberg|first=Dave|title=Open-source 'R' gets Hadoop integration|url=http://news.cnet.com/8301-13846_3-20012446-62.html|work=cnet News|publisher=[[CBS Interactive]]|accessdate=14 July 2011}}</ref> Packages to integrate Hadoop and MapReduce into open source R can also be found on the community package repository, CRAN.<ref>{{cite web|last=Smith|first=David|title=Hadoop ported to R (and it's trivial)|url=http://blog.revolutionanalytics.com/2009/11/hadoop-ported-to-r.html|work=Revolutions|publisher=Revolution Analytics|accessdate=1 September 2011}}</ref><ref>{{cite web|last=Brown|first=Christopher|title=Package:mapReduce|url=https://cran.r-project.org/web/packages/mapReduce/|work=CRAN|publisher=The R Project|accessdate=1 September 2011}}</ref>\n\n==Market position==\nIn comparison to developers of similar analytics tools, Revolution Analytics is a small company; in 2010 the company had a projected revenue of $8–11 million, but no official records of revenue or profit were published in their projections.<ref>{{cite news|last=Xavier|first=Jon|title=Revolution Analytics wants to overthrow old statistical tools|url=http://www.bizjournals.com/sanjose/stories/2010/08/16/smallb1.html?surround=etf&ana=e_article&b=1281931200^3787631|accessdate=14 July 2011|newspaper=Silicon Valley Business Journal|date=15 August 2010}}</ref> According to Nie, the increased use of R - a fully fledged programming language, in contrast to other analytics packages - within academia is helping the company to grow quickly.<ref>{{cite news|last=Hardy|first=Quentin|title=Power in the Numbers|url=https://www.forbes.com/forbes/2010/0524/opinions-software-norman-nie-spss-ideas-opinions_print.html|accessdate=14 July 2011|newspaper=Forbes Magazine|date=24 May 2010}}</ref><ref>{{cite news|last=McNally|first=Steve|title=Names You Need to Know in 2011: R Data Analysis Software|url=https://blogs.forbes.com/smcnally/2010/11/10/names-you-need-to-know-in-2011-r-data-analysis-software/|work=Forbes|accessdate=14 July 2011|date=10 November 2010}}</ref><ref name=Register>{{cite web|last=Olds|first=Dan|title='R' is for Revolution Analytics|url=https://www.theregister.co.uk/2011/03/22/revolution_analytics_profile/|work=The Register|accessdate=14 July 2011}}</ref><ref>{{cite web|last=Lawson|first=Lorraine|title=Another Tool for Analyzing Big Data|url=http://www.itbusinessedge.com/cm/blogs/lawson/another-tool-for-analyzing-big-data/?cs=46294|work=IT Business Edge|accessdate=14 July 2011}}</ref><ref>{{cite news|last=Hardy|first=Quentin|title=Another Open Source Swipe at IBM and SAS|url=https://blogs.forbes.com/quentinhardy/2011/02/01/another-open-source-swipe-at-ibm-and-sas/|work=Forbes|accessdate=14 July 2011|date=1 February 2011}}</ref> Community vice president David Smith suggested that movement away from \"[[black box]]\" analytics toward open source tools in general supported vendors like Revolution over solely proprietary tools.<ref>{{cite web|last=Bodkin|first=Ron|title=Revolution Analytics - Commercializing R for Statistics|url=http://www.infoq.com/news/2011/02/revolution_analytics|work=InfoQ|accessdate=14 July 2011}}</ref>\n\n==Products==\nRevolution Analytics' product Revolution R is available in three editions. Revolution R Open is a free and open source distribution of R with additional features for performance and reproducibility. Revolution R Plus provides technical support and open-source assurance (legal indemnification) subscriptions for Revolution R Open and other open-source components that work with R. (These products were first announced October 15, 2014.<ref>{{cite web|title=Revolution Analytics Introduces Revolution R Open and Revolution R Plus|url=http://www.businesswire.com/news/home/20141015005258/en/Revolution-Analytics-Introduces-Revolution-Open-Revolution}}</ref>) Revolution R Enterprise adds proprietary components to support statistical analysis of [[Big Data]], and is sold as subscriptions for workstations, servers, Hadoop and databases. (Single-user licenses are available free for academic users as well as users competing in [[Kaggle]] [[data mining]] competitions.<ref>{{cite web|title=Free single user subscription to Revolution R Enterprise|url=http://www.revolutionanalytics.com/downloads/free-academic.php|work=Revolution Analytics website|accessdate=2 September 2011}}</ref><ref>{{cite web|last=Finley|first=Klint|title=Revolution Analytics Offers Free Software for Kaggle Competitors|url=http://www.readwriteweb.com/hack/2011/04/revolution-analytics-offers-fr.php|work=ReadWriteWeb|accessdate=14 July 2011|deadurl=yes|archiveurl=https://www.webcitation.org/6APqRgj97?url=http://www.readwriteweb.com/hack/2011/04/revolution-analytics-offers-fr.php|archivedate=4 September 2012|df=}}</ref>)\n\nIn January 2015 Microsoft rebranded and renewed several Revolution Analytics products and offerings for [[Hadoop]], [[Teradata|Teradata Database]], [[SUSE Linux]], [[Red Hat Linux|Red Hat]], and [[Microsoft Windows]]. Microsoft made several of these R-based products free of charge for developers - these products included:\n*'''Microsoft R Server''' which was previously called ''Revolution R Enterprise for Hadoop, Linux and Teradata'' and included new Microsoft enterprise support and purchasing options. Microsoft R Server was further made available to students through the Microsoft DreamSpark programme.\n*'''Microsoft R Server Developer Edition''' a free version for developers that with a feature set akin to the commercial edition.\n*'''Microsoft Data Science Virtual Machine''' an analytics tool developed by the Revolution Analytics division premiered in January 2015.\n*'''Microsoft R Open''' a rebranded version of ''Revolution R Open''.<ref>{{cite web|last=Robinson|first=Daniel|title=Microsoft unveils free Microsoft R Server Developer Edition for big data analytics.|url=http://www.v3.co.uk/v3-uk/news/2441698/microsoft-unveils-free-microsoft-r-server-developer-edition-for-big-data-analytics|work=V3|accessdate=13 January 2016}}</ref><ref>{{cite web|last=Viswav|first=Pradeep|title=Microsoft R Server Now Available For Hadoop, Linux And Teradata.|url=http://microsoft-news.com/microsoft-r-server-now-available-for-hadoop-linux-and-teradata/|work=Microsoft-News|accessdate=13 January 2016}}</ref><ref>{{cite web|last=Foley|first=Mary Jo|title=Microsoft delivers free version of its R analytics Server for developers. Microsoft is rolling out a free version of its R big-data analytics server for developers alongside the rest of the newly rebranded Revolution Analytics servers.|url=http://www.zdnet.com/article/microsoft-delivers-free-version-of-its-r-analytics-server-for-developers/|work=[[ZDNet]] - All About Microsoft|accessdate=13 January 2016}}</ref>\n\n==See also==\n* [[Business models for open-source software]]\n\n==References==\n{{reflist}}\n\n==Further reading==\n* {{cite news|last=Vance|first=Ashlee|title=Data Analysts Captivated by R’s Power|url=https://www.nytimes.com/2009/01/07/technology/business-computing/07program.html|accessdate=14 July 2011|newspaper=The New York Times|date=6 January 2009}}\n\n==External links==\n* ''[http://blog.revolutionanalytics.com/ Revolutions]'', the Revolution Analytics blog\n* ''[http://www.revolutionanalytics.com/aboutus/who-we-r.php About page]'' for Revolution Analytics\n* ''[http://mran.revolutionanalytics.com/ MRAN]'', the distribution site for Revolution R Open\n* [http://www.itbusinessedge.com/cm/community/features/interviews/blog/the-power-of-r-more-companies-using-language-for-business-analytics/?cs=46325&page=1 Interview] with Revolution Analytics COO Jeff Erhardt about R, Hadoop and business analytics\n\n{{Statistical software}}\n{{Microsoft}}\n\n[[Category:Microsoft acquisitions]]\n[[Category:Microsoft subsidiaries]]\n[[Category:R (programming language)]]\n[[Category:Software companies based in California]]"
    },
    {
      "title": "RExcel",
      "url": "https://en.wikipedia.org/wiki/RExcel",
      "text": "{{multiple issues|\n{{Advert|date=September 2013}}\n{{Notability|Products|date=September 2013}}\n}}\n\n{{Infobox software|\n  name =  RExcel |\n  logo =  |\n  screenshot =  |\n  caption =  |\n  developer = [[Erich Neuwirth]] |\n  latest_release_version = 3.2.9 |\n  latest_release_date = {{release date and age|2013|01|06|df=y}} |\n  platform = [[R programming language]],  [[Microsoft Excel]], [[Microsoft Windows]] |\n  genre = [[List of statistical packages|Statistical software]], [[Spreadsheet]] |\n  license = RExcel Noncommercial license or RExcel Commercial license |\n  website = [http://rcom.univie.ac.at/ rcom.univie.ac.at]\n}}\n'''RExcel''' is an addin for [[Microsoft Excel]]. It allows access to the statistics package [[R (programming language)|R]] from within Excel.\n\nThe main features are:\n* Data transfer (matrices and data frames) between R and Excel in both directions\n* Running R code directly from Excel ranges\n* Writing macros calling R to perform calculations without exposing R to the user\n* Calling R functions directly from cell formulas, using Excel's autoupdate mechanism to trigger recalculation by R\n* Using Excel as a [[GUI]] for R, making R functionality accessible through menus and dialog boxes instead of a command line oriented programming style. Using this paradigm, the widely used GUI package R Commander is available as an Excel menu bar.\n* Installed using the package RExcelInstaller from CRAN\n\nRExcel works on [[Microsoft Windows]] ([[Windows XP|XP]], [[Windows Vista|Vista]] or [[Windows 7|7]]), with Excel [[Microsoft Office 2003|2003]], [[Microsoft Office 2007|2007]],\n[[Microsoft Office 2010|2010]], and [[Microsoft Office 2013|2013]].<ref>http://www.statconn.com/products.html</ref>\nIt uses the statconnDCOM (available from the [http://rcom.univie.ac.at same site as RExcel]) server and for certain configurations additionally the rcom package (available from CRAN) to access R from within Excel.\n\n==References==\n{{Reflist}}\n* Baier T., Neuwirth E.,  De Meo M: [http://journal.r-project.org/archive/2011-2/RJournal_2011-2_Baier~et~al.pdf Creating and Deploying an Application with (R)Excel and R] R Journal 3/2, December 2011\n*Baier T. and Neuwirth. E. Excel :: COM :: R. Computational Statistics 22 (2007)\n*Heiberger R. and Neuwirth E. [https://www.springer.com/statistics/computational/book/978-1-4419-0051-7 R Through Excel], Springer Verlag 2009.\n*Neuwirth, E. [http://www.statistik.uni-dortmund.de/useR-2008/abstracts/Neuwirth.pdf R meets the Workplace] - Embedding R into Excel and making it more accessible. Paper presented at the UseR 2008, Dortmund\n*Narasimhan, B. [http://www.r-project.org/useR-2006/Slides/BaierEtAl.pdf Disseminating Statistical Methodology and Results via R and Excel: Two Examples.] Paper presented at the Interface 2007, Philadelphia\n*Baier, T., Heiberger, R., Neuwirth, E., Schinagl, K., & Grossmann, W. [http://www.r-project.org/useR-2006/Slides/BaierEtAl.pdf Using R for teaching statistics to nonmajors: Comparing experiences of two different approaches.] Paper presented at the UseR 2006, Vienna.\n*Konnert, A. [http://www.r-project.org/useR-2006/Abstracts/Konnert.pdf LabNetAnalysis - An instrument for the analysis of data from laboratory networks based on RExcel] Paper presented at the UseR 2006, Vienna.\n\n==External links==\n*[https://web.archive.org/web/20110525215422/http://cran.r-project.org/web/packages/RExcelInstaller/index.html RExcelInstaller at CRAN]\n*[http://rcom.univie.ac.at/ RExcel's web site] has a master installer ''RandFriendsSetup'' which installs R, many R packages, RExcel, and the infrastructure needed to run RExcel (rscproxy, rcom, the statconnDCOM server)\n\n{{Statistical software}}\n\n{{DEFAULTSORT:Rexcel}}\n[[Category:R (programming language)]]\n[[Category:Microsoft Office-related statistical software]]"
    },
    {
      "title": "Rhea (pipeline)",
      "url": "https://en.wikipedia.org/wiki/Rhea_%28pipeline%29",
      "text": "{{Infobox software\n| title                  = Rhea\n| name                   = Rhea\n| logo                   = Rhea Logo.png\n| logo size              = 220px\n| logo caption           =\n| screenshot             = \n| caption                = \n| collapsible            =\n| author                 =\n| developer              = Ilias Lagkouvardos, Sandra Fischer, Neeraj Kumar, Thomas Clavel\n| released               = {{Start date|2016|11|16|df=yes/no}}\n| discontinued           =\n| latest release version = 1.1.0\n| latest release date    = \n| latest preview version = \n| latest preview date    = \n| status                 =\n| programming language   = [[R (programming language)|R]]\n| operating system       = [[Windows]], [[macOS]], [[Ubuntu (operating system)|Ubuntu]], [[Fedora (operating system)|Fedora]], [[Red Hat Linux]], [[openSUSE]]\n| platform               = \n| size                   =\n| language               =\n| genre                  =\n| license                = [[MIT License]]\n| alexa                  =\n| website                = https://lagkouvardos.github.io/Rhea/\n}}\n\n{{context|date=March 2017}}\n'''Rhea'''<ref name=Lagkouvardos2017>{{cite journal|last1=Lagkouvardos|first1=Ilias|last2=Fischer|first2=Sandra|last3=Kumar|first3=Neeraj|last4=Clavel|first4=Thomas|title=Rhea: a transparent and modular R pipeline for microbial profiling based on 16S rRNA gene amplicons|journal=PeerJ|date=11 January 2017|volume=5|pages=e2836|doi=10.7717/peerj.2836}}</ref>  is a [[bioinformatic pipeline]] written in [[R (programming language)|R language]] for the analysis of microbial profiles. It was released during the end of 2016 and it is publicly available through a [[GitHub]] repository.<ref>{{cite web|title=Rhea by Lagkouvardos|url=https://lagkouvardos.github.io/Rhea/|website=lagkouvardos.github.io}}</ref>\n\nStarting with an [[Operational taxonomic unit]] (OTU) table, the pipeline contains scripts that perform the following common analytical steps:\n# Normalization of the OTU table\n# Calculation of the [[alpha diversity]] for each sample\n# Calculation of [[beta diversity]] and visualization of the results with [[Multidimensional scaling#Types|PCoA]]\n# Taxonomic binning\n# Statistical testing\n# Correlation analysis\n\nThe name Rhea was primarily given to the pipeline as a phonetic and visual link to the [[R (programming language)|R]] language used throughout development. Moreover, as stated in the original publication,<ref name=Lagkouvardos2017 /> the name was chosen to reflect the flowing and evolving nature of the scripts, as \"flow\" is one of the suggested etymology of the name of the mythological goddess [[Rhea (mythology)|Rhea]].\n\n== References ==\n<!-- Inline citations added to your article will automatically display here. See https://en.wikipedia.org/wiki/WP:REFB for instructions on how to add citations. -->\n{{reflist}}\n\n[[Category:R (programming language)]]\n[[Category:Free R (programming language) software]]\n[[Category:Software using the MIT license]]\n[[Category:Science software for Linux]]\n\n{{science-software-stub}}"
    },
    {
      "title": "Rnn (software)",
      "url": "https://en.wikipedia.org/wiki/Rnn_%28software%29",
      "text": "{{Infobox software\n| title = rnn\n| name = rnn\n| logo = <!-- [[File: ]] -->\n| logo caption = \n| screenshot = Rnn-software-screenshot-2.png\n| caption = \n| collapsible = \n| author = [[Bastiaan Quast]]\n| developer = \n| released = {{Start date|2015|11|30|df=yes}}\n| discontinued = \n| latest release version = 0.8.1\n| latest release date = {{Start date and age|2018|06|21|df=yes}}\n| latest preview version = \n| latest preview date = \n| repo = https://github.com/bquast/rnn\n| programming language = [[R (programming language)|R]]\n| operating system = \n| platform = \n| size = 460.3 kB (v. 0.8.1)\n| language = \n| language count = \n| language footnote = \n| genre = \n| license = [[GPL v3]]\n| alexa = \n| website = {{URL|https://cran.r-project.org/}}\n}}\n'''rnn''' is an open-source [[machine learning]] framework that implements [[Recurrent Neural Network]] architectures, such as [[LSTM]] and [[gated recurrent unit|GRU]], natively in the [[R (programming language)|R]] programming language.\n\nThe '''rnn''' package is distributed through the [[Comprehensive R Archive Network]]<ref>{{cite web|title=CRAN - Package rnn|url=https://cran.r-project.org/package=rnn}}</ref> under the [[Open-source software|open-source]] [[GPL v3]] license.\n\n== Workflow ==\nThe below example from the '''rnn''' documentation show how to train a recurrent neural network to solve the problem of bit-by-bit binary addition.\n\n<source lang=\"rsplus\">\n> # install the rnn package, including the dependency sigmoid\n> install.packages('rnn')\n\n> # load the rnn package\n> library(rnn)\n\n> # create input data \n> X1 = sample(0:127, 10000, replace=TRUE)\n> X2 = sample(0:127, 10000, replace=TRUE)\n\n> # create output data\n> Y <- X1 + X2\n\n> # convert from decimal to binary notation \n> X1 <- int2bin(X1, length=8)\n> X2 <- int2bin(X2, length=8)\n> Y  <- int2bin(Y,  length=8)\n\n> # move input data into single tensor\n> X <- array( c(X1,X2), dim=c(dim(X1),2) )\n\n> # train the model\n> model <- trainr(Y=Y,\n+                 X=X,\n+                 learningrate   =  1,\n+                 hidden_dim     = 16  )\nTrained epoch: 1 - Learning rate: 1\nEpoch error: 0.839787019539748\n</source>\n\n== sigmoid ==\nThe [[sigmoid function]]s and derivatives used in the package were originally included in the package, from version 0.8.0 onwards, these were released in a separate R package '''sigmoid''', with the intention to enable more general use. The '''sigmoid''' package is a dependency of the '''rnn''' package and therefore automatically installed with it.<ref>{{cite web|title=CRAN - Package sigmoid|url=https://cran.r-project.org/package=sigmoid}}</ref>\n\n== Reception ==\nWith the release of version 0.3.0 in April 2016<ref>{{Cite web|url=https://github.com/bquast/rnn/releases/tag/0.3.0|title=bquast/rnn|website=GitHub|language=en|access-date=2018-07-05}}</ref> the use in production and research environments became more widespread. The package was reviewed several months later on the R blog The Beginner Programmer as \"R provides a simple and very user friendly package named '''rnn''' for working with recurrent neural networks.\",<ref>{{Cite web|url=http://firsttimeprogrammer.blogspot.com/2016/08/plain-vanilla-recurrent-neural-networks.html|title=The Beginner Programmer: Plain vanilla recurrent neural networks in R: waves prediction|last=Mic|date=2016-08-05|website=The Beginner Programmer|access-date=2018-07-06}}</ref> which further increased usage.<ref>{{Cite web|url=https://datascience.stackexchange.com/questions/6964/lstm-or-other-rnn-package-for-r|title=LSTM or other RNN package for R|website=Data Science Stack Exchange|access-date=2018-07-05}}</ref>\n\nThe book [https://www.oreilly.com/library/view/neural-networks-with/9781788397872/ Neural Networks in R] by Balaji Venkateswaran and Giuseppe Ciaburro uses '''rnn''' to demonstrate [[recurrent neural networks]] to R users.<ref>{{Cite news|url=https://www.oreilly.com/library/view/neural-networks-with/9781788397872/9219bb11-a546-4e48-aa5f-689cc720228e.xhtml|title=Neural Networks with R|last=|first=|date=September 2017|work=Neural Networks with R|access-date=2018-10-02|archive-url=https://web.archive.org/web/20181002130929/https://www.oreilly.com/library/view/neural-networks-with/9781788397872/9219bb11-a546-4e48-aa5f-689cc720228e.xhtml|archive-date=2018-10-02|publisher=O'Reilly|language=en|isbn=9781788397872}}</ref>\n\nThe RStudio CRAN mirror download logs\n<ref>{{cite web|title=RStudio CRAN logs|url=http://cran-logs.rstudio.com/}}</ref> show that the package is downloaded on average about 1000 per month from those servers\n,<ref>{{cite web|title=CRANlogs rnn package|url=https://cranlogs.r-pkg.org/badges/rnn}}</ref> with a total of over 20,000 downloads since the first release\n,<ref>{{cite web|title=CRANlogs rnn package|url=https://cranlogs.r-pkg.org/badges/grand-total/rnn}}</ref> according to RDocumentation.org, this puts the package in the 15th percentile of most popular R packages\n.<ref>{{cite web|title=RDocumentation rnn|url=https://www.rdocumentation.org/packages/rnn}}</ref>\n\n== References ==\n{{reflist}}\n\n==External links==\n*[https://github.com/bquast/rnn Repository] on [[GitHub]]\n*[https://cran.r-project.org/package=rnn rnn package] on [[R (programming language)#Packages|CRAN]]\n\n{{Numerical analysis software}}\n{{Deep Learning Software}}\n\n[[Category:Applied machine learning]]\n[[Category:Data mining and machine learning software]]\n[[Category:Deep learning]]\n[[Category:Free statistical software]]\n[[Category:Free science software]]\n[[Category:Open-source artificial intelligence]]\n[[Category:R scientific libraries]]\n[[Category:Free R (programming language) software]]\n[[Category:R (programming language)]]"
    },
    {
      "title": "RStudio",
      "url": "https://en.wikipedia.org/wiki/RStudio",
      "text": "{{multiple issues|\n{{lead too long|date=March 2019}}\n{{third-party|date=March 2019}}\n}}\n{{Infobox software\n| title                  = RStudio\n| name                   = RStudio\n| logo                   = RStudio logo flat.svg\n| logo size              = \n| logo caption           =\n| screenshot             = Rstudio.png\n| caption                = RStudio on Ubuntu 12.10\n| collapsible            =\n| author                 =\n| developer              = RStudio, Inc.\n| released               = {{Start date and age|2011|02|28|df=yes/no}}<ref name=\"originalreleaseblogpost\" />\n| discontinued           =\n| latest release version = 1.2.1335\n| latest release date    = {{Start date and age|2019|04|08|df=yes/no}}<ref>{{cite web|title=RStudio Release Notes|url=https://www.rstudio.com/products/rstudio/release-notes/|website=rstudio.com|access-date=4 May 2019}}</ref>\n| latest preview version = \n| latest preview date    = \n| programming language   = [[Java (programming language)|Java]], [[C++]], [[JavaScript]]<ref>{{cite web|title=rstudio/rstudio|url=https://github.com/rstudio/rstudio/|website=[[GitHub]]|publisher=RStudio|accessdate=18 December 2016}}</ref>\n| operating system       = [[Windows NT]], [[macOS]], [[Ubuntu (operating system)|Ubuntu]], [[Fedora (operating system)|Fedora]], [[Red Hat Linux]], [[openSUSE]]\n| platform               = [[IA-32]], [[x86-64]]; [[Qt (framework)|Qt]]\n| size                   =\n| language               =\n| genre                  =\n| license                = [[Affero General Public License]] v3<ref name=\"urlWhat license is RStudio available under? – RStudio\">{{cite web |url=http://support.rstudio.com/hc/en-us/articles/217801078-What-license-is-RStudio-available-under- |title=What license is RStudio available under? – RStudio |last=Pylvainen |first=Ian |work=rstudio.com |date=2016-03-24 |accessdate=2018-05-25}}</ref>\n| alexa                  =\n| website                = {{URL|https://www.rstudio.com}}\n}}\n{{Portal|Free and open-source software}}\n'''RStudio''' is a [[free and open-source]] [[integrated development environment]] (IDE) for [[R (programming language)|R]], a [[programming language]] for [[statistical computing]] and graphics. RStudio was founded by [[Joseph J. Allaire|JJ Allaire]],<ref>{{cite web|url=https://www.rstudio.com/about/ |title=\"Why Rstudio?\" |publisher=Rstudio.com |accessdate=2015-12-15}}</ref> creator of the programming language [[ColdFusion Markup Language|ColdFusion]]. [[Hadley Wickham]] is the Chief Scientist at RStudio.<ref>{{cite web|url=http://news.idg.no/cw/art.cfm?id=F66B12BB-D13E-94B0-DAA22F5AB01BEFE7 |title=60+ R resources to improve your data skills ( - Software ) |publisher=News.idg.no |date= |accessdate=2014-02-12}}</ref>\n\nRStudio is available in two editions: RStudio Desktop, where the program is run locally as a regular [[desktop application]]; and RStudio Server, which allows accessing RStudio using a [[web browser]] while it is running on a remote Linux server. Prepackaged distributions of RStudio Desktop are available for [[Microsoft Windows|Windows]], [[macOS]], and [[Linux]].\n\nRStudio is available in open source and commercial editions and runs on the desktop (Windows, macOS, and Linux) or in a browser connected to RStudio Server or RStudio Server Pro ([[Debian]], [[Ubuntu (operating system)|Ubuntu]], [[Red Hat Linux]], [[CentOS]], [[openSUSE]] and [[SUSE Linux Enterprise Server|SLES]]).<ref>{{cite web|url=https://www.rstudio.com/products/RStudio/|title=RStudio|work=rstudio.com|accessdate=2 December 2016}}</ref>\n\nRStudio is partly written in the [[C++]] programming language and uses the [[Qt (software)|Qt framework]] for its [[graphical user interface]].<ref>{{cite book|title = Getting Started with RStudio|last = Verzani|first = John|publisher = O'Reilly Media, Inc|isbn = 9781449309039|page = 4}}</ref> The bigger percentage of the code is written in Java. JavaScript is also amongst the languages used.<ref>{{Cite web|url=https://github.com/rstudio/rstudio|title=rstudio/rstudio|website=GitHub|language=en|access-date=2018-09-13}}</ref>\n\nWork on RStudio started around December 2010,<ref>{{cite web|url=https://github.com/rstudio/rstudio/commit/484cb884c28913c19822c42b0cd099ee22832211 |title=portable download of java dependencies · rstudio/rstudio@484cb88 · GitHub |publisher=Github.com |date=2010-12-07 |accessdate=2015-05-01}}</ref> and the first public [[beta version]] (v0.92) was officially announced in February 2011.<ref name=\"originalreleaseblogpost\">{{cite web|url=http://blog.rstudio.org/2011/02/28/rstudio-new-open-source-ide-for-r/ |title=RStudio, new open-source IDE for R &#124; RStudio Blog |publisher=Blog.rstudio.org |date= |accessdate=2015-05-01}}</ref> [[Software versioning#Version 1.0 as a milestone|Version 1.0]] was released on 1 November 2016.<ref>{{cite web|title=Announcing RStudio v1.0!|url=https://blog.rstudio.org/2016/11/01/announcing-rstudio-v1-0/|website=RStudio Blog|date=1 November 2016}}</ref> Version 1.1 was released on 9 October 2017. <ref>{{cite web|title=RStudio v1.1 Released|url= https://blog.rstudio.com/2017/10/09/rstudio-v1.1-released/|website=RStudio Blog|date=9 October 2017}}</ref>\n\nIn April 2018 it was announced RStudio will be providing operational and infrastructure support for Ursa Labs. Ursa Labs will focus on building a new data science runtime powered by [[Apache Arrow]].<ref>{{cite web|last1=Allaire|first1=JJ|title=Arrow and beyond: Collaborating on next generation tools for open source data science|url=https://blog.rstudio.com/2018/04/19/arrow-and-beyond/|website=RStudio|accessdate=13 May 2018}}</ref>\n\nIn April 2019, RStudio launched the RStudio Job Launcher<ref>{{Cite web|url=https://blog.rstudio.com/2019/04/30/rstudio-1-2-release/|title=RStudio 1.2 Release|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=}}</ref> which provides the ability for various RStudio applications, such as RStudio Server Pro, to start processes within various batch processing systems (e.g. Slurm) and container orchestration platforms (e.g. Kubernetes). \n\n==Packages==\nRStudio and its team have contributed to many  R packages.<ref>{{cite web|title=Inspired by R and its community|url=https://www.rstudio.com/products/rpackages/|website=RStudio|accessdate=13 May 2018}}</ref> These include:\n*[[Tidyverse]] – R packages for data science, including [[ggplot2]], dplyr, tidyr, and purrr\n* Shiny – An interactive web technology\n* RMarkdown – Insert R code into markdown documents\n* [[knitr]] – Dynamic reports combining R, TeX, Markdown & HTML\n* packrat – Package dependency tool\n* devtools – Package development tool\n\n== Addins ==\nRStudio provides a mechanism for executing R functions interactively from within the IDE  through the '''Addins''' menu<ref>{{Cite web|url=https://rstudio.github.io/rstudioaddins/|title=RStudio Addins|last=|first=|date=|website=RStudio|archive-url=|archive-date=|dead-url=|access-date=2018-09-16}}</ref>. This enables packages to include [[Graphical user interface|Graphical User Interfaces]] (GUIs) for increased accessibility. Popular packages that use '''Addins''' based GUIs include:\n\n* bookdown – a [[knitr]] extension to create books\n* colourpicker – a graphical tool to pick colours for plots\n*[[datasets.load]] – a graphical tool to search and load datasets\n* googleAuthR – Authenticate with Google APIs\n\n==See also==\n* [[R (programming language)#Interfaces|R interfaces]]\n* [[Comparison of integrated development environments#R|Comparison of integrated development environments]]\n\n==References==\n{{reflist}}\n\n==External links==\n* {{Official website}}\n\n{{Integrated development environments}}\n\n[[Category:Free R (programming language) software]]\n[[Category:R (programming language)]]\n[[Category:Science software for Linux]]\n[[Category:Software using the GNU AGPL license]]\n\n{{science-software-stub}}"
    },
    {
      "title": "SimpleITK",
      "url": "https://en.wikipedia.org/wiki/SimpleITK",
      "text": "__NOTOC__\n{{Infobox software\n| name                   = SimpleITKITK\n| title                  = \n| logo                   = simpleITKToolkitLogo.jpg\n| logo caption           = SimpleITK Logo\n| logo size              = 180px\n| logo alt               = \n| screenshot             = <!-- Image name is enough -->\n| caption                = \n| screenshot size        = \n| screenshot alt         = \n| collapsible            = \n| author                 = \n| developer              = Insight Software Consortium\n| released               = <!-- {{Start date and age|YYYY|MM|DD|df=yes/no}} -->\n| discontinued           = \n| latest release version = 1.2.0\n| latest release date    = {{Start date and age|df=yes|2019|01|10}}\n| latest preview version = \n| latest preview date    = <!-- {{Start date and age|YYYY|MM|DD|df=yes/no}} -->\n| status                 = Active\n| programming language   = [[C++]], [[Python (programming language)|Python]], [[R (programming language)|R]], [[Java (programming language)|Java]], [[C Sharp (programming language)|C#]], [[Lua (programming language)|Lua]], [[Ruby (programming language)|Ruby]], [[Tcl]] \n| operating system       = [[Cross-platform]]\n| platform               = \n| size                   = \n| language               = \n| language count         = <!-- Number only -->\n| language footnote      = \n| genre                  = Library for image analysis\n| license                = [[Apache License|Apache 2.0]]\n| alexa                  = \n| website                = {{URL|http://www.simpleitk.org}}\n| standard               = \n| AsOf                   = \n}}\n'''SimpleITK''' is a simplified, [[open-source software|open-source ]] interface to the [[United States National Library of Medicine]]’s [[Insight Segmentation and Registration Toolkit]] (ITK). The SimpleITK image analysis library is available in multiple programming languages including [[C++]], [[Python (programming language)|Python]], [[R (programming language)|R]]<ref>R. Beare, B. C. Lowekamp, Z. Yaniv, “Image Segmentation, Registration and Characterization in R with SimpleITK”, J Stat Softw, 86(8), 2018, doi:10.18637/jss.v086.i08.</ref>, [[Java (programming language)|Java]], [[C Sharp (programming language)|C#]], [[Lua (programming language)|Lua]], [[Ruby (programming language)|Ruby]] and [[Tcl]]. Binary distributions are available for all three major operating systems ([[Linux]], [[macOS]] and [[Microsoft Windows]]). \n\nDeveloped at the National Library of Medicine (NLM) as an open resource, its primary goal is to make the algorithms available in the ITK library accessible to the broadest range of scientists whose work includes [[image analysis]], irrespective of their software development skills<ref>B. C. Lowekamp, D. T. Chen, L. Ibáñez, D. Blezek, \"The Design of SimpleITK\", Front. Neuroinform.,7:45, 2013, doi:10.3389/fninf.2013.00045.</ref>. \nAs a consequence, the SimpleITK interface exposes only the most commonly modified algorithmic settings of the ITK components. Additionally, the library provides both an [[Object-oriented programming|object oriented]] and a [[Procedural programming|procedural]] interface to most of the image processing filters. The latter enables image analysis workflows with concise syntax. A secondary goal of the library is to promote [[Reproducibility#Reproducible_research|reproducible]] image analysis workflows<ref>Z. Yaniv, B. C. Lowekamp, H.J. Johnson, R. Beare, \"SimpleITK Image-Analysis Notebooks: a Collaborative Environment for Education and Reproducible Research\", J Digit Imaging.,  31(3):290-303, 2018, doi: 10.1007/s10278-017-0037-8.</ref> by using the SimpleITK library in conjunction with modern tools for reproducible computational workflows available in the Python ([[IPython|Jupyter notebooks]]) and R ([[Knitr|knitr package]] ) programming languages. \n\nSoftware development is centered on [[GitHub]] using a [[fork and pull model]]. The project is built using the [[CMake]] tool, with nightly builds posted to the [https://open.cdash.org/index.php?project=SimpleITK project's quality dashboard].\n\nMultiple medical image analysis applications and libraries incorporate SimpleITK as a key building block, as it provides a wide range of image filtering and image IO components with a user friendly interface. Examples include the pyOsirix<ref>M. D. Blackledge, D. J.Collins, D-M Koh, M. O. Leach, \"Rapid development of image analysis research tools: Bridging the gap between researcher and clinician with pyOsiriX\", Comput Biol Med., 69:203-212, 2016, doi: 10.1016/j.compbiomed.2015.12.002 </ref> scripting tool for the popular [[Osirix]] application, the pyradiomics python package for extracting radiomic features from medical imaging<ref> J. J. M. van Griethuysen, A. Fedorov, C. Parmar, A. Hosny, N. Aucoin, V. Narayan, R. G. H. Beets-Tan, J. C. Fillon-Robin, S. Pieper, H. J. W. L. Aerts, \"Computational Radiomics System to Decode the Radiographic Phenotype\", Cancer Research, 77(21): e104–e107, 2017, doi: 10.1158/0008-5472.CAN-17-0339</ref>, the [[3DSlicer]] image analysis application,  the SimpleElastix medical image registration library<ref>K. Marstal, F. Berendsen, M. Staring, S. Klein, \"SimpleElastix: A User-Friendly, Multi-lingual Library for Medical Image Registration\",  IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), 574-582, 2016, doi:10.1109/CVPRW.2016.78</ref>, and the NiftyNet deep learning library for medical imaging<ref>E. Gibson, W. Li, C. Sudre, L. Fidon, D. I. Shakir, G. Wang, Z. Eaton-Rosen, R. Gray, T. Doel, Y. Hu, T. Whyntie, P. Nachev, M. Modat, D. C. Barratt, S. Ourselin, M. J. Cardoso, T. Vercauteren, \"NiftyNet: a deep-learning platform for medical imaging\", Comput Methods Programs Biomed., 158:113-122, 2018, doi: 10.1016/j.cmpb.2018.01.025</ref>.\n\n==History==\n\nThe initial development of SimpleITK was funded by the National Library of Medicine under the [[American Recovery and Reinvestment Act of 2009|American Recovery and Reinvestment Act (ARRA)]] program as a collaboration between The Mayo Clinic, Kitware Inc, The University of Iowa and NLM's intramural program. Since 2013, SimpleITK development is primarily carried out as part of the intramural research program of the National Library of Medicine with collaborators at The University of Iowa and Monash University.\n\nThe first major release of the toolkit was [https://www.nlm.nih.gov/news/nlm_releases_simpleitk.html announced in April-May 2017].\n\n==Examples==\n\n=== Gaussian smoothing ===\nShort Python scripts illustrating image reading, blurring, and writing. Using the object oriented interface: \n\n<source lang=\"python\">\nimport SimpleITK as sitk\nimport sys\n\nif len ( sys.argv ) < 4:\nprint( \"Usage: SimpleGaussian <input> <sigma> <output>\" )\nsys.exit ( 1 )\n\n\nreader = sitk.ImageFileReader()\nreader.SetFileName ( sys.argv[1] )\nimage = reader.Execute()\n\npixelID = image.GetPixelID()\n\ngaussian = sitk.SmoothingRecursiveGaussianImageFilter()\ngaussian.SetSigma ( float ( sys.argv[2] ) )\nimage = gaussian.Execute ( image )\n\ncaster = sitk.CastImageFilter()\ncaster.SetOutputPixelType( pixelID )\nimage = caster.Execute( image )\n\nwriter = sitk.ImageFileWriter()\nwriter.SetFileName ( sys.argv[3] )\nwriter.Execute ( image );\n</source>\n\nA more concise version using the procedural interface:\n\n<source lang=\"python\">\nimport SimpleITK as sitk\nimport sys\n\n\nif len ( sys.argv ) < 4:\nprint( \"Usage: SimpleGaussian <input> <sigma> <output>\" )\nsys.exit ( 1 )\n\nimage = sitk.ReadImage( sys.argv[1] )\npixelID = image.GetPixelID()\nimage = sitk.Cast( sitk.SmoothingRecursiveGaussian( image, float ( sys.argv[2] ) ), pixelID )\nsitk.WriteImage( image, sys.argv[3] )\n</source>\n\n=== Multi-modality Rigid Registration ===\n\nShort R script illustrating the use of the library's registration framework for rigid registration\nof two 3D images:\n\n<source lang=\"r\">\nlibrary(SimpleITK)\n\nargs = commandArgs( trailingOnly=TRUE )\nif( length( args ) < 2 )\n{\n\tcat( \"Usage: registration <fixed_image> <moving_image> <output_transform>\\n\" )\n\tquit( save=\"no\", status=1 )\n}\nfixed_image <- ReadImage( args[1], \"sitkFloat32\" )\nmoving_image <- ReadImage( args[2], \"sitkFloat32\" )\n\ninitial_transform <- CenteredTransformInitializer( fixed_image,\n                                                   moving_image,\n                                                   Euler3DTransform(),\n                                                   \"GEOMETRY\" )\nreg <- ImageRegistrationMethod()\nreg$SetMetricAsMattesMutualInformation( numberOfHistogramBins=50 )\nreg$SetMetricSamplingStrategy( \"RANDOM\" )\nreg$SetMetricSamplingPercentage( 0.01 )\nreg$SetInterpolator( \"sitkLinear\" )\nreg$SetOptimizerAsGradientDescent( learningRate=1.0,\nnumberOfIterations=100 )\nreg$SetOptimizerScalesFromPhysicalShift()\nreg$SetInitialTransform( initial_transform, inPlace=FALSE )\nfinal_transform <- reg$Execute( fixed_image, moving_image )\n\nWriteTransform( final_transform, \"final_transform.tfm\" )\n</source>\n\n==References==\n{{reflist|30em}}\n\n==External links==\n* [http://www.simpleitk.org/ Official website]\n* [https://github.com/SimpleITK Organization on GitHub]\n* Short examples illustrating how to use some of the library components are available on [https://simpleitk.readthedocs.io/en/master/Examples/index.html read the docs].\n* [https://itk.org/SimpleITKDoxygen/html/ Class and procedure documentation] is available via [[Doxygen]].\n* [https://github.com/InsightSoftwareConsortium/SimpleITK-Notebooks Jupyter notebooks on GitHub] with long and extensively documented examples, useful for learning and teaching how to work with SimpleITK.\n* Get help, post questions on the [https://discourse.itk.org/ ITK discussion forum].\n\n[[Category:Python libraries]]\n[[Category:Image processing software]]\n[[Category:R (programming language)]]"
    },
    {
      "title": "Sweave",
      "url": "https://en.wikipedia.org/wiki/Sweave",
      "text": "'''Sweave''' is a [[Function (computer science)|function]] in the [[statistic]]al programming language [[R (programming language)|R]] that enables integration of R code into [[LaTeX]] or [[LyX]] documents. The purpose is \"to create dynamic reports, which can be updated automatically if data or analysis change\".<ref name=\"Leisch2002\">{{cite journal\n| last=Leisch\n| first=Friedrich\n| year=2002\n| title=Sweave, Part I: Mixing R and LaTeX: A short introduction to the Sweave file format and corresponding R functions\n| journal=R News\n| volume=2\n| issue=3\n| pages=28–31\n| url=https://cran.r-project.org/doc/Rnews/Rnews_2002-3.pdf\n| accessdate=22 January 2012\n}}</ref>\n\nThe data analysis is performed at the moment of writing the report, or more exactly, at the moment of compiling the Sweave code with Sweave (i.e., essentially with R) and subsequently with LaTeX. This can facilitate the creation of up-to-date reports for the author.\n\nBecause the Sweave files together with any external R files that might be sourced from them and the data files contain all the information necessary to trace back all steps of the data analyses, Sweave also has the potential to make research more transparent and reproducible to others.<ref name=\"Pineda-Krch2011\">{{cite web\n|url         = http://www.math.ualberta.ca/~mlewis/links/the_joy_of_sweave_v1.pdf\n|accessdate  = 22 Jan 2012\n|title       = The Joy of Sweave – A Beginner’s Guide to Reproducible Research with Sweave\n|first       = Mario \n|last        = Pineda-Krch\n|date        = 17 January 2011\n}}</ref> However, this is only the case to the extent that the author makes the data and the R and Sweave code available. If the author only publishes the resulting [[PDF]] document or printed versions thereof, a report created using Sweave is no more transparent or reproducible than the same report created with other statistical and text preparation software.\n\n==See also==\n* [[knitr]] (an alternative to Sweave in [[R (programming language)|R]])\n* [[LaTeX]]\n* [[Literate Programming]]\n* [[LyX]]\n* [[Reproducibility#Reproducible research|Reproducible research]]\n* [[b:R Programming/Publication Quality Ouput|The R Programming wikibook]]\n\n==References==\n{{reflist}}\n\n==External links==\n*{{Official website|http://www.stat.uni-muenchen.de/~leisch/Sweave/}}\n* [http://mpastell.com/pweave/ Pweave]\n\n{{LaTeX navbox}}\n\n[[Category:R (programming language)]]\n[[Category:Free statistical software]]\n[[Category:Free TeX software]]\n[[Category:Literate programming]]"
    },
    {
      "title": "Hadley Wickham",
      "url": "https://en.wikipedia.org/wiki/Hadley_Wickham",
      "text": "{{Infobox scientist\n| name = Hadley Wickham \n| birth_name = \n| image = Hadley-wickham2016-02-04.jpg\n| image_size        = 200px\n| birth_date = \n| birth_place = \n|death_date = \n|death_place = \n| residence = United States\n| citizenship =\n| nationality =\n| ethnicity =\n| field = {{Plainlist|\n* [[Statistics]]\n* [[Data science]] \n* [[R (programming language)]] }}\n| alma_mater        = [[Iowa State University]], [[University of Auckland]]\n| doctoral_advisors  = {{Plainlist|\n* [[Di Cook]]\n* [[Heike Hofmann]]}}\n| doctoral_students  = Garrett Grolemund\n| thesis_title = Practical tools for exploring data and models\n| thesis_year = 2008\n| thesis_url = http://had.co.nz/thesis/\n| known_for         = [[R (programming language)#Packages|R programming language packages]]\n| influences = \n| influenced = \n| prizes = {{Plainlist|\n* [[John Chambers (statistician)|John Chambers]] Award <small>(2006)</small>\n* Fellow of the [[American Statistical Association]] <small>(2015)</small>}}\n| footnotes         =\n| signature         =\n}}\n\n'''Hadley Wickham''' is a [[statistician]] from [[New Zealand]] who is currently Chief Scientist at [[RStudio]]<ref>{{cite web|url=http://washstat.org/newsletters/wss1310.shtml |title=Washington Statistical Society October 2013 Newsletter |publisher=Washington Statistical Society |date= |accessdate=2014-02-12}}</ref><ref>{{cite web|url=http://news.idg.no/cw/art.cfm?id=F66B12BB-D13E-94B0-DAA22F5AB01BEFE7 |title=60+ R resources to improve your data skills ( - Software ) |publisher=News.idg.no |date= |accessdate=2014-02-12}}</ref> and an [[Professors in the United States#Adjunct professor|adjunct]] [[Professor]] of statistics at the [[University of Auckland]],<ref name=\"University of Auckland Adjunct Professorship - Dr Hadley Alexander Wickham - Honorary, Academic\">{{cite web|url=https://www.stat.auckland.ac.nz/people/hwic004|title=University of Auckland|accessdate=2017-09-03}}</ref> [[Stanford University]],<ref name=\"Stanford University - Adjunct Professor, Institute for Computational and Mathematical Engineering (ICME)\">{{cite web|url=https://profiles.stanford.edu/hadley-wickham|title=Hadley Wickham's Profile - Stanford Profiles|accessdate=2017-09-03}}</ref> and [[Rice University]].<ref name=\"about\">{{cite web|url=http://www.rstudio.com/about/ |title=About - RStudio |accessdate=2014-08-13}}</ref> He is best known for his development of open-source statistical analysis software packages for [[R (programming language)]] that implement logics of [[data visualisation]] and data transformation. Wickham's packages and writing are known for advocating a [[tidy data]] approach to data import, analysis and modelling methods.\n\n==Life==\nWickham received a Bachelors of Human Biology, and a B.Sc. and a M.Sc. in statistics at the [[University of Auckland]] in 1999–2004 and his PhD at [[Iowa State University]] in 2008 under the supervision of [[Di Cook]] and [[Heike Hofmann]].<ref>{{cite thesis |last=Wickham |first=Hadley Alexander |date=2008 |title=Practical tools for exploring data and models |type=PhD |publisher=Iowa State University |oclc=247410260 |doi=10.31274/rtd-180813-16852 |url=http://had.co.nz/thesis/ |access-date=2019-02-14}}</ref><ref>{{cite web|URL=http://blog.revolutionanalytics.com/2010/09/the-r-files-hadley-wickham.html |title= The R-Files: Hadley Wickham}}</ref> In 2006 he was awarded the [[John Chambers (statistician)|John Chambers]] Award for Statistical Computing for his work developing tools for data reshaping and visualisation.<ref>{{cite web|url=http://stat-computing.org/awards/jmc/winners.html |title=John Chambers Award Past winners|publisher=ASA Sections on Statistical Computing, Statistical Graphics|date= |accessdate=2014-08-12}}</ref> His sister Charlotte Wickham is also a statistician.\n\nHe is a prominent and active member of the [[R (programming language)|R]] user community and has developed several notable and widely used packages including [[ggplot2]], plyr, dplyr, and reshape2.<ref name=\"about\" /><ref>{{cite web|url=http://www.r-statistics.com/2013/06/top-100-r-packages-for-2013-jan-may/ |title=Top 100 R Packages for 2013 (Jan-May)! |publisher=R-statistics blog |date= |accessdate=2014-08-12}}</ref> Wickham's data analysis packages for R are collectively known as the '[[tidyverse]]'.<ref>{{cite web|url=http://blog.revolutionanalytics.com/2016/09/tidyverse.html |title=Welcome to the Tidyverse |publisher=Revolution Analytics |date= |accessdate=2016-09-21}}</ref> According to Wickham's [[Tidy data|\"tidy\" approach]], each variable should be a column, each observation should be a row, and each type of observational unit should be a table.<ref>{{cite journal|last1=Wickham|first1=Hadley|title=Tidy Data|journal=Journal of Statistical Software|date=2014|volume=59|issue=10|doi=10.18637/jss.v059.i10}}</ref>\n\nWickham was named a Fellow by the [[American Statistical Association]] in 2015 for \"pivotal contributions to statistical practice through innovative and pioneering research in statistical graphics and computing\".<ref name=asa-fellow>{{cite web|title=ASA names 62 fellows|url=https://www.amstat.org/newsroom/pressreleases/2015-ASANames62NewFellows.pdf|website=American Statistical Association|accessdate=14 November 2015}}</ref>\n\n== Bibliography ==\n* {{Cite book|year=2017|url=http://r4ds.had.co.nz/ |title=R for Data Science : Import, Tidy, Transform, Visualize, and Model Data |first=Hadley|last=Wickham|publisher=O'Reilly Media|last2=Grolemund |first2=Garrett |isbn=1491910399|location=Sebastopol, CA|pages=|oclc=968213225}}\n* {{cite book |year=2015 |author=Wickham, Hadley |title=R Packages |publisher=O'Reilly Media, Inc |location=Sebastopol, CA |pages= |isbn= 978-1491910597}}\n* {{cite book |year=2014 |author=Wickham, Hadley |title=Advanced R |publisher=Chapman & Hall/CRC The R Series |location=New York |pages= |isbn= 978-1466586963  |oclc= |doi= }}\n* {{cite journal |last=Wickham |first=Hadley |last2= |first2= |date=2011 |title=The split-apply-combine strategy for data analysis |journal=Journal of Statistical Software |publisher= |volume=40 |issue=1 |pages=1–29 |doi= }}\n* {{cite journal |last=Wickham |first=Hadley |last2= |first2= |date=2010 |title=A layered grammar of graphics |journal=Journal of Computational and Graphical Statistics |publisher= |volume=19 |issue=1 |pages=3–28 |doi= }}\n* {{cite journal |last=Wickham |first=Hadley |last2= |first2= |date=2010 |title=stringr: modern, consistent string processing |journal=[[The R Journal]]|publisher= |volume=2 |issue=2 |pages=3–28 |doi= }}\n* {{cite book |year=2009 |author=Wickham, Hadley |title=ggplot2: Elegant Graphics for Data Analysis (Use R!) |publisher=Springer |location=New York |pages= |isbn= 0387981403 |oclc= |doi= |accessdate=}}\n* {{cite journal |last=Wickham |first=Hadley |last2= |first2= |date=2007 |title=Reshaping data with the reshape package |journal=Journal of Statistical Software |publisher= |volume=21 |issue=12 |pages=1–20 |doi= }}\n\n== References ==\n{{reflist}}\n\n== External links ==\n* [http://metamarkets.com/2012/profile-of-hadley-wickham-data-scientist-in-residence-at-metamarkets/ Interview] by MetaMarkets.\n* [http://datascience.la/a-conversation-with-hadley-wickham-the-user-2014-interview/ Interview] by Datascience.LA at UseR! 2014\n* [http://strataconf.com/strata2014/public/schedule/speaker/131906 Speaker Hadley Wickham Strata 2014 - O'Reilly Conferences, February 11 - 13, 2014, Santa Clara, CA]\n* [https://www.youtube.com/watch?v=LOXe6Eu59As Interview] at Strata 2014\n* [http://statr.me/2013/09/a-conversation-with-hadley-wickham/ Interview] by Yixuan Qiu (2013)\n* [http://vita.had.co.nz/articles.html Hadley Wickham's scholarly publications]\n* [https://peadarcoyle.wordpress.com/2015/08/02/interview-with-a-data-scientist-hadley-wickham/ Interview] by Models are Illuminating and Wrong\n* [https://www.datacamp.com/courses/writing-functions-in-r Writing functions in R with Hadley & Charlotte Wickham] by Datacamp\n* [https://www.youtube.com/watch?v=1POb5fx_m3I Ihaka Lecture Series 2017: Expressing yourself with R]\n\n{{Authority control}}\n\n{{DEFAULTSORT:Wickham, Hadley}}\n[[Category:New Zealand computer scientists]]\n[[Category:New Zealand statisticians]]\n[[Category:Living people]]\n[[Category:Year of birth missing (living people)]]\n[[Category:Data scientists]]\n[[Category:Fellows of the American Statistical Association]]\n[[Category:R (programming language)]]"
    },
    {
      "title": "Bioconductor",
      "url": "https://en.wikipedia.org/wiki/Bioconductor",
      "text": "{{short description|Software project for the analysis of genomic data}}\n{{Infobox software\n | name                   = Bioconductor\n | logo                   = Bioconductor logo.svg\n | logo size              = 260px\n | caption                = Screenshot of Bioconductor\n | screenshot             =\n | developer              =\n | latest_release_version = 3.9\n | latest_release_date    = {{Release date and age|2019|05|03|df=yes}}\n | operating_system       = [[Linux]], [[macOS]], [[Microsoft Windows|Windows]]\n | platform               = [[R programming language]]\n | genre                  = [[Bioinformatics]]\n | license                = [[Artistic License|Artistic License 2.0]]\n | website                = {{URL|//www.bioconductor.org/}}\n}}\n'''Bioconductor''' is a [[Free software|free]], [[Open-source software|open source]] and [[Open source software development|open development]] software project for the analysis and comprehension of [[Genome|genomic]] data generated by [[Wet laboratory|wet lab]] experiments in [[molecular biology]].\n\nBioconductor is based primarily on the [[statistics|statistical]] [[R (programming language)|R programming language]], but does contain contributions in other programming languages. It has two [[Software release life cycle|releases]] each year that follow the semiannual releases of R. At any one time there is a [[Software versioning|release version]], which corresponds to the released version of R, and a [[Software versioning|development version]], which corresponds to the development version of R. Most users will find the release version appropriate for their needs. In addition there are a large number of [[genome annotation]] packages available that are mainly, but not solely, oriented towards different types of [[microarray]]s.\n\nThe project was started in the Fall of 2001 and is overseen by the Bioconductor core team, based primarily at the [[Fred Hutchinson Cancer Research Center]], with other members coming from international institutions.\n\n== Packages ==\nMost Bioconductor components are distributed as [[R (programming language)|R packages]], which are add-on modules for R. Initially most of the Bioconductor software packages focused on the analysis of single channel [[Affymetrix]] and two or more channel [[Complementary DNA|cDNA]]/[[Oligonucleotide|Oligo]] microarrays. As the project has matured, the functional scope of the software packages broadened to include the analysis of all types of genomic data, such as SAGE, [[Sequence (biology)|sequence]], or [[Single nucleotide polymorphism|SNP]] data.\n\n== Goals ==\nThe broad goals of the projects are to:\n* Provide widespread access to a broad range of powerful [[Statistics|statistical]] and [[Statistical graphics|graphical]] methods for the analysis of genomic data.\n* Facilitate the inclusion of [[genome annotation|biological metadata]] in the analysis of genomic data, e.g. literature data from [[PubMed]], annotation data from LocusLink/Entrez.\n* Provide a common [[Computing platform|software platform]] that enables the rapid [[Software development|development]] and [[Software deployment|deployment]] of [[Plug-in (computing)|plug-able]], [[Scalability|scalable]], and [[Interoperability|interoperable]] software.\n* Further scientific understanding by producing high-quality [[Tutorial|documentation and reproducible research]].\n* Train researchers on computational and statistical methods for the analysis of genomic data.\n\n== Main features ==\n* '''[[Tutorial|Documentation and reproducible research]].''' Each Bioconductor package contains at least one vignette, which is a document that provides a textual, task-oriented description of the package's functionality. These vignettes come in several forms. Many are simple \"[[How-to]]\"s that are designed to demonstrate how a particular task can be accomplished with that package's software. Others provide a more thorough overview of the package or might even discuss general issues related to the package. In the future, the Bioconductor project is looking towards providing vignettes that are not specifically tied to a package, but rather are demonstrating more complex concepts. As with all aspects of the Bioconductor project, users are encouraged to participate in this effort.\n* '''[[Statistics|Statistical and graphical methods]].''' The Bioconductor project aims to provide access to a wide range of powerful statistical and graphical methods for the analysis of genomic data. Analysis packages are available for: pre-processing [[Affymetrix]] and [[Illumina (company)|Illumina]], [[Complementary DNA|cDNA]] array data; identifying [[Expression profiling|differentially expressed genes]]; graph theoretical analyses; plotting genomic data. In addition, the R package system itself provides implementations for a broad range of state-of-the-art [[Statistics|statistical]] and [[Statistical graphics|graphical]] techniques, including [[Linear regression|linear]] and [[Nonlinear regression|non-linear]] modeling, [[cluster analysis]], [[prediction]], [[Resampling (statistics)|resampling]], [[survival analysis]], and [[time series]] analysis.\n* '''[[Genome annotation|Genome Annotation]].''' The Bioconductor project provides software for associating microarray and other genomic data in real time to biological metadata from web databases such as [[GenBank]], LocusLink and [[PubMed]] (annotate package). Functions are also provided for incorporating the results of statistical analysis in HTML reports with links to annotation WWW resources. Software tools are available for assembling and processing genomic annotation data, from databases such as [[GenBank]], the [[Gene Ontology|Gene Ontology Consortium]], LocusLink, [[UniGene]], the [[Human Genome Project|UCSC Human Genome Project]] and others with the AnnotationDbi package. Data packages are distributed to provide mappings between different probe identifiers (e.g. Affy IDs, LocusLink, [[PubMed]]). Customized annotation libraries can also be assembled.\n* '''[[Open-source software|Open source]].''' The Bioconductor project has a commitment to full open source discipline, with distribution via a [[SourceForge.net]]-like platform. All contributions are expected to exist under an [[open source license]] such as [[Artistic License|Artistic 2.0]], [[GNU General Public License|GPL2]], or [[Berkeley Software Distribution|BSD]]. There are many different reasons why open-source software is beneficial to the analysis of microarray data and to computational biology in general. The reasons include:\n** To provide full access to [[algorithm]]s and their implementation\n** To facilitate software improvements through [[Software bug|bug fixing]] and [[Plug-in (computing)|plug-ins]]\n** To encourage good [[Computational statistics|scientific computing and statistical practice]] by providing appropriate tools and instruction\n** To provide a [[Application software|workbench of tools]] that allow researchers to explore and expand the methods used to analyze biological data\n** To ensure that the international [[scientific community]] is the owner of the [[Programming tool|software tools]] needed to carry out research\n** To lead and encourage commercial support and development of those tools that are successful\n** To promote [[Reproducibility|reproducible research]] by providing open and accessible tools with which to carry out that research (reproducible research is distinct from independent verification)\n* '''[[Open source software development|Open development]].''' [[End-user (computer science)|Users]] are encouraged to become [[Software developer|developers]], either by contributing Bioconductor compliant packages or documentation. Additionally Bioconductor provides a mechanism for linking together different groups with [[Goal setting|common goals]] to foster [[collaboration]] on software, possibly at the level of shared development.\n\n== Milestones ==\nEach release of Bioconductor is developed to work best with a chosen version of R.<ref name=\"BioCReleasePage\">{{cite web |title=Bioconductor - Release Announcements |url=https://bioconductor.org/about/release-announcements/ |website=bioconductor.org |publisher=Bioconductor |accessdate=28 May 2019}}</ref> In addition to bugfixes and updates, a new release typically adds packages. The major and current releases are\n{| class=\"wikitable\"\n|-\n! Version\n! Release Date\n! Package Count\n! Dependency\n|-\n| align=\"center\" | 1.0\n| align=\"right\" | {{dts|2002-05-01|abbr=on|format=dmy}}\n| align=\"right\" | 15\n| align=\"center\" | [[R (programming language)|R 1.5]]\n|-\n| align=\"center\" | 2.0\n| align=\"right\" | {{dts|2007-04-26|abbr=on|format=dmy}}\n| align=\"right\" | 214\n| align=\"center\" | [[R (programming language)|R 2.5]]\n|-\n| align=\"center\" | 3.0\n| align=\"right\" | {{dts|2014-10-14|abbr=on|format=dmy}}\n| align=\"right\" | 934\n| align=\"center\" | [[R (programming language)|R 3.1]]\n|-\n| align=\"center\" | 3.9\n| align=\"right\" | {{dts|2019-05-03|abbr=on|format=dmy}}\n| align=\"right\" | 1741\n| align=\"center\" | [[R (programming language)|R 3.6]]\n|}\n\n== Resources ==\n*{{cite book |last=Gentleman |first=R. |author2=Carey, V. |author3=Huber, W. |author4=Irizarry, R. |author5=Dudoit, S.|author5-link=Sandrine Dudoit |year=2005 |title=Bioinformatics and Computational Biology Solutions Using R and Bioconductor |publisher=Springer |isbn=978-0-387-25146-2}}\n*{{cite book |last=Gentleman |first=R. |year=2008 |title=R Programming for Bioinformatics |publisher=Chapman & Hall/CRC |isbn=1-4200-6367-7 |url=https://books.google.com/books?id=34Y6WjJy8zEC}}\n*{{cite book |last=Hahne |first=F. |author2=Huber, W. |author3=Gentleman, R. |author4= Falcon, S. |year=2008 |title=Bioconductor Case Studies |publisher=Springer |isbn=978-0-387-77239-4 |url=https://books.google.com/books?id=F3tAehmRHSwC}}\n*{{cite journal|last1=Gentleman|first1=Robert C.|author1-link=Robert Gentleman (statistician)|last2=Carey|first2=Vincent J.|last3=Bates|first3=Douglas M.|last4=Bolstad|first4=Ben|last5=Dettling|first5=Marcel|last6=Dudoit|first6=Sandrine|author6-link=Sandrine Dudoit|last7=Ellis|first7=Byron|last8=Gautier|first8=Laurent|last9=Ge|first9=Yongchao|last10=Gentry|first10=Jeff|last11=Hornik|first11=Kurt|last12=Hothorn|first12=Torsten|last13=Huber|first13=Wolfgang|last14=Iacus|first14=Stefano|last15=Irizarry|first15=Rafael|last16=Leisch|first16=Friedrich|last17=Li|first17=Cheng|last18=Maechler|first18=Martin|last19=Rossini|first19=Anthony J.|last20=Sawitzki|first20=Gunther|last21=Smith|first21=Colin|last22=Smyth|first22=Gordon|last23=Tierney|first23=Luke|last24=Yang|first24=Jean Y. H.|author24-link=Jean Yang|last25=Zhang|first25=Jianhua|doi=10.1186/gb-2004-5-10-r80|issue=10|journal=[[Genome Biology]]|page=R80|title=Bioconductor: open software development for computational biology and bioinformatics|volume=5|year=2004}}\n\n==See also==\n{{Portal|Free and open-source software|Biology}}\n*[[Computational Biology]]\n*[[Bioinformatics]]\n*[[List of open source bioinformatics software]]\n*[[List of sequence alignment software]]\n*[[R (programming language)]]\n*[[DNA Microarray]]\n*[[Affymetrix]], a microarray technology platform\n\n==References==\n{{Reflist}}\n\n==External links==\n* {{Official website|//www.bioconductor.org}}\n* [http://www.r-project.org The R Project] [[GNU]] R is a programming language for statistical computing.\n* The community of the [[Debian|Debian GNU/Linux]] distribution strives towards an [http://wiki.debian.org/AliothPkgBioc automated building of BioConductor packages] for their distribution. [https://web.archive.org/web/20051124175716/http://bioknoppix.hpcf.upr.edu/ BioKnoppix] and [http://dirk.eddelbuettel.com/quantian.html Quantian] are projects extending [[Knoppix]] that have contributed bootable [[Debian|Debian GNU/Linux]] CDs providing BioConductor installations.\n\n[[Category:Bioinformatics software]]\n[[Category:Free bioinformatics software]]\n[[Category:Free science software]]\n[[Category:Free R (programming language) software]]\n[[Category:Science software for MacOS]]\n[[Category:Science software for Windows]]\n[[Category:Science software for Linux]]"
    },
    {
      "title": "Emacs Speaks Statistics",
      "url": "https://en.wikipedia.org/wiki/Emacs_Speaks_Statistics",
      "text": "{{distinguish|Emacspeak}}\n{{more citations needed|date=November 2018}}\n\n{{Infobox Software |\n  name = Emacs Speaks Statistics|\n  logo = |\n  screenshot = [[Image:RinEmacswithESS.png|250px|R running in emacs with ESS]] |\n  caption = GNU emacs in ESS and iESS mode. In the upper window, S code is edited in emacs' ESS mode. In the lower window the S code is executed by R via iESS.|\n  latest_release_version = 18.10.2 |\n  genre = [[Cross-platform#Cross-platform development environments]] |\n  license = [[GPL]] |\n  website = [https://ess.r-project.org/ ess.r-project.org]\n }}\n\n'''Emacs Speaks Statistics''' ('''ESS''') is an [[Emacs]] package for programming in statistical languages. It adds two types of modes to emacs:\n\n# ESS modes for editing statistical languages like [[R programming language|R]], [[SAS (software)|SAS]] and [[Julia (programming language)|Julia]]; and\n# inferior ESS (iESS) modes for interacting with statistical processes like R and SAS.\n\nModes of types (1) and (2) work seamlessly together. In addition, modes of type (1) provide the capability to submit a batch job for statistical packages like SAS, BUGS or [[Just another Gibbs sampler]] when an interactive session is unwanted due to the potentially lengthy time required for the task to complete.\n\nWith Emacs Speaks Statistics, the user can conveniently edit statistical language commands in one emacs buffer, and execute the code in a second. There are a number of advantages of doing data analysis using Emacs/ESS in this way, rather than interacting with R, S-PLUS or other software directly. First, as indicated above, ESS provides a convenient way of writing and executing code without frequently switching between programs. This also encourages the good practice of keeping a record of one's data analysis, equivalent to working from do-files in [[Stata]]. Third, since emacs is also an able editor of [[LaTeX]] files, it facilitates the integration of data analysis and written text with [[Sweave]].\n\n== External links ==\nESS is freely available for download from [https://ess.r-project.org/ the ESS website], which also contains documentation and links to a mailing list.\n\n{{EmacsNavbox}}\n\n[[Category:Emacs modes]]\n[[Category:Free R (programming language) software]]\n[[Category:Free statistical software]]\n\n\n{{science-software-stub}}"
    },
    {
      "title": "Ggplot2",
      "url": "https://en.wikipedia.org/wiki/Ggplot2",
      "text": "{{Infobox software\n| name = ggplot2\n| title = ggplot2\n| logo = \n| logo caption = \n| screenshot = <!-- [[File: ]] -->\n| caption = \n| collapsible = \n| author = [[Hadley Wickham]], Winston Chang\n| developer = \n| released = 2007-06-10\n| discontinued = \n| latest release version = 3.0.0\n| latest release date = 2018-07-03\n| latest preview version = \n| latest preview date = <!-- {{Start date and age|YYYY|MM|DD|df=yes/no}} -->\n| programming language = [[R (programming language)|R]]\n| operating system = \n| platform = \n| size = \n| language = \n| language count = <!-- DO NOT include this parameter unless you know what it does -->\n| language footnote = \n| status = \n| genre = \n| license = [[GPLv2]]\n| alexa = \n| website = {{URL|https://ggplot2.tidyverse.org/}}\n}}\n{{lowercase title}}\n {{multiple image\n   | direction = vertical\n   | footer    = ggplot2 and base graphics defaults for a simple scatterplot image\n   | image1    = Ggplot2scatter.png\n   | alt1      = ggplot2\n   | caption1  = ggplot2\n   | image2    = BaseRscatter.svg\n   | alt2      = Base graphics\n   | caption2  = Base graphics\n  }}\n'''ggplot2''' is a [[data visualization]] package for the [[Computational statistics|statistical programming]] language [[R (programming language)|R]]. Created by [[Hadley Wickham]] in 2005, ggplot2 is an implementation of [[Leland Wilkinson]]'s  ''Grammar of Graphics''&mdash;a general scheme for data visualization which breaks up graphs into semantic components such as scales and layers. ggplot2 can serve as a replacement for the base graphics in R and contains a number of defaults for web and print display of common scales. Since 2005, ggplot2 has grown in use to become one of the most popular R packages.<ref>{{cite journal|last=Wickham|first=Hadley|title=ggplot2: Elegant Graphics for Data Analysis|journal=Journal of Statistical Software|date=July 2010|volume=35|issue=1|url=http://www.jstatsoft.org/v35/b01/paper}}</ref><ref>{{cite journal|last=Wilkinson|first=Leland|authorlink=Leland Wilkinson|title=ggplot2: Elegant Graphics for Data Analysis by WICKHAM, H|journal=Biometrics|date=June 2011|volume=67|issue=2|pages=678–679|doi=10.1111/j.1541-0420.2011.01616.x}}</ref> It is licensed under GNU GPL v2.<ref>https://cran.r-project.org/web/packages/ggplot2/index.html</ref>\n\n== Updates ==\nOn 2 March 2012, ggplot2 version 0.9.0 was released with numerous changes to internal organization, scale construction and layers.<ref>{{cite web |author =ggplot2 Development Team|title = Changes and Additions to ggplot2-0.9.0| url = https://cloud.github.com/downloads/hadley/ggplot2/guide-col.pdf}}</ref>\n\nOn 25 February 2014, Hadley Wickham formally announced that \"ggplot2 is shifting to maintenance mode. This means that we are no longer adding new features, but we will continue to fix major bugs, and consider new features submitted as pull requests. In recognition [of] this significant milestone, the next version of ggplot2 will be 1.0.0\".<ref>{{cite web |last=Wickham|first=Hadley|title=ggplot2 development|url= https://groups.google.com/d/msg/ggplot2/SSxt8B8QLfo/J2dfKR92rsYJ|publisher=ggplot2 Google Group|accessdate=26 February 2014}}</ref>\nOn 21 December 2015, ggplot 2.0.0 was released. In the announcement, it was stated  that \"ggplot2 now has an official extension mechanism. This means that others can now easily create their [own] stats, geoms and positions, and provide them in other packages.\"<ref>ggplot 2.0.0 http://blog.rstudio.org/2015/12/21/ggplot2-2-0-0/</ref>\n\n==Comparison with base graphics and other packages==\nIn contrast to base R graphics, ggplot2 allows the user to add, remove or alter components in a plot at a high level of abstraction.<ref>{{cite web|last=Smith|first=David|title=Create beautiful statistical graphics with ggplot2|url=http://blog.revolutionanalytics.com/2009/01/create-beautiful-statistical-graphics-with-ggplot2.html|work=Revolutions|publisher=[[Revolution Analytics]]|accessdate=11 July 2011}}</ref>  This abstraction comes at a cost, with ggplot2 being slower than lattice graphics.<ref>http://learnr.wordpress.com/2009/08/26/ggplot2-version-of-figures-in-lattice-multivariate-data-visualization-with-r-final-part/</ref>\n\nOne potential limitation of base R graphics is the \"pen-and-paper model\" utilized to populate the plotting device.<ref>{{cite book|last=Wickham|first=Hadley|title=ggplot2: Elegant Graphics for Data Analysis |year=2009 |publisher=Springer |isbn=978-0-387-98140-6|pages=5}}</ref> Graphical output from the interpreter is added directly to the plotting device or window rather than separately for each distinct element of a plot.<ref>{{cite journal |last=Murrell |first=Paul |title=R Graphics|journal=Wiley Interdisciplinary Reviews: Computational Statistics|date=August 2009|volume=1|issue=2|pages=216–220|doi=10.1002/wics.22}}</ref> In this respect it is similar to the lattice package, though Wickham argues ggplot2 inherits a more formal model of graphics from Wilkinson.<ref>{{cite book|last=Sarkar|first=Deepayan|title=Lattice: multivariate data visualization with R|year=2008|publisher=Springer|isbn=978-0-387-75968-5|pages=xi}}</ref> As such, it allows for a high degree of modularity; the same underlying data can be transformed by many different scales or layers.<ref>{{cite book|last=Teetor|first=Paul|title=R Cookbook|year=2011|publisher=O'Reilly|isbn=978-0-596-80915-7|pages=223}}</ref><ref>{{cite journal |last=Wickham |first=Hadley |title=A Layered Grammar of Graphics |journal=Journal of Computational and Graphical Statistics |date=March 2010|volume=19|issue=1|pages=3–28|doi=10.1198/jcgs.2009.07098}}</ref>\n\nPlots may be created via the convenience function <code>qplot()</code> where arguments and defaults are meant to be similar to base R's <code>plot()</code> function.<ref>{{cite book|title=R: A language and environment for statistical computing|year=2011|publisher=R Foundation for Statistical Computing|location=Vienna, Austria|isbn=3-900051-07-0|url=http://www.R-project.org/|author=R Development Core Team}}</ref><ref>{{cite journal|last=Ginestet|first=Cedric|title=ggplot2: Elegant Graphics for Data Analysis |journal=Journal of the Royal Statistical Society, Series A |date=January 2011 |volume=174 |issue=1 |pages=245–246 |doi=10.1111/j.1467-985X.2010.00676_9.x}}</ref> More complex plotting capacity is available via <code>ggplot()</code> which exposes the user to more explicit elements of the grammar.<ref>{{cite book|last=Muenchen|first=Robert A.|title=R for STATA Users|author2=Hilbe, Joseph M |publisher=Springer |isbn=978-1-4419-1317-3 |doi=10.1007/978-1-4419-1318-0_16 |chapter=Graphics with ggplot2}}</ref>\n\n==Related projects==\n* ggplot for Python<ref>{{cite web |url=https://github.com/yhat/ggplot/ |title=ggplot for Python |publisher=yhat |accessdate=12 October 2014}}</ref>\n* Plotly - Interactive, online ggplot2 graphs<ref>{{cite web |url=https://plot.ly/ggplot2/ |title=Interactive, online ggplot2 graphs |publisher=plotly |accessdate=12 October 2014}}</ref>\n* gramm, a plotting class for MATLAB inspired by ggplot2<ref>{{cite web|title=ggplot for Matlab|url=https://github.com/piermorel/gramm|publisher=gramm|accessdate=11 December 2015}}</ref>\n* gadfly, a system for plotting and visualization written in [[Julia (programming language)|Julia]], based largely on ggplot2<ref>{{cite web|title=Gadfly.jl|url=http://gadflyjl.org|accessdate=11 September 2018}}</ref>\n* Chart::GGPlot - ggplot2 port in [[Perl]]<ref>{{cite web|title= Stephan Loyd/Chart-GGPlot-0.0001|url=https://metacpan.org/release/Chart-GGPlot|accessdate=30 March 2019}}</ref>\n\n== References ==\n{{Reflist}}\n\n==Further reading==\n*{{cite book|last=Wilkinson|first=Leland|authorlink=Leland Wilkinson|title=The Grammar of Graphics|year=2005|publisher=Springer|isbn=978-0-387-98774-3}}\n*{{cite video |people= Wickham, Hadley|date= 6 Jun 2011|title=Engineering Data Analysis (with R and ggplot2) |url=https://www.youtube.com/watch?v=TaxJwC_MP9Q |format= |medium= |language= |trans_title= |publisher= Google Tech Talks}}\n\n== External links ==\n* [https://ggplot2.tidyverse.org/ ggplot2] Example code and documentation\n<!-- * [http://had.co.nz/ggplot2/index.html ggplot2] Example code and documentation -->\n* [https://github.com/hadley/ggplot2 ggplot2] Repository on [[GitHub]]\n\n{{Statistical software}}\n\n{{Use dmy dates |date = September 2011}}\n\n[[Category:Cross-platform free software]]\n[[Category:Free plotting software]]\n[[Category:Free R (programming language) software]]\n[[Category:Free data visualization software]]"
    },
    {
      "title": "Java GUI for R",
      "url": "https://en.wikipedia.org/wiki/Java_GUI_for_R",
      "text": "{{notability|Products|date=April 2016}}\n\n\n{{Infobox Software\n| name                   = JGR\n| logo                   = \n| screenshot             = \n| caption                = \n| developer              =  Markus Helbig, Simon Urbanek, Ian Fellows\n| latest release version = 1.8-4\n| latest release date    = {{release date|2017|09|24}}\n| operating system       = [[Cross-Platform]]\n| platform               = [[R programming language]]\n| genre                  = [[List of statistical packages|Statistical software]]\n| license                = [[GNU General Public License]]\n| website                = http://rforge.net/JGR/\n}}\n\n'''JGR''' (pronounced 'Jaguar') is a universal and unified [[Graphical User Interface]] for the [[R programming language]], licensed under the [[GNU General Public License]].\n\nJGR is a cross-platform stand-alone R terminal, and can be used as a more advanced substitute to the default Rgui (on Windows) or to a simple R session started from a terminal. It provides a friendly R-console complemented by a spreadsheet-like data editor and by a script editor featuring [[syntax highlighting]], [[autocompletion]] and (MS Excel-style) arguments-suggestions for entered functions, and direct command transfer.<ref>{{cite journal| last1 = Helbig | first1 = Markus | last2 = Theus | first2 = Martin | last3 = Urbanek | first3 = Simon \n | title = JGR: JAVA GUI FOR R | journal = Statistical Computing and Graphics Newsletter | volume = 16 | issue = 2 | pages = 9-12 | publisher = ASA | date = December 2005 | url = http://stat-computing.org/newsletter/issues/scgn-16-2.pdf }}\n</ref>\n\nAlthough unlike [[Rcmdr]], [[RKWard]], [[Rattle GUI|Rattle]] or [[PMG (GUI)|PMG]], JGR provides no statistical menu-driven facilities, recently a GUI on top of JGR has been developed: ''Deducer'' aims to be an intuitive graphical data analysis system in some respects similar to [[SPSS]], Cornerstone or [[Minitab]].\n\n==See also==\n* [[R (programming language)#Interfaces|R interfaces]]<!-- list any similar R-related software in this other article -->\n\n==References==\n{{reflist}}\n\n==External links==\n* [https://cran.r-project.org/web/packages/JGR/ JGR] on [[CRAN (R programming language)|CRAN]]\n* [http://www.deducer.org/manual.html Deducer]\n* [https://github.com/markush81/JGR Home of JGR at GitHub]\n\n[[Category:Free R (programming language) software]]"
    },
    {
      "title": "KH Coder",
      "url": "https://en.wikipedia.org/wiki/KH_Coder",
      "text": "{{Infobox software\n| name                   = KH Coder\n| logo                   = \n| screenshot             = \n| caption                = \n| developer              = [[Koichi Higuchi]]\n| latest_release_version = 2.00f\n| latest_release_date    = Dec 2015\n| operating_system       = [[Microsoft Windows]], [[Linux]], [[macOS]]\n| genre                  = [[Qualitative data analysis]], [[Text mining]], [[Content analysis]]\n| license                = [[GPL|GPL2 license]]\n| website                = {{url|http://khc.sourceforge.net/en/}}\n}}\n'''KH Coder''' is an open source software for computer assisted [[qualitative data analysis]], particularly quantitative [[content analysis]] and [[text mining]]. It can be also used for [[computational linguistics]]. It supports processing and etymological information of text in several languages, such as Japanese, English, French, German, Italian, Portuguese and Spanish. Specifically, it can contribute factual examination co-event system hub structure, computerized arranging guide, multidimensional scaling and comparative calculations.<ref> S. N. Vinithra, S.N; Arun Selvan, S.J.; Anand Kumar, M.; Soman, , K.P. (2015): [http://www.indjst.org/index.php/indjst/article/view/80205/ Simulated and Self-Sustained Classification of Twitter Data based on its Sentiment]. Indian Journal of Science and Technology. Vol. 8, Issue 24</ref> \n\nIt is well received by researchers worldwide and used in a large number of disciplines, including [[neuroscience]], [[sociology]], [[psychology]], [[public health]], [[media studies]], [[education research]] and [[computer science]]. There are more than 200 English research papers listed in Google scholar.<ref>[https://scholar.google.com/scholar?lr=lang_en&q=%22KH+Coder%22+%7C+khcoder&hl=en&as_sdt=1,5&as_vis=1 Google Scholar search using Keywords \"KH Coder\" and \"KHCoder\"]</ref> More than 1500 academic research papers were published that use KH Coder according to a list compiled by the author.<ref>Higuchi, Koichi (2017): [http://khc.sourceforge.net/en/bib.html?year=all&lang=English&key= Scholarly research using KH Coder]</ref>\n\nKH Coder has been reviewed as a user friendly tool \"for identifying themes in large unstructured data sets, such as online reviews or open-ended customer feedback\"<ref>Towler, Will (2014): [https://uxmag.com/articles/text-analytics-for-everyone Text Analytics For Everyone]. UX Magazine, July 31, 2014.</ref> and has been reviewed in comparison to [[WordStat]].<ref>Huirong, Cheng;Guobin, Huang; Lin, Zheng (2015): [http://www.tsyqb.com/CN/abstract/abstract1528.shtml  Comparison of Software for Unstructured Text Analysis:KH Coder vs. Wordstat]. 图书与情报, 2015(04): 110-117.</ref>\n\n==Features==\nIts features include:\n* on word-level: Searching, [[Key_Word_in_Context|KWIC concordance]], [[collocation]] statistics, and [[correspondence analysis]]. \n* on category-level: Development of categories or dictionaries, cross tabulation, and [[correspondence analysis]].\n* on word- and category-level: Frequency lists, [[multi-dimensional scaling]], [[co-occurrence]] network, and [[hierarchical cluster analysis]].\n* on document-level: Searching, clustering, and [[Naive Bayes classifier]]\n\nKH Coder allows for further search and statistical analysis functions using back-end tools such as Stanford [[Part-of-speech_tagging|POS Tagger]], the natural language processing toolkit FreeLing, [[Snowball_(programming_language)|Snowball stemmer]], [[MySQL]] and [[R (programming language)|R]].\n==Alternatives==\n*  [[Quantitative Discourse Analysis Package|qdap]] (Windows, Linux, macOS) for quantitative analysis of qualitative transcripts and [[natural language processing]].\n==See also==\n* [[Computer Assisted Qualitative Data Analysis Software]]\n\n==References==\n{{Reflist}}\n\n==Notes== \n* {{Official website|http://khc.sourceforge.net/en/}}\n* [http://khc.sourceforge.net/en/manual_en_v3.pdf KH Coder Reference Manual]\n* [http://khc.sourceforge.net/en/bib.html?year=all&lang=English&key= Scholarly research using KH Coder]\n\n{{Computer-assisted qualitative data analysis software |state=autocollapse}}\n{{DEFAULTSORT:KH Coder}}\n\n[[Category:Free QDA software]]\n[[Category:Cross-platform free software]]\n[[Category:Free R (programming language) software]]\n[[Category:Science software for MacOS]]\n[[Category:Science software for Linux]]"
    },
    {
      "title": "Lumi (software)",
      "url": "https://en.wikipedia.org/wiki/Lumi_%28software%29",
      "text": "{{Other uses|Lumi (disambiguation){{!}}Lumi}}\n{{Infobox software\n | name = lumi software\n | logo =\n | caption = Screenshot of Bioconductor\n | screenshot =\n | developer =\n | latest_release_version = 2.0\n | latest_release_date = March 4, 2007\n | operating_system = [[Linux]], [[UNIX]], [[Mac OS X]], [[Microsoft Windows|Windows]]\n | platform = [[R programming language]] and [[Bioconductor]]\n | genre = Analysis of [[Illumina (company)|Illumina]] microarrays\n | license = [[GNU General Public License]]\n | website = [http://www.bioconductor.org/help/bioc-views/release/bioc/html/lumi.html  lumi software release website]\n}}\n'''lumi''' is a [[Free software|free]], [[Open-source software|open source]] and open development software project for the analysis and comprehension of [[Illumina (company)|Illumina]] expression and methylation microarray data. The project was started in the summer of 2006 and set out to provide algorithms and data management tools of Illumina in the framework of [[Bioconductor]]. It is based on the [[statistics|statistical]] [[R programming language]].\n\n==Features ==\nThe '''lumi''' package provides an analysis pipeline for probe-level Illumina expression and methylation microarray data, including probe-identifier management ([[nuID]]), updated probe-to-gene mapping and annotation using the latest release of RefSeq (nuIDblast), probe-intensity transformation (VST) and normalization (RSN), quality control (QA/QC) and preprocessing methods specific for Illumina methylation data. By extending the ExprSet object with Illumina-specific features, '''lumi''' is designed to work with other Bioconductor packages, such as Limma and GOstats to detect differential genes and conduct Gene Ontology analysis.\n\n==History==\nThe '''lumi''' project was started in the summer of 2006 at the Bioinformatics Core Facility  of the Robert H. Lurie Comprehensive Cancer Center, [[Northwestern University]]. Originally '''lumi''' was designed for the analysis of Illumina Expression BeadArray data. Starting from 2010 (version > 2.0), functions of analyzing Illumina methylation microarray data was added. The project team consists of Drs. Pan Du, Simon M. Lin, and Warren A. Kibbe. The project was started upon a request for collaboration from [[Serdar Bulun|Dr. Serdar E. Bulun]] to analyze a set of new Illumina microarray data acquired at his lab on the study of the effect of retinoic acids on cancers. Dr. Pan Du led the software development of the project. '''lumi''' was the first software package to utilize the unique design of redundancy of beadArrays for the data transformation and normalization processes. The first release of '''lumi''' was on January 3, 2007 through the [[Bioconductor]] website. Before its formal release, it was beta-tested at Norwegian Radiumhospital, Leiden University Medical Center, Universiteit van Amsterdam, Università degli Studi di Brescia,  UC Davis, Wayne State University, NIH, M.D. Anderson Cancer Center, Case Western Reserve University, Harvard University, Washington University, and Walter and Eliza Hall Institute of Medical Research.\n\n== See also ==\n{{Portal|Free and open-source software}}\n\n*[[Bioconductor]], integrated software for the statistical analysis of wet lab data in molecular biology\n*[[Illumina (company)|Illumina Inc.]] and its beadArray technology\n\n==External links==\n* [http://www.bioconductor.org/help/bioc-views/release/bioc/html/lumi.html '''lumi''' software release website]\n* [http://www.basic.northwestern.edu/projects/lumi/ Old '''lumi''' Website]\n* [http://www.bioconductor.org Official Bioconductor Website]\n\n[[Category:Free science software]]\n[[Category:Free R (programming language) software]]\n[[Category:Microarrays]]"
    },
    {
      "title": "Quantitative Discourse Analysis Package",
      "url": "https://en.wikipedia.org/wiki/Quantitative_Discourse_Analysis_Package",
      "text": "{{Infobox software\n| name                   = Quantitative Discourse Analysis Package (qdap)\n| logo                   = \n| screenshot             = \n| caption                = \n| developer              = [[Bryan Goodrich]], [[Dason Kurkiewicz]], [[Tyler Rinker]]\n| latest_release_version = 2.3.2\n| latest_release_date    = Jan 2019\n| operating_system       = [[Microsoft Windows]], [[Linux]], [[Mac OS]]\n| genre                  = [[Qualitative data analysis]], [[Discourse analysis]]\n| license                = [[GPL|GPL2 license]]\n| website                = {{url|https://cran.r-project.org/web/packages/qdap/}}\n}}\n'''Quantitative Discourse Analysis Package (qdap)''' is an [[R (programming language)|R]] package for computer assisted [[qualitative data analysis]], particularly quantitative [[discourse analysis]], [[Transcription (genetics)|transcript]] analysis and [[natural language processing]]. Qdap is installable from, and runs within, the R system.\n\nQdap is a tool for quantitative analysis of qualitative transcripts and therefore provides a bridge between quantitative and qualitative research approaches. It is designed for transcript analysis, but its features overlap with natural language processing and text mining.\n\nIts features include:\n* tools for the preparation of transcript data\n* frequency counts of sentence types, words, sentences, turns of talk, syllables\n* aggregation using grouping variables\n* word extracting and visualization\n* statistical analysis.\n\nFor higher level statistical analysis and visualization of text, qdap is integrated with [[R (programming language)|R]] and offers integration with other R packages.\n\n==Alternatives==\n*  [[KH Coder]] (Windows, Linux, macOS) for quantitative content analysis and text mining.<ref>{{cite web|title=KH Coder website|url=https://sourceforge.net/projects/khc/|accessdate=18 February 2017}}</ref>\n\n==See also==\n* [[Computer Assisted Qualitative Data Analysis Software]]\n\n==References==\n{{reflist}}\n\n==External links==\n*{{Official website|https://cran.r-project.org/web/packages/qdap/}}\n*[https://cran.r-project.org/web/packages/qdap/qdap.pdf qdap manual]\n*[https://github.com/trinker/qdap qdap developer website]\n*[https://rpubs.com/Vasuji/text_mining_01 Text Mining First-step Report]\n\n{{Computer-assisted qualitative data analysis software |state=autocollapse}}\n{{DEFAULTSORT:Quantitative Discourse Analysis Package}}\n\n[[Category:Free QDA software]]\n[[Category:Cross-platform free software]]\n[[Category:Free R (programming language) software]]\n[[Category:Science software for MacOS]]\n[[Category:Science software for Linux]]"
    },
    {
      "title": "R Commander",
      "url": "https://en.wikipedia.org/wiki/R_Commander",
      "text": "{{Infobox software\n| name                   = R Commander\n| logo                   = \n| screenshot             =\n| caption                = <!-- R Commander 0.9-18 -->\n| developer              = [[John Fox (sociologist)|John Fox]] et al.\n| latest release version = 2.3-2\n| latest release date    = {{release date|2017|01|02}}\n| operating system       = [[Cross-Platform]]\n| platform               = [[R programming language]]\n| genre                  = [[List of statistical packages|Statistical software]]\n| license                = [[GNU General Public License]]\n| website                = [http://socserv.mcmaster.ca/jfox/Misc/Rcmdr/ R Commander]\n}}\n\n'''R Commander''' is a [[GUI]] for the [[R programming language]], licensed under the [[GNU General Public License]], and developed and maintained by [[John Fox (sociologist)|John Fox]] in the [[sociology]] department at [[McMaster University]].<ref>{{cite journal |last=Fox |first=John |year=2005 |title=The R Commander: A Basic-Statistics Graphical User Interface to R |journal=[[Journal of Statistical Software]] |volume=14 |issue=9 |pages= |doi= 10.18637/jss.v014.i09|url=http://www.jstatsoft.org/v14/i09/ }}</ref>  Rcmdr looks and works similarly to [[SPSS]] GUI by providing menu to analytics and graphical methods and display for each analysis run the underlying R code.<ref>{{cite book|url=https://books.google.com/books?id=9kMy0CBTegYC&pg=PA46|title=R for SAS and SPSS Users|last=Muenchen|first=Robert A.|publisher=Springer|year=2011|isbn=978-1-4614-0685-3|location=New York|pages=46–48}}</ref>\n\n'''Rcmdr''' can be installed from within R, like any R package. Integration with [[Microsoft Excel]] is provided by the [[RExcel]] package, which also provides an ''RAndFriendsLight'' \"bundle\" graphical installer. R commander is used as a suggested learning environment for a number of R-centric academic statistics books for students and scientists.<ref name=\"Discovering Statistics With R\">[http://www.uk.sagepub.com/books/Book236067 Discovering Statistics With R].</ref><ref name=\"Biostatistics With R\">[https://dx.doi.org/10.1007/978-1-4614-1302-8 Biostatistics with R]</ref>\n\n==See also==\n* [[Comparison of statistical packages]]\n* [[R (programming language)#Interfaces|R interfaces]]<!-- list any similar R-related software in this other article -->\n\n==References==\n{{Reflist}}\n\n==Further reading==\n* {{cite book |first=John |last=Fox |title=Using the R Commander: A Point-and-Click Interface for R |location= |publisher=Chapman & Hall/CRC Press |year=2017 |isbn=978-1-4987-4190-3 }}\n\n==External links==\n*[http://socserv.mcmaster.ca/jfox/Misc/Rcmdr/ Official home page]\n*[https://cran.r-project.org/web/packages/Rcmdr/index.html Rcmdr at CRAN]\n\n[[Category:Free R (programming language) software]]\n\n\n{{science-software-stub}}"
    },
    {
      "title": "Rattle GUI",
      "url": "https://en.wikipedia.org/wiki/Rattle_GUI",
      "text": "{{Infobox software\n| name                   = Rattle GUI\n| title                  = Rattle GUI\n| logo                   = <!-- [[File: ]] -->\n| logo caption           = \n| screenshot             = <!-- [[File: ]] -->\n| caption                = \n| collapsible            = \n| author                 = Graham Williams\n| developer              = Graham Williams\n| released               = <!-- {{Start date|YYYY|MM|DD|df=yes/no}} -->\n| discontinued           = \n| latest release version = 5.1.0\n| latest release date    = {{Start date and age|2017|09|05|df=yes}}\n| latest preview version = \n| latest preview date    = <!-- {{Start date and age|YYYY|MM|DD|df=yes/no}} -->\n| frequently updated     = <!-- DO NOT include this parameter unless you know what it does -->\n| programming language   = [[R (programming language)|R]]\n| operating system       = \n| platform               = \n| size                   = \n| language               = \n| language count         = <!-- DO NOT include this parameter unless you know what it does -->\n| language footnote      = \n| status                 = \n| genre                  = [[GUI widget]] toolkit\n| license                = GNU General Public License\n| website                = {{URL|https://rattle.togaware.com/}}\n}}\n\n'''Rattle GUI''' is a free and [[open source software]] ([[GNU General Public License|GNU GPL]] v2) package providing a [[graphical user interface]] (GUI) for [[data mining]] using the [[R (programming language)|R statistical programming language]]. Rattle is used in a variety of situations. Currently there are 15 different government departments in Australia, in addition to various other organisations around the world, which use Rattle in their data mining activities and as a [[statistical package]].\n\nRattle provides considerable data mining functionality by exposing the power of the R Statistical Software through a graphical user interface. Rattle is also used as a teaching facility to learn the R software Language. There is a Log Code tab, which replicates the R code for any activity undertaken in the GUI, which can be copied and pasted. Rattle can be used for statistical analysis, or model generation. Rattle allows for the dataset to be partitioned into training, validation and testing. The dataset can be viewed and edited. There is also an option for scoring an external data file.\n\n==Features==\n*File Inputs = [[Comma-separated values|CSV]], TXT, [[Microsoft Excel|Excel]], [[Attribute-Relation File Format|ARFF]], ODBC, R Dataset, RData File, Library Packages Datasets, Corpus, and Scripts.\n*Statistics = Min, Max, Quartiles, Mean, St Dev, Missing, Medium, Sum, Variance, Skewness, Kurtosis, chi square.\n*Statistical tests = Correlation, Wilcoxon-Smirnov, Wilcoxon Rank Sum, T-Test, F-Test, and Wilcoxon Signed Rank.\n*Clustering = KMeans, Clara, Hierarchical, and BiCluster.\n*Modeling = Decision Trees, Random Forests, ADA Boost, Support Vector Machine, Logistic Regression, and Neural Net.\n*Evaluation = Confusion Matrix, Risk Charts, Cost Curve, Hand, Lift, ROC, Precision, Sensitivity.\n*Charts = Box Plot, Histogram, Correlations, Dendrograms, Cumulative, Principal Components, Benford, Bar Plot, Dot Plot, and  [[mosaic plot|Mosaic]].\n*Transformations = Rescale (Recenter, Scale 0-1, Median/MAD, Natural Log, and Matrix) - Impute ( Zero/Missing, Mean, Median, Mode & Constant), Recode (Binning, Kmeans, Equal Widths, Indicator, Join Categories) - Cleanup (Delete Ignored, Delete Selected, Delete Missing, Delete Obs with Missing)\n\nRattle also uses two external graphical investigation / plotting tools.  Latticist and GGobi are independent applications which provide highly dynamic and interactive graphic data visualisation for exploratory\ndata analysis.\n\n==Packages==\nThe capabilities of R are extended through user-submitted ''packages'', which allow specialized statistical techniques, graphical devices, as well as import/export capabilities to many external data formats. Rattle uses these packages - RGtk2, pmml, colorspace, ada, amap, arules, biclust, cba, descr, doBy, e1071, ellipse, fEcofin, fBasics, foreign, fpc, gdata, gtools, gplots, gWidgetsRGtk2, Hmisc, kernlab, latticist, Matrix, mice, network, nnet, odfWeave, party, playwith, psych, randomForest, reshape, RGtk2Extras, ROCR, RODBC, rpart, RSvgDevice, survival, timeDate, graph, RBGL, bitops,\n\n==See also==\n* [[R (programming language)#Interfaces|R interfaces]]\n\n==References==\n*Graham J Williams (2011). [https://www.springer.com/statistics/physical+%26+information+science/book/978-1-4419-9889-7 Data Mining with Rattle and R: The Art of Excavating Data for Knowledge Discovery], Springer, Use R!. \n*In 2010, Rattle was listed in the top 10 graphical user interfaces in statistical software by Decision Stats.\n*Rattle is described as an \"attractive, easy-to-use front end ... data mining toolkit\" in an article published in the Teradata Magazine, volume 9, issue 3, page 57 (September 2009).\n*Graham J William (2009). [http://journal.r-project.org/archive/2009-2/RJournal_2009-2_Williams.pdf Rattle: A Data Mining GUI for R]. ''[http://journal.r-project.org/ The R Journal]'' '''1'''(2):45-55.\n\n==External links==\n*[https://rattle.togaware.com/ Official home page]\n*[https://code.google.com/archive/p/rattle/ Source code page]\n\n[[Category:Free R (programming language) software]]\n[[Category:Data mining and machine learning software]]"
    },
    {
      "title": "RGtk2",
      "url": "https://en.wikipedia.org/wiki/RGtk2",
      "text": "{{Infobox software\n| name                   = RGtk2\n| screenshot             =\n| caption                =\n| developer              = Michael Lawrence and Duncan Temple Lang\n| latest release version = 2.12.18\n| operating system       = [[Cross-platform]]\n| platform               = [[Cross-platform]]\n| genre                  = [[widget toolkit]]\n| license                = [[GPL]]\n| website                = [http://www.ggobi.org/rgtk2/ www.ggobi.org/rgtk2]\n}}\n{{Main article|List of language bindings for GTK+}}\n'''RGtk2''' is a set of [[R (programming language)|R]] [[Adapter pattern|wrapper]]s for the [[GTK+]] [[graphical user interface]] [[library (computer science)|library]]. RGtk2 is [[free software]] and licensed under the [[GPL]].\n\n== Syntax ==\nThe code below will produce a 200x200 pixel window with the words \"[[Hello World]]\" inside.\n\n<source lang=\"r\">\nlibrary(RGtk2)\n\ncreateWindow <- function()\n{\n    window <- gtkWindow()\n\n    label <- gtkLabel(\"Hello World\")\n    window$add(label)\n}\n\ncreateWindow()\ngtk.main()\n</source>\n\n== Notable applications that use RGtk2 ==\nRGtk2 has been used in a number of notable applications, some examples:\n\n{{div col}}\n* [[Rattle GUI|Rattle]]\n{{div col end}}\n\n== See also ==\n{{Portal|Free and open-source software}}\n* [[R (programming language)]] (The R statistical programming language)\n\n==References==\n{{Reflist}}\n\n==External links==\n* [http://www.ggobi.org/rgtk2/ RGtk2 Homepage]\n* [https://cran.r-project.org/web/packages/RGtk2 RGtk2 Package on CRAN]\n\n{{GTK}}\n\n[[Category:GTK language bindings]]\n[[Category:Free R (programming language) software]]"
    },
    {
      "title": "RKWard",
      "url": "https://en.wikipedia.org/wiki/RKWard",
      "text": "{{Infobox software\n| name = RKWard\n| logo = \n| screenshot = \n| caption = \n| developer = RKWard community\n| latest release version = 0.7.0b\n| latest release date = {{Start date and age|2018|04|16}}\n| programming language = [[C++]], [[ECMAScript]]\n| operating system = [[BSD]], [[Linux]], [[OS X]], [[Unix]], [[Microsoft Windows|Windows]]\n| genre = [[List of statistical packages|Statistical software]]\n| license = [[GNU General Public License]]\n| website = {{URL|https://rkward.kde.org/}}\n}}\n'''RKWard''' is a transparent front-end to the [[R programming language]], a [[scripting-language]] with a strong focus on [[statistics]] functions. RKWard tries to combine the power of the R language with the ease of use of commercial [[statistical package]]s.\n\nAlthough it can run in numerous environments, it was designed for and integrates with the [[KDE]] desktop environment.\n\nRKWard's features include:\n*Spreadsheet-like data editor\n*[[Syntax highlighting]], [[code folding]] and [[autocomplete|code completion]]\n*Data import (e.g. SPSS, Stata and CSV)\n*Plot preview and browsable history\n*R package management\n*Workspace browser\n*GUI dialogs for all kinds of statistics and plots\n\n== See also ==\n* [[Comparison of statistical packages]]\n* [[R (programming language)#Interfaces|R interfaces]]<!-- list any similar R-related software in this other article -->\n\n== External links ==\n*[https://rkward.kde.org/ RKWard homepage]\n*[https://www.jstatsoft.org/article/view/v049i09 'RKWard: A Comprehensive Graphical User Interface and Integrated Development Environment for Statistical Analysis with R', Stefan Rödiger, Thomas Friedrichsmeier, Prasenjit Kapat, Meik Michalke, ''Journal of Statistical Software'']\n{{KDE}}\n\n[[Category:Free R (programming language) software]]\n[[Category:Free software programmed in C++]]\n[[Category:Free statistical software]]\n[[Category:KDE Applications]]\n[[Category:PHP software]]"
    },
    {
      "title": "Rmetrics",
      "url": "https://en.wikipedia.org/wiki/Rmetrics",
      "text": "{{Multiple issues|\n{{advert|date=April 2012}}\n{{More citations needed|date=April 2012}}\n}}\n\n{{Infobox Software\n | name = Rmetrics\n | logo =\n | developer =\n | operating_system = [[Cross-platform]]: [[Microsoft Windows|Windows]], [[macOS]], [[Linux]]\n | platform = [[R (programming language)|R programming language]]\n | genre = [[Computational finance]] \n | license = [[GPL]]\n | programming language = [[R (programming language)|R]],  [[C (programming language)|C]]/[[C++]], [[Fortran]]\n | website = {{URL|http://www.rmetrics.org/}}\n}}\n'''Rmetrics''' is a [[Free software|free]], [[open-source software|open-source]] and [[Open source software development|open development]] software project for teaching [[computational finance]]. Rmetrics is based primarily on the [[Statistics|statistical]] [[R (programming language)|R programming language]], but does contain contributions in other programming languages, Fortran, C, and C++. The project was started in 2001 by Diethelm Wuertz, based at the [[ETH Zurich|Swiss Federal Institute of Technology]] in [[Zurich]].\n\n== Rmetrics Packages ==\nMost Rmetrics components are distributed as [[R (programming language)|R packages]], which are add-on modules for R.\n\n== Goals ==\nThe broad goals of the projects are\n* to provide widespread access to a broad range of powerful [[Statistics|statistical]] and [[Statistical graphics|graphical]] methods for the analysis of market data and risk management in finance.\n* to provide a common [[Computing platform|software platform]] that enables the rapid [[Software development|development]] and [[Software deployment|deployment]] of [[Software extension|extensible]], [[Scalability|scalable]], and [[Interoperability|interoperable]] software.\n* to strengthen the scientific understanding by producing high-quality [[Tutorial|documentation and reproducible research]].\n* to train researchers on computational and statistical methods for the analysis of financial data and for financial risk management.\n\n== R/Rmetrics Project ==\nRmetrics and the R package system provides a broad range of advantages to the Rmetrics project including\n* a high-level [[interpreted language]] in which one can easily and quickly [[Software prototyping|prototype]] new computational methods.\n* It includes a well established system for packaging together software components and documentation.\n* It can address the diversity and complexity of [[computational finance]] and [[financial engineering]] problems in a common [[Object-oriented programming|object-oriented framework]].\n* It supports a rich set of statistical [[Computer simulation|simulation]] and [[Statistical model|modeling]] activities.\n* It contains cutting edge [[Statistical graphics|data and model visualization]] capabilities.\n* It has been the basis for pathbreaking research in [[Parallel computing|parallel statistical computing]].\n\n== Open Source Commitment ==\nThe Rmetrics project has a commitment to full open source discipline, with distribution via a [[SourceForge.net]]-like platform. All software contributions are expected to exist under an [[open source license]] such as [[GNU General Public License|GPL2]], [[Artistic License|Artistic 2.0]], or [[Berkeley Software Distribution|BSD]]. There are many different reasons why open—source software is beneficial to a software project in finance. The reasons include\n* to provide full access to [[algorithm]]s and their implementation\n** to facilitate software improvements through [[Software bug|bug fixing]] and [[software extension]]\n* to encourage good [[Computational statistics|scientific computing and statistical practice]] by providing appropriate tools and instruction\n* to provide a [[Application software|workbench of tools]] that allow researchers to explore and expand the methods used to analyze biological data\n* to ensure that the international [[scientific community]] is the owner of the [[Programming tool|software tools]] needed to carry out research\n* to lead and encourage commercial support and development of those tools that are successful\n* to promote [[Reproducibility|reproducible research]] by providing open and accessible tools with which to carry out that research (reproducible research is distinct from independent verification)\n* to encourage users to join the Rmetrics project, either by contributing Rmetrics compliant packages or documentation.\n\n== Rmetrics Repository ==\nThe [http://r-forge.r-project.org/projects/rmetrics Rmetrics Repository] is hosted by R-forge. The following developers (in alphabetical order) contribute or have contributed to the Rmetrics packages: Andrew Ellis, Christophe Dutang, David Lüthi, David Scott, Diethelm Würtz, Francesco Gochez, Juri Hinz, Marco Perlin, Martin Mächler, Maxime Debon, Petr Savicky, Philipp Erb, Pierre Chausse, Sergio Guirreri, Spencer Graves, Yohan Chalabi\n\n== Resources ==\n* {{cite book |last=Wuertz |first=Diethelm |author2=Chalabi, Yohan |author3=Chen, William |author4= Ellis, Andrew |year=2009 |title=Portfolio Optimization with R/Rmetrics |publisher=Finance Online Publishing }}\n\n== See also ==\n* [[Computational finance]]\n* [[R (programming language)]]\n\n== External links ==\n* {{Official website|http://www.rmetrics.org/}}\n\n[[Category:Financial software]]\n[[Category:Free R (programming language) software]]\n[[Category:Free science software]]\n[[Category:Science software for Linux]]\n[[Category:Science software for MacOS]]\n[[Category:Science software for Windows]]"
    },
    {
      "title": "RQDA",
      "url": "https://en.wikipedia.org/wiki/RQDA",
      "text": "{{Infobox software\n| name                   = RQDA\n| logo                   =\n| screenshot             = rqda.png\n| screenshot size        = 250px\n| caption                = Main window in RQDA\n| developer              = [[Huang Ronggui]]\n| latest_release_version = 0.3-1\n| latest_release_date    = Mar 2018\n| operating_system       = [[Microsoft Windows]], [[Linux]], [[macOS]]\n| genre                  = Qualitative Data Analysis [[Qualitative Research]]\n| license                = [[New BSD license]]\n| website                = {{url|http://rqda.r-forge.r-project.org/}}\n}}\n'''RQDA''' is an [[R (programming language)|R]] package for computer assisted [[qualitative data analysis]] or [[CAQDAS]]. It is installable from, and runs within, the R statistical software, but has a separate window running a graphical user interface (through [[RGtk2]]). RQDA's approach allows for tight integration of the constructivist approach of qualitative research with quantitative data analysis which can increase the rigor, transparency and validity of qualitative research.<ref>{{Cite journal |doi = 10.1108/QMR-02-2016-0014|title = An RQDA-based constructivist methodology for qualitative research|journal = Qualitative Market Research: An International Journal|volume = 20|pages = 90–112|year = 2017|last1 = Chandra|first1 = Yanto|last2 = Shang|first2 = Liang}}</ref>\n\n==Features==\nIn the graphical interface it has the following functions:\n* Import documents from plain text\n* Support non-English documents, Simplified Chinese Character is well-tested under Windows\n* Support character-level coding\n* Memos for documents, codes, coding, project, files etc.\n* Retrieve coding, and easily gets back to the original file. Conditional retrieval is supported as well.\n* Single-file (*.rqda) format, which is basically the [[SQLite]] database\n* Categorize codes (tree-like categories are avoided)\n* Categorize files\n* Search files by keywords and can highlight keyword in the open file\n* Show attributes of files, which is useful for content analysis\n* Categorise cases and related attributes of cases (to bridge qualitative and quantitative research)\n* Search information about selected cases from the web\n* Rename files, codes, code categories, cases etc.\n* Write and organize fieldwork journals\n\nThrough use of R functions, it can:\n* Import a batch of files\n* Calculate the relation between two codings, given the coding indexes\n* Give a summary of coding and inter-code relationship.\n* Export file/case attributes and show subset of files/cases.\n* Allow for more flexible conditional retrieval.\n* Boolean operations of and, or and not.\n\n==See also==\n* [[Computer Assisted Qualitative Data Analysis Software]]\n\n==External links==\n* {{Official website|http://rqda.r-forge.r-project.org/}}\n* [https://www.youtube.com/user/RQDAtuto/videos?view=1/ RQDA video tutorials]\n* [https://dugontario.files.wordpress.com/2013/12/qualitative-analysis-in-r.pdf Tutorial \"Qualitative Data Analysis in R\"]\n* [http://comm.eval.org/communities/community-home/librarydocuments/viewdocument?DocumentKey=a2ba0451-c075-4d86-9ae2-6720791a1e31 Warner, L. (2012). Eval12 Session 682: R Qualitative Data Analysis (RQDA) Package: A Free Qualitative Analysis Tool (skill-building presentation)]\n* [http://rqda.r-forge.r-project.org/publications.html Scholarly research using RQDA]\n\n==References==\n{{reflist}}\n\n{{Computer-assisted qualitative data analysis software |state=autocollapse}}\n\n{{DEFAULTSORT:Rqda}}\n[[Category:Free QDA software]]\n[[Category:Cross-platform free software]]\n[[Category:Free R (programming language) software]]\n[[Category:Qualitative research]]\n[[Category:Science software for MacOS]]\n[[Category:Science software for Linux]]\n\n\n{{Science-software-stub}}\n{{Software stub}}"
    },
    {
      "title": "Statcheck",
      "url": "https://en.wikipedia.org/wiki/Statcheck",
      "text": "'''Statcheck''' is a [[package manager|software package]] written in the [[programming language]] [[R (programming language)|R]]. Its purpose is to detect [[statistics|statistical]] errors in [[peer-review]]ed [[psychology]] articles<ref>{{Cite journal |url=https://www.psychologicalscience.org/observer/bayesmed-and-statcheck |title=BayesMed and statcheck |issue=3 |last=Nuijten |first=Michèle B. |date=2017-02-28 |journal=Aps Observer |volume=30 |language=en-US |access-date=2018-10-18}}</ref> by searching papers for statistical results, redoing the calculations described in each paper, and comparing the two values to see if they match.<ref name=nature>{{Cite journal |last=Baker |first=Monya |date=2016-11-25 |title=Stat-checking software stirs up psychology |url=http://www.nature.com/news/stat-checking-software-stirs-up-psychology-1.21049 |journal=Nature |language=en |volume=540 |issue=7631 |pages=151–152 |doi=10.1038/540151a |pmid=27905454 |issn=0028-0836}}</ref> It takes advantage of the fact that psychological research papers tend to report their results in accordance with the guidelines published by the [[American Psychological Association]] (APA).<ref>{{Cite journal |last=Wren |first=Jonathan D. |date=2018-06-15 |title=Algorithmically outsourcing the detection of statistical errors and other problems |url=http://emboj.embopress.org/content/37/12/e99651 |journal=The EMBO Journal |language=en |volume=37 |issue=12 |pages=e99651 |doi=10.15252/embj.201899651 |issn=0261-4189 |pmc=6003655 |pmid=29794111}}</ref> This leads to several disadvantages: it can only detect results reported completely and in exact accordance with the APA's guidelines,<ref>{{Cite journal |last=Colombo |first=Matteo |last2=Duev |first2=Georgi |last3=Nuijten |first3=Michèle B. |last4=Sprenger |first4=Jan |date=2018-04-12 |title=Statistical reporting inconsistencies in experimental philosophy |journal=PLOS ONE |volume=13 |issue=4 |pages=e0194360 |doi=10.1371/journal.pone.0194360 |issn=1932-6203 |pmc=5896892 |pmid=29649220}}</ref> and it cannot detect statistics that are only included in tables in the paper.<ref>{{Cite journal |last=van der Zee |first=Tim |last2=Anaya |first2=Jordan |last3=Brown |first3=Nicholas J. L. |date=2017-07-10 |title=Statistical heartburn: an attempt to digest four pizza publications from the Cornell Food and Brand Lab |journal=BMC Nutrition |language=En |volume=3 |issue=1 |doi=10.1186/s40795-017-0167-x |issn=2055-0928}}</ref> Another limitation is that Statcheck cannot deal with statistical corrections to test statistics, like Greenhouse-Geisser or Bonferroni corrections, which actually make tests more conservative.<ref>{{cite arxiv |eprint= 1610.01010|title=Sources of false positives and false negatives in the Statcheck algorithm |last=Schmidt |first=Thomas | language=en-US|class=q-bio.QM |year=2016 }}</ref>\n\n==History==\nStatcheck was first developed in 2015 by Michele Nuijten of [[Tilburg University]] and Sacha Epskamp of the [[University of Amsterdam]].<ref name=vox>{{Cite web |url=https://www.vox.com/science-and-health/2016/9/30/13077658/statcheck-psychology-replication |title=A bot crawled thousands of studies looking for simple math errors. The results are concerning. |last=Resnick |first=Brian |date=2016-09-30 |website=Vox |access-date=2018-10-18}}</ref><ref name=sciencemag>{{Cite web |url=http://www.sciencemag.org/news/2017/11/controversial-software-proving-surprisingly-accurate-spotting-errors-psychology-papers |title=Controversial software is proving surprisingly accurate at spotting errors in psychology papers |last=Chawla |first=Dalmeet Singh |date=2017-11-28 |website=Science  |language=en |access-date=2018-10-18}}</ref> Later that year, Nuijten and her colleagues published a paper using Statcheck on over 30,000 psychology papers and reported that \"half of all published psychology papers...contained at least one p-value that was inconsistent with its test\".<ref>{{Cite journal |last=Nuijten |first=Michèle B. |last2=Hartgerink |first2=Chris H. J. |last3=van Assen |first3=Marcel A. L. M. |last4=Epskamp |first4=Sacha |last5=Wicherts |first5=Jelte M. |date=2015-10-23 |title=The prevalence of statistical reporting errors in psychology (1985–2013) |journal=Behavior Research Methods |language=en |volume=48 |issue=4 |pages=1205–1226 |doi=10.3758/s13428-015-0664-2 |issn=1554-3528 |pmc=5101263 |pmid=26497820}}</ref> The study was subsequently written up favorably in ''[[Nature (journal)|Nature]]''.<ref name=guardian/><ref>{{Cite journal |last=Baker |first=Monya |date=2015-10-28 |title=Smart software spots statistical errors in psychology papers |url=http://www.nature.com/news/smart-software-spots-statistical-errors-in-psychology-papers-1.18657 |journal=Nature |language=en |doi=10.1038/nature.2015.18657 |issn=1476-4687 |access-date=2018-10-19}}</ref> In 2016, Nuijten and Epskamp both received the Leamer-Rosenthal Prize for Open Social Science from the [[Berkeley Initiative for Transparency in the Social Sciences]] for creating Statcheck.<ref>{{Cite web |url=https://www.bitss.org/people/michele-nuijten/ |title=Michèle Nuijten |date=2016-12-16 |website=Berkeley Initiative for Transparency in the Social Sciences |language=en-US |access-date=2018-10-19}}</ref>\n\nIn 2016, Tilburg University researcher Chris Hartgerink used Statcheck to scan over 50,000 psychology papers and posted the results to [[PubPeer]]; he subsequently published the data he extracted from these papers in an article in the journal ''[[Data (journal)|Data]]''.<ref name=guardian/><ref>{{Cite journal |last=Hartgerink |first=Chris |date=2016-09-23 |title=688,112 Statistical Results: Content Mining Psychology Articles for Statistical Test Results |url=https://www.mdpi.com/2306-5729/1/3/14 |journal=Data |language=en |volume=1 |issue=3 |pages=14 |doi=10.3390/data1030014}}</ref> Hartgerink told [[Motherboard (website)|Motherboard]] that \"We're checking how reliable is the actual science being presented by science\".<ref>{{Cite web |url=https://motherboard.vice.com/en_us/article/vv7p59/scientists-are-worried-about-peer-review-by-algorithm-statcheck |title=Scientists Are Worried About 'Peer Review by Algorithm' |last=Buranyi |first=Stephen |date=2016-09-05 |website=Motherboard |language=en-us |access-date=2018-10-18}}</ref> He also told [[Vox (website)|Vox]] that he intended to use Statcheck to perform a function similar to a [[spell checker]] software program.<ref name=vox/> Hartgerink's action also sent [[email]] alerts to every researcher who had authored or co-authored a paper that it had flagged. These flaggings, and their posting on a public forum, proved controversial, prompting the [[German Psychological Society]] to issue a statement condemning the unauthorized use of Statcheck.<ref name=guardian>{{Cite news |url=https://www.theguardian.com/science/2017/feb/01/high-tech-war-on-science |title=The high-tech war on science fraud |last=Buranyi |first=Stephen |date=2017-02-01 |newspaper=The Guardian |language=en-GB |access-date=2018-10-18}}</ref> Psychologist [[Dorothy V.M. Bishop]], who had two of her own papers flagged by Statcheck, criticized the program for publicly flagging many papers (including one of her own) despite not having found any statistical errors in it.<ref>{{Cite web |url=https://retractionwatch.com/2016/09/02/heres-why-more-than-50000-psychology-studies-are-about-to-have-pubpeer-entries/ |title=Here's why more than 50,000 psychology studies are about to have PubPeer entries |date=2016-09-02 |website=Retraction Watch |language=en-US |access-date=2018-10-18}}</ref> Other critics alleged that Statcheck had reported the presence of errors in papers that did not actually contain them, due to the tool's failure to correctly read statistics from certain papers.<ref>{{Cite journal |last=Stokstad |first=Erik |date=2018-09-21 |title=The truth squad |url=http://science.sciencemag.org/content/361/6408/1189 |journal=Science |language=en |volume=361 |issue=6408 |pages=1189–1191 |doi=10.1126/science.361.6408.1189 |issn=0036-8075 |pmid=30237339}}</ref>\n\nIn 2017, Statcheck's developers published a [[preprint]] paper concluding that the program accurately identified statistical errors over 95% of the time.<ref name=sciencemag/> This validity study comprised more than 1,000 hand-checked tests among which 5.00% turned out to be inconsistent.<ref>{{Cite journal |url= https://psyarxiv.com/tcxaj/ |title=The validity of the tool \"Statcheck\" in discovering statistical reporting inconsistencies |last=Nuijten |first=Michèle B. |journal=PsyArXiv Preprints | language=en-US}}</ref> The study found that Statcheck recognized 60% of all statistical tests.  A reanalysis of these data found that if the program flagged a test as inconsistent, it was correct in 60.4% of cases. Reversely, if a test was truly inconsistent, Statcheck flagged it in an estimated 51.8% of cases (this estimate included the undetected tests and assumed that they had the same rate of inconsistencies as the detected tests). Overall, Statcheck's accuracy was 95.9%, half a percentage point higher than the chance level of 95.4% expected when all tests are simply taken at face value. Statcheck was conservatively biased (by about one standard deviation) against flagging tests.<ref>{{Cite journal |url= https://psyarxiv.com/hr6qy/ |title=Statcheck does not work: All the numbers |last=Schmidt |first=Thomas |journal=PsyArXiv Preprints | language=en-US}}</ref>\n\nMore recent research has used Statcheck on papers published in [[Canadian]] psychology journals, finding similar rates of statistical reporting errors as the original authors based on a 30-year sample of such articles. The same study also found many typographical errors in online versions of relatively old papers, and that correcting for these reduced the estimated percent of tests that were erroneously reported.<ref>{{Cite journal |last=Green |first=Christopher D. |last2=Abbas |first2=Sahir |last3=Belliveau |first3=Arlie |last4=Beribisky |first4=Nataly |last5=Davidson |first5=Ian J. |last6=DiGiovanni |first6=Julian |last7=Heidari |first7=Crystal |last8=Martin |first8=Shane M. |last9=Oosenbrug |first9=Eric |date=August 2018|title=Statcheck in Canada: What proportion of CPA journal articles contain errors in the reporting of p-values? |journal=Canadian Psychology |language=en |volume=59 |issue=3 |pages=203–210 |doi=10.1037/cap0000139 |issn=1878-7304}}</ref> Journals that have begun piloting the use of Statcheck as part of their peer review process include ''[[Psychological Science]]'',<ref>{{Cite journal |last=Freedman |first=Leonard P. |last2=Venugopalan |first2=Gautham |last3=Wisman |first3=Rosann |date=2017-05-02 |title=Reproducibility2020: Progress and priorities |url=https://f1000research.com/articles/6-604/v1 |journal=F1000Research |volume=6 |pages=604 |doi=10.12688/f1000research.11334.1 |issn=2046-1402 |pmc=5461896 |pmid=28620458}}</ref> the ''[[Canadian Journal of Human Sexuality]]'',<ref>{{Cite journal |last=Sakaluk |first=John K. |last2=Graham |first2=Cynthia A. |date=2017-11-17 |title=Promoting Transparent Reporting of Conflicts of Interests and Statistical Analyses at The Journal of Sex Research |journal=The Journal of Sex Research |language=en |volume=55 |issue=1 |pages=1–6 |doi=10.1080/00224499.2017.1395387 |pmid=29148841 |issn=0022-4499}}</ref> and the ''[[Journal of Experimental Social Psychology]]''.<ref>{{Cite book |url=https://www.journals.elsevier.com/journal-of-experimental-social-psychology/news/jesp-piloting-the-use-of-statcheck |title=JESP piloting the use of statcheck |website=Journal of Experimental Social Psychology |access-date=2018-10-19}}</ref> The [[open access]] publisher [[PsychOpen]] has also used it on all papers accepted for publication in their journals since 2017.<ref>{{Cite web |url=https://www.psychopen.eu/news/article/psychopen-uses-statcheck-tool-for-quality-check/ |title=PsychOpen uses Statcheck tool for quality check  |date=2017-04-10 |website=PsychOpen |language=en |access-date=2018-10-23}}</ref>\n\n==References==\n{{Reflist}}\n\n==External links==\n*{{Official website|http://statcheck.io/index.php}}\n\n[[Category:Statistical software]]\n[[Category:2015 software]]\n[[Category:Free R (programming language) software]]"
    },
    {
      "title": "Ana (programming language)",
      "url": "https://en.wikipedia.org/wiki/Ana_%28programming_language%29",
      "text": "{{multiple issues|\n{{notability|date=July 2017}}\n{{unreferenced|date=July 2017}}\n}}\n\nIn contexts of [[solar physics]] and [[data analysis]], '''Ana''' is a computer language that is designed for array processing and image data analysis. The name is an acronym for \"A Non Acronym\". Ana began as a [[fork (software development)|fork]] of an early version of [[IDL (programming language)|IDL]], but has diverged significantly since then.\n\nIt is in common use at the [[Lockheed-Martin Space Applications Laboratory]] and at institutions that analyze data from the [[TRACE]] spacecraft, but is not commonly used elsewhere. Ana appears to be intended as [[free software]] though it is not distributed under a recognized [[FOSS]] license. It is available as source code, primarily through the [[Solarsoft]] distribution system.\n\nThe most commonly used application written in Ana is the [[TRACE image browser]], which is designed for browsing and viewing time-lapse movies collected by [[TRACE]], [[Solar and Heliospheric Observatory|SOHO]], [[Yohkoh]], and other observatories.\n\nAna homepage:  [http://ana.lmsal.com/]\n\n{{DEFAULTSORT:Ana (Language)}}\n[[Category:Lockheed Martin]]\n[[Category:Numerical programming languages]]\n[[Category:Array programming languages]]\n[[Category:Earth sciences graphics software]]\n\n\n{{Compu-lang-stub}}"
    },
    {
      "title": "ARITH-MATIC",
      "url": "https://en.wikipedia.org/wiki/ARITH-MATIC",
      "text": "{{no footnotes|date=March 2013}}\n:''You may have been looking for [[arithmetic]], a branch of [[mathematics]].''\n'''ARITH-MATIC''' is an extension of [[Grace Hopper]]'s  [[A-2 (programming language)|A-2]] [[programming language]],<ref>{{cite book|last=Sammet|first=Jean|authorlink=Jean E. Sammet|date=1969|title=Programming Languages: History and Fundamentals|publisher=Prentice-Hall|isbn=978-0-13-729988-1|pages=132}}</ref> developed around 1955. ARITH-MATIC was originally known as A-3, but was renamed by the marketing department of [[Remington Rand]] [[UNIVAC]].\n\n<!--How was A-2 extended?. Answer: I found in the book of Sammet, page 132, this words: 'A-3 (also called ARITH-MATIC) was an improvement of, but not completely compatible with, A-2. It also provided a number of additional facilities which were not in A-2\"-->\n\n== Some ARITH-MATIC subroutines <ref>{{cite techreport|vauthors=Ash R, Broadwin E, Della Valle V, Greene M, Jenny A, Katz C, Yu L|title=Preliminary Manual for MATH-MATIC and ARITH-MATIC Systems for Algebraic Translation and Compilation for Univac I and II|date=April 19, 1957|publisher=Remington Rand Univac|location=Philadelphia, Penn.|url=http://archive.computerhistory.org/resources/access/text/2016/06/102724614-05-01-acc.pdf|access-date=2016-09-23}}</ref>==\n\n{| class=\"wikitable\"\n!style=\"background:#BCC5C5;\"|Type\n!style=\"background:#BCC5C5;\"|Subroutine\n!style=\"background:#BCC5C5;\"|Description\n!style=\"background:#BCC5C5;\"|Explanation\n|-\n|style=\"background:#DCE5E5;\"|Arithmetic\n|style=\"background:#DCE5E5;\"|AAO(A)(B)(C)\n|style=\"background:#DCE5E5;\"|A+B=C\n|style=\"background:#DCE5E5;\"|The A in the middle of 'AA0' stands for addition\n|-\n|style=\"background:#DCE5E5;\"|Arithmetic\n|style=\"background:#DCE5E5;\"|ASO(A)(B)(C)\n|style=\"background:#DCE5E5;\"|A-B=C\n|style=\"background:#DCE5E5;\"|The S in the middle of 'AS0' stands for subtraction\n|-\n|style=\"background:#DCE5E5;\"|Arithmetic\n|style=\"background:#DCE5E5;\"|AMO(A)(B)(C)\n|style=\"background:#DCE5E5;\"|A*B=C\n|style=\"background:#DCE5E5;\"|The M in the middle of 'AM0' stands for multiplication\n|-\n|style=\"background:#DCE5E5;\"|Arithmetic\n|style=\"background:#DCE5E5;\"|ADO(A)(B)(C)\n|style=\"background:#DCE5E5;\"|A/B=C\n|style=\"background:#DCE5E5;\"|The D in the middle of 'AD0' stands for division\n|-\n|style=\"background:#DCE5E5;\"|Trigonometric\n|style=\"background:#DCE5E5;\"|TSO(A)OOO(B)\n|style=\"background:#DCE5E5;\"|Sin(A)=B\n|style=\"background:#DCE5E5;\"|The S in the middle of 'TS0' stands for Sin\n|-\n|style=\"background:#DCE5E5;\"|Trigonometric\n|style=\"background:#DCE5E5;\"|TCO(A)OOO(B)\n|style=\"background:#DCE5E5;\"|Cos(A)=B\n|style=\"background:#DCE5E5;\"|The C in the middle of 'TC0' stands for Cos\n|-\n|style=\"background:#DCE5E5;\"|Trigonometric\n|style=\"background:#DCE5E5;\"|TTO(A)OOO(B)\n|style=\"background:#DCE5E5;\"|Tan(A)=B\n|style=\"background:#DCE5E5;\"|The T in the middle of 'TT0' stands for Tan\n|-\n|style=\"background:#DCE5E5;\"|Trigonometric\n|style=\"background:#DCE5E5;\"|TAT(A)OOO(B)\n|style=\"background:#DCE5E5;\"|Arctan(A)=B\n|style=\"background:#DCE5E5;\"|The AT stands for Arctan\n|-\n|style=\"background:#DCE5E5;\"|Hyperbolic\n|style=\"background:#DCE5E5;\"|HSO(A)OOO(B)\n|style=\"background:#DCE5E5;\"|Sinh(A)=B\n|style=\"background:#DCE5E5;\"|The S in the middle of 'HS0' stands for Sin h\n|-\n|style=\"background:#DCE5E5;\"|Hyperbolic\n|style=\"background:#DCE5E5;\"|HCO(A)OOO(B)\n|style=\"background:#DCE5E5;\"|Cosh(A)=B\n|style=\"background:#DCE5E5;\"|The C in the middle of 'TC0' stands for Cos h\n|-\n|style=\"background:#DCE5E5;\"|Hyperbolic\n|style=\"background:#DCE5E5;\"|HTO(A)OOO(B)\n|style=\"background:#DCE5E5;\"|Tanh(A)=B\n|style=\"background:#DCE5E5;\"|The T in the middle of 'TT0' stands for Tan h\n|-\n|style=\"background:#DCE5E5;\"|General Mathematical\n|style=\"background:#DCE5E5;\"|SQR(A)OOO(B)\n|style=\"background:#DCE5E5;\"|Sqrt(A)=B\n|style=\"background:#DCE5E5;\"|\n|-\n|style=\"background:#DCE5E5;\"|General Mathematical\n|style=\"background:#DCE5E5;\"|APN(A)(N)(B)\n|style=\"background:#DCE5E5;\"|A**N=B\n|style=\"background:#DCE5E5;\"|**: Exponentiation\n|}\n\n==References==\n{{reflist}}\n{{FOLDOC}}\n\n==See also==\n* [[A-0 System]]\n\n==External links==\n* [https://web.archive.org/web/20050306212101/http://cispom.boisestate.edu/cis221emaxson/hophtm.htm Website at Boise via Internet Archive]\n\n{{compu-lang-stub}}\n\n[[Category:Numerical programming languages]]"
    },
    {
      "title": "Bc (programming language)",
      "url": "https://en.wikipedia.org/wiki/Bc_%28programming_language%29",
      "text": "{{more footnotes|date=June 2013}}\n{{lowercase|title=bc programming language}}\n{{Infobox Software \n| name                   = bc\n| logo                   = \n| screenshot             = \n| screenshot size        = \n| caption                = \n| developer              = [[Robert Morris (cryptographer)|Robert Morris]] and [[Lorinda Cherry]] of [[Bell Labs]], Philip A. Nelson\n| released               = {{Release year|df=yes|1975}}\n| latest release version = \n| latest release date    = \n| operating system       = [[Unix]], [[Unix-like]] operating systems, [[FreeDOS]]\n| genre                  = [[Command (computing)|Command]]\n| license                = \n| website                = \n}}\n'''bc''', for ''basic calculator'' (often referred to as ''bench calculator''), is \"''an [[Arbitrary-precision arithmetic|arbitrary-precision]] calculator language''\" with syntax similar to the [[C (programming language)|C programming language]]. bc is typically used as either a mathematical scripting language or as an interactive mathematical shell.\n\n==Overview==\nA typical interactive usage is typing the command <code>bc</code> on a [[Unix]] [[Command-line interface#Command prompt|command prompt]] and entering a mathematical expression, such as {{code|(1 + 3) * 2}}, whereupon {{samp|8}} will be output. While bc can work with arbitrary precision, it actually defaults to zero digits after the decimal point, so the expression {{code|2/3}} yields {{samp|0}}. This can surprise new bc users unaware of this fact. The {{code|-l}} option to bc sets the default ''scale'' (digits after the decimal point) to 20 and adds several additional mathematical functions to the language.\n\n==History==\nbc first appeared in [[Version 6 Unix]] in 1975 and was written by [[Robert Morris (cryptographer)|Robert Morris]] and [[Lorinda Cherry]] of [[Bell Labs]]. bc was preceded by [[dc (computer program)|dc]], an earlier arbitrary-precision calculator written by the same authors. dc could do arbitrary-precision calculations, but its [[reverse Polish notation]] (RPN) syntax was inconvenient for users, and therefore bc was written as a front-end to dc. bc was a very simple [[compiler]] (a single [[yacc]] source file with a few hundred lines), which converted the new, C-like, bc syntax into dc's [[postfix notation]] and piped the results through dc.\n\nIn 1991, [[POSIX]] rigorously defined and standardized bc. Two implementations of this standard survive today: The first is the traditional Unix implementation, a front-end to dc, which survives in Unix and [[Plan 9 from Bell Labs|Plan 9]] systems. The second is the [[free software]] [[GNU]] bc, first released in 1991 by Philip A. Nelson. The GNU implementation has numerous extensions beyond the POSIX standard and is no longer a front-end to dc (it is a [[bytecode interpreter]]).\n\n==Implementations==\n===POSIX bc===\nThe POSIX standardized bc language is traditionally written as a program in the [[dc (computer program)|dc]] programming language to provide a higher level of access to the features of the dc language without the complexities of dc's terse syntax.\n\nIn this form, the bc language contains single-letter [[variable (programming)|variable]], [[array data structure|array]] and [[function (programming)|function]] names and most standard arithmetic operators, as well as the familiar [[control-flow]] constructs (<code>'''if('''cond''')'''...</code>, <code>'''while('''cond''')'''...</code> and <code>'''for('''init''';'''cond''';'''inc''')'''...</code>) from C. Unlike C, an '''<code>if</code>''' clause may not be followed by an '''<code>else</code>'''.\n\nFunctions are defined using a '''<code>define</code>''' keyword, and values are returned from them using a '''<code>return</code>''' followed by the return value in parentheses. The '''<code>auto</code>''' keyword (optional in C) is used to declare a variable as local to a function.\n\nAll numbers and variable contents are [[arbitrary-precision]] numbers whose precision (in decimal places) is determined by the global '''<code>scale</code>''' variable.\n\nThe [[base (exponentiation)|numeric base]] of input (in interactive mode), output and program constants may be specified by setting the reserved '''<code>ibase</code>''' (input base) and '''<code>obase</code>''' (output base) variables.\n\nOutput is generated by deliberately not assigning the result of a calculation to a variable.\n\nComments may be added to bc code by use of the C '''<code>/*</code>''' and '''<code>*/</code>''' (start and end comment) symbols.\n\n====Mathematical operators====\n\n=====Exactly as C=====\nThe following POSIX bc [[Operator (programming)|operators]] behave exactly like their C counterparts:\n\n +     -     *     /\n +=    -=    *=    /=\n ++    --    <     >\n <nowiki>==    !=    <=    >=</nowiki>\n ( )   [ ]   { }\n\n=====Similar to C=====\nThe [[Modulus operator|modulus]] operators, <code>%</code> and <code>%=</code> behave exactly like their C counterparts only when the global '''<code>scale</code>''' variable is set to 0, i.e. all calculations are integer-only. Otherwise the computation is done with the appropriate scale. <code>a%b</code> is defined as <code>a-(a/b)*b</code>. Examples:\n<source lang=\"console\" highlight=\"6,8,10\">\n$ bc\nbc 1.06\nCopyright 1991-1994, 1997, 1998, 2000 Free Software Foundation, Inc.\nThis is free software with ABSOLUTELY NO WARRANTY.\nFor details type `warranty'.\nscale=0; 5%3\n2\nscale=1; 5%3\n.2\nscale=20; 5%3\n.00000000000000000002\n</source>\n\n=====Conflicting with C=====\nThe operators\n\n ^     ^=\n\nsuperficially resemble the C bitwise [[exclusive-or]] operators, but are in fact the bc integer exponentiation operators.\n\nOf particular note, the use of the <code>^</code> operator with negative numbers does not follow the C operator precedence. <code>-2^2</code> gives the answer of 4 under bc rather than −4.\n\n=====\"Missing\" operators relative to C=====\nThe [[bitwise operation|bitwise]], [[Boolean logic|boolean]] and [[conditional (programming)|conditional]] operators:\n\n &     |     ^     &&    ||\n &=    |=    ^=    &&=   ||=\n <<    >>\n <<=   >>=\n ?:\n\nare not available in POSIX bc.\n\n====Built-in functions====\nThe '''<code>sqrt()</code>''' function for calculating [[square root]]s is POSIX bc's only built-in mathematical function. Other functions are available in an external standard library.\n\nThe '''<code>scale()</code>''' function for determining the precision (as with the '''<code>scale</code>''' variable) of its argument and the '''<code>length()</code>''' function for determining the number of significant decimal digits in its argument are also built-in.\n\n====Standard library functions====\nbc's standard math library (defined with the '''-l''' option) contains functions for calculating [[sine]], [[cosine]], [[arctangent]], [[natural logarithm]], the [[exponential function]] and the two parameter [[Bessel function]] ''J''. Most standard mathematical functions (including the other inverse trigonometric functions) can be constructed using these. See external links for implementations of many other functions.\n{| class=\"wikitable\"\n|+The bc standard library<ref name=\":0\">{{Cite web|url=https://www.gnu.org/software/bc/manual/html_mono/bc.html#SEC18|title=bc Command Manual|last=Nelson|first=Philip A.|date=20 March 2001|website=|publisher=[[Free Software Foundation]]|access-date=2017-04-20}}</ref>\n!bc command\n!Function\n!Description\n|-\n|<code>s(x)</code>\n|[[Sine]]\n|Takes ''x'', an angle in [[radian]]s\n|-\n|<code>c(x)</code>\n|[[Cosine]]\n|Takes ''x'', an angle in radians\n|-\n|<code>a(x)</code>\n|[[Arctangent]]\n|Returns radians\n|-\n|<code>l(x)</code>\n|[[Natural logarithm]]\n|\n|-\n|<code>e(x)</code>\n|[[Exponential function]]\n| \n|-\n|<code>j(n,x)</code>\n|[[Bessel function]]\n|Returns the order-''n'' Bessel function of ''x''.\n|}\n\nThe '''-l''' option changes the scale to 20,<ref name=\":0\" /> so things such as modulo may work unexpectedly. For example, writing <code>bc -l</code> and then the command <code>print 3%2</code> outputs 0. But writing <code>scale=0</code> after <code>bc -l</code> and then the command <code>print 3%2</code> will output 1.\n\n===Plan 9 bc===\nPlan 9 bc is identical to POSIX bc but for an additional '''<code>print</code>''' statement.\n\n===GNU bc===\nGNU bc derives from the POSIX standard and includes many enhancements. It is entirely separate from dc-based implementations of the POSIX standard and is instead written in C. Nevertheless, it is fully backwards compatible as all POSIX bc programs will run unmodified as GNU bc programs.\n\nGNU bc variables, arrays and function names may contain more than one character, some more operators have been included from C, and notably, an '''<code>if</code>''' clause may be followed by an '''<code>else</code>'''.\n\nOutput is achieved either by deliberately not assigning a result of a calculation to a variable (the POSIX way) or by using the added '''<code>print</code>''' statement.\n\nFurthermore, a '''<code>read</code>''' statement allows the interactive input of a number into a running calculation.\n\nIn addition to C-style comments, a '''<code>#</code>''' character will cause everything after it until the next new-line to be ignored.\n\nThe value of the last calculation is always stored within the additional built-in '''<code>last</code>''' variable.\n\n====Extra operators====\nThe following [[logical operator]]s are additional to those in POSIX bc:\n\n &&     ||      !\n\nThey are available for use in conditional statements (such as within an '''<code>if</code>''' statement). Note, however, that there are still no equivalent bitwise or assignment operations.\n\n====Functions====\nAll functions available in GNU bc are inherited from POSIX. No further functions are provided as standard with the GNU distribution.\n\n==Example code==\nSince the bc <code>^</code> operator only allows an integer power to its right, one of the first functions a bc user might write is a power function with a floating-point exponent. Both of the below assume the standard library has been included:\n\n===A \"power\" function in POSIX bc===\n<syntaxhighlight lang=\"bc\">\n /* A function to return the integer part of x */\n define i(x) {\n    auto s\n    s = scale\n    scale = 0\n    x /= 1   /* round x down */\n    scale = s\n    return (x)\n }\n\n /* Use the fact that x^y == e^(y*log(x)) */\n define p(x,y) {\n    if (y == i(y)) {\n       return (x ^ y)\n    }\n    return ( e( y * l(x) ) )\n }\n</syntaxhighlight>\n\n===Calculating π to 10000 places===\nCalculate [[pi]] using the builtin [[Inverse trigonometric functions|arctangent]] function, {{mono|a()}}:\n<syntaxhighlight lang=\"console\" highlight=\"3\">\n$ bc -lq\nscale=10000\n4*a(1) # The atan of 1 is 45 degrees, which is pi/4 in radians.\n       # This may take several minutes to calculate.\n</syntaxhighlight>\n\n===A translated C function===\nBecause the syntax of bc is similar to that of [[C (programming language)|C]], published numerical functions written in C can often be translated into bc quite easily, which immediately provides the arbitrary precision of bc.  For example, in the [[Journal of Statistical Software]] (July 2004, Volume 11, Issue 5), [[George Marsaglia]] published the following C code for the [[normal distribution|cumulative normal distribution]]:\n\n<syntaxhighlight lang=\"c\">\ndouble Phi(double x)\n{\n    long double s=x,t=0,b=x,q=x*x,i=1;\n    while(s!=t)\n        s=(t=s)+(b*=q/(i+=2));\n    return .5+s*exp(-.5*q-.91893853320467274178L);\n}\n</syntaxhighlight>\n\nWith some necessary changes to accommodate bc's different syntax, and realizing that the constant \"0.9189...\" is actually log(2*PI)/2, this can be translated to the following GNU bc code:\n\n<syntaxhighlight lang=\"bc\">\ndefine phi(x) {\n    auto s,t,b,q,i,const\n    s=x; t=0; b=x; q=x*x; i=1\n    while(s!=t)\n        s=(t=s)+(b*=q/(i+=2))\n    const=0.5*l(8*a(1))   # 0.91893...\n    return .5+s*e(-.5*q-const)\n}\n</syntaxhighlight>\n\n==Using bc in shell scripts==\nbc can be used non-interactively, with input through a [[Pipeline (Unix)|pipe]]. This is useful inside [[shell script]]s. For example:\n<source lang=\"console\">\n$ result=$(echo \"scale=2; 5 * 7 /3;\" | bc)\n$ echo $result\n11.66\n</source>\nIn contrast, note that the [[Bash (Unix shell)|bash shell]] only performs integer arithmetic, e.g.:\n<source lang=\"console\">\n$ result=$((5 * 7 /3))\n$ echo $result\n11\n</source>\nOne can also use the [[Here document|here-string]] idiom (in bash, ksh, csh):\n<source lang=\"console\">\n$ bc -l <<< \"5*7/3\"\n11.66666666666666666666\n</source>\n\n==See also==\n* [[dc (computer program)|dc programming language]]\n* [[C (programming language)|C programming language]]\n* [[hoc (programming language)|hoc programming language]]\n\n==References==\n{{Reflist}}\n{{Refbegin}}\n* {{man|cu|bc|SUS|arbitrary-precision arithmetic language}}\n* [https://www.gnu.org/software/bc/manual/html_mono/bc.html GNU bc manual page]\n* [https://web.archive.org/web/20090501204511/http://manpages.ubuntu.com/manpages/jaunty/en/man1/bc.1posix.html POSIX bc manual page]\n* [http://plan9.bell-labs.com/magic/man2html/1/bc Plan 9 bc manual page]\n* [http://plan9.bell-labs.com/7thEdMan/vol2/bc 7th Edition Unix bc manual page]\n* [http://compilers.iecc.com/comparch/article/95-09-015 A comp.compilers article on the design and implementation of C-bc]\n* [http://minnie.tuhs.org/cgi-bin/utree.pl?file=V6/usr/source/s1/bc.y 6th Edition Unix bc source code], the first release of bc, from May 1975, compiling bc syntax into dc syntax\n{{Refend}}\n\n==External links==\n* [https://doi.acm.org/10.1145/152923.152925 Dittmer, I. 1993. Error in Unix commands dc and bc for multiple-precision-arithmetic. SIGNUM Newsl. 28, 2 (Apr. 1993), 8&ndash;11.]\n* [http://www.phodd.net/cyrek/gnu-bc/ Collection of useful GNU bc functions]\n* [https://www.gnu.org/software/bc/ GNU bc] (and an [http://alpha.gnu.org/gnu/bc/ alpha version]) from the Free Software Foundation\n* [http://gnuwin32.sourceforge.net/packages/bc.htm bc for Windows] from [[GnuWin32]]\n* [http://x-bc.sourceforge.net/ X-bc] - A Graphical User Interface to bc\n** [http://x-bc.sourceforge.net/extensions_bc.html extensions.bc] - contains functions of trigonometry, exponential functions, functions of number theory and some mathematical constants\n** [http://x-bc.sourceforge.net/scientific_constants_bc.html scientific_constants.bc] - contains particle masses, basic constants, such as speed of light in the vacuum and the gravitational constant\n\n{{Unix commands}}\n\n[[Category:Software calculators]]\n[[Category:Cross-platform free software]]\n[[Category:Free mathematics software]]\n[[Category:Numerical programming languages]]\n[[Category:Standard Unix programs]]\n[[Category:Unix SUS2008 utilities]]"
    },
    {
      "title": "Dc (computer program)",
      "url": "https://en.wikipedia.org/wiki/Dc_%28computer_program%29",
      "text": "{{lowercase|title=dc (Unix)}}\n'''dc''' (''desk calculator'') is a [[cross-platform]] [[reverse Polish notation|reverse-polish]] calculator which supports [[arbitrary-precision arithmetic]].<ref>{{man|1|dc|die.net|an arbitrary precision calculator}}</ref> It is one of the oldest [[Unix]] utilities, predating even the invention of the [[C (programming language)|C programming language]]. Like other utilities of that vintage, it has a powerful set of features but terse syntax.<ref>{{cite web\n|url=http://plan9.bell-labs.com/7thEdMan/vol2/dc\n|title=The sources for the manual page for 7th Edition Unix dc\n}}</ref><ref>{{cite web\n |author=Ritchie, Dennis M. \n |date=Sep 1979 \n |url=http://cm.bell-labs.com/cm/cs/who/dmr/hist.html \n |title=The Evolution of the Unix Timesharing System \n |deadurl=yes \n |archiveurl=http://webarchive.loc.gov/all/20100506231949/http://cm.bell-labs.com/cm/cs/who/dmr/hist.html\n |archivedate=2010-05-06\n |df= \n}}</ref>\nTraditionally, the [[bc programming language|bc]] calculator program (with [[infix notation]]) was implemented on top of dc.\n\nThis article provides some examples in an attempt to give a general flavour of the language; for a complete list of commands and syntax, one should consult the [[man page]] for one's specific implementation.\n\n==History==\n<tt>dc</tt> is the oldest surviving [[Unix]] language. When its home [[Bell Labs]] received a [[PDP-11]], <tt>dc</tt>—written in [[B (computer language)|B]]—was the first language to run on the new computer, even before an assembler.<ref name=\"reader\">{{cite techreport |first1=M. D. |last1=McIlroy |authorlink1=Doug McIlroy |year=1987 |url=http://www.cs.dartmouth.edu/~doug/reader.pdf |title=A Research Unix reader: annotated excerpts from the Programmer's Manual, 1971–1986 |series=CSTR |number=139 |institution=Bell Labs}}</ref>\n\n==Basic operations==\nTo multiply four and five in dc (note that most of the whitespace is optional):\n\n<source lang=\"console\">\n$ cat > cal.txt\n4 5 *\np ^d\n\n$ dc cal.txt\n20\n$\n</source>\n\nYou can also get the result with the commands:\n<source lang=\"console\">\n$ echo \"4 5 * p\" |dc\n</source>\nor\n<source lang=\"console\">\n$ dc -\n4 5*pq\n20\n\n$ dc\n4 5 *\np\n20\nq\n\n$ dc -e '4 5 * p'\n</source>\nThis translates into \"push four and five onto the stack, then, with the multiplication operator, pop two elements  from the stack, multiply them and push the result back on the stack.\"  Then the 'p' command is used to examine (print out to the screen) the top element on the stack. The 'q' command quits the invoked instance of dc. Note that numbers must be spaced from each other even as some operators need not be.\n\nThe [[arithmetic precision]] is changed with the command 'k', which sets the number of fractional digits (the number of digits following the [[radix point|point]]) to be used for arithmetic operations.  Since the default precision is zero, this sequence of commands produces '0' as a result:\n \n 2 3 / p\n\nBy adjusting the precision with 'k', arbitrary number of decimal places can be produced.  This command sequence outputs '.66666'.\n\n 5 k\n 2 3 / p\n\nTo evaluate <math>\\sqrt{\\left(12 + \\left(-3\\right)^4\\right)\\over11}-22</math>: ('v' computes the square root of the top of the stack and '_' is used to input a negative number):\n\n 12 _3 4 ^ + 11 / v 22 -\n p\n\nTo swap the top two elements of the stack, use the 'r' command.  To duplicate the top element, use the 'd' command.\n\n==Input/Output==\nTo read a line from [[stdin]], use the '?' command.  This will evaluate the line as if it were a ''dc'' command, and so it is necessary that it be syntactically correct and potentially be a security problem since the '!' ''dc'' command will allow arbitrary command execution.\n\nAs mentioned above, 'p' will print the top of the stack with a newline after it.  'n' will pop the top of the stack and output it without a trailing newline.  'f' will dump the entire stack with one entry per line.\n\n''dc'' also supports arbitrary input and output [[radix|radices]].  The 'i' command will pop the top of the stack and use it for the input base.  Hex digits must be in upper case to avoid collisions with ''dc'' commands and are not limited to A-F if the input radix is larger than 16.  The 'o' command does the same for the output base, but keep in mind that the input base will affect the parsing of every numeric value afterwards so it is usually advisable to set the output base first.  To read the values, the 'K', 'I' and 'O' commands will push the current precision, input radix and output radix on to the top of the stack.\n\nAs an example, to convert from hex to binary:\n<source lang=\"console\">\n$ echo 16i2o DEADBEEFp | dc\n11011110101011011011111011101111\n</source>\n\n==Language Features==\n\n===Registers===\nIn addition to these basic arithmetic and stack operations, dc includes support for [[Macro (computer science)|macros]], conditionals and storing of results for later retrieval.\n\nThe mechanism underlying macros and conditionals is the '''register''', which in dc is a storage location with a single character name which can be stored to and retrieved from: 'sc' pops the top of the stack and stores it in register c, and 'lc' pushes the value of register c onto the stack. For example:\n\n 3 sc 4 lc * p\n\nRegisters can also be treated as secondary stacks, so values can be pushed and popped between them and the main stack using the 'S' and 'L' commands.\n\n===Strings===\nString values are enclosed in '[' and ']' characters and may be pushed on the stack and stored in registers.  The 'a' command will convert the low order byte of the numeric value into an [[ASCII#ASCII printable characters|ASCII]] character, or if the top of the stack is a string it will replace it with the first character of the string.  There are no ways to build up strings or perform string manipulation other than executing it with the 'x' command, or printing it with the 'P' command.\n\nThe '#' character begins a comment to the end of the line.\n\n===Macros===\nMacros are then implemented by allowing registers and stack entries to be strings as well as numbers. A string can be printed, but it can also be executed (i.e. processed as a sequence of dc commands). So for instance we can store a macro to add one and then multiply by 2 into register m:\n\n [1 + 2 *] sm\n\nand then (using the 'x' command which executes the top of the stack) we can use it like this:\n\n 3 lm x p\n\n===Conditionals===\nFinally, we can use this macro mechanism to provide conditionals. The command '=r' will pop two values from the stack, and execute the macro stored in register 'r' only if they are equal. So this will print the string 'equal' only if the top of the stack is equal to 5:\n<pre>\n[[equal]p] sm 5 =m\n</pre>\n\nOther conditionals are '>', '!>', '<', '!<', '!=', which will execute the specified macro if the top two values on the stack are greater, less than or equal to (\"not greater\"), less than,  greater than or equal to (\"not less than\"), and not equals, respectively.\n\n===Loops===\nLooping is then possible by defining a macro which (conditionally) reinvokes itself.  A simple factorial of the top of the stack might be implemented as:\n\n # F(x): return x!\n # if x-1 > 1\n #    return x * F(x-1)\n # otherwise\n #    return x\n [d1-d1<F*]dsFxp\n\nThe '1Q' command will exit from a macro, allowing an early return. 'q' will quit from two levels of macros (and ''dc'' itself if there are less than two levels on the call stack).  'z' will push the current stack depth before the 'z' operation.\n\n==Examples==\nPrint prime numbers:\n<source lang=\"bash\">\n echo '2p3p[dl!d2+s!%0=@l!l^!<#]s#[s/0ds^]s@[p]s&[ddvs^3s!l#x0<&2+l.x]ds.x'|dc\n</source>\nAs an example of a relatively simple program in dc, this command (in 1 line):\n<source lang=\"bash\">\n dc -e '[[Enter a number (metres), or 0 to exit]psj]sh[q]sz[lhx?d0=z10k39.370079*.5+0k12~1/rn[ feet ]Pn[ inches]P10Pdx]dx'\n</source>\nwill convert distances from metres to feet and inches; the bulk of it is concerned with prompting for input, printing output in a suitable format and looping round to convert another number.\n\nAs an example, here is an implementation of the [[Euclidean algorithm]] to find the [[Greatest common divisor|GCD]]:\n<source lang=\"bash\">\n dc -e '??[dSarLa%d0<a]dsax+p'                   # shortest\n dc -e '[a=]P?[b=]P?[dSarLa%d0<a]dsax+[GCD:]Pp'  # easier-to-read version\n</source>\nComputing the [[factorial]] of an input value, <math>n! = \\prod_{i=1}^n i</math>\n\n dc -e '?[q]sQ[d1=Qd1-lFx*]dsFxp'\n\nA more complex example of dc use embedded in a perl script performs a [[Diffie–Hellman key exchange]].  This was popular as a [[signature block]] among [[cypherpunk]]s during the [[ITAR]] debates, where the short script could be run with only perl and dc, ubiquitous programs on unix-like operating systems:<ref>{{cite web\n|url=http://www.cypherspace.org/adam/rsa/perl-dh.html\n|title=Diffie–Hellman in 2 lines of Perl\n|accessdate=5 Jan 2009\n|author=Adam Back\n}}</ref>\n<source lang=\"perl\">\n #!/usr/bin/perl -- -export-a-crypto-system-sig Diffie-Hellman-2-lines\n ($g,$e,$m)=@ARGV,$m||die\"$0 gen exp mod\\n\";\n print`echo \"16dio1[d2%Sa2/d0<X+d*La1=z\\U$m%0]SX$e\"[$g*]\\EszlXx+p|dc`\n</source>\nA commented version is slightly easier to understand and shows how to use loops, conditionals, and the 'q' command to return from a macro.  With the GNU version of dc, the '|' command can be used to do arbitrary precision modular exponentiation without needing to write the X function.\n<source lang=\"perl\">\n#!/usr/bin/perl\n\nmy ($g,$e,$m) = map { \"\\U$_\" } @ARGV;\ndie \"$0 gen exp mod\\n\" unless $m;\n\nprint `echo $g $e $m | dc -e '\n# Hex input and output\n16dio\n# Read m, e and g from stdin on one line\n?SmSeSg\n\n# Function z: return g * top of stack\n[lg*]sz\n\n# Function Q: remove the top of the stack and return 1\n[sb1q]sQ\n\n# Function X(e): recursively compute g^e % m\n# It is the same as Sm^Lm%, but handles arbitrarily large exponents.\n# Stack at entry: e\n# Stack at exit: g^e % m\n# Since e may be very large, this uses the property that g^e % m == \n#\tif( e == 0 )\n#\t\treturn 1\n#\tx = (g^(e/2)) ^ 2\n#\tif( e % 2 == 1 )\n#\t\tx *= g\n#\treturn x %\n[\n\td 0=Q\t\t# return 1 if e==0 (otherwise, stack: e)\n\td 2% Sa\t\t# Store e%2 in a (stack: e)\n\t2/\t\t# compute e/2\n\tlXx\t\t# call X(e/2)\n\td*\t\t# compute X(e/2)^2\n\tLa1=z\t\t# multiply by g if e%2==1\n\tlm %\t\t# compute (g^e) % m\n] SX\n\nle\t# Load e from the register\nlXx\t# compute g^e % m\np\t# Print the result\n'`;\n</source>\n\n==See also==\n*[[bc programming language]]\n*[[Calculator input methods]]\n*[[HP calculators]]\n*[[Stack machine]]\n\n==References==\n{{Reflist}}\n\n==External links==\n*Package [http://packages.debian.org/search?keywords=dc&searchon=names&exact=1&suite=all&section=all dc] in [[Debian GNU/Linux]] repositories\n*[http://gnuwin32.sourceforge.net/packages/bc.htm Native Windows port] of ''[[bc programming language|bc]]'', which includes ''dc''.\n*[http://dc.pr0.uk dc embedded in a webpage]\n\n{{Unix commands}}\n\n[[Category:Cross-platform software]]\n[[Category:Unix software]]\n[[Category:Software calculators]]\n[[Category:Free mathematics software]]\n[[Category:Numerical programming languages]]\n[[Category:Stack-oriented programming languages]]"
    },
    {
      "title": "Deeplearning4j",
      "url": "https://en.wikipedia.org/wiki/Deeplearning4j",
      "text": "{{cleanup-PR|1=article|date=November 2017}}\n{{Infobox software\n| name                   = Deeplearning4j\n| logo                   = \n| screenshot             = \n| caption                =\n| collapsible            =\n| author                 = Alex D. Black, [[Adam Gibson (computer scientist)|Adam Gibson]], V. Kokorin, Josh Patterson\n| developer              = [https://github.com/SkymindIO/deeplearning4j/graphs/contributors Various]\n| released               = <!-- {{Start date and age|YYYY|MM|DD|df=yes}} -->\n| latest release version = 1.0.0-beta4\n| latest release date    = {{Start date and age|2019|5|10|df=yes}}\n| latest preview version = \n| latest preview date    = <!-- {{Start date and age|YYYY|MM|DD|df=yes}} -->\n| programming language   = [[Java (programming language)|Java]], [[Scala (programming language)|Scala]], [[CUDA]], [[C (programming language)|C]], [[C++]], [[Python (programming language)|Python]], [[Clojure]]\n| operating system       = [[Linux]], [[macOS]], [[Microsoft Windows|Windows]], [[Android (operating system)|Android]]\n| platform               = [[Cross-platform]]\n| size                   =\n| language               = English\n| status                 = Active\n| genre                  = [[Natural language processing]], [[deep learning]], [[machine vision]], [[artificial intelligence]]\n| license                = [[Apache License 2.0]]\n| website                = {{URL|deeplearning4j.org}}\n}}\n\n{{machine learning bar}}\nEclipse '''Deeplearning4j''' is a [[deep learning]] programming [[Library (computing)|library]] written for [[Java (programming language)|Java]] and the [[Java virtual machine]] (JVM)<ref name=\"wired\">{{cite web|first=Cade|last=Metz|title=The Mission to Bring Google's AI to the Rest of the World|work=[[Wired.com]]|date=2014-06-02|url=https://www.wired.com/2014/06/skymind-deep-learning/|accessdate=2014-06-28}}</ref><ref>{{cite web|url=http://www.businessweek.com/articles/2014-06-03/teaching-smaller-companies-how-to-probe-deep-learning-on-their-own|title=Deep Learning for (Some of) the People|last=Vance|first=Ashlee|work=[[Bloomberg Businessweek]]|date=2014-06-03|accessdate=2014-06-28}}</ref> and a [[computing]] framework with wide support for [[deep learning]] algorithms.<ref>{{cite web|url=https://venturebeat.com/2015/11/14/deep-learning-frameworks/|title=Want an open-source deep learning framework? Take your pick|last=Novet|first=Jordan|work=[[VentureBeat]]|date=2015-11-14|accessdate=2015-11-24}}</ref> Deeplearning4j includes implementations of the [[restricted Boltzmann machine]], [[deep belief net]], deep autoencoder, stacked denoising autoencoder and [[Recursive neural network#Tensor|recursive neural tensor network]], [[word2vec]], doc2vec, and [[GloVe (machine learning)|GloVe]]. These algorithms all include [[Distributed computing|distributed]] [[Parallel computing|parallel]] versions that integrate with [[Apache Hadoop]] and [[Apache Spark|Spark]].<ref>{{cite web|url=https://www.youtube.com/watch?v=LCsc1hFuNac|title=Adam Gibson, DeepLearning4j on Spark and Data Science on JVM with nd4j, SF Spark @Galvanize 20150212 |last=TV|first=Functional|work=SF Spark Meetup|date=2015-02-12|accessdate=2015-03-01}}</ref>\n\nDeeplearning4j is [[open-source software]] released under [[Apache License]] 2.0,<ref>{{cite web|title=Github Repository|url=https://github.com/agibsonccc/java-deeplearning}}</ref> developed mainly by a [[machine learning]] group headquartered in [[San Francisco]] and [[Tokyo]] and led by Adam Gibson.<ref name=\"deeplearning4j.org\">{{cite web|url=http://deeplearning4j.org/|title=deeplearning4j.org}}</ref><ref>{{cite web|title=Crunchbase Profile|url=http://www.crunchbase.com/person/adam-gibson}}</ref> It is supported commercially by the startup Skymind, which bundles DL4J, [[Tensorflow]], [[Keras]] and other deep learning libraries in an enterprise distribution called the Skymind Intelligence Layer.<ref>{{cite web|title=Skymind Intelligence Layer Community Edition|url=https://skymind.ai/quickstart}}</ref> Deeplearning4j was contributed to the [[Eclipse Foundation]] in October 2017.<ref>{{cite web|title=Eclipse Deeplearning4j Project Page|url=https://projects.eclipse.org/proposals/deeplearning4j}}</ref><ref>{{cite web|title=Skymind’s Deeplearning4j, the Eclipse Foundation, and scientific computing in the JVM|url=https://jaxenter.com/skymind-deeplearning4j-eclipse-138872.html|work=Jaxenter|accessdate=2017-11-15}}</ref>\n\n==Introduction==\nDeeplearning4j relies on the widely used programming language [[Java (programming language)|Java]], though it is compatible with [[Clojure]] and includes a [[Scala (programming language)|Scala]] [[application programming interface]] (API). It is powered by its own open-source numerical computing library, [[ND4J (software)|ND4J]], and works with both [[central processing unit]]s (CPUs) and [[graphics processing unit]]s (GPUs).<ref name=\"om\">{{cite web|first=Derrick|last=Harris|title=A startup called Skymind launches, pushing open source deep learning|work=[[GigaOM.com]]|date=2014-06-02|url=http://gigaom.com/2014/06/02/a-startup-called-skymind-launches-pushing-open-source-deep-learning/|accessdate=2014-06-29}}</ref><ref name=\"vb\">{{cite web|first=Jordan|last=Novet|title=Skymind launches with open-source, plug-and-play deep learning features for your app|date=2014-06-02|url=https://venturebeat.com/2014/06/02/skymind-launches-with-open-source-plug-and-play-deep-learning-features-for-your-app//|accessdate=2014-06-29}}</ref>\n\nDeeplearning4j has been used in several commercial and academic applications. The code is hosted on [[GitHub]].<ref>[https://github.com/deeplearning4j/deeplearning4j Deeplearning4j source code]</ref> A support forum is maintained on [[Gitter]].<ref>[https://gitter.im/deeplearning4j/deeplearning4j Deeplearning4j Gitter Support Channel]</ref>\n\nThe framework is composable, meaning shallow neural nets such as restricted Boltzmann machines, convolutional nets, autoencoders, and recurrent nets can be added to one another to create deep nets of varying types. It also has extensive visualization tools,<ref>[http://deeplearning4j.org/visualization Deeplearning4j Visualization Tools]</ref> and a computation graph.<ref>[http://deeplearning4j.org/compgraph Deeplearning4j Computation Graph]</ref>\n\n==Distributed==\nTraining with Deeplearning4j occurs in a cluster. Neural nets are trained in parallel via iterative reduce, which works on [[Hadoop]]-YARN and on [[Apache Spark|Spark]].<ref name=\"deeplearning4j.org\"/><ref>{{cite web|url=https://github.com/emsixteeen/IterativeReduce|title=Iterative reduce}}</ref> Deeplearning4j also integrates with CUDA kernels to conduct pure GPU operations, and works with distributed GPUs.\n\n==Scientific computing for the JVM==\nDeeplearning4j includes an n-dimensional array class using [[ND4J (software)|ND4J]] that allows scientific computing in Java and Scala, similar to the functions that [[NumPy]] provides to [[Python (programming language)|Python]]. It's effectively based on a library for [[linear algebra]] and [[Matrix (mathematics)|matrix]] manipulation in a production environment.\n\n==DataVec vectorization library for machine-learning==\nDataVec vectorizes various file formats and data types using an [[input/output]] format system similar to Hadoop's use of MapReduce; that is, it turns various data types into columns of scalars termed [[Vector (mathematics and physics)|vectors]]. DataVec is designed to vectorize CSVs, images, sound, text, video, and time series.<ref>[http://deeplearning4j.org/datavec DataVec ETL for Machine Learning]</ref><ref>[https://www.infoq.com/articles/deep-learning-time-series-anomaly-detection Anomaly Detection for Time Series Data with Deep Learning]</ref>\n\n==Text and NLP==\nDeeplearning4j includes a [[vector space model]]ing and [[topic model]]ing toolkit, implemented in Java and integrating with parallel GPUs for performance. It is designed to handle large text sets.\n\nDeeplearning4j includes implementations of term frequency–inverse document frequency ([[tf–idf]]), [[deep learning]], and Mikolov's word2vec algorithm,<ref>[https://code.google.com/p/word2vec/ word2vec]</ref> doc2vec, and GloVe, reimplemented and optimized in Java. It relies on [[t-distributed stochastic neighbor embedding]] (t-SNE) for word-cloud visualizations.\n\n==Real-world use cases and integrations==\nReal-world use cases for Deeplearning4j include network intrusion detection and cybersecurity, fraud detection for the financial sector,<ref>http://www.skymind.io/finance/</ref><ref>https://skymind.ai/bsa-aml{{Dead link|date=September 2018 |bot=InternetArchiveBot |fix-attempted=yes }}</ref> anomaly detection in industries such as manufacturing, recommender systems in e-commerce and advertising,<ref>{{cite web |url=http://www.skymind.io/commerce/ |title=Archived copy |accessdate=2016-02-22 |deadurl=yes |archiveurl=https://web.archive.org/web/20160310082156/http://www.skymind.io/commerce/ |archivedate=2016-03-10 |df= }}</ref> and image recognition.<ref>https://skymind.ai/image{{Dead link|date=September 2018 |bot=InternetArchiveBot |fix-attempted=yes }}</ref> Deeplearning4j has integrated with other machine-learning platforms such as RapidMiner, Prediction.io,<ref>https://www.rapidminerchina.com/en/products/shop/product/deeplearning4j/{{Dead link|date=September 2018 |bot=InternetArchiveBot |fix-attempted=yes }}</ref> and [[Weka (machine learning)|Weka]].<ref>https://deeplearning.cms.waikato.ac.nz/</ref>\n\n==Machine Learning Model Server==\n\nDeeplearning4j serves machine-learning models for inference in production using the free developer edition of SKIL, the Skymind Intelligence Layer.<ref>{{Cite web |url=https://skymind.ai/products |title=Archived copy |access-date=2017-09-20 |archive-url=https://web.archive.org/web/20170921001159/https://skymind.ai/products |archive-date=2017-09-21 |dead-url=yes }}</ref><ref>{{Cite web |url=https://deeplearning4j.org/modelserver |title=Archived copy |access-date=2017-09-20 |archive-url=https://web.archive.org/web/20170921001516/https://deeplearning4j.org/modelserver |archive-date=2017-09-21 |dead-url=yes }}</ref> A model server serves the parametric machine-learning models that makes decisions about data. It is used for the inference stage of a machine-learning workflow, after data pipelines and model training. A model server is the tool that allows data science research to be deployed in a real-world production environment.\n\nWhat a Web server is to the Internet, a model server is to AI. Where a Web server receives an HTTP request and returns data about a Web site, a model server receives data, and returns a decision or prediction about that data: e.g. sent an image, a model server might return a label for that image, identifying faces or animals in photographs.\n\nThe SKIL model server is able to import models from Python frameworks such as Tensorflow, Keras, Theano and CNTK, overcoming a major barrier in deploying deep learning models.\n\n==Benchmarks==\nDeeplearning4j is as fast as Caffe for non-trivial image recognition tasks using multiple GPUs.<ref>https://github.com/deeplearning4j/dl4j-benchmark</ref> For programmers unfamiliar with HPC on the JVM, there are several parameters that must be adjusted to optimize neural network training time. These include setting the heap space, the garbage collection algorithm, employing off-heap memory and pre-saving data (pickling) for faster ETL.<ref>https://deeplearning4j.org/benchmark</ref> Together, these optimizations can lead to a 10x acceleration in performance with Deeplearning4j.\n\n==API Languages: Java, Scala, Python , Clojure & Kotlin==\nDeeplearning4j can be used via multiple API languages including Java, Scala, Python, Clojure and Kotlin. Its Scala API is called ScalNet.<ref>https://deeplearning4j.org/scala</ref>  Keras serves as its Python API.<ref>{{Cite web |url=https://deeplearning4j.org/keras# |title=Archived copy |access-date=2017-02-25 |archive-url=https://web.archive.org/web/20170225133010/https://deeplearning4j.org/keras# |archive-date=2017-02-25 |dead-url=yes |df= }}</ref>  And its Clojure wrapper is known as DL4CLJ.<ref>{{Cite web |url=https://deeplearning4j.org/clojure |title=Archived copy |access-date=2017-02-25 |archive-url=https://web.archive.org/web/20170225133007/https://deeplearning4j.org/clojure |archive-date=2017-02-25 |dead-url=yes }}</ref> The core languages performing the large-scale mathematical operations necessary for deep learning are C, C++ and CUDA C.\n\n==Tensorflow, Keras & Deeplearning4j==\n\nTensorflow, Keras and Deeplearning4j work together. Deeplearning4j can import models from Tensorflow and other Python frameworks if they have been created with Keras.<ref>{{Cite web |url=https://deeplearning4j.org/tensorflow |title=Archived copy |access-date=2017-09-07 |archive-url=https://web.archive.org/web/20170908021856/https://deeplearning4j.org/tensorflow |archive-date=2017-09-08 |dead-url=yes }}</ref>\n\n==See also==\n{{Portal|Free and open-source software|Java (programming language)}}\n* [[Comparison of deep learning software]]\n* [[Artificial intelligence]]\n* [[Machine learning]]\n* [[Deep learning]]\n\n==References==\n{{Reflist|30em}}\n\n==External links==\n* {{official website|www.deeplearning4j.org}}\n\n{{Computer vision footer}}\n{{Deep Learning Software}}\n\n[[Category:Applied machine learning]]\n[[Category:Artificial neural networks]]\n[[Category:Cluster computing]]\n[[Category:Data mining and machine learning software]]\n[[Category:Deep learning]]\n[[Category:Neural network software]]\n[[Category:Free data analysis software]]\n[[Category:Free science software]]\n[[Category:Free software programmed in Java (programming language)]]\n[[Category:Software programmed in Java (programming language)]]\n[[Category:Free software programmed in Scala]]\n[[Category:Free statistical software]]\n[[Category:Hadoop]]\n[[Category:Image processing]]\n[[Category:Information technology companies of the United States]]\n[[Category:Java (programming language) libraries]]\n[[Category:Java platform]]\n[[Category:Java programming language family]]\n[[Category:JVM programming languages]]\n[[Category:Machine learning]]\n[[Category:Natural language processing]]\n[[Category:Numerical programming languages]]\n[[Category:Open-source artificial intelligence]]\n[[Category:Scala (programming language)]]\n[[Category:Software using the Apache license]]\n[[Category:Technology companies based in the San Francisco Bay Area]]"
    },
    {
      "title": "Fortran",
      "url": "https://en.wikipedia.org/wiki/Fortran",
      "text": "{{short description|General-purpose programming language}}\n{{Use dmy dates|date=January 2012}}\n{{Infobox programming language\n| name = Fortran\n| logo = [[File:Fortran acs cover.jpeg|150px]]\n| logo caption = ''The Fortran Automatic Coding System for the [[IBM 704]]'' (15 October 1956), the first programmer's reference manual for Fortran\n| paradigm = [[Multi-paradigm programming language|multi-paradigm]]: [[Structured programming|structured]], [[Imperative programming|imperative]] ([[Procedural programming|procedural]], [[Object-oriented programming|object-oriented]]), [[Generic programming|generic]]\n| year = {{Start date and age|1957}}\n| designer = [[John Backus]]\n| developer = [[John Backus]] and [[IBM]]\n| latest release version = Fortran 2018 (ISO/IEC 1539-1:2018)\n| latest release date = {{Start date and age|2018|11|28}}\n| typing = [[Strong and weak typing|strong]], [[Type system|static]], [[Manifest typing|manifest]]\n| implementations = [[Absoft Fortran Compilers|Absoft]], [[Cray]], [[GNU Fortran|GFortran]], [[G95]], [[IBM]] XL Fortran, [[Intel Fortran Compiler|Intel]], [[Hitachi]], Lahey/Fujitsu, [[Numerical Algorithms Group]], [[Watcom C compiler|Open Watcom]], [[PathScale]], [[PGI compiler|PGI]], [[Silverfrost FTN95|Silverfrost]], [[Oracle Solaris Studio]], Visual Fortran, others\n| dialects = \n| influenced_by = [[Speedcoding]]\n| influenced = [[ALGOL 58]], [[BASIC]], [[C (programming language)|C]], [[Chapel (programming language)|Chapel]],<ref name=\"chplspec\">{{cite web|title=Chapel spec (Acknowledgements)|url=http://chapel.cray.com/spec/spec-0.98.pdf|date=2015-10-01|accessdate=2016-01-14|publisher=Cray Inc}}</ref> [[CMS-2 (programming language)|CMS-2]], [[Fortress (programming language)|Fortress]], [[PL/I]], [[PACT I]], [[MUMPS]], [[IDL_(programming_language)|IDL]], [[Ratfor]]\n| operating_system = \n| license = \n| file_ext = {{code|.f}}, {{code|.for}}, {{code|.f90}}\n| website = \n}}\n\n'''Fortran''' ({{IPAc-en|ˈ|f|ɔr|t|r|æ|n}}; formerly '''FORTRAN''', derived from ''Formula Translation''<ref>{{cite web\n | url = http://www.thefreedictionary.com/FORTRAN\n | title = FORTRAN\n | work = American Heritage Dictionary of the English Language\n | publisher = The Free Dictionary\n | edition = 5\n | year = 2011\n | accessdate = 2016-02-08\n }}</ref>) is a general-purpose, [[compiled language|compiled]]  [[imperative programming|imperative]] [[programming language]] that is especially suited to [[numerical analysis|numeric computation]] and [[computational science|scientific computing]].\n\nOriginally developed by [[IBM]]<ref name=\"Where\">{{cite web |url= http://www.softwarepreservation.org/projects/FORTRAN/paper/p25-backus.pdf |author=John Backus |title=The history of FORTRAN I, II and III |publisher= Softwarepreservation.org |accessdate=19 November 2014}}</ref> in the 1950s for scientific and engineering applications, FORTRAN came to dominate this area of programming early on and has been in continuous use for over six decades in computationally intensive areas such as [[numerical weather prediction]], [[finite element method|finite element analysis]], [[computational fluid dynamics]], [[computational physics]], [[crystallography]] and [[computational chemistry]]. It is a popular language for [[high-performance computing]]<ref name=\"hpc\">{{cite journal |url= http://queue.acm.org/detail.cfm?id=1820518 |author=Eugene Loh |title=The Ideal HPC Programming Language |journal=Queue |date=18 June 2010 |volume=8 |issue=6}}</ref> and is used for programs that benchmark and rank the world's [[TOP500|fastest supercomputers]].<ref>{{cite web|title = HPL – <!--ndash ok here as substitute for hyphen?--> A Portable Implementation of the High-Performance Linpack Benchmark for Distributed-Memory Computers | accessdate = 2015-02-21 | url = http://www.netlib.org/benchmark/hpl}}</ref>\n\nFortran encompasses a lineage of versions, each of which evolved to add extensions to the language while usually retaining compatibility with prior versions.  Successive versions have added support for [[structured programming]]\nand processing of character-based data (FORTRAN 77), [[array programming]], [[modular programming]] and [[generic programming]] (Fortran 90), [[High Performance Fortran|high performance Fortran]] (Fortran 95), [[object-oriented programming]] (Fortran 2003) and [[concurrent programming]] (Fortran 2008).\n\nFortran's design was the basis for many other programming languages. Among the better known is [[BASIC]], which is based on FORTRAN II with a number of syntax cleanups, notably better logical structures,<ref>{{cite magazine |url=http://time.com/69316/basic/ |magazine=Time |title=Fifty Years of BASIC |date=29 April 2014}}</ref> and other changes to more easily work in an interactive environment.<ref>{{cite web |url=https://www.gamasutra.com/view/news/216469/A_basic_history_of_BASIC_on_its_50th_birthday.php |title=A basic history of BASIC on its 50th birthday |website=Gamasutra |date=1 May 2014 |first=John |last=Szczepaniak}}</ref>\n\n== Naming ==\nThe names of earlier versions of the language through FORTRAN 77 were conventionally spelled in all-capitals (FORTRAN 77 was the last version in which the use of lowercase letters in keywords was strictly non-standard).  The capitalization has been dropped in referring to newer versions beginning with Fortran 90. The official language [[international standard|standards]] now refer to the language as \"Fortran\" rather than all-caps \"FORTRAN\".\n\n==History==\n[[File:IBM 704 mainframe.gif|right|thumb|320px|An [[IBM 704]] [[mainframe computer]]]]\nIn late 1953, [[John Backus|John W. Backus]] submitted a proposal to his superiors at [[IBM]] to develop a more practical alternative to [[assembly language]] for programming their [[IBM 704]] [[mainframe computer]].<ref name=\"history-fortran-i-ii-333\">{{cite journal|title=The History of Fortran I, II, and III|author=John Backus|authorlink=John Backus|journal=IEEE Annals of the History of Computing|volume=20|issue=4|pages=68–78|date=October-December 1998|doi=10.1109/85.728232}}</ref>{{rp|69}} Backus' historic FORTRAN team consisted of programmers Richard Goldberg, Sheldon F. Best, Harlan Herrick, Peter Sheridan, [[Roy Nutt]], Robert Nelson, Irving Ziller, [[Lois Haibt]], and [[David Sayre]].<ref name=\"Backus57\">{{cite conference|url=http://www.softwarepreservation.org/projects/FORTRAN/paper/BackusEtAl-FortranAutomaticCodingSystem-1957.pdf|title=The FORTRAN Automatic Coding System|conference=Western Joint Computer Conference|pages=188–198|date=February 1957|doi=10.1145/1455567.1455599|author1=J. W. Backus|authorlink1=John Backus|author2=R. J. Beeber|author3=S. Best|author4=R. Goldberg|author5=L. M. Haibt|authorlink5=Lois Haibt|author6=H. L. Herrick|author7=R. A. Nelson|author8=D. Sayre|authorlink8=David Sayre|author9=P. B. Sheridan|author10=H. Stern|author11=L. Ziller|author12=R. A. Hughes|author13=R. Nutt|authorlink13=Roy Nutt}}</ref>  Its concepts included easier entry of equations into a computer, an idea developed by [[J. Halcombe Laning]] and demonstrated in the [[Laning and Zierler system]] of 1952.<ref>Mindell, David, Digital Apollo, MIT Press, Cambridge MA, 2008, p.99</ref>\n\nA draft specification for ''The IBM Mathematical Formula Translating System'' was completed by November 1954.<ref name=\"history-fortran-i-ii-333\"/>{{rp|71}}  The first manual for FORTRAN appeared in October 1956,<ref name=\"history-fortran-i-ii-333\"/>{{rp|72}} with the first FORTRAN [[compiler]] delivered in April 1957.<ref name=\"history-fortran-i-ii-333\"/>{{rp|75}}  This was the first [[optimizing compiler]], because customers were reluctant to use a [[high-level programming language]] unless its compiler could generate code with performance comparable to that of hand-coded assembly language.<ref>[http://polaris.cs.uiuc.edu/publications/c1070.pdf The Fortran I Compiler] \"The Fortran I compiler was the first major project in code optimization. It tackled problems of crucial importance whose general solution was an important research focus in compiler technology for several decades. Many classical techniques for compiler analysis and optimization can trace their origins and inspiration to the Fortran I compiler.\"</ref>\n\nWhile the community was skeptical that this new method could possibly outperform hand-coding, it reduced the number of programming [[Statement (programming)|statements]] necessary to operate a machine by a factor of 20, and quickly gained acceptance.  John Backus said during a 1979 interview with ''Think'', the IBM employee magazine, \"Much of my work has come from being lazy. I didn't like writing programs, and so, when I was working on the [[IBM 701]], writing programs for computing missile trajectories, I started work on a programming system to make it easier to write programs.\"<ref>{{cite news|url=http://www.nbcnews.com/id/17704662/ns/technology_and_science-tech_and_gadgets/t/fortran-creator-john-backus-dies|title=Fortran creator John Backus dies|publisher=[[MSNBC]]|author=Brian Bergstein|date=May 20, 2007|accessdate=29 October 2018}}</ref>\n\nThe language was widely adopted by scientists for writing numerically intensive programs, which encouraged compiler writers to produce compilers that could generate faster and more efficient code.  The inclusion of a [[complex data type|complex number data type]] in the language made Fortran especially suited to technical applications such as electrical engineering.{{citation needed|date=June 2018}}\n\nBy 1960, versions of FORTRAN were available for the [[IBM 709]], [[IBM 650|650]], [[IBM 1620|1620]], and [[IBM 7090|7090]] computers.  Significantly, the increasing popularity of FORTRAN spurred competing computer manufacturers to provide FORTRAN compilers for their machines, so that by 1963 over 40 FORTRAN compilers existed.  For these reasons, FORTRAN is considered to be the first widely used [[Cross-platform_software|cross-platform]] programming language.\n\nThe development of Fortran paralleled the [[History of compiler writing|early evolution of compiler technology]], and many advances in the theory and design of [[compiler]]s were specifically motivated by the need to generate efficient code for Fortran programs.\n\n===FORTRAN===\nThe initial release of FORTRAN for the IBM 704 contained 32 [[Statement (programming)|statements]], including:\n\n* {{code|DIMENSION}} and {{code|EQUIVALENCE}} statements\n* Assignment statements\n* Three-way [[Arithmetic IF|''arithmetic'' {{code|IF}}]] statement, which passed control to one of three locations in the program depending on whether the result of the arithmetic statement was negative, zero, or positive\n* {{code|IF}} statements for checking exceptions ({{code|ACCUMULATOR OVERFLOW}}, {{code|QUOTIENT OVERFLOW}}, and {{code|DIVIDE CHECK}}); and {{code|IF}} statements for manipulating [[front panel|sense switches and sense lights]]\n* {{code|GO TO}}, computed {{code|GO TO}}, {{code|ASSIGN}}, and assigned {{code|GO TO}}\n* {{code|DO}} loops\n* Formatted I/O: {{code|FORMAT}}, {{code|READ}}, {{code|READ INPUT TAPE}}, {{code|WRITE}}, {{code|WRITE OUTPUT TAPE}}, {{code|PRINT}}, and {{code|PUNCH}}\n* Unformatted I/O: {{code|READ TAPE}}, {{code|READ DRUM}}, {{code|WRITE TAPE}}, and {{code|WRITE DRUM}}\n* Other I/O: {{code|END FILE}}, {{code|REWIND}}, and {{code|BACKSPACE}}\n* {{code|PAUSE}}, {{code|STOP}}, and {{code|CONTINUE}}\n* {{code|FREQUENCY}} statement (for providing [[optimization (computer science)|optimization]] hints to the compiler).\n\nThe arithmetic {{code|IF}} statement was reminiscent of (but not readily implementable by) a three-way comparison instruction (CAS{{snd}} Compare Accumulator with Storage) available on the 704. The statement provided the only way to compare numbers{{snd}} by testing their difference, with an attendant risk of overflow. This deficiency was later overcome by \"logical\" facilities introduced in FORTRAN IV.\n\nThe {{code|FREQUENCY}} statement was used originally (and optionally) to give branch probabilities for the three branch cases of the arithmetic IF statement. The first FORTRAN compiler used this weighting to perform ''at compile time'' a [[Monte Carlo method|Monte Carlo simulation]] of the generated code, the results of which were used to optimize the placement of basic blocks in memory{{snd}} a very sophisticated optimization for its time. The Monte Carlo technique is documented in Backus et al.'s paper on this original implementation, ''The FORTRAN Automatic Coding System'':\n\n<blockquote>\nThe fundamental unit of program is the [[basic block]]; a basic block is a stretch of program which has one entry point and one exit point. The purpose of section 4 is to prepare for section 5 a table of predecessors (PRED table) which enumerates the basic blocks and lists for every basic block each of the basic blocks which can be its immediate predecessor in flow, together with the absolute frequency of each such basic block link. This table is obtained by running the program once in Monte-Carlo fashion, in which the outcome of conditional transfers arising out of IF-type statements and computed GO TO's is determined by a random number generator suitably weighted according to whatever FREQUENCY statements have been provided.<ref name=\"Backus57\" /></blockquote>\n\nMany years later, the {{code|FREQUENCY}} statement had no effect on the code, and was treated as a comment statement, since the compilers no longer did this kind of compile-time simulation. A similar fate has befallen ''compiler hints'' in several other programming languages; for example [[C (programming language)|C]]'s {{code|register|lang=c}} keyword.{{citation needed|date=September 2013}}\n\nThe first FORTRAN compiler reported diagnostic information by halting the program when an error was found and outputting an error code on its console. That code could be looked up by the programmer in an error messages table in the operator's manual, providing them with a brief description of the problem.<ref>{{cite book|last1=Applied Science Division and Programming Research Department, International Business Machines Corporation|title=The FORTRAN Automatic Coding System for the IBM 704 EDPM : Programmer's Reference Manual|date=October 15, 1956|pages=19–20|url=http://archive.computerhistory.org/resources/text/Fortran/102649787.05.01.acc.pdf}}</ref><ref>{{cite book|last1=Programming Research Department, International Business Machines Corporation|title=The FORTRAN Automatic Coding System for the IBM 704 EDPM : Preliminary Operator's Manual|date=April 8, 1957|pages=6–37|url=http://www.softwarepreservation.org/projects/FORTRAN/manual/Prelim_Oper_Man-1957_04_07.pdf}}</ref> Later, an error handling subroutine to handle users error such as division by zero, developed by NASA<ref>{{cite web|author=Betty Jo Armstead|date=January 21, 2015|url=https://spaceodyssey.dmns.org/media/62497/myyearsatnasa-_bettyjoarmstead.pdf|title=My Years at NASA|website=Denver Museum of Nature & Science|access-date=June 15, 2019}}</ref> was incorporated, giving users feedback on which line of code the error appeared.\n\n==== Fixed layout and punched cards ====\n[[File:FortranCardPROJ039.agr.jpg|thumb|FORTRAN code on a [[punched card]], showing the specialized uses of columns 1–5, 6 and 73–80]]\n{{see|Computer programming in the punched card era}}\nBefore the development of disk files, text editors and terminals, programs were most often entered on a [[keypunch]] keyboard onto 80-column [[punched card]]s, one line to a card. The resulting deck of cards would be fed into a card reader to be compiled. Punched card codes included no lower-case letters or many special characters, and special versions of the IBM 026 [[keypunch]] were offered that would correctly print the re-purposed special characters used in FORTRAN.\n\nReflecting punched card input practice, Fortran programs were originally written in a fixed-column format, with the first 72 columns read into twelve 36-bit words.\n\nA letter \"C\" in column 1 caused the entire card to be treated as a comment and ignored by the compiler. Otherwise, the columns of the card were divided into four fields:\n* 1 to 5 were the label field: a sequence of digits here was taken as a label for use in DO or control statements such as GO TO and IF, or to identify a FORMAT statement referred to in a WRITE or READ statement. Leading zeros are ignored and 0 is not a valid label number. \n* 6 was a continuation field: a character other than a blank or a zero here caused the card to be taken as a continuation of the statement on the prior card. The continuation cards were usually numbered 1, 2, ''etc.'' and the starting card might therefore have zero in its continuation column – which is not a continuation of its preceding card. \n* 7 to 72 served as the statement field. \n* 73 to 80 were ignored (the IBM 704's [[IBM 711|card reader]] only used 72 columns).<ref>[http://www.mirrorservice.org/sites/www.bitsavers.org/pdf/ibm/7090/22-6528-4_7090Manual.pdf Reference Manual, IBM 7090 Data Processing System], 1961, IBM A22-6528-3.</ref>\n\nColumns 73 to 80 could therefore be used for identification information, such as punching a sequence number or text, which could be used to re-order cards if a stack of cards was dropped; though in practice this was reserved for stable, production programs. An [[IBM 519]] could be used to copy a program deck and add sequence numbers. Some early compilers, e.g., the IBM 650's, had additional restrictions due to limitations on their card readers.<ref>{{cite web |url= http://www.bitsavers.org/pdf/ibm/fortran/F28-8074-3_FORTRANII_GenInf.pdf |publisher=Bitsavers.org |title=Fortran II User Manual |accessdate=19 November 2014}}</ref> [[Keypunch]]es could be programmed to tab to column 7 and skip out after column 72. Later compilers relaxed most fixed-format restrictions, and the requirement was eliminated in the Fortran 90 standard.\n\nWithin the statement field, [[whitespace character]]s (blanks) were ignored outside a text literal. This allowed omitting spaces between tokens for brevity or including spaces within identifiers for clarity. For example, {{code|AVG OF X}} was a valid identifier, equivalent to {{code|AVGOFX}}, and <syntaxhighlight lang=\"fortran\" inline>101010DO101I=1,101</syntaxhighlight> was a valid statement, equivalent to \n<syntaxhighlight lang=\"fortranfixed\" inline>10101    DO 101   I = 1, 101</syntaxhighlight> because the zero in column 6 is treated as if it were a space (!), while <syntaxhighlight lang=\"fortran\" inline>101010DO101I=1.101</syntaxhighlight> was instead <syntaxhighlight lang=\"fortranfixed\" inline>10101    DO101I = 1.101</syntaxhighlight>, the assignment of 1.101 to a variable called <syntaxhighlight lang=\"fortran\" inline>DO101I</syntaxhighlight>. Note the slight visual difference between a comma and a period.\n\n[[Hollerith constant|Hollerith strings]], originally allowed only in FORMAT and DATA statements, were prefixed by a character count and the letter H (e.g., {{code|26HTHIS IS ALPHANUMERIC DATA.}}), allowing blanks to be retained within the character string. Miscounts were a problem.\n\n===FORTRAN II===\nIBM's ''FORTRAN II'' appeared in 1958.  The main enhancement was to support [[procedural programming]] by allowing user-written subroutines and functions which returned values, with parameters passed by [[Call by reference#Call by reference|reference]].  The COMMON statement provided a way for subroutines to access common (or [[global variable|global]]) variables. Six new statements were introduced:<ref>{{cite manual|url=http://bitsavers.org/pdf/ibm/704/C28-6000-2_704_FORTRANII.pdf|title=Reference Manual, FORTRAN II for the IBM 704 Data Processing System|year=1958|id=C28-6000-2}}</ref>\n\n* {{code|SUBROUTINE}}, {{code|FUNCTION}}, and {{code|END}}\n* {{code|CALL}} and {{code|RETURN}}\n* {{code|COMMON}}\n\nOver the next few years, FORTRAN II would also add support for the {{code|DOUBLE PRECISION}} and {{code|COMPLEX}} data types.\n\nEarly FORTRAN compilers supported no [[Recursion (computer science)|recursion]] in subroutines. Early computer architectures supported no concept of a stack, and when they did directly support subroutine calls, the return location was often stored in one fixed location adjacent to the subroutine code (e.g. the [[IBM 1130]]) or a specific machine register ([[IBM 360]] ''et seq''), which only allows recursion if a stack is maintained by software and the return address is stored on the stack before the call is made and restored after the call returns. Although not specified in FORTRAN 77, many F77 compilers supported recursion as an option, and the [[Burroughs large systems|Burroughs mainframes]], designed with recursion built-in, did so by default. It became a standard in Fortran 90 via the new keyword RECURSIVE.<ref>{{cite web |url= http://www.ibiblio.org/pub/languages/fortran/ch1-12.html |title=Ibibilio.org |publisher=Ibiblio.org |accessdate=15 September 2014}}</ref>\n\n====Simple FORTRAN II program====\nThis program, for [[Heron's formula]], reads data on a tape reel containing three 5-digit integers A, B, and C as input. There are no \"type\" declarations available: variables whose name starts with I, J, K, L, M, or N are \"fixed-point\" (i.e. integers), otherwise floating-point. Since integers are to be processed in this example, the names of the variables start with the letter \"I\". The name of a variable must start with a letter and can continue with both letters and digits, up to a limit of six characters in FORTRAN II.  If A, B, and C cannot represent the sides of a triangle in plane geometry, then the program's execution will end with an error code of \"STOP 1\".  Otherwise, an output line will be printed showing the input values for A, B, and C, followed by the computed AREA of the triangle as a floating-point number occupying ten spaces along the line of output and showing 2 digits after the decimal point, the .2 in F10.2 of the FORMAT statement with label 601.\n\n<syntaxhighlight lang=\"fortranfixed\">\nC AREA OF A TRIANGLE WITH A STANDARD SQUARE ROOT FUNCTION\nC INPUT - TAPE READER UNIT 5, INTEGER INPUT\nC OUTPUT - LINE PRINTER UNIT 6, REAL OUTPUT\nC INPUT ERROR DISPLAY ERROR OUTPUT CODE 1 IN JOB CONTROL LISTING\n      READ INPUT TAPE 5, 501, IA, IB, IC\n  501 FORMAT (3I5)\nC IA, IB, AND IC MAY NOT BE NEGATIVE OR ZERO\nC FURTHERMORE, THE SUM OF TWO SIDES OF A TRIANGLE\nC MUST BE GREATER THAN THE THIRD SIDE, SO WE CHECK FOR THAT, TOO\n      IF (IA) 777, 777, 701\n  701 IF (IB) 777, 777, 702\n  702 IF (IC) 777, 777, 703\n  703 IF (IA+IB-IC) 777, 777, 704\n  704 IF (IA+IC-IB) 777, 777, 705\n  705 IF (IB+IC-IA) 777, 777, 799\n  777 STOP 1\nC USING HERON'S FORMULA WE CALCULATE THE\nC AREA OF THE TRIANGLE\n  799 S = FLOATF (IA + IB + IC) / 2.0\n      AREA = SQRTF( S * (S - FLOATF(IA)) * (S - FLOATF(IB)) *\n     +     (S - FLOATF(IC)))\n      WRITE OUTPUT TAPE 6, 601, IA, IB, IC, AREA\n  601 FORMAT (4H A= ,I5,5H  B= ,I5,5H  C= ,I5,8H  AREA= ,F10.2,\n     +        13H SQUARE UNITS)\n      STOP\n      END\n</syntaxhighlight>\n\n===FORTRAN III===\n[[File:FortranCodingForm.png|thumb|right|300px|A FORTRAN coding form, printed on paper and intended to be used by programmers to prepare programs for punching onto cards by [[keypunch]] operators.  Now obsolete.]]\nIBM also developed a ''FORTRAN III'' in 1958 that allowed for inline assembly code among other features; however, this version was never released as a product.  Like the 704 FORTRAN and FORTRAN II, FORTRAN III included machine-dependent features that made code written in it unportable from machine to machine.<ref name=\"history-fortran-i-ii-333\"/>{{rp|76}}  Early versions of FORTRAN provided by other vendors suffered from the same disadvantage.\n\n===IBM 1401 FORTRAN===\nFORTRAN was provided for the [[IBM 1401]] computer by an innovative 63-phase compiler that ran entirely in its [[Magnetic core memory|core memory]] of only 8000 (six-bit) characters.  The compiler could be run from tape, or from a 2200-card deck; it used no further tape or disk storage.  It kept the program in memory and loaded [[Overlay (programming)|overlays]] that gradually transformed it, in place, into executable form, as described by Haines.<ref>{{cite journal\n| first = L. H.\n| last = Haines\n| title = Serial compilation and the 1401 FORTRAN compiler\n| journal = IBM Systems Journal\n| volume = 4\n| issue = 1\n| year = 1965\n| pages = 73–80\n| url = http://domino.research.IBM.com/tchjr/journalindex.nsf/495f80c9d0f539778525681e00724804/cde711e5ad6786e485256bfa00685a03?OpenDocument\n| doi = 10.1147/sj.41.0073\n}}</ref> \nThis article was reprinted, edited, in both editions of ''Anatomy of a Compiler'' <ref>{{cite book | first = John A. N. | last = Lee | title = Anatomy of a Compiler | publisher = Van Nostrand Reinhold | date = 1967}}</ref> and in the IBM manual \"Fortran Specifications and Operating Procedures, IBM 1401\".<ref>{{cite book|title=Fortran Specifications and Operating Procedures, IBM 1401|url=http://bitsavers.org/pdf/ibm/1401/C24-1455-2_Fortran_Specifications_and_Operating_Procedures_Apr65.pdf|publisher=IBM|id=C24-1455-2}}</ref>  The executable form was not entirely [[machine language]]; rather, floating-point arithmetic, sub-scripting, input/output, and function references were interpreted, preceding [[UCSD Pascal]] [[P-code machine#UCSD p-Machine|P-code]] by two decades.\n\nIBM later provided a FORTRAN IV compiler for the 1400 series of computers.<ref>{{cite book|title=Fortran IV Language Specifications, Program Specifications, and Operating Procedures, IBM 1401, 1440, and 1460|url=http://bitsavers.org/pdf/ibm/1401/C24-3322-2_Fortran_IV_Language_Specifications_IBM_1401_1440_1460_Apr66.pdf|date=April 1966|publisher=IBM|id=C24-3322-2}}</ref>\n\n===FORTRAN IV===\nStarting in 1961, as a result of customer demands, IBM began development of a ''FORTRAN IV'' that removed the machine-dependent features of FORTRAN II (such as {{code|READ INPUT TAPE}}), while adding new features such as a [[Boolean data type|{{code|LOGICAL}} data type]], logical [[Boolean expression]]s and the ''logical IF statement'' as an alternative to the ''arithmetic IF statement.''  FORTRAN IV was eventually released in 1962, first for the [[IBM 7030 Stretch|IBM 7030]] (\"Stretch\") computer, followed by versions for the [[IBM 7090]], [[IBM 7090|IBM 7094]], and later for the [[IBM 1401]] in 1966.\n\nBy 1965, FORTRAN IV was supposed to be compliant with the ''standard'' being developed by the [[American National Standards Institute|American Standards Association]] X3.4.3 FORTRAN Working Group.<ref name=\"McCracken\">{{cite book|last=McCracken|first=Daniel D.|title=A Guide to FORTRAN IV Programming|year=1965|publisher=Wiley|location=New York|isbn=978-0-471-58281-6|page=v|chapter=Preface}}</ref>\n\nBetween 1966 and 1968, IBM offered several FORTRAN IV compilers for its  [[IBM System/360|System/360]], each named by letters that indicated the minimum amount of memory the complier needed to run.\n<ref>{{cite web\n| url = http://www.fortran.bcs.org/2007/jubilee/implementations.php \n| title = List of FORTRAN Implementations 1957 - 1967\n| publisher = IEEE Annals\n| year = 2017\n| accessdate = 2017-10-17\n}}</ref>\nThe letters (F, G, H) matched the codes used with System/360 model numbers to indicate memory size, each letter increment being a factor of two larger:<ref>{{cite book|url=http://bitsavers.org/pdf/ibm/360/funcChar/A22-6898-1_360-50_funcChar_1967.pdf|title=IBM System/360 Model 50 Functional Characteristics|publisher=IBM|year=1967|id=A22-6898-1}}</ref>{{rp|p. 5}}\n* 1966 : FORTRAN IV F for DOS/360 (64K bytes)\n* 1966 : FORTRAN IV G for OS/360 (128K bytes)\n* 1968 : FORTRAN IV H for OS/360 (256K bytes)\n\nAt about this time FORTRAN IV had started to become an important educational tool and implementations such as the University of Waterloo's WATFOR and [[WATFIV]] were created to simplify the complex compile and link processes of earlier compilers.\n\n===FORTRAN 66===\nPerhaps the most significant development in the early history of FORTRAN was the decision by the ''American Standards Association'' (now [[American National Standards Institute]] (ANSI)) to form a committee sponsored by BEMA, the Business Equipment Manufacturers Association, to develop an ''American Standard Fortran''.  The resulting two standards, approved in March 1966, defined two languages, ''FORTRAN'' (based on FORTRAN IV, which had served as a de facto standard), and ''Basic FORTRAN'' (based on FORTRAN II, but stripped of its machine-dependent features).  The FORTRAN defined by the first standard, officially denoted X3.9-1966, became known as ''FORTRAN 66'' (although many continued to term it FORTRAN IV, the language on which the standard was largely based).  FORTRAN 66 effectively became the first industry-standard version of FORTRAN. FORTRAN 66 included:\n\n* Main program, {{code|SUBROUTINE}}, {{code|FUNCTION}}, and {{code|BLOCK DATA}} program units\n* {{code|INTEGER}}, {{code|REAL}}, {{code|DOUBLE PRECISION}}, {{code|COMPLEX}}, and {{code|LOGICAL}} [[data type]]s\n* {{code|COMMON}}, {{code|DIMENSION}}, and {{code|EQUIVALENCE}} statements\n* {{code|DATA}} statement for specifying initial values\n* [[Intrinsic function|Intrinsic]] and {{code|EXTERNAL}} (e.g., library) functions\n* Assignment statement\n* {{code|GO TO}}, computed {{code|GO TO}}, assigned {{code|GO TO}}, and {{code|ASSIGN}} statements\n* Logical {{code|IF}} and arithmetic (three-way) {{code|IF}} statements\n* {{code|DO}} loop statement\n* {{code|READ}}, {{code|WRITE}}, {{code|BACKSPACE}}, {{code|REWIND}}, and {{code|ENDFILE}} statements for sequential I/O\n* {{code|FORMAT}} statement and assigned format\n* {{code|CALL}}, {{code|RETURN}}, {{code|PAUSE}}, and {{code|STOP}} statements\n* [[Hollerith constant]]s in {{code|DATA}} and {{code|FORMAT}} statements, and as arguments to procedures\n* Identifiers of up to six characters in length\n* Comment lines\n* {{code|END}} line\n\n===FORTRAN 77===\n[[File:Ftn-elim-1240x1709.jpg|thumb|FORTRAN-77 program with compiler output, written on a\n[[Control Data Corporation|CDC]] [[CDC Cyber|175]] at [[RWTH Aachen University]], Germany, in 1987]]\n[[File:4.3 BSD UWisc VAX Emulation f77 Manual.png|thumb|[[4.3BSD|4.3 BSD]] for the [[Digital Equipment Corporation]] (DEC) [[VAX]], displaying the [[man page|manual]] for FORTRAN 77 (f77) compiler]]\nAfter the release of the FORTRAN 66 standard, compiler vendors introduced several extensions to ''Standard Fortran'', prompting ANSI committee X3J3 in 1969 to begin work on revising the 1966 standard, under sponsorship of [[CBEMA]], the Computer Business Equipment Manufacturers Association (formerly BEMA).  Final drafts of this revised standard circulated in 1977, leading to formal approval of the new FORTRAN standard in April 1978.  The new standard, called ''FORTRAN 77'' and officially denoted X3.9-1978, added a number of significant features to address many of the shortcomings of FORTRAN 66:\n\n* Block {{code|IF}} and {{code|END IF}} statements, with optional {{code|ELSE}} and {{code|ELSE IF}} clauses, to provide improved language support for [[structured programming]]\n* {{code|DO}} loop extensions, including parameter expressions, negative increments, and zero trip counts\n* {{code|OPEN}}, {{code|CLOSE}}, and {{code|INQUIRE}} statements for improved I/O capability\n* Direct-access file I/O\n* {{code|IMPLICIT}} statement, to override implicit conventions that undeclared variables are INTEGER if their name begins with I, J, K, L, M, or N (and REAL otherwise)\n* {{code|CHARACTER}} data type, replacing Hollerith strings with vastly expanded facilities for character input and output and processing of character-based data\n* {{code|PARAMETER}} statement for specifying constants\n* {{code|SAVE}} statement for persistent local variables\n* Generic names for intrinsic functions (e.g. {{code|SQRT}} also accepts arguments of other types, such as {{code|COMPLEX}} or {{code|REAL*16}}).\n* A set of intrinsics ({{code|LGE, LGT, LLE, LLT}}) for <U>lexical</U> comparison of strings, based upon the [[ASCII]] [[collating sequence]]. (These ASCII functions were demanded by the [[United States Department of Defense|U.S. Department of Defense]], in their conditional approval vote.{{Citation needed|date=October 2011}})\n\nIn this revision of the standard, a number of features were removed or altered in a manner that might invalidate formerly standard-conforming programs.\n''(Removal was the only allowable alternative to X3J3 at that time, since the concept of \"[[deprecation]]\" was not yet available for ANSI standards.)''\nWhile most of the 24 items in the conflict list (see Appendix A2 of X3.9-1978) addressed loopholes or pathological cases permitted by the prior standard but rarely used, a small number of specific capabilities were deliberately removed, such as:\n\n* [[Hollerith constant]]s and [[Herman Hollerith|Hollerith]] data, such as <syntaxhighlight lang=\"fortran\" inline>      GREET = 12HHELLO THERE!</syntaxhighlight>\n* Reading into an H edit (Hollerith field) descriptor in a FORMAT specification\n* Overindexing of array bounds by subscripts <syntaxhighlight lang=\"fortranfixed\">\n      DIMENSION A(10,5)\n      Y=  A(11,1)\n</syntaxhighlight>\n* Transfer of control out of and back into the range of a DO loop (also known as \"Extended Range\")\n\n====Variants: Minnesota FORTRAN====\n[[Control Data Corporation]] computers had another version of FORTRAN 77, called Minnesota FORTRAN (MNF), designed especially for student use, with variations in output constructs, special uses of COMMONs and DATA statements, optimizations code levels for compiling, and detailed error listings, extensive warning messages, and debugs.<ref>{{cite web|url=http://www.chilton-computing.org.uk/acd/literature/reports/p008.htm|title=FORTRAN Compilers and Loaders|publisher=Chilton-programming.org.uk|accessdate=19 November 2014}}</ref>\n\n===Transition to ANSI Standard Fortran===\nThe development of a revised standard to succeed FORTRAN 77 would be repeatedly delayed as the standardization process struggled to keep up with rapid changes in computing and programming practice.  In the meantime, as the \"Standard FORTRAN\" for nearly fifteen years, FORTRAN 77 would become the historically most important dialect.\n\nAn important practical extension to FORTRAN 77 was the release of MIL-STD-1753 in 1978.<ref>{{cite book\n  | last = Mil-std-1753\n  | title = DoD Supplement to X3.9-1978\n  | publisher = [[United States Government Printing Office]]\n  | url = http://www.fortran.com/fortran/mil_std_1753.html\n  }}</ref> This specification, developed by the [[United States Department of Defense|U.S. Department of Defense]], standardized a number of features implemented by most FORTRAN 77 compilers but not included in the ANSI FORTRAN 77 standard. These features would eventually be incorporated into the Fortran 90 standard.\n\n* {{code|DO WHILE}}, {{code|EXIT}}, {{code|CYCLE}},  and {{code|END DO}} statements\n* {{code|INCLUDE}} statement\n* {{code|IMPLICIT NONE}} variant of the {{code|IMPLICIT}} statement\n* [[Bit manipulation]] intrinsic functions, based on similar functions included in [[Industrial Real-Time Fortran|Industrial Real-Time Fortran (ANSI/ISA S61.1 (1976))]]\n\nThe [[Institute of Electrical and Electronics Engineers|IEEE]] 1003.9 [[POSIX]] Standard, released in 1991, provided a simple means for FORTRAN 77 programmers to issue POSIX system calls.<ref>{{cite book\n |title        = IEEE 1003.9-1992 - IEEE Standard for InformationTechnology - POSIX(R) FORTRAN 77 Language Interfaces - Part 1: Binding for System Application Program Interface (API)\n |url          = https://standards.ieee.org/standard/1003_9-1992.html\n |publisher    = [[IEEE]]\n |accessdate   = 24 November 2018\n}}</ref> Over 100 calls were defined in the document{{snd}} allowing access to POSIX-compatible process control, signal handling, file system control, device control, procedure pointing, and stream I/O in a portable manner.\n\n===Fortran 90===\nThe much-delayed successor to FORTRAN 77, informally known as ''Fortran 90'' (and prior to that, ''Fortran 8X''), was finally released as ISO/IEC standard 1539:1991 in 1991 and an ANSI Standard in 1992.  In addition to changing the official spelling from FORTRAN to Fortran, this major revision added many new features to reflect the significant changes in programming practice that had evolved since the 1978 standard:\n\n* [[free-form language|Free-form source input]], also with lowercase Fortran keywords\n* Identifiers up to 31 characters in length (In the previous standard, it was only six characters).\n* Inline comments\n* Ability to operate on arrays (or array sections) as a whole, thus greatly simplifying math and engineering computations.\n** whole, partial and masked array assignment statements and array expressions, such as <syntaxhighlight lang=fortran inline>X(1:N)=R(1:N)*COS(A(1:N))</syntaxhighlight>\n** {{code|WHERE}} statement for selective array assignment\n** array-valued constants and expressions,\n** user-defined array-valued functions and array constructors.\n* [[recursion (computer science)|{{code|RECURSIVE}}]] procedures\n* [[Modular programming|Modules]], to group related [[Subroutine|procedures]] and data together, and make them available to other program units, including the capability to limit the accessibility to only specific parts of the module.\n* A vastly improved argument-passing mechanism, allowing [[type signature|interfaces]] to be checked at compile time\n* User-written interfaces for generic procedures\n* [[Operator overloading]]\n* Derived (structured) data types\n* New data type declaration syntax, to specify the data type and other attributes of variables\n* [[Dynamic memory allocation]] by means of the {{code|ALLOCATABLE}} attribute and the {{code|ALLOCATE}} and {{code|DEALLOCATE}} statements\n* [[Pointer (computer programming)|{{code|POINTER}}]] attribute, pointer assignment, and {{code|NULLIFY}} statement to facilitate the creation and manipulation of dynamic [[data structure]]s\n* Structured looping constructs, with an {{code|END DO}} statement for loop termination, and {{code|EXIT}} and {{code|CYCLE}} statements for terminating normal {{code|DO}} loop iterations in an orderly way\n* {{code|SELECT}} . . . {{code|CASE}} construct for multi-way selection\n* Portable specification of numerical precision under the user's control\n* New and enhanced intrinsic procedures.\n\n====Obsolescence and deletions====\nUnlike the prior revision, Fortran 90 removed no features. ''(Appendix B.1 says, \"The list of deleted features in this standard is empty.\")'' Any standard-conforming FORTRAN 77 program is also standard-conforming under Fortran 90, and either standard should be usable to define its behavior.\n\nA small set of features were identified as \"obsolescent\" and expected to be removed in a future standard.  All of the functionalities of these early version features are performed by new Fortran 95 features.  Some are kept to simplify porting of old programs but may eventually be deleted.\n{| class=\"wikitable\"\n|-\n! Obsolescent feature\n! Example\n! Status/fate in Fortran 95\n|-\n| Arithmetic IF-statement\n| <syntaxhighlight lang=\"fortranfixed\">\n      IF (X) 10, 20, 30\n</syntaxhighlight>\n| Deprecated\n|-\n| Non-integer DO parameters or control variables\n| <syntaxhighlight lang=\"fortranfixed\">\n      DO 9 X= 1.7, 1.6, -0.1\n</syntaxhighlight>\n| Deleted\n|-\n| Shared DO-loop termination or <br />termination with a statement <br />other than END DO or CONTINUE &nbsp;\n| <syntaxhighlight lang=\"fortranfixed\">\n      DO 9 J= 1, 10\n          DO 9 K= 1, 10\n  9       L=  J + K\n</syntaxhighlight>\n| Deprecated\n|-\n| Branching to END IF <br />\nfrom outside a block\n| <syntaxhighlight lang=\"fortranfixed\">\n 66   GO TO 77 ; . . .\n      IF (E) THEN ;     . . .\n 77   END IF\n</syntaxhighlight>\n| Deleted\n|-\n| Alternate return\n| <syntaxhighlight lang=\"fortranfixed\">\n      CALL SUBR( X, Y, *100, *200 )\n</syntaxhighlight>\n| Deprecated\n|-\n|    PAUSE statement\n| <syntaxhighlight lang=\"fortranfixed\">\n      PAUSE 600\n</syntaxhighlight>\n| Deleted\n|-\n|    ASSIGN statement <br /> &nbsp; and assigned GO TO statement\n| <syntaxhighlight lang=\"fortranfixed\">\n 100   . . .\n      ASSIGN 100 TO H\n       . . .\n      GO TO H . . .\n</syntaxhighlight>\n| Deleted\n|-\n| Assigned statement numbers and FORMAT specifiers\n| <syntaxhighlight lang=\"fortranfixed\">\n      ASSIGN 606 TO F ... WRITE ( 6, F )...\n</syntaxhighlight>\n| Deleted\n|-\n| H edit descriptors\n| <syntaxhighlight lang=\"fortranfixed\">\n 606  FORMAT ( 9H1GOODBYE. )\n</syntaxhighlight>\n| Deleted\n|-\n| Computed GO TO statement\n| <syntaxhighlight lang=\"fortranfixed\">\n      GO TO (10, 20, 30, 40), index\n</syntaxhighlight>\n| (obsolete)\n|-\n| Statement functions\n| <syntaxhighlight lang=\"fortranfixed\">\n      FOIL( X, Y )=  X**2 + 2*X*Y + Y**2\n</syntaxhighlight>\n| (obsolete)\n|-\n| DATA statements <br /> &nbsp; among executable statements\n| <syntaxhighlight lang=\"fortranfixed\">\n      X= 27.3\n      DATA  A, B, C  / 5.0, 12.0, 13.0 /\n      . . .\n</syntaxhighlight>\n| (obsolete)\n|-\n| CHARACTER* form of CHARACTER declaration\n| <syntaxhighlight lang=\"fortranfixed\">\n      CHARACTER*8 STRING   ! Use CHARACTER(8)\n</syntaxhighlight>\n| (obsolete)\n|-\n| Assumed character length functions\n| <syntaxhighlight lang=\"fortranfixed\">\n      CHARACTER*(*) STRING\n</syntaxhighlight>\n| (obsolete)<ref name=\"assume\">{{cite web|title=Declaration Statements for Character Types|url=http://h30266.www3.hpe.com/odl/unix/progtool/cf95au56/lrm0085.htm|work=Compaq Fortran Language Reference Manual|publisher=Compaq Computer Corporation|location=Texas, Huston, US|year=1999|quote=The form CHARACTER*(*) is an obsolescent feature in Fortran 95.|accessdate=17 September 2018}}</ref>\n|-\n| Fixed form source code\n| Column 1 contains C or * or ! for comments.<br /> Columns 1 through 5 for statement numbers<br /> Any character in column 6 for continuation.<br /> Columns 73 and up ignored\n| (obsolete)\n|}\n\n====\"Hello world\" example====\n<syntaxhighlight lang=\"fortran\">\nprogram helloworld\n     print *, \"Hello world!\"\nend program helloworld \n</syntaxhighlight>\n\n===Fortran 95===\n{{Redirect|F95|the Düsseldorf-based football club|Fortuna Düsseldorf}}\n{{main|Fortran 95 language features}}\n''Fortran 95'', published officially as ISO/IEC 1539-1:1997, was a minor revision, mostly to resolve some outstanding issues from the Fortran 90 standard.  Nevertheless, Fortran 95 also added a number of extensions, notably from the [[High Performance Fortran]] specification:\n\n* {{code|FORALL}} and nested {{code|WHERE}} constructs to aid vectorization\n* User-defined {{code|PURE}} and {{code|ELEMENTAL}} procedures\n* Default initialization of derived type components, including pointer initialization\n* Expanded the ability to use initialization expressions for data objects\n* Initialization of pointers to {{code|NULL()}}\n* Clearly defined that {{code|ALLOCATABLE}} arrays are automatically deallocated when they go out of scope.\n\nA number of intrinsic functions were extended (for example a {{code|dim}} argument was added to the {{code|maxloc}} intrinsic).\n\nSeveral features noted in Fortran 90 to be \"obsolescent\" were removed from Fortran 95:\n\n* {{code|DO}} statements using {{code|REAL}} and {{code|DOUBLE PRECISION}} index variables\n* Branching to an {{code|END IF}} statement from outside its block\n* {{code|PAUSE}} statement\n* {{code|ASSIGN}} and assigned {{code|GO TO}} statement, and assigned format specifiers\n* {{code|H}} Hollerith edit descriptor.\n\nAn important supplement to Fortran 95 was the [[International Organization for Standardization|ISO technical report]] ''TR-15581: Enhanced Data Type Facilities'', informally known as the ''Allocatable TR.''  This specification defined enhanced use of {{code|ALLOCATABLE}} arrays, prior to the availability of fully Fortran 2003-compliant Fortran compilers.  Such uses include {{code|ALLOCATABLE}} arrays as derived type components, in procedure dummy argument lists, and as function return values.  ({{code|ALLOCATABLE}} arrays are preferable to {{code|POINTER}}-based arrays because {{code|ALLOCATABLE}} arrays are guaranteed by Fortran 95 to be deallocated automatically when they go out of scope, eliminating the possibility of [[memory leak]]age.  In addition, elements of allocatable arrays are contiguous, and [[aliasing (computing)|aliasing]] is not an issue for optimization of array references, allowing compilers to generate faster code than in the case of pointers.<ref>{{cite web|title=Fortran 95 Reference|url=https://gcc.gnu.org/onlinedocs/gcc-4.1.0/gfortran/|publisher=Gnu.Org|accessdate=10 May 2014}}</ref>)\n\nAnother important supplement to Fortran 95 was the [[International Organization for Standardization|ISO]] technical report ''TR-15580: Floating-point exception handling'', informally known as the ''IEEE TR.''  This specification defined support for [[IEEE 754-2008|IEEE floating-point arithmetic]] and [[floating point]] [[exception handling]].\n\n====Conditional compilation and varying length strings====\nIn addition to the mandatory \"Base language\"\n(defined in ISO/IEC 1539-1 : 1997),\nthe Fortran 95 language also includes two optional modules:\n* Varying length character strings (ISO/IEC 1539-2 : 2000)\n* Conditional compilation (ISO/IEC 1539-3 : 1998)\nwhich, together, compose the multi-part International Standard (ISO/IEC 1539).\n\nAccording to the standards developers, \"the optional parts describe self-contained features which have been requested by a substantial body of users and/or implementors, but which are not deemed to be of sufficient generality for them to be required in all standard-conforming Fortran compilers.\" Nevertheless, if a standard-conforming Fortran does provide such options, then they \"must be provided in accordance with the description of those facilities in the appropriate Part of the Standard\".\n\n===Fortran 2003===\n''Fortran 2003,'' officially published as ISO/IEC 1539-1:2004, is a major revision introducing many new features.<ref>{{cite web|title=Fortran 2003– Last Working Draft|url=http://www.j3-fortran.org/doc/year/04/04-007.txt|publisher=Gnu.Org|accessdate=10 May 2014}}</ref> A comprehensive summary of the new features of Fortran 2003 is available at the Fortran Working Group (ISO/IEC JTC1/SC22/WG5) official Web site.<ref>[http://www.nag.co.uk/sc22wg5/ Fortran Working Group (WG5)]. It may also be downloaded as a [https://wg5-fortran.org/N1551-N1600/N1579.pdf PDF file], FTP.nag.co.uk</ref>\n\nFrom that article, the major enhancements for this revision include:\n\n* Derived type enhancements: parameterized derived types, improved control of accessibility, improved structure constructors, and finalizers\n* [[Object-oriented programming]] support: [[inheritance (computer science)|type extension and inheritance]], [[Type polymorphism|polymorphism]], dynamic type allocation, and type-bound procedures, providing complete support for [[abstract data type]]s\n* Data manipulation enhancements: allocatable components (incorporating TR 15581), deferred type parameters, [[volatile variable|{{code|VOLATILE}} attribute]], explicit type specification in array constructors and allocate statements, pointer enhancements, extended initialization expressions, and enhanced intrinsic procedures\n* Input/output enhancements: [[Asynchronous I/O|asynchronous]] transfer, stream access, user specified transfer operations for derived types, user specified control of rounding during format conversions, named constants for preconnected units, the {{code|FLUSH}} statement, regularization of keywords, and access to error messages\n* [[Function pointer|Procedure pointers]]\n* Support for [[IEEE 754-2008|IEEE floating-point arithmetic]] and [[floating point]] [[exception handling]] (incorporating TR 15580)\n* Interoperability with the C programming language\n* Support for international usage: access to [[Universal Character Set|ISO 10646]] 4-byte characters and choice of decimal or comma in numeric formatted input/output\n* Enhanced integration with the host operating system: access to [[command-line interface|command line]] arguments, [[environment variable]]s, and processor error messages\n\nAn important supplement to Fortran 2003 was the [[International Organization for Standardization|ISO technical report]] ''TR-19767: Enhanced module facilities in Fortran.''  This report provided ''sub-modules,'' which make Fortran modules more similar to [[Modula-2]] modules.  They are similar to [[Ada (programming language)|Ada]] private child sub-units.  This allows the specification and implementation of a module to be expressed in separate program units, which improves packaging of large libraries, allows preservation of trade secrets while publishing definitive interfaces, and prevents compilation cascades.\n\n===Fortran 2008===\nISO/IEC 1539-1:2010, informally known as Fortran 2008, was approved in September 2010.<ref>{{cite web|title=N1836, Summary of Voting/Table of Replies on ISO/IEC FDIS 1539-1, Information technology – Programming languages – Fortran – Part 1: Base language|url=https://wg5-fortran.org/N1801-N1850/N1836.pdf}}</ref><ref>{{cite web|title=Fortran 2008 – Last Working Draft|url=http://www.j3-fortran.org/doc/year/10/10-007.pdf|publisher=Gnu.Org|accessdate=10 May 2014}}</ref>   As with Fortran 95, this is a minor upgrade, incorporating clarifications and corrections to Fortran 2003, as well as introducing a select few new capabilities.  The new capabilities include:\n\n* Sub-modules – additional structuring facilities for modules; supersedes ISO/IEC TR 19767:2005\n* [[Coarray Fortran]] – a parallel execution model\n* The [[Scalable parallelism|DO CONCURRENT]] construct – for loop iterations with no interdependencies\n* The CONTIGUOUS attribute – to specify storage layout restrictions\n* The [[Dynamic scoping|BLOCK construct]] – can contain declarations of objects with construct scope\n* [[Recursive data type|Recursive allocatable components]] – as an alternative to recursive pointers in derived types\n\nThe Final Draft international Standard (FDIS) is available as document N1830.<ref>N1830, Information technology – Programming languages – Fortran – Part 1: Base language [ftp://ftp.nag.co.uk/sc22wg5/N1801-N1850/N1830.pdf]{{dead link|date=January 2016}}</ref>\n\nAn important supplement to Fortran 2008 is the [[International Organization for Standardization|ISO]] Technical Specification (TS) 29113 on ''Further Interoperability of Fortran with C'',<ref>ISO page to [http://www.iso.org/iso/iso_catalogue/catalogue_tc/catalogue_detail.htm?csnumber=45136 ISO/IEC DTS 29113, Further Interoperability of Fortran with C]</ref><ref>{{cite web|url=https://wg5-fortran.org/N1901-N1950/N1917.pdf|title=Draft of the Technical Specification (TS) 29113|website=wg5-fortran.org}}</ref> which has been submitted to ISO in May 2012 for approval. The specification adds support for accessing the array descriptor from C and allows ignoring the type and rank of arguments.\n\n===Fortran 2018===\nThe latest revision of the language (Fortran 2018) was earlier referred to as Fortran 2015.<ref name=\"Fortran2018name\">{{cite web|url=https://software.intel.com/en-us/blogs/2017/11/20/doctor-fortran-in-eighteen-is-the-new-fifteen|title=Doctor Fortran in \"Eighteen is the new Fifteen\"|publisher=Software.intel.com|accessdate=20 November 2017}}</ref> It is a significant revision and was released on November 28, 2018.<ref name=\"F2018\">{{cite web|url=https://wg5-fortran.org/f2018.html|publisher=ISO|title=Fortran 2018|accessdate=30 November 2018}}</ref>\n\nFortran 2018 incorporates two previously published Technical Specifications:\n* ISO/IEC TS 29113:2012 Further Interoperability with C<ref name=\"TS29113\">{{cite web|url=https://wg5-fortran.org/N1901-N1950/N1942.pdf|title=Further Interoperability with C|publisher=ISO|accessdate=20 November 2017}}</ref>\n* ISO/IEC TS 18508:2015 Additional Parallel Features in Fortran<ref name=\"TS18508\">{{cite web|url=http://isotc.iso.org/livelink/livelink?func=ll&objId=17288706&objAction=Open|title=Additional Parallel Features in Fortran|publisher=ISO|accessdate=20 November 2017}}</ref>\n\nAdditional changes and new features include support for ISO/IEC/IEEE 60559:2011 (the latest version of the [[IEEE 754|IEEE floating point standard]] as of 2019), hexadecimal input/output, IMPLICIT NONE enhancements and other changes<ref name=\"F2015newfeat\">{{cite web|url=http://isotc.iso.org/livelink/livelink?func=ll&objId=19044944&objAction=Open|publisher=ISO|title=The New Features of Fortran 2015|accessdate=23 June 2017}}</ref><ref name=\"Fortran2015Closes\">{{cite web|url=https://software.intel.com/en-us/blogs/2015/09/04/doctor-fortran-in-one-door-closes|title=Doctor Fortran in \"One Door Closes\"|publisher=Software.intel.com|accessdate=21 September 2015}}</ref><ref name=\"Fortran2015\">{{cite web|url=http://software.intel.com/en-us/blogs/2013/08/08/doctor-fortran-goes-dutch-fortran-2015|title=Doctor Fortran Goes Dutch: Fortran 2015|publisher=Software.intel.com|accessdate=19 November 2014}}</ref><ref>[http://j3-fortran.org/doc/year/18/18-007r1.pdf Fortran 2018 Interpretation Document], 9 October 2018</ref>\n\n==Science and engineering==\nAlthough a 1968 journal article by the authors of [[BASIC]] already described FORTRAN as \"old-fashioned\",<ref name=\"dtss196810\">{{cite journal | url=http://dtss.dartmouth.edu/sciencearticle/index.html | title=Dartmouth Time-Sharing |author1=Kemeny, John G. |author2=Kurtz, Thomas E. | journal=Science | date=11 October 1968 | volume=162 | issue=3850 | pages=223–228| doi=10.1126/science.162.3850.223 }}</ref> Fortran has now been in use for several decades and there is a vast body of Fortran software in daily use throughout the scientific and engineering communities.<ref>{{cite web|last=Phillips|first=Lee|title=Scientific computing's future: Can any coding language top a 1950s behemoth?|url=https://arstechnica.com/science/2014/05/scientific-computings-future-can-any-coding-language-top-a-1950s-behemoth/|website=Ars Technica|accessdate=8 May 2014}}</ref> [[Jay Pasachoff]] wrote in 1984 that \"physics and astronomy students simply have to learn FORTRAN.  So much exists in FORTRAN that it seems unlikely that scientists will change to Pascal, Modula-2, or whatever.\"<ref name=\"pasachoff198404\">{{cite news | url=https://archive.org/stream/byte-magazine-1984-04/1984_04_BYTE_09-04_Real-World_Interfacing#page/n403/mode/2up | title=Scientists: FORTRAN vs. Modula-2 | work=BYTE | date=April 1984 | accessdate=6 February 2015 | author=Pasachoff, Jay M. | authorlink=Jay Pasachoff | pages=404 | type=letter}}</ref> In 1993, [[Cecil E. Leith]] called FORTRAN the \"mother tongue of scientific computing\", adding that its replacement by any other possible language \"may remain a forlorn hope\".<ref name=\"Galperin\">{{cite book|last=Galperin|first=Boris|title=Large Eddy Simulation of Complex Engineering and Geophysical Flows|year=1993|publisher=Cambridgey|location=London|isbn=978-0-521-43009-8|page=573|chapter=26}}</ref>\n\nIt is the primary language for some of the most intensive [[Supercomputer|super-computing]] tasks, such as in [[astronomy]], [[climate model]]ing, computational chemistry, [[computational economics]], [[computational fluid dynamics]], [[computational physics]], data analysis, [[hydrological modeling]], numerical linear algebra and numerical libraries ([[LAPACK]], [[IMSL Numerical Libraries|IMSL]] and [[NAG Numerical Library|NAG]]), [[optimization]], satellite simulation, [[structural engineering]], and [[numerical weather prediction|weather prediction]].{{Citation needed|date=April 2019}}  Many of the floating-point benchmarks to gauge the performance of new computer processors, such as [http://www.spec.org/cpu2006/CFP2006/ CFP2006], the floating-point component of the [[Standard Performance Evaluation Corporation|SPEC]] [http://www.spec.org/cpu2006/ CPU2006] benchmarks, are written in Fortran.\n\nApart from this, more modern codes in computational science generally use large program libraries, such as [[METIS]] for graph partitioning, [[PETSc]] or [[Trilinos]] for linear algebra capabilities, [[Dune (software)|DUNE]] or [[FEniCS Project|FEniCS]] for mesh and finite element support, and other generic libraries.  Since the late 1990s, almost all of the most widely used support libraries have been written in [[C (programming language)|C]] and, more often, [[C++]]. On the other hand, high-level languages such as [[Matlab]], [[Python (programming language)|Python]], or [[R (programming language)|R]] are becoming popular in particular areas of computational science. Consequently, a growing fraction of scientific programs are also written in these languages.  For this reason, [[foreign function interface|facilities for inter-operation with C]] were added to Fortran 2003 and enhanced by ISO/IEC technical specification 29113, which will be incorporated into Fortran 2018. This shift in the popularity of programming languages is also evident in the selection of applications between the [[SPECfp#Benchmarks 2|SPEC CPU 2000]] and [[SPECfp#Benchmarks|SPEC CPU 2006]] floating point benchmarks.{{citation needed|date=December 2017}}\n\nSoftware for NASA probes [[Voyager 1]] and [[Voyager 2]] was originally written in FORTRAN 5, and later ported to FORTRAN 77.  {{as of|2013|9|25}}, some of the software is still written in Fortran and some has been ported to C.<ref>{{Cite web| title = Interstellar 8-Track: How Voyager's Vintage Tech Keeps Running| work = WIRED| accessdate = 2017-12-23| url = https://www.wired.com/2013/09/vintage-voyager-probes/}}</ref>\n\n==Language features==\n{{expand section|date=January 2018}}\nThe precise characteristics and syntax of Fortran 95 are discussed in [[Fortran 95 language features]].\n\n==Portability==\n[[Portability (computer science)|Portability]] was a problem in the early days because there was no agreed upon standard{{snd}} not even IBM's reference manual{{snd}} and computer companies vied to differentiate their offerings from others by providing incompatible features.  Standards have improved portability.  The 1966 standard provided a reference [[Syntax (programming languages)|syntax]] and semantics, but vendors continued to provide incompatible extensions.  Although careful programmers were coming to realize that use of incompatible extensions caused expensive portability problems, and were therefore using programs such as ''The PFORT Verifier,''<ref>{{cite journal |title=Methods to ensure the standardization of FORTRAN software\n|quote=PFORT ... Library ...|osti=5361454\n}}</ref><ref name=\"PP4\">{{cite book |title=A portable mathematical subroutine library\n|volume=57\n|pages=165–177\n|author=P. A. Fox |date=1977\n|quote=PORT ... written in (PFORT) .. ANS Fortran|doi=10.1007/3-540-08446-0_42\n|chapter=Port — A portable mathematical subroutine library\n|series=Lecture Notes in Computer Science\n|isbn=978-3-540-08446-4\n}}</ref> it was not until after the 1977 standard, when the National Bureau of Standards (now [[National Institute of Standards and Technology|NIST]]) published ''FIPS PUB 69'', that processors purchased by the U.S. Government were required to diagnose extensions of the standard.  Rather than offer two processors, essentially every compiler eventually had at least an option to diagnose extensions.<ref>{{cite web  |website=[[IEEE]].org |date=1975 |title=A machine and configuration independent Fortran: Portable Fortran\n|url=https://ieeexplore.ieee.org/document/6312825\n|author=D. E. Whitten}}</ref><ref>{{cite web |title=Portability Issues\n|url=https://www.gnu.org/software/sather/docs-1.2/tutorial/fortran-portability.html\n|quote=.. discusses .. portability of .. Fortran}}</ref>\n\nIncompatible extensions were not the only portability problem.  For numerical calculations, it is important to take account of the characteristics of the arithmetic.  This was addressed by Fox et al. in the context of the 1966 standard by the ''PORT'' library.<ref name=PP4/>  The ideas therein became widely used, and were eventually incorporated into the 1990 standard by way of intrinsic inquiry functions.  The widespread (now almost universal) adoption of the [[IEEE 754-2008|IEEE 754]] standard for binary floating-point arithmetic has essentially removed this problem.\n\nAccess to the computing environment (e.g., the program's command line, environment variables, textual explanation of error conditions) remained a problem until it was addressed by the 2003 standard.\n\nLarge collections of library software that could be described as being loosely related to engineering and scientific calculations, such as graphics libraries, have been written in C, and therefore access to them presented a portability problem.  This has been addressed by incorporation of C interoperability into the 2003 standard.\n\nIt is now possible (and relatively easy) to write an entirely portable program in Fortran, even without recourse to a preprocessor.\n\n==Variants==\n\n===Fortran 5===\nFortran 5 was marketed by [[Data General]] Corp in the late 1970s and early 1980s, for the [[Data General Nova|Nova]], [[Data General Eclipse|Eclipse]], and [[Data General Eclipse MV/8000|MV]] line of computers.  It had an optimizing compiler that was quite good for minicomputers of its time.  The language most closely resembles FORTRAN 66.  The name is a [[pun]] on the earlier FORTRAN IV.\n\n===FORTRAN V===\nFORTRAN V was distributed by [[Control Data Corporation]] in 1968 for the [[CDC 6600]] series. The language was based upon FORTRAN IV.<ref name=\"FIV\">{{cite web|url=http://hopl.murdoch.edu.au/showlanguage.prx?exp=1092&language=CDC%20Fortran|title=Towards FORTRAN VI|last=Healy|first=MJR|year=1968|work=Advanced scientific Fortran by CDC|publisher=CDC|pages=169–172|accessdate=10 April 2009|archive-url=https://web.archive.org/web/20090705035806/http://hopl.murdoch.edu.au/showlanguage.prx?exp=1092&language=CDC%20Fortran|archive-date=5 July 2009|dead-url=yes|df=dmy-all}}</ref>\n\nUnivac also offered a compiler for the 1100 series known as FORTRAN V.  A spinoff of Univac Fortran V was Athena FORTRAN.\n\n===Fortran 6===\n'''Fortran 6''' or Visual Fortran 2001 was licensed to [[Compaq]] by [[Microsoft]]. They have licensed Compaq Visual Fortran and have provided the Visual Studio 5 environment interface for [[Visual Studio 97|Compaq v6]] up to v6.1.<ref>{{cite web |url=http://www.cs-software.com/software/fortran/compaq/cvf_relnotes.html#61ver_news |title=third party release notes for Fortran v6.1 |date=15 March 2011|publisher=Cs-software.com|accessdate=19 November 2014}}</ref>\n\n===Specific variants===\nVendors of high-performance scientific computers (''e.g.,'' [[Burroughs Corporation|Burroughs]], [[Control Data Corporation]] (CDC), [[Cray]], [[Honeywell]], [[IBM]], [[Texas Instruments]], and [[UNIVAC]]) added extensions to Fortran to take advantage of special hardware features such as [[CPU cache|instruction cache]], CPU [[pipeline (computing)|pipelines]], and vector arrays.  For example, one of IBM's FORTRAN compilers (''H Extended IUP'') had a level of optimization which reordered the [[machine code]] [[instruction (computer science)|instructions]] to keep multiple internal arithmetic units busy simultaneously.  Another example is ''CFD'', a special variant of FORTRAN designed specifically for the [[ILLIAC IV]] supercomputer, running at [[NASA]]'s [[NASA Ames Research Center|Ames Research Center]].\nIBM Research Labs also developed an extended FORTRAN-based language called ''VECTRAN'' for processing vectors and matrices.\n\n[[Object-Oriented Fortran]] was an object-oriented extension of Fortran, in which data items can be grouped into objects, which can be instantiated and executed in parallel.  It was available for Sun, Iris, [[Intel iPSC|iPSC]], and nCUBE, but is no longer supported.\n\nSuch machine-specific extensions have either disappeared over time or have had elements incorporated into the main standards. The major remaining extension is [[OpenMP]], which is a cross-platform extension for shared memory programming.  One new extension, Coarray Fortran, is intended to support parallel programming.\n\n====FOR TRANSIT for the IBM 650====\n''FOR TRANSIT'' was the name of a reduced version of the IBM 704 FORTRAN language,\nwhich was implemented for the IBM 650, using a translator program developed\nat Carnegie in the late 1950s.<ref>\"Internal Translator (IT) A Compiler for the IBM 650\",\nby A. J. Perlis, J. W. Smith, and H. R. Van Zoeren, Computation Center,\nCarnegie Institute of Technology\n</ref>\nThe following comment appears in the IBM Reference Manual (''FOR TRANSIT Automatic Coding System'' C28-4038, Copyright 1957, 1959 by IBM):\n<blockquote>The FORTRAN system was designed for a more complex machine than the 650, and consequently some of the 32 statements found in the FORTRAN Programmer's Reference Manual are not acceptable to the FOR TRANSIT system.  In addition, certain restrictions to the FORTRAN language have been added.  However, none of these restrictions make a source program written for FOR TRANSIT incompatible with the FORTRAN system for the 704.</blockquote>\n\nThe permissible statements were:\n\n* Arithmetic assignment statements, e.g., <code>a = b</code>\n* {{code|GO to n}}\n* <code>GO TO (n<sub>1</sub>, n<sub>2</sub>, ..., n<sub>m</sub>), i</code>\n* <code>IF (a) n<sub>1</sub>, n<sub>2</sub>, n<sub>3</sub></code>\n* {{code|PAUSE}}\n* {{code|STOP}}\n* <code>DO n i = m1, m2</code>\n* {{code|CONTINUE}}\n* {{code|END}}\n* {{code|READ n, list}}\n* {{code|PUNCH n, list}}\n* {{code|DIMENSION V, V, V, ...}}\n* {{code|EQUIVALENCE (a,b,c), (d,c), ...}}\n\nUp to ten subroutines could be used in one program.\n\nFOR TRANSIT statements were limited to columns 7 through 56, only.\nPunched cards were used for input and output on the IBM 650.  Three passes were required to translate source code to the \"IT\" language, then to compile the IT statements into SOAP assembly language, and finally to produce the object program, which could then be loaded into the machine to run the program (using punched cards for data input, and outputting results onto punched cards).\n\nTwo versions existed for the 650s with a 2000 word memory drum:  FOR TRANSIT I (S) and FOR TRANSIT II, the latter for machines equipped with indexing registers and automatic floating point decimal ([[Bi-quinary coded decimal|bi-quinary]]) arithmetic.  Appendix A of the manual included wiring diagrams for the [[IBM 533]] card reader/punch [[plugboard|control panel]].\n\n===Fortran-based languages===\nPrior to FORTRAN 77, a number of [[preprocessor]]s were commonly used to provide a friendlier language, with the advantage that the preprocessed code could be compiled on any machine with a standard FORTRAN compiler.  These preprocessors would typically support [[structured programming]], variable names longer than six characters, additional data types, [[conditional compilation]], and even [[Macro (computer science)|macro]] capabilities.  Popular preprocessors included [[FLECS]], [[iftran]], [[Mortran|MORTRAN]], [[SFtran]], [[S-Fortran]], [[Ratfor]], and [[Ratfiv]].  Ratfor and Ratfiv, for example, implemented a [[C (programming language)|C]]-like language, outputting preprocessed code in standard FORTRAN 66.  Despite advances in the Fortran language, preprocessors continue to be used for conditional compilation and macro substitution.\n\nOne of the earliest versions of FORTRAN, introduced in the '60s, was popularly used in colleges and universities.  Developed, supported, and distributed by the [[University of Waterloo]], [[WATFIV|WATFOR]] was based largely on FORTRAN IV.  A student using WATFOR could submit their batch FORTRAN job and, if there were no syntax errors, the program would move straight to execution.  This simplification allowed students to concentrate on their program's syntax and semantics, or execution logic flow, rather than dealing with submission [[Job Control Language]] (JCL), the compile/link-edit/execution successive process(es), or other complexities of the mainframe/minicomputer environment.  A down side to this simplified environment was that WATFOR was not a good choice for programmers needing the expanded abilities of their host processor(s), e.g., WATFOR typically had very limited access to I/O devices. WATFOR was succeeded by [[WATFIV]] and its later versions.\n\n{{sxhl|2=fortran|1=program; s=0 i=1,n;  s=s+1;  stop i;  s='s'  Stop}}  (line programming)\n\n[[LRLTRAN]] was developed at the [[Lawrence Radiation Laboratory]] to provide support for vector arithmetic and dynamic storage, among other extensions to support systems programming.  The distribution included the [[LTSS operating system]].\n\nThe Fortran-95 Standard includes an optional ''Part 3'' which defines an optional [[conditional compilation]] capability.  This capability is often referred to as \"CoCo\".\n\nMany Fortran compilers have integrated subsets of the [[C preprocessor]] into their systems.\n\n[[SIMSCRIPT]] is an application specific Fortran preprocessor for modeling and simulating large discrete systems.\n\nThe [[F (programming language)|F programming language]] was designed to be a clean subset of Fortran 95 that attempted to remove the redundant, unstructured, and deprecated features of Fortran, such as the {{code|EQUIVALENCE}} statement.  F retains the array features added in Fortran 90, and removes control statements that were made obsolete by structured programming constructs added to both FORTRAN 77 and Fortran 90.  F is described by its creators as \"a compiled, structured, array programming language especially well suited to education and scientific computing\".<ref>{{cite web | url=http://www.fortran.com/F/index.html | title= F Programming Language Homepage|publisher=Fortran.com|accessdate=19 November 2014}}</ref>\n\nLahey and Fujitsu teamed up to create Fortran for the Microsoft [[.NET Framework]].<ref>{{cite web | url=http://www.lahey.com/lf71/lfnet.htm | title=Fortran for .NET Language System | deadurl=yes | archiveurl=https://web.archive.org/web/20141018201259/http://www.lahey.com/lf71/lfnet.htm | archivedate=18 October 2014 | df=dmy-all }}</ref> Silverfrost FTN95 is also capable of creating .NET code.<ref>{{cite web | url=http://www.silverfrost.com/11/ftn95_overview.aspx | title=FTN95: Fortran 95 for Windows|publisher=Silverfrost.com|accessdate=19 November 2014}}</ref>\n\n==Code examples==\n{{details|Wikibooks:Fortran/Fortran examples}}\nThe following program illustrates dynamic memory allocation and array-based operations, two features introduced with Fortran 90.  Particularly noteworthy is the absence of {{code|DO}} loops and {{code|IF}}/{{code|THEN}} statements in manipulating the array; mathematical operations are applied to the array as a whole.  Also apparent is the use of descriptive variable names and general code formatting that conform with contemporary programming style.  This example computes an average over data entered interactively.\n\n<syntaxhighlight lang=\"fortran\">\nprogram average\n\n  ! Read in some numbers and take the average\n  ! As written, if there are no data points, an average of zero is returned\n  ! While this may not be desired behavior, it keeps this example simple\n\n  implicit none\n\n  real, dimension(:), allocatable :: points\n  integer                         :: number_of_points\n  real                            :: average_points=0., positive_average=0., negative_average=0.\n\n  write (*,*) \"Input number of points to average:\"\n  read  (*,*) number_of_points\n\n  allocate (points(number_of_points))\n\n  write (*,*) \"Enter the points to average:\"\n  read  (*,*) points\n\n  ! Take the average by summing points and dividing by number_of_points\n  if (number_of_points > 0) average_points = sum(points) / number_of_points\n\n  ! Now form average over positive and negative points only\n  if (count(points > 0.) > 0) then\n     positive_average = sum(points, points > 0.) / count(points > 0.)\n  end if\n\n  if (count(points < 0.) > 0) then\n     negative_average = sum(points, points < 0.) / count(points < 0.)\n  end if\n\n  deallocate (points)\n\n  ! Print result to terminal\n  write (*,'(a,g12.4)') 'Average = ', average_points\n  write (*,'(a,g12.4)') 'Average of positive points = ', positive_average\n  write (*,'(a,g12.4)') 'Average of negative points = ', negative_average\n\nend program average\n</syntaxhighlight>\n\n==Humor==\nDuring the same FORTRAN standards committee meeting at which the name \"FORTRAN 77\" was chosen, a satirical technical proposal was incorporated into the official distribution bearing the title \"Letter O [[considered harmful|Considered Harmful]]\".  This proposal purported to address the confusion that sometimes arises between the letter \"O\" and the numeral zero, by eliminating the letter from allowable variable names.  However, the method proposed was to eliminate the letter from the character set entirely (thereby retaining 48 as the number of lexical characters, which the colon had increased to 49).  This was considered beneficial in that it would promote structured programming, by making it impossible to use the notorious {{code|GO TO}} statement as before. (Troublesome {{code|FORMAT}} statements would also be eliminated.)  It was noted that this \"might invalidate some existing programs\" but that most of these \"probably were non-conforming, anyway\".<ref>X3J3 post-meeting distribution for meeting held at Brookhaven National Laboratory in November 1976.{{unreliable source?|date=August 2014}}</ref><ref>\"The obliteration of O\", Computer Weekly, 3 March 1977.</ref>\n\nWhen assumed-length arrays were being added, there was a dispute as to the appropriate character to separate upper and lower bounds. In a comment examining these arguments, Dr. Walt Brainerd penned an article entitled \"Astronomy vs. Gastroenterology\" because some proponents had suggested using the star or asterisk (\"*\"), while others favored the colon (\":\").{{Citation needed|date=July 2016}}\n\nIn FORTRAN 77 (and most earlier versions), variable names beginning with the letters I–N had a default type of integer, while variables starting with any other letters defaulted to real, although programmers could override the defaults with an explicit declaration.<ref>{{Cite web|url=http://docs.oracle.com/cd/E19957-01/805-4939/z40007365fbc/index.html|title=Rules for Data Typing (FORTRAN 77 Language Reference)|website=docs.oracle.com|access-date=2016-09-29}}</ref> This led to the joke: \"In Fortran, GOD is REAL (unless declared INTEGER).\"\n\n==See also==\n{{Portal|Computer programming}}\n* [[f2c]]\n* [[FORMAC (programming language)|FORMAC]]\n* [[List of compilers#Fortran compilers|List of Fortran compilers]]\n* [[List of numerical libraries#Fortran|List of Fortran numerical libraries]]\n* [[List of programming languages]]\n* [[Matrix representation]]\n* [[Row-major order]]\n\n==References==\n{{Reflist|30em}}\n\n==Further reading==\n;Articles\n* {{Cite journal|last=Allen|first=F.E.|date=September 1981|title=A History of Language Processor Technology in IBM|journal=IBM Journal of Research and Development|volume=25|issue=5|pages=535–548| doi = 10.1147/rd.255.0535 }}\n* {{cite conference|url=http://www.softwarepreservation.org/projects/FORTRAN/paper/BackusEtAl-FortranAutomaticCodingSystem-1957.pdf|title=The FORTRAN Automatic Coding System|conference=Western Joint Computer Conference|pages=188–198|date=February 1957|doi=10.1145/1455567.1455599|author1=J. W. Backus|authorlink1=John Backus|author2=R. J. Beeber|author3=S. Best|author4=R. Goldberg|author5=L. M. Haibt|authorlink5=Lois Haibt|author6=H. L. Herrick|author7=R. A. Nelson|author8=D. Sayre|authorlink8=David Sayre|author9=P. B. Sheridan|author10=H. Stern|author11=L. Ziller|author12=R. A. Hughes|author13=R. Nutt|authorlink13=Roy Nutt}}\n* {{Cite journal|last1=Chivers|first1=Ian D.|first2=Jane|last2=Sleightholme|year=2013|title=Compiler support for the Fortran 2003 & 2008 standards|journal=ACM SIGPLAN Fortran Forum|volume=28|issue=1|pages=26–28|issn=1061-7264|doi=10.1145/1520752.1520755|url=http://www.fortranplus.co.uk/fortran_info.html|archive-url=https://web.archive.org/web/20080516202558/http://www.fortranplus.co.uk/fortran_info.html|dead-url=yes|archive-date=2008-05-16}}\n* {{cite web|url=http://hopl.murdoch.edu.au/showlanguage.prx?exp=8&language=FORTRAN |title=FORTRAN – Backus et al high-level compiler (Computer Language) |last=Pigott |first=Diarmuid |year=2006 |work=The Encyclopedia of Computer Languages |publisher=[[Murdoch University]] |accessdate=5 May 2010 |deadurl=yes |archiveurl=https://web.archive.org/web/20091008230959/http://hopl.murdoch.edu.au/showlanguage.prx?exp=8&language=FORTRAN |archivedate=8 October 2009 |df=dmy }}\n* {{Cite journal|year=1985|title=Design Considerations for IBM Personal Computer Professional FORTRAN, an Optimizing Compiler|journal=IBM Systems Journal|volume=24|issue=1|pages=49–60|url=http://www.research.ibm.com/journal/sj/241/ibmsj2401G.pdf|last1=Roberts |first1=Mark L. |last2=Griffiths |first2=Peter D.|doi=10.1147/sj.241.0049}}\n\n;\"Core\" language standards\n* {{Cite book\n  | last = Ansi x3.9-1966\n  | title = USA Standard FORTRAN\n  | publisher = American National Standards Institute\n  | url = http://www.fh-jena.de/~kleine/history/languages/ansi-x3dot9-1966-Fortran66.pdf\n  }} Informally known as FORTRAN 66.\n* {{Cite book\n  | last = Ansi x3.9-1978\n  | title = American National Standard – Programming Language FORTRAN\n  | publisher = American National Standards Institute\n  | url = http://www.fortran.com/fortran/F77_std/rjcnf.html\n  }} Also known as [[International Organization for Standardization|ISO]] 1539–1980, informally known as FORTRAN 77.\n* {{Cite book\n  | last = ANSI X3.198-1992 (R1997) / ISO/IEC 1539:1991\n  | title = American National Standard – Programming Language Fortran Extended\n  | publisher = American National Standards Institute / ISO/IEC\n  | url = http://www.iso.org/iso/en/CatalogueDetailPage.CatalogueDetail?CSNUMBER=17366\n  | archive-url = https://web.archive.org/web/20020501111055/http://www.iso.org/iso/en/CatalogueDetailPage.CatalogueDetail?CSNUMBER=17366\n  | dead-url = yes\n  | archive-date = 1 May 2002\n  | df = dmy-all\n  }} Informally known as Fortran 90.\n* {{Cite book\n |last         = ISO/IEC 1539-1:1997\n |title        = Information technology – Programming languages – Fortran – Part 1: Base language\n |url          = http://j3-fortran.org/doc/standing/archive/007/97-007r2/pdf/97-007r2.pdf\n |access-date  = 13 December 2007\n |archive-url  = https://web.archive.org/web/20110818190618/http://j3-fortran.org/doc/standing/archive/007/97-007r2/pdf/97-007r2.pdf\n |archive-date = 18 August 2011\n |dead-url     = yes\n |df           = dmy-all\n}} Informally known as Fortran 95.  There are a further two parts to this standard.  Part 1 has been formally adopted by ANSI.\n* {{Cite book\n  | last = ISO/IEC 1539-1:2004\n  | title = Information technology – Programming languages – Fortran – Part 1: Base language\n  | url = http://www.dkuug.dk/jtc1/sc22/open/n3661.pdf\n  }} Informally known as Fortran 2003.\n* {{Cite book\n  | last = ISO/IEC 1539-1:2010 (Final Draft International Standard)\n  | title = Information technology – Programming languages – Fortran – Part 1: Base language\n  | url = ftp://ftp.nag.co.uk/sc22wg5/N1801-N1850/N1830.pdf\n  }}{{dead link|date=July 2017 |bot=InternetArchiveBot |fix-attempted=yes }} Informally known as Fortran 2008.\n\n;Related standards\n* {{Cite journal\n  | last = Kneis\n  | first = Wilfried\n  | title = Draft standard Industrial Real-Time FORTRAN\n  | journal = ACM SIGPLAN Notices\n  | issn = 0362-1340\n  |date=October 1981\n  | volume = 16\n  | issue = 7\n  | pages = 45–60\n  | doi = 10.1145/947864.947868\n  | title-link = Industrial Real-Time Fortran\n  }}\n* {{Cite book|title=ISO 8651-1:1988 Information processing systems – Computer graphics – Graphical Kernel System (GKS) language bindings – Part 1: FORTRAN|url=http://www.iso.org/iso/catalogue_detail?csnumber=16024|year=1988|publisher=[[International Organization for Standardization|ISO]]|location=Geneva, Switzerland}}\n\n;Other reference material\n* {{cite book |url=http://www.ecma-international.org/publications/files/ECMA-ST-WITHDRAWN/ECMA-9,%201st%20Edition,%20April%201965.pdf |title=ECMA Standard on FORTRAN |publisher=European Computer Manufacturers Association |date=April 1965 |accessdate=2014-11-17}}\n* {{cite book |url=http://wwwcdf.pd.infn.it/localdoc/f77_sun.pdf |title=FORTRAN 77 4.0 Reference Manual |publisher=Sun Microsystems, Inc. |year=1995 |accessdate=2014-11-17}}\n* {{cite web |url=http://www.atkielski.com/PDF/data/fortran.pdf |title=FORTRAN Coding Form |publisher=[[IBM]] |accessdate=2014-11-17 |deadurl=yes |archiveurl=https://web.archive.org/web/20150608095341/http://www.atkielski.com/PDF/data/fortran.pdf |archivedate=8 June 2015 |df=dmy-all }}\n* {{cite book |url=http://www.fh-jena.de/~kleine/history/languages/GC28-6515-10-FORTRAN-IV-Language.pdf |title=IBM System/360 and System/370 Fortran IV Language |publisher=[[International Business Machines]] |date=May 1974 |accessdate=2014-11-17}}\n* {{cite web |url=http://michaelgoerz.net/refcards/fortran_refcard_a4.pdf |title=Modern Fortran Reference Card |last=Goerz |first=Michael |date=2014 |accessdate=2014-12-14}}\n\n;Textbooks\n* {{Cite book\n  | first1 = Jeanne C.\n  | last1  = Adams\n  | first2 = Walter S.\n  | last2  = Brainerd\n  | first3 = Richard A.\n  | last3  = Hendrickson\n  | first4 = Richard E.\n  | last4  = Maine\n  | first5 = Jeanne T.\n  | last5  = Martin\n  | first6 =  Brian T.\n  | last6  = Smith\n\n  | year = 2009\n  | title = The Fortran 2003 Handbook\n  | edition = 1st\n  | publisher = [[Springer Science+Business Media|Springer]]\n  | isbn = 978-1-84628-378-9}}\n* {{Cite book\n  | first = Ed\n  | last = Akin\n  | year = 2003\n  | title = Object Oriented Programming via Fortran 90/95\n  | edition = 1st\n  | publisher = [[Cambridge University Press]]\n  | isbn = 978-0-521-52408-7}}\n* {{Cite book\n  | first = Stephen J.\n  | last = Chapman\n  | year = 2007\n  | title = Fortran 95/2003 for Scientists and Engineers\n  | edition = 3rd\n  | publisher = McGraw-Hill\n  | isbn = 978-0-07-319157-7}}\n* {{Cite book\n  | first1 = Ian\n  | last1 = Chivers\n  | first2 = Jane\n  | last2=Sleightholme\n  | year = 2015\n  | title = Introduction to Programming with Fortran\n  | edition = 3rd\n  | publisher = Springer\n  | isbn =  978-3-319-17700-7}}\n* {{Cite book\n  | first = D. M.\n  | last = Etter\n  | year = 1990\n  | title = Structured FORTRAN 77 for Engineers and Scientists\n  | edition = 3rd\n  | publisher = The Benjamin/Cummings Publishing Company, Inc.\n  | isbn = 978-0-8053-0051-2}}\n* {{Cite book\n  | first1 = T. M. R.\n  | last1 = Ellis\n  | first2 = Ivor R.\n  | last2 = Phillips\n  | first3=Thomas M.\n  | last3 = Lahey\n  | year = 1994\n  | title = Fortran 90 Programming\n  | edition = 1st\n  | publisher = Addison Wesley\n  | isbn = 978-0-201-54446-6}}\n* {{Cite book\n  | first = Michael\n  | last = Kupferschmid\n  | year = 2002\n  | title = Classical Fortran: Programming for Engineering and Scientific Applications\n  | publisher = Marcel Dekker (CRC Press)\n  | isbn = 978-0-8247-0802-3}}\n* {{Cite book\n  | first = Daniel D.\n  | last = McCracken\n  | year = 1961\n  | title = A Guide to FORTRAN Programming\n  | publisher = Wiley\n  | location = New York\n  | lccn = 61016618}}\n* {{Cite book\n  | first = Michael\n  | last = Metcalf\n  |author2=John Reid |author3=Malcolm Cohen\n   | year = 2011\n  | title = Modern Fortran Explained\n  | publisher = [[Oxford University Press]]\n  | isbn = 978-0-19-960142-4}}\n* {{Cite book\n  | first = Larry\n  | last = Nyhoff\n  |author2=Sanford Leestma\n  | year = 1995\n  | title = FORTRAN 77 for Engineers and Scientists with an Introduction to Fortran 90\n  | edition = 4th\n  | publisher = [[Prentice Hall]]\n  | isbn = 978-0-13-363003-9}}\n* {{Cite book|last=Page|first=Clive G.|title=Professional Programmer's Guide to Fortran77|url=http://www.star.le.ac.uk/~cgp/prof77.html|accessdate=4 May 2010|edition=7 June 2005|year=1988|publisher=Pitman|location=London|isbn=978-0-273-02856-7}}\n* {{Cite book|last=Press|first=William H.|title=Numerical Recipes in Fortran 90: The Art of Parallel Scientific Computing|url=http://www.nrbook.com/a/bookf90pdf.php|year=1996|publisher=Cambridge University Press|location=Cambridge, UK|isbn=978-0-521-57439-6}}\n* {{Cite book|last1=Sleighthome|first1=Jane|last2=Chivers|first2=Ian David|title=Interactive Fortran 77: A Hands-On Approach|url=http://www.fortranplus.co.uk/fortran_books.html|edition=2nd|series=Computers and their applications|year=1990|publisher=E. Horwood|location=Chichester|isbn=978-0-13-466764-5|access-date=12 March 2014|archive-url=https://web.archive.org/web/20140312213359/http://www.fortranplus.co.uk/fortran_books.html|archive-date=12 March 2014|dead-url=yes|df=dmy-all}}\n\n==External links==\n{{Wikibooks|Fortran}}\n{{Wikiquote|Fortran}}\n* [https://wg5-fortran.org/ ISO/IEC JTC1/SC22/WG5] – the official home of Fortran standards\n* [https://gcc.gnu.org/wiki/GFortranStandards Fortran Standards Documents] – GFortran standards\n* [http://www.softwarepreservation.org/projects/FORTRAN/ History of FORTRAN and Fortran II] – [[Computer History Museum]]\n* [https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/19700015982.pdf Valmer Norrod, et al:\"A self-study course in FORTRAN programing – Volume I – textbook\", Computer Science Corporation El Segundo, California, (April,1970). NASA(N70-25287).]\n* [https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/19700015983.pdf Valmer Norrod, Sheldom Blecher, and Martha Horton: \"A self-study course in FORTRAN programing – Volume II – workbook\", NASA CR-1478, Vol.II (April,1970), NASA(N70-25288).]\n{{IBM}}\n{{Programming languages}}\n\n{{Authority control}}\n\n[[Category:Fortran| ]]\n[[Category:Fortran programming language family| ]]\n[[Category:American inventions]]\n[[Category:Array programming languages]]\n[[Category:Computer standards]]\n[[Category:Numerical programming languages]]\n[[Category:Object-oriented programming languages]]\n[[Category:Procedural programming languages]]\n[[Category:High-level programming languages]]\n[[Category:Programming languages created in 1957]]\n[[Category:Programming languages with an ISO standard]]\n[[Category:Statically typed programming languages]]\n[[Category:Unix programming tools]]"
    },
    {
      "title": "Fortress (programming language)",
      "url": "https://en.wikipedia.org/wiki/Fortress_%28programming_language%29",
      "text": "{{External links|date=September 2016}}\n{{Infobox programming language\n| name = Fortress\n| logo = \n| paradigm = \n| year = 2006\n| designer = \n| developer = [[Sun Labs]]\n| discontinued = yes\n| latest_release_version = 1.0_5033\n| latest_release_date = {{Start date and age|2011|09|07}}\n| latest_test_version = \n| latest_test_date = \n| typing = [[Static typing|Static]]\n| implementations = \n| dialects = \n| influenced_by = [[Fortran]], [[Scala (programming language)|Scala]], [[Haskell (programming language)|Haskell]]\n| influenced = \n| operating_system = [[Cross-platform]]\n| platform = [[Java SE]] 1.6+\n| license = [[BSD licenses|BSD]]\n| website = {{URL|https://github.com/stokito/fortress-lang}}\n}}\n\n'''Fortress''' is a discontinued experimental [[programming language]] for [[high-performance computing]], created by [[Sun Microsystems]] with funding from [[DARPA]]'s [[High Productivity Computing Systems]] project. One of the language designers was [[Guy L. Steele Jr.]], whose previous work includes [[Scheme (programming language)|Scheme]], [[Common Lisp]], and [[Java (programming language)|Java]].\n\n== Design ==\nThe name \"Fortress\" was intended to connote a secure [[Fortran]], i.e., \"a language for high-performance computation that provides abstraction and type safety on par with modern programming language principles\".<ref name=\"spec\">{{cite web|url=http://research.sun.com/projects/plrg/Publications/fortress.1.0.pdf |title=Archived copy |accessdate=2010-04-23 |deadurl=yes |archiveurl=https://web.archive.org/web/20130120063452/http://labs.oracle.com/projects/plrg/Publications/fortress.1.0.pdf |archivedate=2013-01-20 |df= }}</ref> Language features included implicit [[parallel programming|parallelism]], [[Unicode]] support and concrete [[syntax]] similar to [[mathematical notation]]. The language was not designed to be similar to Fortran. Syntactically, it most resembles [[Scala (programming language)|Scala]], [[Standard ML]], and [[Haskell (programming language)|Haskell]]. Fortress was designed from the outset to have multiple syntactic stylesheets. Source code can be rendered as [[ASCII]] text, in [[Unicode]], or as a prettied image. This would allow for support of mathematical symbols and other symbols in the rendered output for easier reading. An [[emacs]]-based tool called ''fortify'' transforms ASCII-based Fortress source code into [[LaTeX]] output.<ref name=\"java.net\">{{cite web |url=https://java.net/downloads/projectfortress/reference.pdf |format=PDF |title=Project Fortress Reference Card |website=Java.net |accessdate=2016-09-24 |deadurl=yes |archiveurl=https://web.archive.org/web/20160304052722/https://java.net/downloads/projectfortress/reference.pdf |archivedate=2016-03-04 |df= }}</ref>\n\nFortress was also designed to be both highly parallel and have rich functionality contained within libraries, drawing from Java. For example, the <code>for</code> loop construct was a parallel operation, which would not necessarily iterate in a strictly linear manner, depending on the underlying implementation. However, the <code>for</code> construct was a library function and could be replaced by another version of the programmer's liking rather than being built into the language.\n\nFortress' designers made its syntax as close as possible to [[pseudocode]] and analyzed hundreds of [[computer science]] and [[mathematics]] papers, courses, books and journals using pseudocode to extract the common usage patterns of the English language and standard mathematical notation when used to represent [[algorithm]]s in pseudocode. Then they made the compiler trying to maintain a one-to-one correspondence between pseudocode and executable Fortress.<ref>{{cite web|url=https://stackoverflow.com/a/2302499 |title=pseudocode - Standards for pseudo code? |publisher=Stack Overflow |date=2009-10-16 |accessdate=2016-09-24}}</ref>{{better source|date=March 2014}}\n\n== History ==\nFortress was one of three languages created with funding from the [[High Productivity Computing Systems]] project; the others were [[X10 (programming language)|X10]] from IBM and [[Chapel (programming language)|Chapel]] from [[Cray|Cray, Inc]]. In November 2006, when DARPA approved funding for the third phase of the HPCS project, X10 and Chapel were funded, but Fortress was not,<ref>[https://blogs.oracle.com/simons/entry/sun_not_selected_for_hpcs \"Sun Not Selected for HPCS Phase III: My Thoughts\"] {{webarchive|url=https://web.archive.org/web/20120106124629/http://blogs.oracle.com/simons/entry/sun_not_selected_for_hpcs |date=2012-01-06 }}, Josh Simons, Sun Microsystems, November 22, 2006</ref> leading to uncertainty about the future of Fortress.\n\nIn January 2007, Fortress was transformed into \"an open-source project with an open-source community. People outside Sun can write Fortress code and test it using the open-source Fortress interpreter.\"<ref>[http://www.gbcacm.org/website/semInfo.php?id=1137]{{dead link|date=September 2016}}</ref>\nVersion 1.0 of the Fortress Language Specification was released in April 2008, along with a compliant implementation targeting the [[Java Virtual Machine]].\n\nIn July 2012, Steele announced that active development on Fortress would cease after a brief winding-down period, citing complications with using Fortress's type system on existing virtual machines.<ref name=\"over\">{{cite web |url=https://blogs.oracle.com/projectfortress/entry/fortress_wrapping_up |title=Fortress Wrapping Up (Project Fortress) |website=Blogs.oracle.com |date= |accessdate=2016-09-24 |deadurl=yes |archiveurl=https://web.archive.org/web/20160924201206/https://blogs.oracle.com/projectfortress/entry/fortress_wrapping_up |archivedate=2016-09-24 |df= }}</ref>\n\n== Example: Hello world! ==\n\nThis is the Fortress version of the archetypal [[hello world]] program, as presented in the ''Fortress Reference Card'':<ref name=\"java.net\"/>\n\n<pre>\ncomponent hello\nexport Executable\nrun() = println(“Hello, World!”)\nend\n</pre>\n\nThe ''export'' statement makes the program [[executable program|executable]] and every executable program in Fortress must implement the ''run()'' function. The file where the program is saved for compilation must have the same name as the one specified in the initial ''component'' statement. The ''println()'' function is what outputs the \"Hello, World!\" words on the screen.\n\n== See also ==\n{{Portal|Free and open-source software}}\n\n* [[Partitioned global address space]]\n* [[SISAL]]\n\n==References==\n{{Reflist}}\n\n==External links==\n* [https://web.archive.org/web/20110411185649/http://projectfortress.java.net/ Project Fortress website]\n* [https://web.archive.org/web/20110716163020/http://projectfortress.sun.com/Projects/Community/timeline Active Timeline of Specification and Reference Implementation]\n* [http://www.ccs.neu.edu/home/samth/fortress-spec.pdf The Fortress Language Specification (Latest version is 1.0, March 31, 2008)]\n* [https://web.archive.org/web/20090416193110/http://research.sun.com/minds/2005-0302/ The Soul of Fortress - Interview with Fortress developer Guy Steele]\n* [https://web.archive.org/web/20120830054925/http://java.net/projects/projectfortress/pages/Home Fortress Open Source Project Home (BSD License)]\n* [https://web.archive.org/web/20090430082513/http://research.sun.com/projects/plrg Sun's Programming Language Research Group]\n* [https://web.archive.org/web/20090430082513/http://research.sun.com/projects/plrg/Publications/ Fortress Publications and Specifications]\n* [https://code.google.com/p/fortress-development-tools/ Fortress Plugin For Eclipse (alpha)]\n* [https://web.archive.org/web/20090204043501/http://research.sun.com/projects/plrg/Fortress/faq.html Fortress FAQ]\n* [https://web.archive.org/web/20060819201513/http://research.sun.com/projects/plrg/PLDITutorialSlides9Jun2006.pdf Fortress Tutorial Slides]\n* [https://web.archive.org/web/20111108094602/http://java.net/projects/projectfortress/lists  Fortress Mailing Lists]\n* [http://lambda-the-ultimate.org/node/view/673 Lambda the Ultimate article]\n* [http://news.cnet.com/Suns-Fortran-replacement-goes-open-source/2100-7344_3-6150063.html?tag=st.prev Sun's Fortran replacement goes open-source] (CNET News.com, January 12, 2007)\n* [http://www.slideshare.net/alexmiller/project-fortress Fortress presentation]\n* [https://web.archive.org/web/20091019130642/http://blogs.sun.com/simons/entry/fortress_parallel_by_default Parallel By Default -- An Annotated Fortress Overview presentation]\n\n{{Sun Microsystems}}\n{{Numerical analysis software}}\n\n{{DEFAULTSORT:Fortress (Programming Language)}}\n[[Category:Array programming languages]]\n[[Category:Concurrent programming languages]]\n[[Category:Discontinued programming languages]]\n[[Category:Fortran programming language family]]\n[[Category:JVM programming languages]]\n[[Category:Numerical programming languages]]\n[[Category:Programming languages created in 2006]]\n[[Category:Software using the BSD license]]"
    }
  ]
}