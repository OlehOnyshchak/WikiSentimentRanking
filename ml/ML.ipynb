{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/sentiment-analysis-with-pyspark-bc8e83f80c35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/trom/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.embeddings import *\n",
    "import sparknlp\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression, LogisticRegressionModel\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.sql import SQLContext, Row\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "import pandas as pd  \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv = './train/training.1600000.processed.noemoticon.csv' #file at https://1drv.ms/u/s!AqlC23XtB27BisoM5u56CMPeNOBQKw\n",
    "# df = pd.read_csv(csv, header=None, encoding=\"ISO-8859-1\", usecols=[0,5], names=['target', 'text'])\n",
    "# df = df[['text', 'target']]\n",
    "\n",
    "# df.dropna(inplace=True)\n",
    "# df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "# df.loc[df.target == 0, 'target'] = -1\n",
    "# df.loc[df.target == 2, 'target'] = 0\n",
    "# df.loc[df.target == 4, 'target'] = 1\n",
    "\n",
    "# # df.to_csv('./train/clean_tweet.csv', index=False)\n",
    "\n",
    "# train_df, val_df = train_test_split(df, test_size=0.21)\n",
    "\n",
    "# train_df.to_csv('./train/clean_tweet_train.csv', index=False)\n",
    "# val_df.to_csv('./train/clean_tweet_val.csv', index=False)\n",
    "\n",
    "# train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://blog.sicara.com/get-started-pyspark-jupyter-guide-tutorial-ae2fe84f594f\n",
    "spark = sparknlp.start()\n",
    "sc = spark.sparkContext\n",
    "sqlCtx = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = sqlCtx.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('./train/clean_tweet_train.csv')\n",
    "val_set = sqlCtx.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('./train/clean_tweet_val.csv')\n",
    "\n",
    "train_set = train_set.dropna()\n",
    "val_set = val_set.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, CountVectorizer\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+--------------------+--------------------+--------------------+-----+\n",
      "|                text|target|               words|                  tf|            features|label|\n",
      "+--------------------+------+--------------------+--------------------+--------------------+-----+\n",
      "|Tired, and I feel...|    -1|[tired,, and, i, ...|(65536,[14,2647,8...|(65536,[14,2647,8...|  0.0|\n",
      "|@PunkyStyle I wil...|     1|[@punkystyle, i, ...|(65536,[19387,238...|(65536,[19387,238...|  1.0|\n",
      "|@marzwah @groundv...|    -1|[@marzwah, @groun...|(65536,[9265,1222...|(65536,[9265,1222...|  0.0|\n",
      "|kind of sort of a...|    -1|[kind, of, sort, ...|(65536,[1431,6052...|(65536,[1431,6052...|  0.0|\n",
      "|Updated the banne...|    -1|[updated, the, ba...|(65536,[8436,1056...|(65536,[8436,1056...|  0.0|\n",
      "+--------------------+------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "hashtf = HashingTF(numFeatures=2**16, inputCol=\"words\", outputCol='tf')\n",
    "idf = IDF(inputCol='tf', outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\n",
    "label_stringIdx = StringIndexer(inputCol = \"target\", outputCol = \"label\")\n",
    "pipeline = Pipeline(stages=[tokenizer, hashtf, idf, label_stringIdx])\n",
    "\n",
    "pipelineFit = pipeline.fit(train_set)\n",
    "train_df = pipelineFit.transform(train_set)\n",
    "val_df = pipelineFit.transform(val_set)\n",
    "train_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(maxIter=100)\n",
    "lrModel = lr.fit(train_df)\n",
    "predictions = lrModel.transform(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8494658040471438"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrModel.save('./train/lr.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "sameModel = LogisticRegressionModel.load(\"./train/lr.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_text(text):\n",
    "    df = spark.createDataFrame([(text, 2)], ['text', 'target'])\n",
    "    df_transformed = pipelineFit.transform(df) # To fix\n",
    "    predictions = lrModel.transform(df_transformed)\n",
    "    predictions = predictions.select(['text', 'probability', 'prediction'])\n",
    "    print(predictions.toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   text                                probability  prediction\n",
      "0  good  [0.23836792493263662, 0.7616320750673634]         1.0\n"
     ]
    }
   ],
   "source": [
    "score_text(\"good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  text                               probability  prediction\n",
      "0  bad  [0.7248553830736533, 0.2751446169263467]         0.0\n"
     ]
    }
   ],
   "source": [
    "score_text(\"bad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       text                                probability  prediction\n",
      "0  good bad  [0.5240550953790853, 0.47594490462091465]         0.0\n"
     ]
    }
   ],
   "source": [
    "score_text(\"good bad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            text                               probability  prediction\n",
      "0  good bad good  [0.3151640808375155, 0.6848359191624844]         1.0\n"
     ]
    }
   ],
   "source": [
    "score_text(\"good bad good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
