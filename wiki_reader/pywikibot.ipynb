{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage of python script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dumped 100 pages\n",
      "Dumped 200 pages\n",
      "Dumped 300 pages\n",
      "Dumped 400 pages\n",
      "Dumped 500 pages\n",
      "Dumped 600 pages\n",
      "Dumped 700 pages\n",
      "Dumped 800 pages\n",
      "Dumped 900 pages\n",
      "Dumped 1000 pages\n",
      "Wall time: 32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import reader\n",
    "\n",
    "reader.query('Mathematics', limit=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation (Debug purposes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pywikibot\n",
    "from pywikibot import pagegenerators\n",
    "import json\n",
    "import mwparserfromhell as mwp\n",
    "\n",
    "def _clean(wiki_text):\n",
    "    wikicode = mwp.parse(wiki_text)\n",
    "    return wikicode.strip_code()\n",
    "\n",
    "def _dump(path, data):\n",
    "    with open(path, 'w', encoding='utf8') as outfile:  \n",
    "        json.dump(data, outfile, indent=2, ensure_ascii=False)\n",
    "\n",
    "def query(request, batch_size=100):\n",
    "    requests_base = Path('../requests')\n",
    "    requests_path = requests_base / request\n",
    " \n",
    "    if requests_path.exists():\n",
    "        return\n",
    "\n",
    "    requests_path.mkdir(parents=True)\n",
    "    \n",
    "    site = pywikibot.Site()\n",
    "    category = pywikibot.Category(site, request)\n",
    "    pages = category.articles(namespaces=[0], #type of entities to query, 0 = page\n",
    "                              recurse=True, # also query all subpages\n",
    "                              content = True) # preloaod pages\n",
    "    \n",
    "    count = 0\n",
    "    pages_key = 'pages'\n",
    "    data = { pages_key: [] }\n",
    "    for p in pages:\n",
    "        count += 1\n",
    "        data[pages_key].append({\n",
    "            'title': p.title(),\n",
    "            'url': p.full_url(),\n",
    "            'text': _clean(p.text),\n",
    "        })\n",
    "        \n",
    "        if count % batch_size == 0:\n",
    "            _dump(requests_path / (str(count) + '.json'), data)\n",
    "            data = { pages_key: [] }\n",
    "            print('Dumped {} pages'.format(count))\n",
    "            \n",
    "        if count == 1000:\n",
    "            break\n",
    "            \n",
    "    if len(data[pages_key]):\n",
    "        _dump(requests_path / (str(count) + '.json'), data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
